Command: bash evaluate_polyformer_b_aihub_manufact.sh
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launch.py:188: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  FutureWarning,
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2024-11-21 07:04:33 | INFO | bert.file_utils | PyTorch version 1.13.1+cu117 available.
2024-11-21 07:04:33 | INFO | bert.file_utils | PyTorch version 1.13.1+cu117 available.
2024-11-21 07:04:33 | INFO | bert.file_utils | PyTorch version 1.13.1+cu117 available.
2024-11-21 07:04:33 | INFO | bert.file_utils | PyTorch version 1.13.1+cu117 available.
2024-11-21 07:04:33 | INFO | bert.file_utils | PyTorch version 1.13.1+cu117 available.
2024-11-21 07:04:33 | INFO | bert.file_utils | PyTorch version 1.13.1+cu117 available.
2024-11-21 07:04:33 | INFO | bert.file_utils | PyTorch version 1.13.1+cu117 available.
2024-11-21 07:04:33 | INFO | bert.file_utils | PyTorch version 1.13.1+cu117 available.
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | distributed init (rank 1): env://
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | Start init
2024-11-21 07:04:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | distributed init (rank 4): env://
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | Start init
2024-11-21 07:04:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | distributed init (rank 0): env://
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | Start init
2024-11-21 07:04:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | distributed init (rank 3): env://
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | Start init
2024-11-21 07:04:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | distributed init (rank 2): env://
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | Start init
2024-11-21 07:04:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | distributed init (rank 6): env://
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | Start init
2024-11-21 07:04:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | distributed init (rank 7): env://
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | Start init
2024-11-21 07:04:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | distributed init (rank 5): env://
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | Start init
2024-11-21 07:04:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2024-11-21 07:04:35 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | initialized host ailab-server-bengio as rank 5
single-machine distributed training is initialized.
2024-11-21 07:04:35 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | initialized host ailab-server-bengio as rank 6
single-machine distributed training is initialized.
2024-11-21 07:04:35 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-21 07:04:35 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-21 07:04:35 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | initialized host ailab-server-bengio as rank 4
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | initialized host ailab-server-bengio as rank 0
single-machine distributed training is initialized.
single-machine distributed training is initialized.
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | initialized host ailab-server-bengio as rank 1
single-machine distributed training is initialized.
2024-11-21 07:04:35 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | initialized host ailab-server-bengio as rank 7
single-machine distributed training is initialized.
2024-11-21 07:04:35 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-21 07:04:35 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | initialized host ailab-server-bengio as rank 3
single-machine distributed training is initialized.
2024-11-21 07:04:35 | INFO | fairseq.distributed.utils | initialized host ailab-server-bengio as rank 2
single-machine distributed training is initialized.
2024-11-21 07:04:37 | INFO | ofa.evaluate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../polyformer_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '../finetune/polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{"data":"../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv","bpe_dir":"../../utils/BPE","selected_cols":"0,5,6,2,4,3"}', 'results_path': '../../results_polyformer_b/aihub_indoor_test_1120/'}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 4, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 4, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'aihub_indoor_test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 3, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'refcoco', 'data': '../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv', 'selected_cols': None, 'bpe_dir': None, 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'num_bins': 64, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': False, 'eval_args': '{}', 'uses_ema': False, 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2024-11-21 07:04:37 | INFO | ofa.evaluate | loading model(s) from ../finetune/polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
2024-11-21 07:04:37 | INFO | ofa.evaluate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../polyformer_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '../finetune/polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{"data":"../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv","bpe_dir":"../../utils/BPE","selected_cols":"0,5,6,2,4,3"}', 'results_path': '../../results_polyformer_b/aihub_indoor_test_1120/'}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'aihub_indoor_test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 3, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'refcoco', 'data': '../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv', 'selected_cols': None, 'bpe_dir': None, 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'num_bins': 64, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': False, 'eval_args': '{}', 'uses_ema': False, 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2024-11-21 07:04:37 | INFO | ofa.evaluate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../polyformer_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '../finetune/polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{"data":"../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv","bpe_dir":"../../utils/BPE","selected_cols":"0,5,6,2,4,3"}', 'results_path': '../../results_polyformer_b/aihub_indoor_test_1120/'}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 5, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 5, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'aihub_indoor_test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 3, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'refcoco', 'data': '../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv', 'selected_cols': None, 'bpe_dir': None, 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'num_bins': 64, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': False, 'eval_args': '{}', 'uses_ema': False, 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2024-11-21 07:04:37 | INFO | ofa.evaluate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../polyformer_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '../finetune/polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{"data":"../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv","bpe_dir":"../../utils/BPE","selected_cols":"0,5,6,2,4,3"}', 'results_path': '../../results_polyformer_b/aihub_indoor_test_1120/'}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 6, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 6, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'aihub_indoor_test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 3, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'refcoco', 'data': '../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv', 'selected_cols': None, 'bpe_dir': None, 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'num_bins': 64, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': False, 'eval_args': '{}', 'uses_ema': False, 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2024-11-21 07:04:37 | INFO | ofa.evaluate | loading model(s) from ../finetune/polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
2024-11-21 07:04:37 | INFO | ofa.evaluate | loading model(s) from ../finetune/polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
2024-11-21 07:04:37 | INFO | ofa.evaluate | loading model(s) from ../finetune/polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
2024-11-21 07:04:37 | INFO | ofa.evaluate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../polyformer_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '../finetune/polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{"data":"../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv","bpe_dir":"../../utils/BPE","selected_cols":"0,5,6,2,4,3"}', 'results_path': '../../results_polyformer_b/aihub_indoor_test_1120/'}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 2, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 2, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'aihub_indoor_test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 3, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'refcoco', 'data': '../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv', 'selected_cols': None, 'bpe_dir': None, 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'num_bins': 64, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': False, 'eval_args': '{}', 'uses_ema': False, 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2024-11-21 07:04:37 | INFO | ofa.evaluate | loading model(s) from ../finetune/polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
2024-11-21 07:04:37 | INFO | ofa.evaluate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../polyformer_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '../finetune/polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{"data":"../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv","bpe_dir":"../../utils/BPE","selected_cols":"0,5,6,2,4,3"}', 'results_path': '../../results_polyformer_b/aihub_indoor_test_1120/'}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 1, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 1, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'aihub_indoor_test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 3, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'refcoco', 'data': '../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv', 'selected_cols': None, 'bpe_dir': None, 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'num_bins': 64, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': False, 'eval_args': '{}', 'uses_ema': False, 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2024-11-21 07:04:37 | INFO | ofa.evaluate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../polyformer_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '../finetune/polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{"data":"../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv","bpe_dir":"../../utils/BPE","selected_cols":"0,5,6,2,4,3"}', 'results_path': '../../results_polyformer_b/aihub_indoor_test_1120/'}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 7, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 7, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'aihub_indoor_test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 3, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'refcoco', 'data': '../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv', 'selected_cols': None, 'bpe_dir': None, 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'num_bins': 64, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': False, 'eval_args': '{}', 'uses_ema': False, 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2024-11-21 07:04:37 | INFO | ofa.evaluate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../polyformer_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '../finetune/polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{"data":"../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv","bpe_dir":"../../utils/BPE","selected_cols":"0,5,6,2,4,3"}', 'results_path': '../../results_polyformer_b/aihub_indoor_test_1120/'}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 3, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 3, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'aihub_indoor_test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 3, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'refcoco', 'data': '../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv', 'selected_cols': None, 'bpe_dir': None, 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'num_bins': 64, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': False, 'eval_args': '{}', 'uses_ema': False, 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2024-11-21 07:04:37 | INFO | ofa.evaluate | loading model(s) from ../finetune/polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
2024-11-21 07:04:37 | INFO | ofa.evaluate | loading model(s) from ../finetune/polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
2024-11-21 07:04:37 | INFO | ofa.evaluate | loading model(s) from ../finetune/polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
2024-11-21 07:04:41 | INFO | tasks.base_task | source dictionary: 4100 types
2024-11-21 07:04:41 | INFO | tasks.base_task | target dictionary: 4100 types
2024-11-21 07:04:41 | INFO | tasks.base_task | source dictionary: 4100 types
2024-11-21 07:04:41 | INFO | tasks.base_task | target dictionary: 4100 types
2024-11-21 07:04:41 | INFO | tasks.base_task | source dictionary: 4100 types
2024-11-21 07:04:41 | INFO | tasks.base_task | target dictionary: 4100 types
2024-11-21 07:04:41 | INFO | tasks.base_task | source dictionary: 4100 types
2024-11-21 07:04:41 | INFO | tasks.base_task | source dictionary: 4100 types
2024-11-21 07:04:41 | INFO | tasks.base_task | target dictionary: 4100 types
2024-11-21 07:04:41 | INFO | tasks.base_task | target dictionary: 4100 types
2024-11-21 07:04:41 | INFO | tasks.base_task | source dictionary: 4100 types
2024-11-21 07:04:41 | INFO | tasks.base_task | target dictionary: 4100 types
2024-11-21 07:04:41 | INFO | tasks.base_task | source dictionary: 4100 types
2024-11-21 07:04:41 | INFO | tasks.base_task | target dictionary: 4100 types
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2024-11-21 07:04:41 | INFO | tasks.base_task | source dictionary: 4100 types
2024-11-21 07:04:41 | INFO | tasks.base_task | target dictionary: 4100 types
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
local datafile ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 3 row count 6250 total row count 50000
local datafile ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping



file ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 2 row count 6250 total row count 50000file ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 7 row count 6250 total row count 50000file ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 4 row count 6250 total row count 50000file ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 5 row count 6250 total row count 50000



local datafile ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 1 row count 6250 total row count 50000
local datafile ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 0 row count 6250 total row count 50000
local datafile ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_test_1121/aihub_indoor_test.tsv slice_id 6 row count 6250 total row count 50000
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
inference step:  34
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
inference step:  22
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
inference step:  35
inference step:  27
inference step:  24
inference step:  38
inference step:  40
inference step:  39
inference step:  52
inference step:  25
inference step:  32
inference step:  41
inference step:  42
inference step:  30
inference step:  34
inference step:  27
inference step:  19
inference step:  27
inference step:  22
inference step:  43
inference step:  16
inference step:  43
inference step:  16
inference step:  29
inference step:  49
inference step:  29
inference step:  36
inference step:  210
inference step:  23
inference step:  30
inference step:  26
inference step:  39
inference step:  29
inference step:  40
inference step:  52
inference step:  44
inference step:  19
inference step:  37
inference step:  30
inference step:  33
inference step:  34
inference step:  29
inference step:  210
inference step:  34
inference step:  21
inference step:  29
inference step:  27
inference step:  34
inference step:  33
inference step:  30
inference step:  35
inference step:  210
inference step:  22
inference step:  29
inference step:  27
inference step:  25
inference step:  27
inference step:  42
inference step:  15
inference step:  22
inference step:  43
inference step:  31
inference step:  34
inference step:  17
inference step:  210
inference step:  60
inference step:  21
inference step:  40
inference step:  18
inference step:  30
inference step:  19
inference step:  210
inference step:  26
inference step:  27
inference step:  31
inference step:  64
inference step:  29
inference step:  22
2024-11-21 07:06:00 | INFO | fairseq.logging.progress_bar | :     11 / 391 sentences=16
inference step:  36
inference step:  25
inference step:  26
inference step:  32
inference step:  25
2024-11-21 07:06:03 | INFO | fairseq.logging.progress_bar | :     11 / 391 sentences=16
inference step:  210
inference step:  37
inference step:  27
2024-11-21 07:06:05 | INFO | fairseq.logging.progress_bar | :     11 / 391 sentences=16
inference step:  40
inference step:  30
inference step:  210
inference step:  210
2024-11-21 07:06:07 | INFO | fairseq.logging.progress_bar | :     11 / 391 sentences=16
inference step:  25
2024-11-21 07:06:08 | INFO | fairseq.logging.progress_bar | :     11 / 391 sentences=16
inference step:  63
inference step:  25
inference step:  24
inference step:  35
2024-11-21 07:06:10 | INFO | fairseq.logging.progress_bar | :     11 / 391 sentences=16
inference step:  25
inference step:  30
2024-11-21 07:06:11 | INFO | fairseq.logging.progress_bar | :     11 / 391 sentences=16
inference step:  36
inference step:  30
inference step:  23
inference step:  34
inference step:  24
inference step:  210
inference step:  79
inference step:  33
2024-11-21 07:06:15 | INFO | fairseq.logging.progress_bar | :     11 / 391 sentences=16
inference step:  26
inference step:  18
inference step:  31
inference step:  64
inference step:  22
inference step:  30
inference step:  47
inference step:  38
inference step:  210
inference step:  29
inference step:  23
inference step:  30
inference step:  60
inference step:  47
inference step:  23
inference step:  24
inference step:  64
inference step:  84
inference step:  25
inference step:  38
inference step:  31
inference step:  33
inference step:  22
inference step:  23
inference step:  210
inference step:  84
inference step:  31
inference step:  41
inference step:  46
inference step:  210
inference step:  40
inference step:  25
inference step:  23
inference step:  210
inference step:  32
inference step:  23
inference step:  31
inference step:  21
inference step:  26
inference step:  36
inference step:  17
inference step:  33
inference step:  32
2024-11-21 07:06:40 | INFO | fairseq.logging.progress_bar | :     21 / 391 sentences=16
inference step:  30
inference step:  46
inference step:  210
inference step:  30
inference step:  24
inference step:  38
inference step:  210
inference step:  40
inference step:  25
inference step:  210
inference step:  35
inference step:  56
inference step:  35
inference step:  21
inference step:  210
inference step:  34
inference step:  79
2024-11-21 07:06:49 | INFO | fairseq.logging.progress_bar | :     21 / 391 sentences=16
inference step:  24
inference step:  21
inference step:  26
inference step:  22
inference step:  24
2024-11-21 07:06:52 | INFO | fairseq.logging.progress_bar | :     21 / 391 sentences=16
2024-11-21 07:06:52 | INFO | fairseq.logging.progress_bar | :     21 / 391 sentences=16
inference step:  40
inference step:  35
inference step:  43
2024-11-21 07:06:54 | INFO | fairseq.logging.progress_bar | :     21 / 391 sentences=16
inference step:  25
inference step:  54
2024-11-21 07:06:55 | INFO | fairseq.logging.progress_bar | :     21 / 391 sentences=16
inference step:  27
inference step:  22
2024-11-21 07:06:56 | INFO | fairseq.logging.progress_bar | :     21 / 391 sentences=16
inference step:  210
inference step:  37
inference step:  46
inference step:  29
inference step:  210
2024-11-21 07:06:59 | INFO | fairseq.logging.progress_bar | :     21 / 391 sentences=16
inference step:  27
inference step:  24
inference step:  41
inference step:  53
inference step:  41
inference step:  48
inference step:  32
inference step:  22
inference step:  210
inference step:  43
inference step:  26
inference step:  210
inference step:  34
inference step:  29
inference step:  27
inference step:  24
inference step:  38
inference step:  210
inference step:  210
inference step:  25
inference step:  21
inference step:  210
inference step:  27
inference step:  210
inference step:  25
inference step:  22
inference step:  39
inference step:  32
inference step:  40
inference step:  25
inference step:  210
inference step:  21
inference step:  29
inference step:  38
inference step:  49
inference step:  32
inference step:  27
inference step:  210
inference step:  31
inference step:  27
inference step:  19
inference step:  32
inference step:  55
inference step:  36
inference step:  22
inference step:  51
inference step:  28
inference step:  20
inference step:  43
2024-11-21 07:07:27 | INFO | fairseq.logging.progress_bar | :     31 / 391 sentences=16
inference step:  32
inference step:  24
inference step:  17
inference step:  23
inference step:  26
inference step:  45
inference step:  94
inference step:  50
2024-11-21 07:07:32 | INFO | fairseq.logging.progress_bar | :     31 / 391 sentences=16
inference step:  33
inference step:  21
inference step:  42
inference step:  18
inference step:  28
2024-11-21 07:07:34 | INFO | fairseq.logging.progress_bar | :     31 / 391 sentences=16
inference step:  210
inference step:  33
inference step:  210
inference step:  30
2024-11-21 07:07:37 | INFO | fairseq.logging.progress_bar | :     31 / 391 sentences=16
inference step:  17
inference step:  210
inference step:  24
inference step:  210
inference step:  25
inference step:  210
inference step:  23
2024-11-21 07:07:41 | INFO | fairseq.logging.progress_bar | :     31 / 391 sentences=16
inference step:  23
2024-11-21 07:07:42 | INFO | fairseq.logging.progress_bar | :     31 / 391 sentences=16
inference step:  23
inference step:  18
inference step:  34
inference step:  111
inference step:  210
2024-11-21 07:07:44 | INFO | fairseq.logging.progress_bar | :     31 / 391 sentences=16
inference step:  24
inference step:  30
inference step:  26
inference step:  23
inference step:  25
inference step:  23
inference step:  25
inference step:  66
inference step:  26
inference step:  210
inference step:  210
inference step:  31
inference step:  27
inference step:  21
inference step:  24
2024-11-21 07:07:53 | INFO | fairseq.logging.progress_bar | :     31 / 391 sentences=16
inference step:  20
inference step:  32
inference step:  37
inference step:  25
inference step:  23
inference step:  28
inference step:  39
inference step:  32
inference step:  26
inference step:  20
inference step:  210
inference step:  25
inference step:  22
inference step:  24
inference step:  210
inference step:  210
inference step:  31
inference step:  22
inference step:  23
inference step:  22
inference step:  31
inference step:  30
inference step:  32
inference step:  53
inference step:  40
inference step:  210
inference step:  26
inference step:  28
inference step:  210
inference step:  32
inference step:  72
inference step:  22
inference step:  61
inference step:  50
inference step:  32
inference step:  27
2024-11-21 07:08:13 | INFO | fairseq.logging.progress_bar | :     41 / 391 sentences=16
inference step:  30
inference step:  33
inference step:  21
inference step:  26
inference step:  24
inference step:  41
inference step:  210
inference step:  26
2024-11-21 07:08:17 | INFO | fairseq.logging.progress_bar | :     41 / 391 sentences=16
inference step:  26
inference step:  40
inference step:  31
inference step:  23
2024-11-21 07:08:18 | INFO | fairseq.logging.progress_bar | :     41 / 391 sentences=16
2024-11-21 07:08:19 | INFO | fairseq.logging.progress_bar | :     41 / 391 sentences=16
inference step:  30
inference step:  33
inference step:  25
inference step:  21
inference step:  210
2024-11-21 07:08:22 | INFO | fairseq.logging.progress_bar | :     41 / 391 sentences=16
inference step:  20
inference step:  27
inference step:  34
2024-11-21 07:08:23 | INFO | fairseq.logging.progress_bar | :     41 / 391 sentences=16
inference step:  28
inference step:  210
inference step:  28
inference step:  210
inference step:  24
inference step:  41
inference step:  34
inference step:  27
inference step:  55
inference step:  210
inference step:  25
2024-11-21 07:08:31 | INFO | fairseq.logging.progress_bar | :     41 / 391 sentences=16
inference step:  39
inference step:  22
inference step:  210
inference step:  24
inference step:  210
inference step:  30
inference step:  21
inference step:  26
inference step:  28
inference step:  210
inference step:  54
inference step:  29
inference step:  47
inference step:  28
inference step:  36
inference step:  210
inference step:  210
inference step:  31
2024-11-21 07:08:41 | INFO | fairseq.logging.progress_bar | :     41 / 391 sentences=16
inference step:  25
inference step:  210
inference step:  34
inference step:  210
inference step:  43
inference step:  27
inference step:  50
inference step:  44
inference step:  24
inference step:  46
inference step:  210
inference step:  85
inference step:  28
inference step:  35
inference step:  59
inference step:  210
2024-11-21 07:08:51 | INFO | fairseq.logging.progress_bar | :     51 / 391 sentences=16
inference step:  210
inference step:  61
inference step:  62
inference step:  65
inference step:  21
inference step:  35
inference step:  32
inference step:  210
inference step:  63
inference step:  26
inference step:  210
inference step:  89
inference step:  31
inference step:  27
inference step:  28
inference step:  42
inference step:  30
inference step:  22
inference step:  32
inference step:  31
inference step:  36
inference step:  210
inference step:  210
inference step:  35
inference step:  24
inference step:  43
inference step:  22
2024-11-21 07:09:08 | INFO | fairseq.logging.progress_bar | :     51 / 391 sentences=16
inference step:  25
inference step:  69
2024-11-21 07:09:09 | INFO | fairseq.logging.progress_bar | :     51 / 391 sentences=16
inference step:  25
inference step:  210
inference step:  54
2024-11-21 07:09:11 | INFO | fairseq.logging.progress_bar | :     51 / 391 sentences=16
inference step:  57
inference step:  29
inference step:  210
inference step:  26
2024-11-21 07:09:13 | INFO | fairseq.logging.progress_bar | :     51 / 391 sentences=16
2024-11-21 07:09:13 | INFO | fairseq.logging.progress_bar | :     51 / 391 sentences=16
inference step:  47
inference step:  37
inference step:  21
inference step:  24
inference step:  19
inference step:  210
inference step:  32
inference step:  31
inference step:  210
inference step:  48
inference step:  29
inference step:  39
2024-11-21 07:09:20 | INFO | fairseq.logging.progress_bar | :     51 / 391 sentences=16
inference step:  20
inference step:  61
inference step:  44
inference step:  19
inference step:  20
inference step:  210
inference step:  31
inference step:  36
inference step:  24
2024-11-21 07:09:25 | INFO | fairseq.logging.progress_bar | :     51 / 391 sentences=16
inference step:  210
inference step:  22
inference step:  25
inference step:  38
inference step:  31
inference step:  26
inference step:  22
inference step:  33
inference step:  210
inference step:  30
inference step:  58
inference step:  28
inference step:  23
inference step:  25
inference step:  37
2024-11-21 07:09:33 | INFO | fairseq.logging.progress_bar | :     61 / 391 sentences=16
inference step:  21
inference step:  34
inference step:  35
inference step:  30
inference step:  210
inference step:  63
inference step:  210
inference step:  25
inference step:  23
inference step:  15
inference step:  210
inference step:  33
inference step:  22
inference step:  22
inference step:  210
inference step:  29
inference step:  53
inference step:  18
inference step:  34
inference step:  210
inference step:  15
inference step:  28
inference step:  24
inference step:  21
inference step:  28
inference step:  37
inference step:  36
inference step:  210
inference step:  28
inference step:  26
2024-11-21 07:09:51 | INFO | fairseq.logging.progress_bar | :     61 / 391 sentences=16
inference step:  35
inference step:  34
inference step:  33
inference step:  28
inference step:  28
inference step:  38
inference step:  75
inference step:  40
inference step:  34
2024-11-21 07:09:56 | INFO | fairseq.logging.progress_bar | :     61 / 391 sentences=16
inference step:  29
inference step:  27
inference step:  31
inference step:  63
inference step:  26
2024-11-21 07:09:58 | INFO | fairseq.logging.progress_bar | :     61 / 391 sentences=16
inference step:  15
inference step:  23
2024-11-21 07:09:59 | INFO | fairseq.logging.progress_bar | :     61 / 391 sentences=16
inference step:  28
inference step:  27
inference step:  71
inference step:  210
2024-11-21 07:10:02 | INFO | fairseq.logging.progress_bar | :     61 / 391 sentences=16
inference step:  50
2024-11-21 07:10:03 | INFO | fairseq.logging.progress_bar | :     61 / 391 sentences=16
inference step:  28
inference step:  29
inference step:  210
inference step:  27
inference step:  26
inference step:  37
inference step:  109
inference step:  29
inference step:  26
inference step:  34
inference step:  37
inference step:  37
inference step:  30
inference step:  39
inference step:  25
inference step:  36
inference step:  210
inference step:  27
inference step:  21
2024-11-21 07:10:14 | INFO | fairseq.logging.progress_bar | :     61 / 391 sentences=16
inference step:  51
inference step:  40
inference step:  31
inference step:  28
inference step:  22
inference step:  28
inference step:  23
inference step:  38
inference step:  25
inference step:  21
inference step:  55
inference step:  26
2024-11-21 07:10:19 | INFO | fairseq.logging.progress_bar | :     71 / 391 sentences=16
inference step:  38
inference step:  36
inference step:  49
inference step:  210
inference step:  29
inference step:  32
inference step:  28
inference step:  29
inference step:  33
inference step:  210
inference step:  24
inference step:  37
inference step:  48
inference step:  36
inference step:  23
inference step:  36
inference step:  31
inference step:  15
inference step:  28
inference step:  45
inference step:  22
inference step:  32
inference step:  31
inference step:  210
inference step:  21
inference step:  25
inference step:  26
inference step:  38
inference step:  29
inference step:  22
inference step:  34
2024-11-21 07:10:37 | INFO | fairseq.logging.progress_bar | :     71 / 391 sentences=16
inference step:  29
2024-11-21 07:10:38 | INFO | fairseq.logging.progress_bar | :     71 / 391 sentences=16
inference step:  31
inference step:  16
inference step:  210
inference step:  43
inference step:  29
inference step:  210
inference step:  210
2024-11-21 07:10:42 | INFO | fairseq.logging.progress_bar | :     71 / 391 sentences=16
inference step:  43
inference step:  26
inference step:  32
2024-11-21 07:10:43 | INFO | fairseq.logging.progress_bar | :     71 / 391 sentences=16
inference step:  33
inference step:  20
inference step:  30
inference step:  34
inference step:  31
inference step:  210
inference step:  210
inference step:  48
2024-11-21 07:10:48 | INFO | fairseq.logging.progress_bar | :     71 / 391 sentences=16
inference step:  32
inference step:  22
2024-11-21 07:10:50 | INFO | fairseq.logging.progress_bar | :     71 / 391 sentences=16
inference step:  30
inference step:  25
inference step:  42
inference step:  210
inference step:  31
inference step:  53
inference step:  28
inference step:  210
inference step:  67
inference step:  27
2024-11-21 07:10:55 | INFO | fairseq.logging.progress_bar | :     71 / 391 sentences=16
inference step:  44
inference step:  29
inference step:  210
inference step:  79
inference step:  49
inference step:  24
inference step:  210
inference step:  24
inference step:  210
inference step:  62
inference step:  22
inference step:  210
inference step:  26
inference step:  34
inference step:  21
2024-11-21 07:11:04 | INFO | fairseq.logging.progress_bar | :     81 / 391 sentences=16
inference step:  210
inference step:  210
inference step:  28
inference step:  31
inference step:  23
inference step:  210
inference step:  32
inference step:  29
inference step:  23
inference step:  33
inference step:  56
inference step:  28
inference step:  40
inference step:  34
inference step:  32
inference step:  210
inference step:  68
inference step:  30
inference step:  33
inference step:  210
inference step:  45
inference step:  27
inference step:  38
inference step:  28
inference step:  38
inference step:  26
inference step:  31
inference step:  32
inference step:  31
inference step:  34
inference step:  29
inference step:  210
2024-11-21 07:11:23 | INFO | fairseq.logging.progress_bar | :     81 / 391 sentences=16
inference step:  210
inference step:  30
2024-11-21 07:11:24 | INFO | fairseq.logging.progress_bar | :     81 / 391 sentences=16
inference step:  34
inference step:  24
inference step:  28
inference step:  210
inference step:  210
inference step:  41
inference step:  23
inference step:  210
2024-11-21 07:11:29 | INFO | fairseq.logging.progress_bar | :     81 / 391 sentences=16
inference step:  210
inference step:  22
inference step:  46
inference step:  27
inference step:  23
2024-11-21 07:11:31 | INFO | fairseq.logging.progress_bar | :     81 / 391 sentences=16
inference step:  105
inference step:  50
inference step:  24
inference step:  26
inference step:  29
inference step:  33
inference step:  30
2024-11-21 07:11:35 | INFO | fairseq.logging.progress_bar | :     81 / 391 sentences=16
inference step:  23
inference step:  52
inference step:  35
inference step:  210
inference step:  32
2024-11-21 07:11:38 | INFO | fairseq.logging.progress_bar | :     81 / 391 sentences=16
inference step:  39
inference step:  26
inference step:  35
inference step:  39
inference step:  33
inference step:  39
inference step:  32
inference step:  32
inference step:  29
inference step:  32
inference step:  32
2024-11-21 07:11:45 | INFO | fairseq.logging.progress_bar | :     81 / 391 sentences=16
inference step:  210
inference step:  20
inference step:  38
inference step:  37
inference step:  49
inference step:  210
inference step:  22
inference step:  46
inference step:  29
inference step:  33
inference step:  25
inference step:  24
inference step:  28
inference step:  29
inference step:  76
inference step:  48
inference step:  28
inference step:  26
inference step:  102
inference step:  15
inference step:  29
inference step:  36
inference step:  210
inference step:  29
inference step:  40
inference step:  45
inference step:  26
inference step:  30
2024-11-21 07:11:59 | INFO | fairseq.logging.progress_bar | :     91 / 391 sentences=16
inference step:  48
inference step:  44
inference step:  45
inference step:  34
inference step:  210
2024-11-21 07:12:02 | INFO | fairseq.logging.progress_bar | :     91 / 391 sentences=16
inference step:  210
inference step:  210
inference step:  29
inference step:  53
inference step:  22
inference step:  36
inference step:  27
2024-11-21 07:12:06 | INFO | fairseq.logging.progress_bar | :     91 / 391 sentences=16
inference step:  37
inference step:  32
inference step:  91
inference step:  30
2024-11-21 07:12:08 | INFO | fairseq.logging.progress_bar | :     91 / 391 sentences=16
inference step:  35
inference step:  47
inference step:  40
inference step:  44
inference step:  43
inference step:  32
inference step:  54
inference step:  25
inference step:  22
inference step:  28
inference step:  66
inference step:  210
inference step:  36
inference step:  29
inference step:  124
2024-11-21 07:12:19 | INFO | fairseq.logging.progress_bar | :     91 / 391 sentences=16
inference step:  30
inference step:  31
inference step:  210
inference step:  210
inference step:  46
inference step:  210
inference step:  27
inference step:  28
inference step:  37
inference step:  24
2024-11-21 07:12:24 | INFO | fairseq.logging.progress_bar | :     91 / 391 sentences=16
inference step:  27
inference step:  32
2024-11-21 07:12:26 | INFO | fairseq.logging.progress_bar | :     91 / 391 sentences=16
inference step:  30
2024-11-21 07:12:26 | INFO | fairseq.logging.progress_bar | :     91 / 391 sentences=16
inference step:  210
inference step:  33
inference step:  31
inference step:  210
inference step:  26
inference step:  30
inference step:  27
inference step:  22
inference step:  210
inference step:  18
inference step:  26
inference step:  27
inference step:  31
inference step:  22
inference step:  21
inference step:  210
inference step:  94
inference step:  32
inference step:  189
inference step:  30
inference step:  60
inference step:  30
inference step:  23
inference step:  40
inference step:  210
inference step:  34
inference step:  47
inference step:  35
inference step:  18
inference step:  28
inference step:  28
inference step:  210
inference step:  27
inference step:  39
inference step:  23
2024-11-21 07:12:46 | INFO | fairseq.logging.progress_bar | :    101 / 391 sentences=16
inference step:  31
inference step:  23
inference step:  25
inference step:  44
2024-11-21 07:12:50 | INFO | fairseq.logging.progress_bar | :    101 / 391 sentences=16
inference step:  39
inference step:  41
inference step:  35
inference step:  210
inference step:  21
inference step:  83
inference step:  210
inference step:  29
inference step:  23
2024-11-21 07:12:54 | INFO | fairseq.logging.progress_bar | :    101 / 391 sentences=16
inference step:  29
inference step:  18
inference step:  39
inference step:  210
inference step:  30
inference step:  210
inference step:  24
inference step:  32
inference step:  210
inference step:  18
2024-11-21 07:13:00 | INFO | fairseq.logging.progress_bar | :    101 / 391 sentences=16
inference step:  36
inference step:  29
inference step:  32
inference step:  23
inference step:  22
inference step:  26
inference step:  28
2024-11-21 07:13:03 | INFO | fairseq.logging.progress_bar | :    101 / 391 sentences=16
inference step:  25
inference step:  23
inference step:  25
2024-11-21 07:13:04 | INFO | fairseq.logging.progress_bar | :    101 / 391 sentences=16
inference step:  17
inference step:  25
inference step:  26
inference step:  26
inference step:  21
inference step:  210
inference step:  23
inference step:  32
inference step:  29
inference step:  144
inference step:  25
inference step:  26
inference step:  42
inference step:  26
inference step:  45
inference step:  31
inference step:  22
inference step:  210
inference step:  210
inference step:  36
inference step:  210
inference step:  28
2024-11-21 07:13:17 | INFO | fairseq.logging.progress_bar | :    101 / 391 sentences=16
inference step:  36
inference step:  102
2024-11-21 07:13:19 | INFO | fairseq.logging.progress_bar | :    101 / 391 sentences=16
inference step:  27
inference step:  29
inference step:  68
inference step:  68
inference step:  35
inference step:  34
inference step:  29
inference step:  31
inference step:  25
inference step:  41
inference step:  28
2024-11-21 07:13:26 | INFO | fairseq.logging.progress_bar | :    111 / 391 sentences=16
inference step:  24
inference step:  46
inference step:  54
inference step:  42
2024-11-21 07:13:28 | INFO | fairseq.logging.progress_bar | :    111 / 391 sentences=16
inference step:  26
inference step:  33
inference step:  24
inference step:  210
inference step:  22
inference step:  35
inference step:  24
inference step:  86
inference step:  20
inference step:  39
inference step:  30
inference step:  210
inference step:  22
inference step:  32
inference step:  45
inference step:  210
inference step:  23
inference step:  26
inference step:  28
inference step:  30
inference step:  39
inference step:  21
inference step:  25
inference step:  17
2024-11-21 07:13:42 | INFO | fairseq.logging.progress_bar | :    111 / 391 sentences=16
inference step:  27
inference step:  32
inference step:  50
inference step:  70
inference step:  210
inference step:  31
2024-11-21 07:13:45 | INFO | fairseq.logging.progress_bar | :    111 / 391 sentences=16
inference step:  35
inference step:  18
inference step:  25
inference step:  30
inference step:  56
inference step:  31
inference step:  38
inference step:  24
inference step:  21
inference step:  21
inference step:  210
inference step:  24
inference step:  22
inference step:  25
inference step:  29
2024-11-21 07:13:53 | INFO | fairseq.logging.progress_bar | :    111 / 391 sentences=16
inference step:  23
inference step:  25
inference step:  37
inference step:  30
inference step:  53
2024-11-21 07:13:57 | INFO | fairseq.logging.progress_bar | :    111 / 391 sentences=16
inference step:  33
inference step:  29
inference step:  31
inference step:  19
inference step:  210
inference step:  48
inference step:  26
inference step:  20
inference step:  26
inference step:  27
inference step:  42
inference step:  32
inference step:  24
inference step:  36
inference step:  34
2024-11-21 07:14:04 | INFO | fairseq.logging.progress_bar | :    121 / 391 sentences=16
inference step:  31
inference step:  35
2024-11-21 07:14:05 | INFO | fairseq.logging.progress_bar | :    111 / 391 sentences=16
inference step:  49
inference step:  26
2024-11-21 07:14:05 | INFO | fairseq.logging.progress_bar | :    121 / 391 sentences=16
inference step:  29
inference step:  32
inference step:  31
inference step:  24
inference step:  26
inference step:  210
inference step:  41
inference step:  26
inference step:  43
inference step:  21
inference step:  20
2024-11-21 07:14:12 | INFO | fairseq.logging.progress_bar | :    111 / 391 sentences=16
inference step:  75
inference step:  30
inference step:  53
inference step:  210
inference step:  22
inference step:  22
inference step:  45
inference step:  210
inference step:  36
inference step:  24
inference step:  66
inference step:  43
inference step:  42
inference step:  92
inference step:  30
inference step:  210
inference step:  28
inference step:  29
inference step:  210
inference step:  210
inference step:  23
inference step:  31
inference step:  28
inference step:  26
inference step:  29
inference step:  23
2024-11-21 07:14:28 | INFO | fairseq.logging.progress_bar | :    121 / 391 sentences=16
inference step:  30
inference step:  28
inference step:  40
inference step:  18
inference step:  210
inference step:  29
inference step:  41
2024-11-21 07:14:32 | INFO | fairseq.logging.progress_bar | :    121 / 391 sentences=16
inference step:  26
inference step:  19
2024-11-21 07:14:33 | INFO | fairseq.logging.progress_bar | :    121 / 391 sentences=16
inference step:  73
inference step:  25
inference step:  27
inference step:  42
inference step:  70
inference step:  35
inference step:  35
inference step:  24
inference step:  32
inference step:  43
inference step:  29
inference step:  30
inference step:  210
inference step:  35
inference step:  23
inference step:  44
inference step:  26
inference step:  27
inference step:  40
inference step:  27
inference step:  29
2024-11-21 07:14:46 | INFO | fairseq.logging.progress_bar | :    131 / 391 sentences=16
inference step:  21
inference step:  26
inference step:  34
inference step:  42
2024-11-21 07:14:47 | INFO | fairseq.logging.progress_bar | :    121 / 391 sentences=16
inference step:  40
inference step:  210
inference step:  210
2024-11-21 07:14:49 | INFO | fairseq.logging.progress_bar | :    131 / 391 sentences=16
inference step:  54
inference step:  27
inference step:  23
inference step:  32
2024-11-21 07:14:51 | INFO | fairseq.logging.progress_bar | :    121 / 391 sentences=16
inference step:  39
inference step:  36
inference step:  27
inference step:  30
inference step:  25
inference step:  32
inference step:  41
inference step:  34
inference step:  36
inference step:  28
inference step:  26
inference step:  210
inference step:  13
inference step:  22
inference step:  28
inference step:  32
inference step:  31
inference step:  26
inference step:  27
inference step:  32
inference step:  33
2024-11-21 07:15:02 | INFO | fairseq.logging.progress_bar | :    121 / 391 sentences=16
inference step:  25
inference step:  33
inference step:  43
inference step:  21
inference step:  27
inference step:  18
inference step:  37
inference step:  21
inference step:  31
inference step:  28
inference step:  26
inference step:  59
inference step:  35
inference step:  20
inference step:  18
inference step:  20
inference step:  38
inference step:  30
inference step:  47
2024-11-21 07:15:13 | INFO | fairseq.logging.progress_bar | :    131 / 391 sentences=16
inference step:  29
inference step:  29
inference step:  21
inference step:  23
inference step:  34
inference step:  68
2024-11-21 07:15:15 | INFO | fairseq.logging.progress_bar | :    131 / 391 sentences=16
inference step:  21
2024-11-21 07:15:17 | INFO | fairseq.logging.progress_bar | :    131 / 391 sentences=16
inference step:  210
inference step:  21
inference step:  22
inference step:  29
inference step:  210
inference step:  27
inference step:  23
inference step:  42
inference step:  36
inference step:  25
inference step:  33
inference step:  42
inference step:  45
inference step:  31
inference step:  24
2024-11-21 07:15:24 | INFO | fairseq.logging.progress_bar | :    141 / 391 sentences=16
inference step:  41
inference step:  46
inference step:  42
inference step:  210
inference step:  39
inference step:  133
inference step:  38
2024-11-21 07:15:29 | INFO | fairseq.logging.progress_bar | :    141 / 391 sentences=16
inference step:  23
inference step:  25
inference step:  32
inference step:  133
inference step:  210
2024-11-21 07:15:32 | INFO | fairseq.logging.progress_bar | :    131 / 391 sentences=16
inference step:  32
inference step:  18
inference step:  210
inference step:  30
inference step:  43
inference step:  47
inference step:  41
inference step:  44
inference step:  41
inference step:  46
inference step:  31
inference step:  28
inference step:  69
inference step:  16
inference step:  210
inference step:  18
inference step:  33
inference step:  30
inference step:  52
2024-11-21 07:15:41 | INFO | fairseq.logging.progress_bar | :    131 / 391 sentences=16
inference step:  210
inference step:  28
2024-11-21 07:15:44 | INFO | fairseq.logging.progress_bar | :    131 / 391 sentences=16
inference step:  210
inference step:  37
inference step:  18
inference step:  45
inference step:  34
inference step:  210
inference step:  43
inference step:  27
inference step:  30
inference step:  36
inference step:  210
inference step:  30
inference step:  37
inference step:  210
inference step:  210
inference step:  37
inference step:  30
inference step:  27
inference step:  31
inference step:  63
inference step:  31
inference step:  22
inference step:  26
inference step:  18
inference step:  20
inference step:  26
inference step:  36
inference step:  26
inference step:  20
2024-11-21 07:16:01 | INFO | fairseq.logging.progress_bar | :    141 / 391 sentences=16
inference step:  28
inference step:  29
inference step:  37
inference step:  33
inference step:  25
inference step:  32
inference step:  32
inference step:  24
2024-11-21 07:16:04 | INFO | fairseq.logging.progress_bar | :    141 / 391 sentences=16
inference step:  22
2024-11-21 07:16:05 | INFO | fairseq.logging.progress_bar | :    151 / 391 sentences=16
inference step:  26
2024-11-21 07:16:06 | INFO | fairseq.logging.progress_bar | :    141 / 391 sentences=16
inference step:  43
inference step:  34
inference step:  52
inference step:  27
inference step:  32
inference step:  210
2024-11-21 07:16:08 | INFO | fairseq.logging.progress_bar | :    141 / 391 sentences=16
inference step:  33
inference step:  31
inference step:  24
inference step:  22
inference step:  69
2024-11-21 07:16:11 | INFO | fairseq.logging.progress_bar | :    151 / 391 sentences=16
inference step:  26
inference step:  42
inference step:  210
inference step:  23
inference step:  210
inference step:  210
inference step:  22
inference step:  48
inference step:  57
inference step:  38
inference step:  34
inference step:  33
inference step:  64
inference step:  35
inference step:  39
inference step:  210
inference step:  210
inference step:  35
2024-11-21 07:16:24 | INFO | fairseq.logging.progress_bar | :    141 / 391 sentences=16
inference step:  210
inference step:  31
inference step:  29
inference step:  105
inference step:  210
inference step:  83
inference step:  40
inference step:  30
inference step:  33
inference step:  55
inference step:  24
inference step:  35
inference step:  77
inference step:  49
inference step:  105
inference step:  20
inference step:  30
inference step:  32
inference step:  28
inference step:  25
inference step:  30
inference step:  42
inference step:  30
inference step:  41
inference step:  40
inference step:  31
inference step:  210
inference step:  20
inference step:  210
inference step:  36
inference step:  51
inference step:  32
inference step:  40
2024-11-21 07:16:41 | INFO | fairseq.logging.progress_bar | :    141 / 391 sentences=16
inference step:  26
inference step:  31
inference step:  38
inference step:  210
inference step:  210
inference step:  29
inference step:  28
inference step:  31
inference step:  27
2024-11-21 07:16:45 | INFO | fairseq.logging.progress_bar | :    151 / 391 sentences=16
inference step:  21
inference step:  44
inference step:  53
inference step:  32
inference step:  24
2024-11-21 07:16:47 | INFO | fairseq.logging.progress_bar | :    161 / 391 sentences=16
inference step:  27
2024-11-21 07:16:49 | INFO | fairseq.logging.progress_bar | :    151 / 391 sentences=16
inference step:  25
inference step:  37
inference step:  30
inference step:  41
2024-11-21 07:16:50 | INFO | fairseq.logging.progress_bar | :    161 / 391 sentences=16
inference step:  17
inference step:  49
inference step:  21
inference step:  28
inference step:  22
2024-11-21 07:16:54 | INFO | fairseq.logging.progress_bar | :    151 / 391 sentences=16
inference step:  25
inference step:  23
inference step:  33
inference step:  46
inference step:  20
inference step:  26
inference step:  33
inference step:  18
inference step:  210
2024-11-21 07:16:58 | INFO | fairseq.logging.progress_bar | :    151 / 391 sentences=16
inference step:  25
inference step:  22
inference step:  51
inference step:  42
inference step:  210
inference step:  26
inference step:  43
inference step:  21
inference step:  24
2024-11-21 07:17:04 | INFO | fairseq.logging.progress_bar | :    151 / 391 sentences=16
inference step:  26
inference step:  26
inference step:  30
inference step:  210
inference step:  210
inference step:  33
inference step:  33
inference step:  87
inference step:  26
inference step:  21
inference step:  22
inference step:  57
inference step:  23
inference step:  24
inference step:  34
inference step:  106
inference step:  210
inference step:  210
inference step:  210
inference step:  22
inference step:  25
inference step:  36
inference step:  25
inference step:  23
inference step:  97
inference step:  31
inference step:  27
inference step:  32
inference step:  210
inference step:  210
inference step:  24
inference step:  40
inference step:  26
inference step:  25
inference step:  30
inference step:  210
2024-11-21 07:17:25 | INFO | fairseq.logging.progress_bar | :    171 / 391 sentences=16
inference step:  26
2024-11-21 07:17:25 | INFO | fairseq.logging.progress_bar | :    161 / 391 sentences=16
inference step:  24
inference step:  36
inference step:  210
inference step:  210
2024-11-21 07:17:27 | INFO | fairseq.logging.progress_bar | :    151 / 391 sentences=16
inference step:  38
inference step:  24
inference step:  27
inference step:  21
inference step:  31
inference step:  47
inference step:  38
inference step:  27
inference step:  27
inference step:  210
inference step:  42
inference step:  27
inference step:  43
inference step:  28
inference step:  210
inference step:  45
inference step:  32
inference step:  25
inference step:  25
inference step:  33
2024-11-21 07:17:40 | INFO | fairseq.logging.progress_bar | :    161 / 391 sentences=16
2024-11-21 07:17:40 | INFO | fairseq.logging.progress_bar | :    161 / 391 sentences=16
inference step:  38
inference step:  16
inference step:  49
inference step:  33
inference step:  40
inference step:  22
inference step:  18
inference step:  210
inference step:  210
inference step:  31
inference step:  39
inference step:  43
inference step:  19
inference step:  30
2024-11-21 07:17:47 | INFO | fairseq.logging.progress_bar | :    161 / 391 sentences=16
inference step:  28
inference step:  210
inference step:  23
2024-11-21 07:17:50 | INFO | fairseq.logging.progress_bar | :    161 / 391 sentences=16
inference step:  210
inference step:  19
inference step:  57
inference step:  24
inference step:  43
inference step:  33
inference step:  27
inference step:  20
2024-11-21 07:17:54 | INFO | fairseq.logging.progress_bar | :    171 / 391 sentences=16
inference step:  32
inference step:  34
inference step:  30
inference step:  22
inference step:  44
inference step:  38
inference step:  25
inference step:  37
inference step:  84
inference step:  38
inference step:  23
inference step:  30
inference step:  31
inference step:  36
inference step:  21
inference step:  61
inference step:  37
inference step:  48
inference step:  38
inference step:  31
inference step:  31
inference step:  28
inference step:  31
inference step:  210
inference step:  45
inference step:  39
inference step:  27
inference step:  64
2024-11-21 07:18:09 | INFO | fairseq.logging.progress_bar | :    171 / 391 sentences=16
inference step:  31
inference step:  34
inference step:  26
inference step:  17
inference step:  49
2024-11-21 07:18:11 | INFO | fairseq.logging.progress_bar | :    181 / 391 sentences=16
inference step:  27
inference step:  210
2024-11-21 07:18:13 | INFO | fairseq.logging.progress_bar | :    161 / 391 sentences=16
inference step:  33
inference step:  23
inference step:  28
inference step:  49
inference step:  32
inference step:  21
inference step:  210
inference step:  36
inference step:  29
inference step:  48
2024-11-21 07:18:18 | INFO | fairseq.logging.progress_bar | :    171 / 391 sentences=16
inference step:  44
inference step:  21
inference step:  17
inference step:  24
inference step:  34
inference step:  210
2024-11-21 07:18:22 | INFO | fairseq.logging.progress_bar | :    171 / 391 sentences=16
inference step:  22
inference step:  25
inference step:  48
inference step:  30
inference step:  19
inference step:  23
inference step:  30
inference step:  210
inference step:  26
inference step:  30
inference step:  38
inference step:  210
inference step:  30
inference step:  36
inference step:  210
inference step:  48
inference step:  39
inference step:  20
inference step:  59
2024-11-21 07:18:33 | INFO | fairseq.logging.progress_bar | :    171 / 391 sentences=16
inference step:  27
2024-11-21 07:18:34 | INFO | fairseq.logging.progress_bar | :    171 / 391 sentences=16
inference step:  210
inference step:  18
inference step:  30
inference step:  79
inference step:  47
2024-11-21 07:18:37 | INFO | fairseq.logging.progress_bar | :    181 / 391 sentences=16
inference step:  24
inference step:  62
inference step:  25
inference step:  30
inference step:  27
inference step:  23
inference step:  86
inference step:  44
inference step:  41
inference step:  16
inference step:  67
inference step:  26
inference step:  29
inference step:  27
inference step:  30
inference step:  41
inference step:  65
inference step:  13
inference step:  27
inference step:  23
inference step:  65
inference step:  36
inference step:  24
inference step:  13
inference step:  34
inference step:  73
inference step:  25
inference step:  31
inference step:  26
inference step:  47
inference step:  23
2024-11-21 07:18:53 | INFO | fairseq.logging.progress_bar | :    181 / 391 sentences=16
inference step:  45
inference step:  21
inference step:  29
inference step:  26
2024-11-21 07:18:55 | INFO | fairseq.logging.progress_bar | :    191 / 391 sentences=16
inference step:  18
inference step:  28
inference step:  210
inference step:  210
2024-11-21 07:18:58 | INFO | fairseq.logging.progress_bar | :    171 / 391 sentences=16
inference step:  28
inference step:  19
inference step:  53
inference step:  29
inference step:  28
inference step:  210
inference step:  41
inference step:  24
inference step:  20
inference step:  24
inference step:  28
inference step:  32
inference step:  34
inference step:  22
2024-11-21 07:19:05 | INFO | fairseq.logging.progress_bar | :    181 / 391 sentences=16
inference step:  17
inference step:  32
inference step:  23
inference step:  22
inference step:  23
inference step:  21
inference step:  210
2024-11-21 07:19:09 | INFO | fairseq.logging.progress_bar | :    181 / 391 sentences=16
inference step:  37
inference step:  44
inference step:  64
inference step:  85
inference step:  28
inference step:  25
inference step:  30
inference step:  23
inference step:  59
inference step:  210
inference step:  48
inference step:  79
inference step:  24
2024-11-21 07:19:16 | INFO | fairseq.logging.progress_bar | :    181 / 391 sentences=16
inference step:  24
inference step:  28
inference step:  48
2024-11-21 07:19:19 | INFO | fairseq.logging.progress_bar | :    181 / 391 sentences=16
inference step:  56
inference step:  36
inference step:  23
inference step:  210
2024-11-21 07:19:20 | INFO | fairseq.logging.progress_bar | :    191 / 391 sentences=16
inference step:  19
inference step:  25
inference step:  29
inference step:  38
inference step:  27
inference step:  30
inference step:  65
inference step:  35
inference step:  24
inference step:  210
inference step:  36
inference step:  18
inference step:  44
inference step:  30
inference step:  24
inference step:  36
inference step:  30
inference step:  17
inference step:  18
inference step:  29
inference step:  37
inference step:  29
inference step:  210
inference step:  31
inference step:  44
inference step:  34
inference step:  20
2024-11-21 07:19:38 | INFO | fairseq.logging.progress_bar | :    201 / 391 sentences=16
inference step:  210
inference step:  33
inference step:  36
2024-11-21 07:19:39 | INFO | fairseq.logging.progress_bar | :    181 / 391 sentences=16
inference step:  67
inference step:  210
inference step:  32
inference step:  30
inference step:  210
inference step:  20
2024-11-21 07:19:42 | INFO | fairseq.logging.progress_bar | :    191 / 391 sentences=16
inference step:  36
inference step:  210
inference step:  30
inference step:  32
inference step:  29
inference step:  210
inference step:  45
inference step:  33
inference step:  41
inference step:  29
inference step:  24
inference step:  40
2024-11-21 07:19:48 | INFO | fairseq.logging.progress_bar | :    191 / 391 sentences=16
inference step:  32
inference step:  38
inference step:  26
inference step:  27
inference step:  24
inference step:  37
inference step:  32
inference step:  22
inference step:  27
inference step:  35
inference step:  28
inference step:  94
inference step:  68
inference step:  27
inference step:  34
inference step:  27
inference step:  19
inference step:  210
inference step:  30
inference step:  24
inference step:  26
2024-11-21 07:19:59 | INFO | fairseq.logging.progress_bar | :    191 / 391 sentences=16
inference step:  45
inference step:  51
inference step:  21
inference step:  28
inference step:  36
2024-11-21 07:20:02 | INFO | fairseq.logging.progress_bar | :    201 / 391 sentences=16
inference step:  21
2024-11-21 07:20:03 | INFO | fairseq.logging.progress_bar | :    191 / 391 sentences=16
inference step:  52
inference step:  24
inference step:  39
inference step:  41
inference step:  19
inference step:  32
inference step:  30
inference step:  23
inference step:  49
inference step:  45
inference step:  67
inference step:  23
inference step:  29
inference step:  210
inference step:  61
inference step:  69
inference step:  21
2024-11-21 07:20:12 | INFO | fairseq.logging.progress_bar | :    191 / 391 sentences=16
inference step:  33
inference step:  29
inference step:  31
inference step:  44
inference step:  210
inference step:  210
inference step:  21
inference step:  210
inference step:  24
inference step:  42
2024-11-21 07:20:18 | INFO | fairseq.logging.progress_bar | :    211 / 391 sentences=16
inference step:  39
inference step:  32
inference step:  23
inference step:  105
inference step:  210
inference step:  210
inference step:  28
inference step:  26
inference step:  26
2024-11-21 07:20:24 | INFO | fairseq.logging.progress_bar | :    191 / 391 sentences=16
inference step:  24
inference step:  36
inference step:  30
2024-11-21 07:20:24 | INFO | fairseq.logging.progress_bar | :    201 / 391 sentences=16
inference step:  25
inference step:  29
inference step:  51
inference step:  34
inference step:  33
inference step:  210
inference step:  29
inference step:  29
inference step:  27
inference step:  64
inference step:  35
inference step:  33
2024-11-21 07:20:31 | INFO | fairseq.logging.progress_bar | :    201 / 391 sentences=16
inference step:  21
inference step:  46
inference step:  35
inference step:  30
inference step:  35
inference step:  24
inference step:  210
inference step:  23
inference step:  34
inference step:  23
inference step:  32
inference step:  27
inference step:  19
inference step:  43
inference step:  30
2024-11-21 07:20:38 | INFO | fairseq.logging.progress_bar | :    211 / 391 sentences=16
inference step:  32
inference step:  34
inference step:  31
inference step:  27
inference step:  36
inference step:  210
inference step:  20
inference step:  27
inference step:  41
inference step:  27
inference step:  32
2024-11-21 07:20:46 | INFO | fairseq.logging.progress_bar | :    201 / 391 sentences=16
inference step:  26
inference step:  39
inference step:  23
inference step:  30
inference step:  37
inference step:  28
inference step:  210
2024-11-21 07:20:49 | INFO | fairseq.logging.progress_bar | :    201 / 391 sentences=16
inference step:  39
inference step:  23
inference step:  28
inference step:  53
inference step:  32
inference step:  28
inference step:  38
inference step:  37
inference step:  33
inference step:  41
2024-11-21 07:20:55 | INFO | fairseq.logging.progress_bar | :    201 / 391 sentences=16
inference step:  34
inference step:  27
inference step:  210
inference step:  25
inference step:  41
inference step:  17
inference step:  210
inference step:  27
inference step:  36
inference step:  27
inference step:  27
inference step:  36
inference step:  16
inference step:  210
inference step:  21
inference step:  25
inference step:  210
2024-11-21 07:21:06 | INFO | fairseq.logging.progress_bar | :    221 / 391 sentences=16
inference step:  50
inference step:  210
inference step:  41
inference step:  32
inference step:  27
2024-11-21 07:21:08 | INFO | fairseq.logging.progress_bar | :    201 / 391 sentences=16
inference step:  21
inference step:  26
inference step:  19
inference step:  28
inference step:  25
inference step:  29
2024-11-21 07:21:11 | INFO | fairseq.logging.progress_bar | :    211 / 391 sentences=16
inference step:  41
inference step:  22
inference step:  210
inference step:  22
inference step:  44
inference step:  37
inference step:  35
inference step:  24
inference step:  22
inference step:  210
inference step:  28
inference step:  30
inference step:  38
inference step:  45
inference step:  32
inference step:  210
inference step:  24
inference step:  23
inference step:  42
inference step:  55
2024-11-21 07:21:24 | INFO | fairseq.logging.progress_bar | :    221 / 391 sentences=16
inference step:  31
inference step:  21
inference step:  30
inference step:  23
inference step:  22
inference step:  36
inference step:  44
inference step:  36
inference step:  46
2024-11-21 07:21:30 | INFO | fairseq.logging.progress_bar | :    211 / 391 sentences=16
inference step:  37
inference step:  30
inference step:  210
inference step:  27
inference step:  38
inference step:  210
inference step:  45
inference step:  110
2024-11-21 07:21:35 | INFO | fairseq.logging.progress_bar | :    211 / 391 sentences=16
inference step:  24
inference step:  29
inference step:  24
2024-11-21 07:21:36 | INFO | fairseq.logging.progress_bar | :    211 / 391 sentences=16
inference step:  21
inference step:  25
inference step:  27
inference step:  35
inference step:  40
inference step:  210
inference step:  26
inference step:  22
inference step:  210
inference step:  56
inference step:  24
inference step:  31
inference step:  25
2024-11-21 07:21:44 | INFO | fairseq.logging.progress_bar | :    211 / 391 sentences=16
inference step:  63
inference step:  18
inference step:  36
inference step:  210
inference step:  31
inference step:  29
inference step:  210
inference step:  31
inference step:  23
inference step:  210
inference step:  53
inference step:  25
2024-11-21 07:21:51 | INFO | fairseq.logging.progress_bar | :    231 / 391 sentences=16
inference step:  24
inference step:  29
inference step:  32
inference step:  26
inference step:  31
inference step:  24
inference step:  25
inference step:  26
inference step:  67
inference step:  26
inference step:  35
inference step:  210
inference step:  17
inference step:  210
2024-11-21 07:22:00 | INFO | fairseq.logging.progress_bar | :    211 / 391 sentences=16
inference step:  31
inference step:  29
inference step:  18
2024-11-21 07:22:01 | INFO | fairseq.logging.progress_bar | :    221 / 391 sentences=16
inference step:  52
inference step:  32
inference step:  28
inference step:  22
inference step:  29
inference step:  41
inference step:  210
inference step:  210
inference step:  46
inference step:  34
inference step:  23
inference step:  25
inference step:  27
inference step:  38
inference step:  51
inference step:  33
inference step:  21
inference step:  80
inference step:  37
inference step:  28
2024-11-21 07:22:13 | INFO | fairseq.logging.progress_bar | :    221 / 391 sentences=16
2024-11-21 07:22:14 | INFO | fairseq.logging.progress_bar | :    231 / 391 sentences=16
inference step:  55
inference step:  34
inference step:  45
2024-11-21 07:22:15 | INFO | fairseq.logging.progress_bar | :    221 / 391 sentences=16
inference step:  21
inference step:  50
inference step:  210
inference step:  51
inference step:  22
inference step:  29
inference step:  42
inference step:  27
inference step:  46
inference step:  210
inference step:  21
inference step:  24
inference step:  22
inference step:  210
inference step:  210
inference step:  33
inference step:  29
inference step:  28
inference step:  94
inference step:  22
inference step:  25
inference step:  77
inference step:  210
inference step:  31
inference step:  210
2024-11-21 07:22:31 | INFO | fairseq.logging.progress_bar | :    221 / 391 sentences=16
inference step:  210
inference step:  33
inference step:  210
inference step:  210
2024-11-21 07:22:34 | INFO | fairseq.logging.progress_bar | :    221 / 391 sentences=16
inference step:  35
inference step:  35
inference step:  30
inference step:  76
inference step:  43
inference step:  29
inference step:  210
2024-11-21 07:22:38 | INFO | fairseq.logging.progress_bar | :    241 / 391 sentences=16
inference step:  44
inference step:  47
inference step:  38
inference step:  210
inference step:  23
inference step:  26
inference step:  35
2024-11-21 07:22:41 | INFO | fairseq.logging.progress_bar | :    231 / 391 sentences=16
inference step:  24
inference step:  51
inference step:  20
inference step:  33
inference step:  28
inference step:  84
inference step:  38
inference step:  27
inference step:  25
inference step:  33
inference step:  31
inference step:  23
inference step:  49
2024-11-21 07:22:48 | INFO | fairseq.logging.progress_bar | :    221 / 391 sentences=16
inference step:  22
inference step:  34
inference step:  59
inference step:  59
inference step:  37
inference step:  31
inference step:  21
inference step:  23
inference step:  41
inference step:  68
inference step:  41
inference step:  47
inference step:  36
inference step:  34
inference step:  36
inference step:  34
inference step:  27
inference step:  24
inference step:  27
inference step:  40
inference step:  30
2024-11-21 07:23:00 | INFO | fairseq.logging.progress_bar | :    231 / 391 sentences=16
inference step:  27
inference step:  49
inference step:  37
inference step:  30
inference step:  35
inference step:  210
inference step:  14
inference step:  31
inference step:  24
2024-11-21 07:23:05 | INFO | fairseq.logging.progress_bar | :    241 / 391 sentences=16
inference step:  24
inference step:  52
inference step:  210
inference step:  210
inference step:  22
2024-11-21 07:23:07 | INFO | fairseq.logging.progress_bar | :    231 / 391 sentences=16
inference step:  24
2024-11-21 07:23:08 | INFO | fairseq.logging.progress_bar | :    231 / 391 sentences=16
inference step:  33
inference step:  30
inference step:  24
inference step:  33
inference step:  33
inference step:  23
inference step:  36
inference step:  210
inference step:  31
inference step:  35
inference step:  210
inference step:  210
inference step:  22
inference step:  49
inference step:  40
inference step:  35
inference step:  22
2024-11-21 07:23:18 | INFO | fairseq.logging.progress_bar | :    231 / 391 sentences=16
inference step:  26
inference step:  26
inference step:  25
inference step:  25
inference step:  33
inference step:  76
inference step:  49
inference step:  26
inference step:  26
inference step:  27
inference step:  35
inference step:  23
2024-11-21 07:23:25 | INFO | fairseq.logging.progress_bar | :    251 / 391 sentences=16
2024-11-21 07:23:26 | INFO | fairseq.logging.progress_bar | :    241 / 391 sentences=16
inference step:  63
inference step:  73
inference step:  45
inference step:  30
inference step:  24
inference step:  63
inference step:  29
inference step:  210
inference step:  31
inference step:  30
inference step:  40
inference step:  30
inference step:  26
inference step:  60
inference step:  23
inference step:  28
inference step:  29
inference step:  210
inference step:  40
inference step:  31
inference step:  19
2024-11-21 07:23:36 | INFO | fairseq.logging.progress_bar | :    231 / 391 sentences=16
inference step:  36
inference step:  210
inference step:  27
inference step:  42
inference step:  210
inference step:  28
inference step:  35
inference step:  23
inference step:  210
inference step:  210
inference step:  210
inference step:  43
inference step:  33
inference step:  61
inference step:  17
inference step:  32
inference step:  22
2024-11-21 07:23:47 | INFO | fairseq.logging.progress_bar | :    241 / 391 sentences=16
2024-11-21 07:23:47 | INFO | fairseq.logging.progress_bar | :    241 / 391 sentences=16
inference step:  33
inference step:  39
inference step:  210
inference step:  33
inference step:  21
inference step:  29
inference step:  36
inference step:  33
inference step:  42
inference step:  30
inference step:  24
2024-11-21 07:23:53 | INFO | fairseq.logging.progress_bar | :    251 / 391 sentences=16
inference step:  19
inference step:  36
inference step:  53
inference step:  210
inference step:  39
inference step:  210
inference step:  48
inference step:  32
inference step:  28
inference step:  22
2024-11-21 07:24:00 | INFO | fairseq.logging.progress_bar | :    241 / 391 sentences=16
inference step:  210
inference step:  31
inference step:  210
inference step:  34
inference step:  21
inference step:  27
inference step:  210
inference step:  37
inference step:  210
inference step:  26
inference step:  38
inference step:  24
inference step:  26
inference step:  26
2024-11-21 07:24:08 | INFO | fairseq.logging.progress_bar | :    251 / 391 sentences=16
inference step:  87
inference step:  34
2024-11-21 07:24:09 | INFO | fairseq.logging.progress_bar | :    241 / 391 sentences=16
inference step:  29
inference step:  29
inference step:  26
inference step:  27
inference step:  20
inference step:  28
inference step:  23
2024-11-21 07:24:13 | INFO | fairseq.logging.progress_bar | :    261 / 391 sentences=16
inference step:  35
inference step:  43
inference step:  24
inference step:  210
inference step:  31
inference step:  25
inference step:  39
inference step:  210
inference step:  42
inference step:  17
inference step:  31
inference step:  26
2024-11-21 07:24:19 | INFO | fairseq.logging.progress_bar | :    241 / 391 sentences=16
inference step:  34
inference step:  210
inference step:  210
inference step:  37
inference step:  14
inference step:  210
inference step:  36
inference step:  24
inference step:  40
inference step:  210
inference step:  41
inference step:  32
inference step:  20
inference step:  46
inference step:  33
inference step:  34
inference step:  29
2024-11-21 07:24:30 | INFO | fairseq.logging.progress_bar | :    251 / 391 sentences=16
inference step:  22
inference step:  28
2024-11-21 07:24:30 | INFO | fairseq.logging.progress_bar | :    251 / 391 sentences=16
inference step:  28
inference step:  42
inference step:  210
inference step:  210
inference step:  32
inference step:  22
2024-11-21 07:24:34 | INFO | fairseq.logging.progress_bar | :    261 / 391 sentences=16
inference step:  27
inference step:  32
inference step:  33
inference step:  210
inference step:  16
inference step:  25
inference step:  20
inference step:  29
inference step:  39
inference step:  210
inference step:  34
inference step:  23
inference step:  46
inference step:  27
inference step:  25
inference step:  24
inference step:  36
inference step:  40
inference step:  50
inference step:  27
inference step:  54
inference step:  210
inference step:  210
inference step:  34
inference step:  29
2024-11-21 07:24:49 | INFO | fairseq.logging.progress_bar | :    251 / 391 sentences=16
inference step:  29
inference step:  34
inference step:  28
inference step:  23
inference step:  38
inference step:  21
inference step:  210
inference step:  210
inference step:  58
2024-11-21 07:24:53 | INFO | fairseq.logging.progress_bar | :    251 / 391 sentences=16
inference step:  44
inference step:  28
inference step:  29
inference step:  23
2024-11-21 07:24:56 | INFO | fairseq.logging.progress_bar | :    271 / 391 sentences=16
inference step:  210
inference step:  23
inference step:  38
2024-11-21 07:24:57 | INFO | fairseq.logging.progress_bar | :    261 / 391 sentences=16
inference step:  64
inference step:  25
inference step:  210
inference step:  27
inference step:  34
inference step:  27
inference step:  42
inference step:  22
inference step:  30
inference step:  210
inference step:  210
inference step:  51
inference step:  210
inference step:  23
inference step:  38
2024-11-21 07:25:07 | INFO | fairseq.logging.progress_bar | :    251 / 391 sentences=16
inference step:  35
inference step:  26
inference step:  31
inference step:  62
inference step:  210
inference step:  19
inference step:  29
inference step:  24
inference step:  23
inference step:  32
inference step:  26
inference step:  78
inference step:  24
2024-11-21 07:25:14 | INFO | fairseq.logging.progress_bar | :    261 / 391 sentences=16
inference step:  26
inference step:  27
inference step:  24
inference step:  21
inference step:  19
inference step:  210
inference step:  41
inference step:  31
inference step:  44
inference step:  20
2024-11-21 07:25:19 | INFO | fairseq.logging.progress_bar | :    271 / 391 sentences=16
2024-11-21 07:25:19 | INFO | fairseq.logging.progress_bar | :    261 / 391 sentences=16
inference step:  210
inference step:  29
inference step:  39
inference step:  28
inference step:  34
inference step:  30
inference step:  41
inference step:  210
inference step:  42
inference step:  52
inference step:  210
inference step:  23
inference step:  63
inference step:  32
inference step:  66
inference step:  71
inference step:  25
inference step:  23
inference step:  38
inference step:  33
inference step:  210
inference step:  210
inference step:  58
inference step:  55
inference step:  34
inference step:  31
inference step:  33
inference step:  21
inference step:  43
inference step:  62
inference step:  33
inference step:  23
inference step:  31
inference step:  40
inference step:  82
inference step:  32
2024-11-21 07:25:39 | INFO | fairseq.logging.progress_bar | :    281 / 391 sentences=16
inference step:  27
inference step:  22
inference step:  30
inference step:  78
2024-11-21 07:25:40 | INFO | fairseq.logging.progress_bar | :    261 / 391 sentences=16
inference step:  210
2024-11-21 07:25:41 | INFO | fairseq.logging.progress_bar | :    261 / 391 sentences=16
inference step:  42
inference step:  30
inference step:  54
inference step:  68
inference step:  210
2024-11-21 07:25:44 | INFO | fairseq.logging.progress_bar | :    271 / 391 sentences=16
inference step:  43
inference step:  37
inference step:  34
inference step:  210
inference step:  34
inference step:  38
inference step:  210
inference step:  20
inference step:  29
inference step:  210
inference step:  210
inference step:  25
inference step:  31
inference step:  19
inference step:  210
inference step:  27
2024-11-21 07:25:53 | INFO | fairseq.logging.progress_bar | :    281 / 391 sentences=16
2024-11-21 07:25:54 | INFO | fairseq.logging.progress_bar | :    271 / 391 sentences=16
inference step:  28
inference step:  20
inference step:  30
2024-11-21 07:25:57 | INFO | fairseq.logging.progress_bar | :    261 / 391 sentences=16
inference step:  32
inference step:  210
inference step:  34
inference step:  210
inference step:  21
inference step:  23
inference step:  24
inference step:  27
inference step:  210
inference step:  26
inference step:  30
inference step:  39
inference step:  39
inference step:  43
inference step:  21
inference step:  23
inference step:  210
inference step:  30
inference step:  210
inference step:  32
inference step:  210
inference step:  32
inference step:  210
inference step:  24
inference step:  210
inference step:  29
inference step:  210
inference step:  210
inference step:  21
inference step:  210
inference step:  39
inference step:  210
2024-11-21 07:26:17 | INFO | fairseq.logging.progress_bar | :    271 / 391 sentences=16
inference step:  32
inference step:  210
inference step:  210
inference step:  33
inference step:  210
inference step:  27
inference step:  29
inference step:  22
inference step:  36
inference step:  210
inference step:  36
inference step:  28
inference step:  30
inference step:  23
inference step:  210
inference step:  29
2024-11-21 07:26:25 | INFO | fairseq.logging.progress_bar | :    271 / 391 sentences=16
inference step:  38
2024-11-21 07:26:26 | INFO | fairseq.logging.progress_bar | :    271 / 391 sentences=16
inference step:  21
inference step:  34
inference step:  34
inference step:  18
inference step:  50
inference step:  25
inference step:  26
inference step:  36
inference step:  50
2024-11-21 07:26:31 | INFO | fairseq.logging.progress_bar | :    291 / 391 sentences=16
inference step:  25
inference step:  36
inference step:  23
inference step:  210
inference step:  26
inference step:  38
inference step:  25
2024-11-21 07:26:35 | INFO | fairseq.logging.progress_bar | :    281 / 391 sentences=16
inference step:  27
inference step:  67
inference step:  34
inference step:  31
inference step:  44
inference step:  22
2024-11-21 07:26:39 | INFO | fairseq.logging.progress_bar | :    271 / 391 sentences=16
inference step:  20
inference step:  29
inference step:  210
inference step:  34
inference step:  40
2024-11-21 07:26:41 | INFO | fairseq.logging.progress_bar | :    281 / 391 sentences=16
inference step:  34
inference step:  45
inference step:  32
2024-11-21 07:26:43 | INFO | fairseq.logging.progress_bar | :    291 / 391 sentences=16
inference step:  19
inference step:  35
inference step:  23
inference step:  64
inference step:  24
inference step:  35
inference step:  62
inference step:  18
inference step:  34
inference step:  28
inference step:  36
inference step:  35
inference step:  22
inference step:  31
inference step:  45
inference step:  27
inference step:  58
inference step:  23
inference step:  23
inference step:  40
inference step:  210
inference step:  21
inference step:  25
inference step:  33
inference step:  30
inference step:  25
inference step:  23
inference step:  25
inference step:  46
inference step:  26
inference step:  32
inference step:  27
inference step:  46
inference step:  32
inference step:  24
inference step:  28
inference step:  45
2024-11-21 07:27:04 | INFO | fairseq.logging.progress_bar | :    281 / 391 sentences=16
inference step:  23
inference step:  34
inference step:  24
inference step:  49
inference step:  66
inference step:  25
inference step:  210
inference step:  27
inference step:  29
inference step:  32
inference step:  30
inference step:  51
inference step:  32
inference step:  25
inference step:  43
inference step:  85
inference step:  43
inference step:  33
2024-11-21 07:27:14 | INFO | fairseq.logging.progress_bar | :    281 / 391 sentences=16
inference step:  30
2024-11-21 07:27:15 | INFO | fairseq.logging.progress_bar | :    301 / 391 sentences=16
2024-11-21 07:27:15 | INFO | fairseq.logging.progress_bar | :    281 / 391 sentences=16
inference step:  26
inference step:  36
inference step:  49
inference step:  44
inference step:  18
inference step:  46
inference step:  210
inference step:  32
inference step:  26
2024-11-21 07:27:19 | INFO | fairseq.logging.progress_bar | :    281 / 391 sentences=16
inference step:  71
inference step:  30
inference step:  62
inference step:  66
2024-11-21 07:27:22 | INFO | fairseq.logging.progress_bar | :    291 / 391 sentences=16
inference step:  26
inference step:  49
2024-11-21 07:27:23 | INFO | fairseq.logging.progress_bar | :    301 / 391 sentences=16
inference step:  45
inference step:  25
inference step:  31
inference step:  210
inference step:  46
inference step:  210
inference step:  31
inference step:  28
inference step:  44
inference step:  64
2024-11-21 07:27:29 | INFO | fairseq.logging.progress_bar | :    291 / 391 sentences=16
inference step:  24
inference step:  26
inference step:  25
inference step:  25
inference step:  27
inference step:  210
inference step:  45
inference step:  210
inference step:  28
inference step:  50
inference step:  210
inference step:  24
inference step:  51
inference step:  29
inference step:  42
inference step:  29
inference step:  28
inference step:  210
inference step:  28
inference step:  24
inference step:  67
inference step:  210
inference step:  68
inference step:  48
inference step:  32
inference step:  35
2024-11-21 07:27:46 | INFO | fairseq.logging.progress_bar | :    291 / 391 sentences=16
inference step:  48
inference step:  43
inference step:  23
inference step:  23
inference step:  210
inference step:  40
inference step:  36
inference step:  37
inference step:  30
inference step:  210
inference step:  50
inference step:  33
inference step:  210
inference step:  22
inference step:  39
inference step:  21
inference step:  43
inference step:  210
inference step:  210
inference step:  39
inference step:  34
inference step:  37
inference step:  29
inference step:  210
inference step:  36
inference step:  45
inference step:  210
inference step:  30
inference step:  210
2024-11-21 07:28:02 | INFO | fairseq.logging.progress_bar | :    291 / 391 sentences=16
inference step:  41
2024-11-21 07:28:03 | INFO | fairseq.logging.progress_bar | :    291 / 391 sentences=16
inference step:  210
inference step:  41
inference step:  39
2024-11-21 07:28:04 | INFO | fairseq.logging.progress_bar | :    291 / 391 sentences=16
inference step:  29
inference step:  23
inference step:  46
2024-11-21 07:28:07 | INFO | fairseq.logging.progress_bar | :    311 / 391 sentences=16
inference step:  35
2024-11-21 07:28:07 | INFO | fairseq.logging.progress_bar | :    311 / 391 sentences=16
inference step:  27
inference step:  43
inference step:  32
inference step:  58
inference step:  40
inference step:  210
inference step:  78
inference step:  39
inference step:  34
inference step:  48
inference step:  33
2024-11-21 07:28:13 | INFO | fairseq.logging.progress_bar | :    301 / 391 sentences=16
inference step:  29
inference step:  210
inference step:  59
2024-11-21 07:28:15 | INFO | fairseq.logging.progress_bar | :    301 / 391 sentences=16
inference step:  52
inference step:  27
inference step:  32
inference step:  210
inference step:  41
inference step:  31
inference step:  21
inference step:  31
inference step:  38
inference step:  210
inference step:  23
inference step:  33
inference step:  26
inference step:  36
inference step:  30
inference step:  22
inference step:  45
inference step:  43
inference step:  29
inference step:  29
inference step:  28
inference step:  32
inference step:  210
inference step:  35
inference step:  31
inference step:  33
inference step:  33
inference step:  31
inference step:  26
inference step:  28
inference step:  34
inference step:  45
inference step:  28
inference step:  78
inference step:  31
inference step:  22
inference step:  44
inference step:  210
inference step:  24
inference step:  26
inference step:  24
inference step:  29
inference step:  23
2024-11-21 07:28:42 | INFO | fairseq.logging.progress_bar | :    301 / 391 sentences=16
inference step:  23
inference step:  36
inference step:  23
inference step:  26
inference step:  210
inference step:  32
inference step:  25
inference step:  21
inference step:  20
inference step:  28
inference step:  25
inference step:  210
inference step:  37
inference step:  26
2024-11-21 07:28:49 | INFO | fairseq.logging.progress_bar | :    321 / 391 sentences=16
inference step:  31
inference step:  23
2024-11-21 07:28:50 | INFO | fairseq.logging.progress_bar | :    301 / 391 sentences=16
inference step:  31
inference step:  39
inference step:  33
inference step:  28
2024-11-21 07:28:53 | INFO | fairseq.logging.progress_bar | :    321 / 391 sentences=16
inference step:  72
inference step:  45
inference step:  57
inference step:  32
inference step:  31
inference step:  31
inference step:  41
2024-11-21 07:28:57 | INFO | fairseq.logging.progress_bar | :    301 / 391 sentences=16
inference step:  79
2024-11-21 07:28:57 | INFO | fairseq.logging.progress_bar | :    311 / 391 sentences=16
2024-11-21 07:28:58 | INFO | fairseq.logging.progress_bar | :    301 / 391 sentences=16
inference step:  39
inference step:  35
inference step:  34
2024-11-21 07:29:00 | INFO | fairseq.logging.progress_bar | :    311 / 391 sentences=16
inference step:  210
inference step:  30
inference step:  26
inference step:  210
inference step:  23
inference step:  37
inference step:  71
inference step:  56
inference step:  41
inference step:  31
inference step:  47
inference step:  60
inference step:  64
inference step:  29
inference step:  60
inference step:  210
inference step:  22
inference step:  48
inference step:  41
inference step:  210
inference step:  53
inference step:  18
inference step:  19
inference step:  26
inference step:  210
inference step:  20
inference step:  210
inference step:  26
inference step:  36
inference step:  26
inference step:  24
inference step:  44
inference step:  39
inference step:  25
inference step:  27
inference step:  28
inference step:  40
inference step:  29
inference step:  41
inference step:  210
inference step:  23
inference step:  39
inference step:  210
inference step:  42
inference step:  35
inference step:  28
inference step:  29
2024-11-21 07:29:29 | INFO | fairseq.logging.progress_bar | :    311 / 391 sentences=16
inference step:  39
inference step:  28
inference step:  53
inference step:  74
2024-11-21 07:29:31 | INFO | fairseq.logging.progress_bar | :    331 / 391 sentences=16
inference step:  31
inference step:  37
inference step:  210
inference step:  33
inference step:  68
inference step:  26
inference step:  30
inference step:  23
inference step:  37
inference step:  60
inference step:  77
2024-11-21 07:29:37 | INFO | fairseq.logging.progress_bar | :    311 / 391 sentences=16
inference step:  210
inference step:  44
inference step:  20
inference step:  210
2024-11-21 07:29:39 | INFO | fairseq.logging.progress_bar | :    331 / 391 sentences=16
inference step:  30
2024-11-21 07:29:40 | INFO | fairseq.logging.progress_bar | :    311 / 391 sentences=16
inference step:  30
inference step:  31
inference step:  210
inference step:  166
inference step:  26
inference step:  33
inference step:  26
inference step:  25
2024-11-21 07:29:46 | INFO | fairseq.logging.progress_bar | :    321 / 391 sentences=16
inference step:  34
inference step:  210
inference step:  46
inference step:  32
inference step:  210
2024-11-21 07:29:48 | INFO | fairseq.logging.progress_bar | :    311 / 391 sentences=16
inference step:  29
inference step:  32
inference step:  210
inference step:  31
inference step:  29
inference step:  32
inference step:  50
inference step:  25
inference step:  27
inference step:  210
inference step:  45
inference step:  25
inference step:  35
inference step:  39
inference step:  20
inference step:  29
inference step:  45
inference step:  28
inference step:  20
inference step:  51
inference step:  53
inference step:  23
2024-11-21 07:30:00 | INFO | fairseq.logging.progress_bar | :    321 / 391 sentences=16
inference step:  29
inference step:  210
inference step:  24
inference step:  29
inference step:  27
inference step:  27
inference step:  32
inference step:  23
inference step:  210
inference step:  28
inference step:  73
inference step:  210
inference step:  24
inference step:  59
inference step:  30
inference step:  210
inference step:  25
inference step:  43
inference step:  32
inference step:  32
inference step:  42
inference step:  25
inference step:  24
2024-11-21 07:30:13 | INFO | fairseq.logging.progress_bar | :    321 / 391 sentences=16
inference step:  210
inference step:  38
inference step:  23
inference step:  22
2024-11-21 07:30:15 | INFO | fairseq.logging.progress_bar | :    341 / 391 sentences=16
inference step:  26
inference step:  27
inference step:  210
inference step:  17
2024-11-21 07:30:18 | INFO | fairseq.logging.progress_bar | :    341 / 391 sentences=16
inference step:  27
2024-11-21 07:30:18 | INFO | fairseq.logging.progress_bar | :    321 / 391 sentences=16
inference step:  30
inference step:  20
inference step:  23
inference step:  21
inference step:  22
inference step:  20
inference step:  22
inference step:  29
inference step:  42
inference step:  210
inference step:  32
inference step:  28
inference step:  210
inference step:  25
2024-11-21 07:30:26 | INFO | fairseq.logging.progress_bar | :    331 / 391 sentences=16
inference step:  24
inference step:  31
inference step:  24
inference step:  89
inference step:  32
inference step:  35
inference step:  210
inference step:  25
inference step:  21
inference step:  33
inference step:  27
inference step:  27
inference step:  210
inference step:  23
inference step:  30
inference step:  23
inference step:  24
inference step:  36
inference step:  30
2024-11-21 07:30:36 | INFO | fairseq.logging.progress_bar | :    321 / 391 sentences=16
2024-11-21 07:30:36 | INFO | fairseq.logging.progress_bar | :    321 / 391 sentences=16
inference step:  210
inference step:  27
inference step:  28
inference step:  26
inference step:  52
inference step:  91
inference step:  210
inference step:  24
inference step:  25
inference step:  55
inference step:  26
inference step:  33
inference step:  46
inference step:  26
inference step:  33
inference step:  25
inference step:  210
inference step:  58
inference step:  28
inference step:  58
inference step:  210
inference step:  36
inference step:  23
inference step:  210
2024-11-21 07:30:49 | INFO | fairseq.logging.progress_bar | :    331 / 391 sentences=16
inference step:  26
inference step:  29
inference step:  54
inference step:  30
inference step:  210
inference step:  33
inference step:  21
inference step:  27
inference step:  47
inference step:  21
inference step:  30
inference step:  210
inference step:  20
inference step:  105
inference step:  18
2024-11-21 07:30:58 | INFO | fairseq.logging.progress_bar | :    331 / 391 sentences=16
inference step:  17
inference step:  37
2024-11-21 07:30:59 | INFO | fairseq.logging.progress_bar | :    351 / 391 sentences=16
inference step:  39
inference step:  19
inference step:  56
2024-11-21 07:31:00 | INFO | fairseq.logging.progress_bar | :    351 / 391 sentences=16
inference step:  22
inference step:  31
inference step:  25
inference step:  210
inference step:  21
inference step:  36
inference step:  21
inference step:  25
inference step:  30
inference step:  23
inference step:  36
2024-11-21 07:31:06 | INFO | fairseq.logging.progress_bar | :    341 / 391 sentences=16
inference step:  19
inference step:  30
inference step:  31
inference step:  21
2024-11-21 07:31:09 | INFO | fairseq.logging.progress_bar | :    331 / 391 sentences=16
inference step:  33
inference step:  41
inference step:  35
inference step:  19
inference step:  31
inference step:  210
inference step:  22
2024-11-21 07:31:13 | INFO | fairseq.logging.progress_bar | :    331 / 391 sentences=16
inference step:  23
inference step:  23
inference step:  54
inference step:  32
inference step:  65
inference step:  29
inference step:  32
inference step:  33
inference step:  21
inference step:  21
inference step:  30
inference step:  28
inference step:  33
inference step:  28
inference step:  26
inference step:  36
inference step:  23
2024-11-21 07:31:22 | INFO | fairseq.logging.progress_bar | :    331 / 391 sentences=16
inference step:  210
inference step:  23
inference step:  39
inference step:  47
inference step:  19
inference step:  210
inference step:  73
inference step:  24
inference step:  38
inference step:  33
inference step:  33
inference step:  35
inference step:  67
inference step:  15
inference step:  34
inference step:  25
inference step:  36
inference step:  48
inference step:  38
inference step:  32
inference step:  51
inference step:  29
inference step:  25
inference step:  35
inference step:  31
inference step:  34
inference step:  45
2024-11-21 07:31:37 | INFO | fairseq.logging.progress_bar | :    341 / 391 sentences=16
inference step:  25
inference step:  33
inference step:  43
2024-11-21 07:31:39 | INFO | fairseq.logging.progress_bar | :    341 / 391 sentences=16
inference step:  25
inference step:  28
inference step:  37
inference step:  26
inference step:  25
inference step:  29
inference step:  22
2024-11-21 07:31:43 | INFO | fairseq.logging.progress_bar | :    361 / 391 sentences=16
inference step:  39
inference step:  27
inference step:  36
inference step:  33
inference step:  21
2024-11-21 07:31:45 | INFO | fairseq.logging.progress_bar | :    351 / 391 sentences=16
inference step:  210
inference step:  32
inference step:  27
inference step:  26
inference step:  32
inference step:  24
inference step:  35
2024-11-21 07:31:49 | INFO | fairseq.logging.progress_bar | :    361 / 391 sentences=16
inference step:  32
inference step:  27
2024-11-21 07:31:50 | INFO | fairseq.logging.progress_bar | :    341 / 391 sentences=16
inference step:  42
inference step:  29
inference step:  33
inference step:  22
inference step:  27
inference step:  210
inference step:  40
inference step:  25
inference step:  29
inference step:  22
inference step:  23
inference step:  31
inference step:  24
2024-11-21 07:31:58 | INFO | fairseq.logging.progress_bar | :    341 / 391 sentences=16
inference step:  30
inference step:  32
inference step:  27
inference step:  31
inference step:  22
inference step:  26
inference step:  39
inference step:  28
inference step:  30
inference step:  35
inference step:  28
inference step:  45
inference step:  37
inference step:  35
inference step:  55
inference step:  29
inference step:  58
inference step:  30
inference step:  85
inference step:  43
inference step:  23
inference step:  39
inference step:  210
2024-11-21 07:32:11 | INFO | fairseq.logging.progress_bar | :    341 / 391 sentences=16
inference step:  34
inference step:  16
inference step:  45
inference step:  60
inference step:  35
inference step:  24
inference step:  28
inference step:  41
inference step:  27
inference step:  30
inference step:  35
inference step:  34
inference step:  78
inference step:  210
inference step:  31
inference step:  31
inference step:  35
2024-11-21 07:32:20 | INFO | fairseq.logging.progress_bar | :    351 / 391 sentences=16
inference step:  23
inference step:  37
inference step:  29
inference step:  21
inference step:  19
inference step:  105
inference step:  210
inference step:  37
inference step:  28
inference step:  42
2024-11-21 07:32:26 | INFO | fairseq.logging.progress_bar | :    351 / 391 sentences=16
inference step:  30
inference step:  24
inference step:  35
inference step:  210
inference step:  20
inference step:  45
inference step:  37
2024-11-21 07:32:30 | INFO | fairseq.logging.progress_bar | :    371 / 391 sentences=16
inference step:  25
inference step:  210
inference step:  22
inference step:  28
inference step:  29
2024-11-21 07:32:33 | INFO | fairseq.logging.progress_bar | :    351 / 391 sentences=16
inference step:  35
inference step:  22
inference step:  41
2024-11-21 07:32:35 | INFO | fairseq.logging.progress_bar | :    371 / 391 sentences=16
2024-11-21 07:32:35 | INFO | fairseq.logging.progress_bar | :    361 / 391 sentences=16
inference step:  32
inference step:  44
inference step:  27
inference step:  210
inference step:  46
inference step:  25
inference step:  25
inference step:  16
inference step:  26
inference step:  36
inference step:  33
inference step:  210
inference step:  32
inference step:  210
inference step:  27
inference step:  53
inference step:  45
inference step:  38
inference step:  30
2024-11-21 07:32:47 | INFO | fairseq.logging.progress_bar | :    351 / 391 sentences=16
inference step:  23
inference step:  31
inference step:  49
inference step:  210
inference step:  55
inference step:  56
inference step:  37
inference step:  57
inference step:  36
inference step:  210
inference step:  26
inference step:  210
inference step:  59
inference step:  21
2024-11-21 07:32:55 | INFO | fairseq.logging.progress_bar | :    351 / 391 sentences=16
inference step:  30
inference step:  17
inference step:  42
inference step:  35
inference step:  27
inference step:  37
inference step:  210
inference step:  210
inference step:  25
inference step:  29
inference step:  58
inference step:  21
inference step:  35
inference step:  32
2024-11-21 07:33:04 | INFO | fairseq.logging.progress_bar | :    361 / 391 sentences=16
inference step:  210
inference step:  25
inference step:  210
inference step:  210
inference step:  210
inference step:  32
inference step:  36
inference step:  22
inference step:  47
inference step:  47
inference step:  31
inference step:  32
inference step:  25
inference step:  64
inference step:  32
inference step:  210
inference step:  210
2024-11-21 07:33:13 | INFO | fairseq.logging.progress_bar | :    361 / 391 sentences=16
inference step:  44
inference step:  25
inference step:  22
inference step:  35
inference step:  20
inference step:  17
inference step:  30
inference step:  28
2024-11-21 07:33:19 | INFO | fairseq.logging.progress_bar | :    371 / 391 sentences=16
2024-11-21 07:33:19 | INFO | fairseq.logging.progress_bar | :    381 / 391 sentences=16
inference step:  56
inference step:  25
inference step:  210
2024-11-21 07:33:20 | INFO | fairseq.logging.progress_bar | :    381 / 391 sentences=16
inference step:  56
inference step:  28
inference step:  37
inference step:  210
inference step:  34
inference step:  31
inference step:  35
inference step:  28
inference step:  64
inference step:  71
inference step:  28
inference step:  30
inference step:  34
inference step:  30
inference step:  24
2024-11-21 07:33:28 | INFO | fairseq.logging.progress_bar | :    361 / 391 sentences=16
inference step:  34
inference step:  26
inference step:  36
inference step:  30
inference step:  35
inference step:  27
inference step:  36
inference step:  43
2024-11-21 07:33:33 | INFO | fairseq.logging.progress_bar | :    361 / 391 sentences=16
inference step:  23
inference step:  26
inference step:  47
inference step:  47
inference step:  45
inference step:  28
inference step:  23
inference step:  22
inference step:  16
inference step:  29
inference step:  57
inference step:  51
inference step:  27
inference step:  33
inference step:  30
inference step:  30
inference step:  44
2024-11-21 07:33:43 | INFO | fairseq.logging.progress_bar | :    361 / 391 sentences=16
inference step:  22
inference step:  210
inference step:  26
inference step:  210
inference step:  40
inference step:  39
inference step:  42
inference step:  23
inference step:  30
inference step:  40
inference step:  210
inference step:  71
inference step:  16
inference step:  22
inference step:  39
inference step:  43
inference step:  210
inference step:  39
inference step:  21
inference step:  64
inference step:  27
inference step:  43
inference step:  210
inference step:  28
inference step:  46
inference step:  40
2024-11-21 07:33:58 | INFO | fairseq.logging.progress_bar | :    381 / 391 sentences=16
inference step:  32
inference step:  210
inference step:  40
inference step:  25
inference step:  24
2024-11-21 07:34:01 | INFO | fairseq.logging.progress_bar | :    391 / 391 sentences=10
2024-11-21 07:34:01 | INFO | fairseq.logging.progress_bar | :    391 / 391 sentences=10
inference step:  44
inference step:  210
2024-11-21 07:34:03 | INFO | fairseq.logging.progress_bar | :    371 / 391 sentences=16
inference step:  29
inference step:  210
inference step:  50
inference step:  31
2024-11-21 07:34:06 | INFO | fairseq.logging.progress_bar | :    371 / 391 sentences=16
2024-11-21 07:34:06 | INFO | fairseq.logging.progress_bar | :    371 / 391 sentences=16
inference step:  23
inference step:  49
inference step:  22
inference step:  210
inference step:  23
inference step:  26
inference step:  26
inference step:  32
inference step:  44
inference step:  28
inference step:  210
inference step:  55
inference step:  54
inference step:  46
inference step:  33
inference step:  26
inference step:  42
inference step:  70
inference step:  30
inference step:  69
inference step:  22
inference step:  33
2024-11-21 07:34:22 | INFO | fairseq.logging.progress_bar | :    371 / 391 sentences=16
inference step:  28
inference step:  29
inference step:  24
inference step:  32
inference step:  40
inference step:  27
inference step:  26
inference step:  43
inference step:  49
inference step:  37
inference step:  23
inference step:  22
inference step:  32
2024-11-21 07:34:33 | INFO | fairseq.logging.progress_bar | :    371 / 391 sentences=16
inference step:  31
inference step:  21
inference step:  30
inference step:  44
inference step:  34
inference step:  210
inference step:  26
inference step:  28
inference step:  40
inference step:  38
inference step:  33
inference step:  210
inference step:  28
inference step:  24
inference step:  67
inference step:  42
2024-11-21 07:34:44 | INFO | fairseq.logging.progress_bar | :    391 / 391 sentences=10
inference step:  22
2024-11-21 07:34:45 | INFO | fairseq.logging.progress_bar | :    381 / 391 sentences=16
inference step:  27
inference step:  210
inference step:  22
2024-11-21 07:34:49 | INFO | fairseq.logging.progress_bar | :    381 / 391 sentences=16
inference step:  210
inference step:  35
inference step:  32
inference step:  17
inference step:  102
inference step:  210
inference step:  97
inference step:  22
inference step:  210
inference step:  49
inference step:  35
2024-11-21 07:35:00 | INFO | fairseq.logging.progress_bar | :    381 / 391 sentences=16
inference step:  32
inference step:  33
inference step:  25
inference step:  210
inference step:  39
2024-11-21 07:35:05 | INFO | fairseq.logging.progress_bar | :    381 / 391 sentences=16
inference step:  27
inference step:  24
inference step:  49
inference step:  42
inference step:  34
inference step:  19
inference step:  89
inference step:  79
inference step:  16
inference step:  19
inference step:  25
inference step:  21
inference step:  51
inference step:  24
inference step:  31
inference step:  46
inference step:  24
inference step:  41
inference step:  48
inference step:  76
inference step:  40
inference step:  33
inference step:  23
2024-11-21 07:35:24 | INFO | fairseq.logging.progress_bar | :    381 / 391 sentences=16
inference step:  29
2024-11-21 07:35:27 | INFO | fairseq.logging.progress_bar | :    391 / 391 sentences=10
inference step:  21
inference step:  210
inference step:  50
inference step:  26
inference step:  50
inference step:  32
inference step:  23
inference step:  23
2024-11-21 07:35:32 | INFO | fairseq.logging.progress_bar | :    391 / 391 sentences=10
inference step:  48
inference step:  25
inference step:  20
inference step:  18
inference step:  29
inference step:  30
inference step:  210
inference step:  34
inference step:  35
2024-11-21 07:35:48 | INFO | fairseq.logging.progress_bar | :    391 / 391 sentences=10
inference step:  210
inference step:  57
2024-11-21 07:35:52 | INFO | fairseq.logging.progress_bar | :    391 / 391 sentences=10
inference step:  27
inference step:  40
2024-11-21 07:35:58 | INFO | fairseq.logging.progress_bar | :    391 / 391 sentences=10
2024-11-21 07:35:58 | INFO | ofa.evaluate | sample_cnt: tensor([50000.], device='cuda:0'), mIoU score: 0.647, oIoU score: 0.743, ap det score (box prec@0.5): 0.9141, f score: 0.7436, J&F: 0.6953

2024-11-21 07:35:58 | INFO | ofa.evaluate | sample_cnt: tensor([50000.], device='cuda:3'), mIoU score: 0.647, oIoU score: 0.743, ap det score (box prec@0.5): 0.9141, f score: 0.7436, J&F: 0.6953

2024-11-21 07:35:58 | INFO | ofa.evaluate | sample_cnt: tensor([50000.], device='cuda:7'), mIoU score: 0.647, oIoU score: 0.743, ap det score (box prec@0.5): 0.9141, f score: 0.7436, J&F: 0.6953

2024-11-21 07:35:58 | INFO | ofa.evaluate | sample_cnt: tensor([50000.], device='cuda:4'), mIoU score: 0.647, oIoU score: 0.743, ap det score (box prec@0.5): 0.9141, f score: 0.7436, J&F: 0.6953

2024-11-21 07:35:58 | INFO | ofa.evaluate | sample_cnt: tensor([50000.], device='cuda:1'), mIoU score: 0.647, oIoU score: 0.743, ap det score (box prec@0.5): 0.9141, f score: 0.7436, J&F: 0.6953

2024-11-21 07:35:58 | INFO | ofa.evaluate | sample_cnt: tensor([50000.], device='cuda:2'), mIoU score: 0.647, oIoU score: 0.743, ap det score (box prec@0.5): 0.9141, f score: 0.7436, J&F: 0.6953

2024-11-21 07:35:58 | INFO | ofa.evaluate | sample_cnt: tensor([50000.], device='cuda:5'), mIoU score: 0.647, oIoU score: 0.743, ap det score (box prec@0.5): 0.9141, f score: 0.7436, J&F: 0.6953

2024-11-21 07:35:58 | INFO | ofa.evaluate | sample_cnt: tensor([50000.], device='cuda:6'), mIoU score: 0.647, oIoU score: 0.743, ap det score (box prec@0.5): 0.9141, f score: 0.7436, J&F: 0.6953

2024-11-21 07:35:58 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 1
2024-11-21 07:35:58 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 3
2024-11-21 07:35:58 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 7
2024-11-21 07:35:58 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 4
2024-11-21 07:35:58 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2024-11-21 07:35:58 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 5
2024-11-21 07:35:58 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 6
2024-11-21 07:35:58 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 2
2024-11-21 07:35:58 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-11-21 07:35:58 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-11-21 07:35:58 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-11-21 07:35:58 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-11-21 07:35:58 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-11-21 07:35:58 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-11-21 07:35:58 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-11-21 07:35:58 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
