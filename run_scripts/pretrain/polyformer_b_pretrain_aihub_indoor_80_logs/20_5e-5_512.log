/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launch.py:188: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  FutureWarning,
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2024-10-31 08:19:17 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu117 available.
2024-10-31 08:19:17 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu117 available.
2024-10-31 08:19:17 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu117 available.
2024-10-31 08:19:17 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu117 available.
2024-10-31 08:19:17 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu117 available.
2024-10-31 08:19:17 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu117 available.
2024-10-31 08:19:17 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu117 available.
2024-10-31 08:19:17 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu117 available.
2024-10-31 08:19:23 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2024-10-31 08:19:23 - utils.py[line:261] - INFO: Start init
2024-10-31 08:19:23 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2024-10-31 08:19:23 - utils.py[line:258] - INFO: distributed init (rank 2): env://
2024-10-31 08:19:23 - utils.py[line:261] - INFO: Start init
2024-10-31 08:19:23 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 2
2024-10-31 08:19:23 - utils.py[line:258] - INFO: distributed init (rank 4): env://
2024-10-31 08:19:23 - utils.py[line:261] - INFO: Start init
2024-10-31 08:19:23 - utils.py[line:258] - INFO: distributed init (rank 5): env://
2024-10-31 08:19:23 - utils.py[line:261] - INFO: Start init
2024-10-31 08:19:23 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 4
2024-10-31 08:19:23 - utils.py[line:258] - INFO: distributed init (rank 7): env://
2024-10-31 08:19:23 - utils.py[line:261] - INFO: Start init
2024-10-31 08:19:23 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 5
2024-10-31 08:19:23 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 7
2024-10-31 08:19:23 - utils.py[line:258] - INFO: distributed init (rank 6): env://
2024-10-31 08:19:23 - utils.py[line:261] - INFO: Start init
2024-10-31 08:19:23 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 6
2024-10-31 08:19:23 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2024-10-31 08:19:23 - utils.py[line:261] - INFO: Start init
2024-10-31 08:19:23 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2024-10-31 08:19:23 - utils.py[line:258] - INFO: distributed init (rank 3): env://
2024-10-31 08:19:23 - utils.py[line:261] - INFO: Start init
2024-10-31 08:19:23 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 3
2024-10-31 08:19:23 - distributed_c10d.py[line:354] - INFO: Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-10-31 08:19:23 - utils.py[line:274] - INFO: initialized host cheetah-676973745f61696c6162-gzn5in-5cbcd8c768-b46pk as rank 3
single-machine distributed training is initialized.
2024-10-31 08:19:23 - distributed_c10d.py[line:354] - INFO: Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-10-31 08:19:23 - utils.py[line:274] - INFO: initialized host cheetah-676973745f61696c6162-gzn5in-5cbcd8c768-b46pk as rank 6
single-machine distributed training is initialized.
2024-10-31 08:19:23 - distributed_c10d.py[line:354] - INFO: Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-10-31 08:19:23 - utils.py[line:274] - INFO: initialized host cheetah-676973745f61696c6162-gzn5in-5cbcd8c768-b46pk as rank 2
single-machine distributed training is initialized.
2024-10-31 08:19:23 - distributed_c10d.py[line:354] - INFO: Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-10-31 08:19:23 - utils.py[line:274] - INFO: initialized host cheetah-676973745f61696c6162-gzn5in-5cbcd8c768-b46pk as rank 4
single-machine distributed training is initialized.
2024-10-31 08:19:23 - distributed_c10d.py[line:354] - INFO: Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-10-31 08:19:23 - utils.py[line:274] - INFO: initialized host cheetah-676973745f61696c6162-gzn5in-5cbcd8c768-b46pk as rank 5
2024-10-31 08:19:23 - distributed_c10d.py[line:354] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
single-machine distributed training is initialized.
2024-10-31 08:19:23 - utils.py[line:274] - INFO: initialized host cheetah-676973745f61696c6162-gzn5in-5cbcd8c768-b46pk as rank 0
single-machine distributed training is initialized.
2024-10-31 08:19:23 - distributed_c10d.py[line:354] - INFO: Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-10-31 08:19:23 - utils.py[line:274] - INFO: initialized host cheetah-676973745f61696c6162-gzn5in-5cbcd8c768-b46pk as rank 7
2024-10-31 08:19:23 - distributed_c10d.py[line:354] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
single-machine distributed training is initialized.
2024-10-31 08:19:23 - utils.py[line:274] - INFO: initialized host cheetah-676973745f61696c6162-gzn5in-5cbcd8c768-b46pk as rank 1
single-machine distributed training is initialized.
2024-10-31 08:19:28 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../polyformer_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 1000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 20, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 20, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 1000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'score', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='polyformer_b', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='polyformer_b', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid=20, best_checkpoint_metric='score', bf16=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, cls_weight=0.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../datasets/pretrain/train_aihub_indoor_80.tsv,../../datasets/pretrain/val_aihub_indoor_80.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, det_weight=1.0, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_acc=True, eval_args='{"beam":5,"min_len":2,"max_len_a":0,"max_len_b":2}', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=20, max_image_size=512, max_source_positions=1024, max_src_length=80, max_target_positions=1024, max_tgt_length=420, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=8, num_bins=64, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', out_index=3, pad=1, patch_image_size=512, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, restore_file='checkpoint_last.pt', sample_patch_num=196, save_dir='./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512', save_interval=1, save_interval_updates=1000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', scst=False, scst_args='{}', seed=1, selected_cols='0,3,1,2', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='refcoco_pretrain', tensorboard_logdir=None, threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[8], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../polyformer_module', uses_ema=False, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=1000, vis_encoder_type='swin-base', wandb_project=None, warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'refcoco_pretrain', 'data': '../../datasets/pretrain/train_aihub_indoor_80.tsv,../../datasets/pretrain/val_aihub_indoor_80.tsv', 'selected_cols': '0,3,1,2', 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 80, 'max_tgt_length': 420, 'code_dict_size': 8192, 'patch_image_size': 512, 'num_bins': 64, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': True, 'eval_args': '{"beam":5,"min_len":2,"max_len_a":0,"max_len_b":2}', 'uses_ema': False, 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'det_weight': 1.0, 'cls_weight': 0.0, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2024-10-31 08:19:28 - base_task.py[line:187] - INFO: source dictionary: 4100 types
2024-10-31 08:19:28 - base_task.py[line:188] - INFO: target dictionary: 4100 types
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
The model and loaded state dict do not match exactly

unexpected key in source state_dict: norm.weight, norm.bias, head.weight, head.bias, layers.0.blocks.1.attn_mask, layers.1.blocks.1.attn_mask, layers.2.blocks.1.attn_mask, layers.2.blocks.3.attn_mask, layers.2.blocks.5.attn_mask, layers.2.blocks.7.attn_mask, layers.2.blocks.9.attn_mask, layers.2.blocks.11.attn_mask, layers.2.blocks.13.attn_mask, layers.2.blocks.15.attn_mask, layers.2.blocks.17.attn_mask

missing keys in source state_dict: norm3.weight, norm3.bias

Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 1 row count 6840 total row count 54715
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 2 row count 6840 total row count 54715
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
The model and loaded state dict do not match exactly

unexpected key in source state_dict: norm.weight, norm.bias, head.weight, head.bias, layers.0.blocks.1.attn_mask, layers.1.blocks.1.attn_mask, layers.2.blocks.1.attn_mask, layers.2.blocks.3.attn_mask, layers.2.blocks.5.attn_mask, layers.2.blocks.7.attn_mask, layers.2.blocks.9.attn_mask, layers.2.blocks.11.attn_mask, layers.2.blocks.13.attn_mask, layers.2.blocks.15.attn_mask, layers.2.blocks.17.attn_mask

missing keys in source state_dict: norm3.weight, norm3.bias

2024-10-31 08:19:42 - train.py[line:101] - INFO: PolyFormerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(4100, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): SwinTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (pos_drop): Dropout(p=0.0, inplace=False)
      (layers): ModuleList(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): Identity()
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.009)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=512, out_features=256, bias=False)
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=256, out_features=256, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.017)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=256, out_features=1024, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1024, out_features=256, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=256, out_features=256, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.026)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=256, out_features=1024, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1024, out_features=256, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=1024, out_features=512, bias=False)
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.035)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.043)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (2): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.052)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (3): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.061)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (4): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.070)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (5): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.078)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (6): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.087)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (7): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.096)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (8): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.104)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (9): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.113)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (10): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.122)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (11): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.130)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (12): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.139)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (13): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.148)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (14): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.157)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (15): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.165)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (16): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.174)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (17): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.183)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=2048, out_features=1024, bias=False)
            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.191)
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.200)
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
      )
      (norm3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
    (bert): XLMRobertaForMaskedLM(
      (roberta): XLMRobertaModel(
        (embeddings): XLMRobertaEmbeddings(
          (word_embeddings): Embedding(250002, 768, padding_idx=1)
          (position_embeddings): Embedding(514, 768, padding_idx=1)
          (token_type_embeddings): Embedding(1, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): XLMRobertaEncoder(
          (layer): ModuleList(
            (0): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
      )
      (lm_head): XLMRobertaLMHead(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (decoder): Linear(in_features=768, out_features=250002, bias=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(4100, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (reg_head): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): Linear(in_features=768, out_features=768, bias=True)
        (2): Linear(in_features=768, out_features=2, bias=True)
      )
    )
    (cls_head): Linear(in_features=768, out_features=3, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2024-10-31 08:19:42 - train.py[line:102] - INFO: task: RefcocoPretrainTask
2024-10-31 08:19:42 - train.py[line:103] - INFO: model: PolyFormerModel
2024-10-31 08:19:42 - train.py[line:104] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2024-10-31 08:19:42 - train.py[line:108] - INFO: num. shared model params: 478,547,732 (num. trained: 478,547,732)
2024-10-31 08:19:42 - train.py[line:115] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 5 row count 6839 total row count 54715
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 4 row count 6839 total row count 54715
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 6 row count 6839 total row count 54715
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 0 row count 6840 total row count 54715
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 3 row count 6839 total row count 54715
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 7 row count 6839 total row count 54715
2024-10-31 08:19:43 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2024-10-31 08:19:44 - distributed_c10d.py[line:354] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-10-31 08:19:44 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2024-10-31 08:19:44 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.layers.0.downsample.reduction.bias <- encoder.embed_images.layers.1.downsample.reduction.bias
2024-10-31 08:19:44 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.layers.0.downsample.reduction.bias <- encoder.embed_images.layers.2.downsample.reduction.bias
2024-10-31 08:19:44 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.layers.0.downsample.reduction.bias <- decoder.cls_head.bias
2024-10-31 08:19:44 - trainer.py[line:124] - INFO: detected shared parameter: encoder.bert.roberta.embeddings.word_embeddings.weight <- encoder.bert.lm_head.decoder.weight
2024-10-31 08:19:44 - trainer.py[line:124] - INFO: detected shared parameter: encoder.bert.lm_head.bias <- encoder.bert.lm_head.decoder.bias
2024-10-31 08:19:46 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 8 workers***********************
2024-10-31 08:19:46 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.394 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-10-31 08:19:46 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.394 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-10-31 08:19:46 - utils.py[line:765] - INFO: rank   2: capabilities =  8.0  ; total memory = 39.394 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-10-31 08:19:46 - utils.py[line:765] - INFO: rank   3: capabilities =  8.0  ; total memory = 39.394 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-10-31 08:19:46 - utils.py[line:765] - INFO: rank   4: capabilities =  8.0  ; total memory = 39.394 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-10-31 08:19:46 - utils.py[line:765] - INFO: rank   5: capabilities =  8.0  ; total memory = 39.394 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-10-31 08:19:46 - utils.py[line:765] - INFO: rank   6: capabilities =  8.0  ; total memory = 39.394 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-10-31 08:19:46 - utils.py[line:765] - INFO: rank   7: capabilities =  8.0  ; total memory = 39.394 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-10-31 08:19:46 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 8 workers***********************
2024-10-31 08:19:46 - train.py[line:145] - INFO: training on 8 devices (GPUs/TPUs)
2024-10-31 08:19:46 - train.py[line:151] - INFO: max tokens per device = None and max sentences per device = 20
2024-10-31 08:19:46 - trainer.py[line:458] - INFO: Preparing to load checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 08:19:46 - trainer.py[line:624] - INFO: No existing checkpoint found ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 08:19:46 - trainer.py[line:639] - INFO: loading train data for epoch 1
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping





local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000


local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
slice_id 4 seek offset 200000
slice_id 2 seek offset 100000
slice_id 3 seek offset 150000
slice_id 7 seek offset 350000
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
slice_id 5 seek offset 250000
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
slice_id 1 seek offset 50000
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
slice_id 6 seek offset 300000
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
slice_id 0 seek offset 0
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
2024-10-31 08:19:50 - trainer.py[line:703] - INFO: begin training epoch 1
2024-10-31 08:19:50 - train.py[line:297] - INFO: Start iterating over samples
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/jovyan/SSDb/miniconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
loss_reg: 0.3369140625 loss_cls: 0.0
loss_reg: 0.32861328125 loss_cls: 0.0
loss_reg: 0.361572265625 loss_cls: 0.0
loss_reg: 0.30712890625 loss_cls: 0.0
loss_reg: 0.336669921875 loss_cls: 0.0
loss_reg: 0.353271484375 loss_cls: 0.0
loss_reg: 0.42138671875 loss_cls: 0.0
loss_reg: 0.38427734375 loss_cls: 0.0
loss_reg: 0.377197265625 loss_cls: 0.0
loss_reg: 0.34033203125 loss_cls: 0.0
loss_reg: 0.36474609375 loss_cls: 0.0
loss_reg: 0.32275390625 loss_cls: 0.0
loss_reg: 0.33984375 loss_cls: 0.0
loss_reg: 0.341552734375 loss_cls: 0.0
loss_reg: 0.314697265625 loss_cls: 0.0
loss_reg: 0.332763671875 loss_cls: 0.0
loss_reg: 0.340087890625 loss_cls: 0.0
loss_reg: 0.323974609375 loss_cls: 0.0
loss_reg: 0.308349609375 loss_cls: 0.0
loss_reg: 0.370361328125 loss_cls: 0.0
loss_reg: 0.34716796875 loss_cls: 0.0
loss_reg: 0.31787109375 loss_cls: 0.0
loss_reg: 0.32177734375 loss_cls: 0.0
loss_reg: 0.30029296875 loss_cls: 0.0
loss_reg: 0.34765625 loss_cls: 0.0
loss_reg: 0.33056640625 loss_cls: 0.0
loss_reg: 0.404541015625 loss_cls: 0.0
loss_reg: 0.313232421875 loss_cls: 0.0
loss_reg: 0.373291015625 loss_cls: 0.0
loss_reg: 0.3662109375 loss_cls: 0.0
loss_reg: 0.31005859375 loss_cls: 0.0
loss_reg: 0.37109375 loss_cls: 0.0
loss_reg: 0.38427734375 loss_cls: 0.0
loss_reg: 0.384033203125 loss_cls: 0.0
loss_reg: 0.34326171875 loss_cls: 0.0
loss_reg: 0.374267578125 loss_cls: 0.0
loss_reg: 0.314208984375 loss_cls: 0.0
loss_reg: 0.340576171875 loss_cls: 0.0
loss_reg: 0.3583984375 loss_cls: 0.0
loss_reg: 0.3466796875 loss_cls: 0.0
loss_reg: 0.327880859375 loss_cls: 0.0
loss_reg: 0.323486328125 loss_cls: 0.0
loss_reg: 0.33740234375 loss_cls: 0.0
loss_reg: 0.354736328125 loss_cls: 0.0
loss_reg: 0.331787109375 loss_cls: 0.0
loss_reg: 0.3427734375 loss_cls: 0.0
loss_reg: 0.35009765625 loss_cls: 0.0
loss_reg: 0.36572265625 loss_cls: 0.0
loss_reg: 0.36328125 loss_cls: 0.0
loss_reg: 0.390625 loss_cls: 0.0
loss_reg: 0.32421875 loss_cls: 0.0
loss_reg: 0.321044921875 loss_cls: 0.0
loss_reg: 0.35302734375 loss_cls: 0.0
loss_reg: 0.341064453125 loss_cls: 0.0
loss_reg: 0.365234375 loss_cls: 0.0
loss_reg: 0.358154296875 loss_cls: 0.0
loss_reg: 0.34716796875 loss_cls: 0.0
loss_reg: 0.37841796875 loss_cls: 0.0
loss_reg: 0.35888671875 loss_cls: 0.0
loss_reg: 0.31591796875 loss_cls: 0.0
loss_reg: 0.312255859375 loss_cls: 0.0
loss_reg: 0.37255859375 loss_cls: 0.0
loss_reg: 0.37890625 loss_cls: 0.0
loss_reg: 0.375732421875 loss_cls: 0.0
2024-10-31 08:22:00 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 313 loss=0.017, loss_v1=0, loss_v2=0, nll_loss=3.255, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.54, wps=415.9, ups=0.08, wpb=5117.9, bsz=1280, num_updates=10, lr=1.33333e-06, gnorm=0.033, clip=0, loss_scale=128, train_wall=39, gb_free=9.5, wall=133
2024-10-31 08:24:05 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 313 loss=0.016, loss_v1=0, loss_v2=0, nll_loss=3.316, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.96, wps=410, ups=0.08, wpb=5118.4, bsz=1280, num_updates=20, lr=2.66667e-06, gnorm=0.02, clip=0, loss_scale=128, train_wall=40, gb_free=9.5, wall=258
2024-10-31 08:26:08 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 313 loss=0.015, loss_v1=0, loss_v2=0, nll_loss=3.444, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.89, wps=413.6, ups=0.08, wpb=5117.7, bsz=1280, num_updates=30, lr=4e-06, gnorm=0.012, clip=0, loss_scale=128, train_wall=40, gb_free=9.5, wall=382
2024-10-31 08:28:12 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 313 loss=0.015, loss_v1=0, loss_v2=0, nll_loss=3.697, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.97, wps=413.4, ups=0.08, wpb=5117.7, bsz=1280, num_updates=40, lr=5.33333e-06, gnorm=0.013, clip=0, loss_scale=128, train_wall=37, gb_free=9.5, wall=506
2024-10-31 08:30:15 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 313 loss=0.013, loss_v1=0, loss_v2=0, nll_loss=3.905, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=14.98, wps=414.9, ups=0.08, wpb=5118.3, bsz=1280, num_updates=50, lr=6.66667e-06, gnorm=0.016, clip=0, loss_scale=128, train_wall=35, gb_free=9.5, wall=629
2024-10-31 08:32:19 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 313 loss=0.012, loss_v1=0, loss_v2=0, nll_loss=3.797, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.9, wps=415.2, ups=0.08, wpb=5118.4, bsz=1280, num_updates=60, lr=8e-06, gnorm=0.017, clip=0, loss_scale=128, train_wall=41, gb_free=9.5, wall=752
2024-10-31 08:34:22 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 313 loss=0.011, loss_v1=0, loss_v2=0, nll_loss=4.029, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=16.33, wps=413.8, ups=0.08, wpb=5118.4, bsz=1280, num_updates=70, lr=9.33333e-06, gnorm=0.012, clip=0, loss_scale=128, train_wall=58, gb_free=9.6, wall=876
2024-10-31 08:36:27 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 313 loss=0.01, loss_v1=0, loss_v2=0, nll_loss=4.21, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=18.51, wps=411.8, ups=0.08, wpb=5117.3, bsz=1280, num_updates=80, lr=1.06667e-05, gnorm=0.011, clip=0, loss_scale=128, train_wall=67, gb_free=9.5, wall=1000
2024-10-31 08:38:30 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 313 loss=0.01, loss_v1=0, loss_v2=0, nll_loss=4.176, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=18.07, wps=416.7, ups=0.08, wpb=5118.6, bsz=1280, num_updates=90, lr=1.2e-05, gnorm=0.008, clip=0, loss_scale=128, train_wall=74, gb_free=9.6, wall=1123
2024-10-31 08:40:32 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 313 loss=0.009, loss_v1=0, loss_v2=0, nll_loss=4.137, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=17.6, wps=417.4, ups=0.08, wpb=5118.3, bsz=1280, num_updates=100, lr=1.33333e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=70, gb_free=9.5, wall=1246
2024-10-31 08:42:35 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 313 loss=0.009, loss_v1=0, loss_v2=0, nll_loss=4.08, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=16.91, wps=418, ups=0.08, wpb=5118.6, bsz=1280, num_updates=110, lr=1.46667e-05, gnorm=0.006, clip=0, loss_scale=128, train_wall=70, gb_free=9.5, wall=1368
2024-10-31 08:44:38 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 313 loss=0.009, loss_v1=0, loss_v2=0, nll_loss=4.13, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=17.51, wps=414.8, ups=0.08, wpb=5117.7, bsz=1280, num_updates=120, lr=1.6e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=86, gb_free=9.5, wall=1492
2024-10-31 08:46:41 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 313 loss=0.009, loss_v1=0, loss_v2=0, nll_loss=4.166, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=17.95, wps=415.1, ups=0.08, wpb=5118.7, bsz=1280, num_updates=130, lr=1.73333e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=103, gb_free=9.4, wall=1615
2024-10-31 08:48:44 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 313 loss=0.009, loss_v1=0, loss_v2=0, nll_loss=4.176, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=18.07, wps=416.1, ups=0.08, wpb=5117.9, bsz=1280, num_updates=140, lr=1.86667e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=109, gb_free=9.6, wall=1738
2024-10-31 08:50:47 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 313 loss=0.009, loss_v1=0, loss_v2=0, nll_loss=4.163, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=17.91, wps=418.8, ups=0.08, wpb=5117.6, bsz=1280, num_updates=150, lr=2e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=113, gb_free=9.6, wall=1860
2024-10-31 08:52:48 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 313 loss=0.009, loss_v1=0, loss_v2=0, nll_loss=4.168, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=17.98, wps=419.8, ups=0.08, wpb=5117.6, bsz=1280, num_updates=160, lr=2.13333e-05, gnorm=0.006, clip=0, loss_scale=128, train_wall=107, gb_free=9.4, wall=1982
2024-10-31 08:54:51 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 313 loss=0.009, loss_v1=0, loss_v2=0, nll_loss=4.192, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=18.28, wps=418.4, ups=0.08, wpb=5117.7, bsz=1280, num_updates=170, lr=2.26667e-05, gnorm=0.008, clip=0, loss_scale=128, train_wall=100, gb_free=9.5, wall=2104
2024-10-31 08:56:53 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 313 loss=0.009, loss_v1=0, loss_v2=0, nll_loss=4.282, ntokens=5117.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=19.46, wps=416.9, ups=0.08, wpb=5117.5, bsz=1280, num_updates=180, lr=2.4e-05, gnorm=0.008, clip=0, loss_scale=128, train_wall=99, gb_free=9.5, wall=2227
2024-10-31 08:58:56 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=4.26, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=19.16, wps=418.7, ups=0.08, wpb=5117.7, bsz=1280, num_updates=190, lr=2.53333e-05, gnorm=0.011, clip=0, loss_scale=128, train_wall=98, gb_free=9.5, wall=2349
2024-10-31 09:00:58 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=4.122, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=17.41, wps=419.8, ups=0.08, wpb=5118, bsz=1280, num_updates=200, lr=2.66667e-05, gnorm=0.013, clip=0, loss_scale=128, train_wall=100, gb_free=9.5, wall=2471
2024-10-31 09:03:01 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=4.065, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=16.73, wps=416.1, ups=0.08, wpb=5118.2, bsz=1280, num_updates=210, lr=2.8e-05, gnorm=0.009, clip=0, loss_scale=128, train_wall=102, gb_free=9.5, wall=2594
2024-10-31 09:05:03 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=4.036, ntokens=5118.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=16.41, wps=417.7, ups=0.08, wpb=5118.8, bsz=1280, num_updates=220, lr=2.93333e-05, gnorm=0.012, clip=0, loss_scale=128, train_wall=108, gb_free=9.5, wall=2717
2024-10-31 09:07:05 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.968, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=15.65, wps=419.4, ups=0.08, wpb=5117.4, bsz=1280, num_updates=230, lr=3.06667e-05, gnorm=0.034, clip=0, loss_scale=128, train_wall=116, gb_free=9.5, wall=2839
2024-10-31 09:09:08 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.897, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=14.89, wps=415.4, ups=0.08, wpb=5117.9, bsz=1280, num_updates=240, lr=3.2e-05, gnorm=0.01, clip=0, loss_scale=128, train_wall=115, gb_free=9.5, wall=2962
2024-10-31 09:11:11 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.875, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=14.67, wps=417.3, ups=0.08, wpb=5118.2, bsz=1280, num_updates=250, lr=3.33333e-05, gnorm=0.008, clip=0, loss_scale=128, train_wall=123, gb_free=9.5, wall=3085
2024-10-31 09:13:13 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.91, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=15.03, wps=418.9, ups=0.08, wpb=5118.1, bsz=1280, num_updates=260, lr=3.46667e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=122, gb_free=9.5, wall=3207
2024-10-31 09:15:16 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.933, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=15.27, wps=418.5, ups=0.08, wpb=5118.1, bsz=1280, num_updates=270, lr=3.6e-05, gnorm=0.008, clip=0, loss_scale=128, train_wall=122, gb_free=9.5, wall=3329
2024-10-31 09:17:17 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.971, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=15.68, wps=419.9, ups=0.08, wpb=5118.6, bsz=1280, num_updates=280, lr=3.73333e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=122, gb_free=9.5, wall=3451
2024-10-31 09:19:20 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.978, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=15.76, wps=417.8, ups=0.08, wpb=5117.6, bsz=1280, num_updates=290, lr=3.86667e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=122, gb_free=9.5, wall=3574
2024-10-31 09:21:22 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.952, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=15.47, wps=420.6, ups=0.08, wpb=5118.7, bsz=1280, num_updates=300, lr=4e-05, gnorm=0.008, clip=0, loss_scale=128, train_wall=122, gb_free=9.5, wall=3695
2024-10-31 09:23:24 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.92, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=15.14, wps=417.2, ups=0.08, wpb=5118.2, bsz=1280, num_updates=310, lr=4.13333e-05, gnorm=0.008, clip=0, loss_scale=128, train_wall=123, gb_free=9.5, wall=3818
slice_id 6 seek offset 41037
slice_id 7 seek offset 47876
2024-10-31 09:23:53 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 4 seek offset 27359slice_id 1 seek offset 6840
slice_id 5 seek offset 34198

slice_id 2 seek offset 13680
slice_id 3 seek offset 20520
slice_id 1 seek offset 6840
slice_id 5 seek offset 34198
slice_id 3 seek offset 20520
slice_id 2 seek offset 13680
slice_id 4 seek offset 27359
slice_id 6 seek offset 41037
slice_id 7 seek offset 47876
slice_id 0 seek offset 0
2024-10-31 09:32:41 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.008 | loss_v1 0 | loss_v2 0 | nll_loss 3.988 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 15.87 | score 0.1493 | wps 415.8 | wpb 639.7 | bsz 160 | num_updates 313
2024-10-31 09:32:41 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 313 updates
2024-10-31 09:32:41 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000

file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
slice_id 3 seek offset 150000
slice_id 4 seek offset 200000
slice_id 5 seek offset 250000
slice_id 6 seek offset 300000
slice_id 2 seek offset 100000
slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
2024-10-31 09:32:53 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-10-31 09:33:07 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 1 @ 313 updates, score 0.1493) (writing took 26.010040558874607 seconds)
2024-10-31 09:33:07 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 313 updates
2024-10-31 09:33:07 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 09:33:19 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 09:33:19 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 1 @ 313 updates, score 0) (writing took 11.9156608954072 seconds)
2024-10-31 09:33:19 - train.py[line:336] - INFO: end of epoch 1 (average epoch stats below)
2024-10-31 09:33:19 - progress_bar.py[line:282] - INFO: epoch 001 | loss 0.01 | loss_v1 0 | loss_v2 0 | nll_loss 3.974 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 15.72 | wps 363.1 | ups 0.07 | wpb 5109.9 | bsz 1278 | num_updates 313 | lr 4.17333e-05 | gnorm 0.011 | clip 0 | loss_scale 128 | train_wall 2811 | gb_free 9.5 | wall 4413
2024-10-31 09:33:19 - trainer.py[line:639] - INFO: loading train data for epoch 2
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-10-31 09:33:22 - trainer.py[line:703] - INFO: begin training epoch 2
2024-10-31 09:33:22 - train.py[line:297] - INFO: Start iterating over samples
2024-10-31 09:34:51 - progress_bar.py[line:274] - INFO: epoch 002:      7 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.919, ntokens=4862, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=15.13, wps=70.8, ups=0.01, wpb=4862, bsz=1216, num_updates=320, lr=4.26667e-05, gnorm=0.008, clip=0, loss_scale=128, train_wall=53, gb_free=9.5, wall=4504
2024-10-31 09:36:54 - progress_bar.py[line:274] - INFO: epoch 002:     17 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.931, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=15.25, wps=415, ups=0.08, wpb=5118.1, bsz=1280, num_updates=330, lr=4.4e-05, gnorm=0.006, clip=0, loss_scale=128, train_wall=35, gb_free=9.5, wall=4628
2024-10-31 09:38:57 - progress_bar.py[line:274] - INFO: epoch 002:     27 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.947, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=15.43, wps=417.9, ups=0.08, wpb=5117.6, bsz=1280, num_updates=340, lr=4.53333e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=35, gb_free=9.5, wall=4750
2024-10-31 09:41:01 - progress_bar.py[line:274] - INFO: epoch 002:     37 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.952, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=15.47, wps=410.5, ups=0.08, wpb=5117.6, bsz=1280, num_updates=350, lr=4.66667e-05, gnorm=0.006, clip=0, loss_scale=128, train_wall=35, gb_free=9.5, wall=4875
2024-10-31 09:43:04 - progress_bar.py[line:274] - INFO: epoch 002:     47 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.94, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=15.34, wps=415.8, ups=0.08, wpb=5118.2, bsz=1280, num_updates=360, lr=4.8e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=35, gb_free=9.5, wall=4998
2024-10-31 09:45:08 - progress_bar.py[line:274] - INFO: epoch 002:     57 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.891, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=14.84, wps=414.1, ups=0.08, wpb=5118.4, bsz=1280, num_updates=370, lr=4.93333e-05, gnorm=0.006, clip=0, loss_scale=128, train_wall=35, gb_free=9.5, wall=5122
2024-10-31 09:47:11 - progress_bar.py[line:274] - INFO: epoch 002:     67 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.91, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=15.04, wps=415.8, ups=0.08, wpb=5118.4, bsz=1280, num_updates=380, lr=4.99575e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=35, gb_free=9.5, wall=5245
2024-10-31 09:49:15 - progress_bar.py[line:274] - INFO: epoch 002:     77 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.918, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=15.11, wps=414, ups=0.08, wpb=5117.7, bsz=1280, num_updates=390, lr=4.98726e-05, gnorm=0.01, clip=0, loss_scale=128, train_wall=35, gb_free=9.5, wall=5368
2024-10-31 09:51:17 - progress_bar.py[line:274] - INFO: epoch 002:     87 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.934, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=15.28, wps=418.9, ups=0.08, wpb=5118.1, bsz=1280, num_updates=400, lr=4.97876e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=35, gb_free=9.5, wall=5491
2024-10-31 09:53:20 - progress_bar.py[line:274] - INFO: epoch 002:     97 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.947, ntokens=5118.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=15.43, wps=414.4, ups=0.08, wpb=5118.9, bsz=1280, num_updates=410, lr=4.97026e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=35, gb_free=9.5, wall=5614
2024-10-31 09:55:24 - progress_bar.py[line:274] - INFO: epoch 002:    107 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.938, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=15.33, wps=415.3, ups=0.08, wpb=5118.3, bsz=1280, num_updates=420, lr=4.96177e-05, gnorm=0.008, clip=0, loss_scale=128, train_wall=35, gb_free=9.5, wall=5737
2024-10-31 09:57:27 - progress_bar.py[line:274] - INFO: epoch 002:    117 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.936, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=15.31, wps=416, ups=0.08, wpb=5117.8, bsz=1280, num_updates=430, lr=4.95327e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=35, gb_free=9.5, wall=5860
2024-10-31 09:59:29 - progress_bar.py[line:274] - INFO: epoch 002:    127 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.894, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=14.87, wps=417.6, ups=0.08, wpb=5118.3, bsz=1280, num_updates=440, lr=4.94477e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=35, gb_free=9.5, wall=5983
2024-10-31 10:01:32 - progress_bar.py[line:274] - INFO: epoch 002:    137 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.848, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=14.4, wps=417, ups=0.08, wpb=5118.4, bsz=1280, num_updates=450, lr=4.93628e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=35, gb_free=9.5, wall=6106
2024-10-31 10:03:35 - progress_bar.py[line:274] - INFO: epoch 002:    147 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.816, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=14.09, wps=415, ups=0.08, wpb=5117.4, bsz=1280, num_updates=460, lr=4.92778e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=35, gb_free=9.5, wall=6229
2024-10-31 10:05:38 - progress_bar.py[line:274] - INFO: epoch 002:    157 / 313 loss=0.008, loss_v1=0, loss_v2=0, nll_loss=3.853, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=14.45, wps=417.8, ups=0.08, wpb=5117.6, bsz=1280, num_updates=470, lr=4.91929e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=35, gb_free=9.6, wall=6351
2024-10-31 10:07:41 - progress_bar.py[line:274] - INFO: epoch 002:    167 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.905, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=14.98, wps=414, ups=0.08, wpb=5117.9, bsz=1280, num_updates=480, lr=4.91079e-05, gnorm=0.006, clip=0, loss_scale=128, train_wall=35, gb_free=9.5, wall=6475
2024-10-31 10:09:44 - progress_bar.py[line:274] - INFO: epoch 002:    177 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.943, ntokens=5117.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=15.38, wps=416.3, ups=0.08, wpb=5117.5, bsz=1280, num_updates=490, lr=4.90229e-05, gnorm=0.008, clip=0, loss_scale=128, train_wall=35, gb_free=9.5, wall=6598
2024-10-31 10:11:47 - progress_bar.py[line:274] - INFO: epoch 002:    187 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.906, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=14.99, wps=417.2, ups=0.08, wpb=5117.7, bsz=1280, num_updates=500, lr=4.8938e-05, gnorm=0.008, clip=0, loss_scale=128, train_wall=35, gb_free=9.5, wall=6721
2024-10-31 10:13:50 - progress_bar.py[line:274] - INFO: epoch 002:    197 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.886, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=14.78, wps=417.8, ups=0.08, wpb=5117.6, bsz=1280, num_updates=510, lr=4.8853e-05, gnorm=0.009, clip=0, loss_scale=128, train_wall=35, gb_free=9.5, wall=6843
2024-10-31 10:15:52 - progress_bar.py[line:274] - INFO: epoch 002:    207 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.808, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=14, wps=417, ups=0.08, wpb=5118.3, bsz=1280, num_updates=520, lr=4.87681e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=6966
2024-10-31 10:17:55 - progress_bar.py[line:274] - INFO: epoch 002:    217 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.761, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.56, wps=415.5, ups=0.08, wpb=5118.6, bsz=1280, num_updates=530, lr=4.86831e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=7089
2024-10-31 10:19:58 - progress_bar.py[line:274] - INFO: epoch 002:    227 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.741, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.37, wps=416.9, ups=0.08, wpb=5118.3, bsz=1280, num_updates=540, lr=4.85981e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=7212
2024-10-31 10:22:01 - progress_bar.py[line:274] - INFO: epoch 002:    237 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.743, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.39, wps=417.5, ups=0.08, wpb=5117.3, bsz=1280, num_updates=550, lr=4.85132e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=7334
2024-10-31 10:24:02 - progress_bar.py[line:274] - INFO: epoch 002:    247 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.735, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.32, wps=420.6, ups=0.08, wpb=5118.3, bsz=1280, num_updates=560, lr=4.84282e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=7456
2024-10-31 10:26:06 - progress_bar.py[line:274] - INFO: epoch 002:    257 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.742, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.38, wps=413.3, ups=0.08, wpb=5118, bsz=1280, num_updates=570, lr=4.83432e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=7580
2024-10-31 10:28:10 - progress_bar.py[line:274] - INFO: epoch 002:    267 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.757, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.52, wps=413.4, ups=0.08, wpb=5117.8, bsz=1280, num_updates=580, lr=4.82583e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=7704
2024-10-31 10:30:14 - progress_bar.py[line:274] - INFO: epoch 002:    277 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.734, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.31, wps=414.2, ups=0.08, wpb=5118.7, bsz=1280, num_updates=590, lr=4.81733e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=7827
2024-10-31 10:32:17 - progress_bar.py[line:274] - INFO: epoch 002:    287 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.738, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.34, wps=416.3, ups=0.08, wpb=5118.1, bsz=1280, num_updates=600, lr=4.80884e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=7950
2024-10-31 10:34:20 - progress_bar.py[line:274] - INFO: epoch 002:    297 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.684, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.86, wps=414.1, ups=0.08, wpb=5118.4, bsz=1280, num_updates=610, lr=4.80034e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=8074
2024-10-31 10:36:24 - progress_bar.py[line:274] - INFO: epoch 002:    307 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.673, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.76, wps=413.6, ups=0.08, wpb=5118, bsz=1280, num_updates=620, lr=4.79184e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=8198
slice_id 6 seek offset 41037
2024-10-31 10:37:29 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 4 seek offset 27359
slice_id 7 seek offset 47876slice_id 5 seek offset 34198

slice_id 1 seek offset 6840slice_id 2 seek offset 13680

slice_id 3 seek offset 20520
slice_id 2 seek offset 13680
slice_id 4 seek offset 27359
slice_id 3 seek offset 20520
slice_id 1 seek offset 6840
slice_id 6 seek offset 41037
slice_id 7 seek offset 47876
slice_id 0 seek offset 0
slice_id 5 seek offset 34198
2024-10-31 10:46:18 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss 0.007 | loss_v1 0 | loss_v2 0 | nll_loss 3.772 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 13.66 | score 0.1543 | wps 415.1 | wpb 639.7 | bsz 160 | num_updates 626 | best_score 0.1543
2024-10-31 10:46:18 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 626 updates
2024-10-31 10:46:18 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping



local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
slice_id 4 seek offset 200000
slice_id 3 seek offset 150000
slice_id 7 seek offset 350000
slice_id 2 seek offset 100000
slice_id 1 seek offset 50000
slice_id 5 seek offset 250000
slice_id 6 seek offset 300000
2024-10-31 10:46:29 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-10-31 10:46:42 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 2 @ 626 updates, score 0.1543) (writing took 23.34429758042097 seconds)
2024-10-31 10:46:42 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 626 updates
2024-10-31 10:46:42 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 10:46:53 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 10:46:53 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 2 @ 626 updates, score 0) (writing took 11.70165491476655 seconds)
2024-10-31 10:46:53 - train.py[line:336] - INFO: end of epoch 2 (average epoch stats below)
2024-10-31 10:46:53 - progress_bar.py[line:282] - INFO: epoch 002 | loss 0.008 | loss_v1 0 | loss_v2 0 | nll_loss 3.846 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 14.38 | wps 362.3 | ups 0.07 | wpb 5109.9 | bsz 1278 | num_updates 626 | lr 4.78675e-05 | gnorm 0.007 | clip 0 | loss_scale 256 | train_wall 1101 | gb_free 9.5 | wall 8827
2024-10-31 10:46:53 - trainer.py[line:639] - INFO: loading train data for epoch 3
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-10-31 10:46:56 - trainer.py[line:703] - INFO: begin training epoch 3
2024-10-31 10:46:56 - train.py[line:297] - INFO: Start iterating over samples
2024-10-31 10:47:48 - progress_bar.py[line:274] - INFO: epoch 003:      4 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.686, ntokens=4862, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=12.87, wps=71, ups=0.01, wpb=4862, bsz=1216, num_updates=630, lr=4.78335e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=33, gb_free=9.5, wall=8882
2024-10-31 10:49:50 - progress_bar.py[line:274] - INFO: epoch 003:     14 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.623, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.32, wps=419.2, ups=0.08, wpb=5118.2, bsz=1280, num_updates=640, lr=4.77485e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=9004
2024-10-31 10:51:53 - progress_bar.py[line:274] - INFO: epoch 003:     24 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.616, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.26, wps=417.4, ups=0.08, wpb=5117.7, bsz=1280, num_updates=650, lr=4.76636e-05, gnorm=0.009, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=9127
2024-10-31 10:53:55 - progress_bar.py[line:274] - INFO: epoch 003:     34 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.636, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.43, wps=418.9, ups=0.08, wpb=5117.6, bsz=1280, num_updates=660, lr=4.75786e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=35, gb_free=9.6, wall=9249
2024-10-31 10:55:57 - progress_bar.py[line:274] - INFO: epoch 003:     44 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.716, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.14, wps=419.6, ups=0.08, wpb=5118, bsz=1280, num_updates=670, lr=4.74936e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=9371
2024-10-31 10:58:00 - progress_bar.py[line:274] - INFO: epoch 003:     54 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.709, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.08, wps=416.4, ups=0.08, wpb=5118.7, bsz=1280, num_updates=680, lr=4.74087e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=9494
2024-10-31 11:00:02 - progress_bar.py[line:274] - INFO: epoch 003:     64 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.707, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.06, wps=419.1, ups=0.08, wpb=5118.1, bsz=1280, num_updates=690, lr=4.73237e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=9616
2024-10-31 11:02:04 - progress_bar.py[line:274] - INFO: epoch 003:     74 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.692, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.92, wps=418.8, ups=0.08, wpb=5118, bsz=1280, num_updates=700, lr=4.72387e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=9738
2024-10-31 11:04:06 - progress_bar.py[line:274] - INFO: epoch 003:     84 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.631, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.39, wps=419.9, ups=0.08, wpb=5117.8, bsz=1280, num_updates=710, lr=4.71538e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=9860
2024-10-31 11:06:09 - progress_bar.py[line:274] - INFO: epoch 003:     94 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.582, ntokens=5118.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.98, wps=418.9, ups=0.08, wpb=5118.9, bsz=1280, num_updates=720, lr=4.70688e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=9982
2024-10-31 11:08:12 - progress_bar.py[line:274] - INFO: epoch 003:    104 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.621, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.3, wps=415.3, ups=0.08, wpb=5118.3, bsz=1280, num_updates=730, lr=4.69839e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=10105
2024-10-31 11:10:14 - progress_bar.py[line:274] - INFO: epoch 003:    114 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.684, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.86, wps=418.5, ups=0.08, wpb=5118, bsz=1280, num_updates=740, lr=4.68989e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=10228
2024-10-31 11:12:17 - progress_bar.py[line:274] - INFO: epoch 003:    124 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.68, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.82, wps=417.4, ups=0.08, wpb=5118.4, bsz=1280, num_updates=750, lr=4.68139e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=10350
2024-10-31 11:14:19 - progress_bar.py[line:274] - INFO: epoch 003:    134 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.632, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.4, wps=417.7, ups=0.08, wpb=5118.4, bsz=1280, num_updates=760, lr=4.6729e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=35, gb_free=9.6, wall=10473
2024-10-31 11:16:21 - progress_bar.py[line:274] - INFO: epoch 003:    144 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.679, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.81, wps=419.3, ups=0.08, wpb=5117.3, bsz=1280, num_updates=770, lr=4.6644e-05, gnorm=0.009, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=10595
2024-10-31 11:18:24 - progress_bar.py[line:274] - INFO: epoch 003:    154 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.644, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.51, wps=418.3, ups=0.08, wpb=5117.7, bsz=1280, num_updates=780, lr=4.6559e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=10717
2024-10-31 11:20:27 - progress_bar.py[line:274] - INFO: epoch 003:    164 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.591, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.05, wps=414.1, ups=0.08, wpb=5117.8, bsz=1280, num_updates=790, lr=4.64741e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=10841
2024-10-31 11:22:30 - progress_bar.py[line:274] - INFO: epoch 003:    174 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.624, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.33, wps=418, ups=0.08, wpb=5117.8, bsz=1280, num_updates=800, lr=4.63891e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=10963
2024-10-31 11:24:32 - progress_bar.py[line:274] - INFO: epoch 003:    184 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.631, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.39, wps=419.8, ups=0.08, wpb=5117.7, bsz=1280, num_updates=810, lr=4.63042e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=11085
2024-10-31 11:26:34 - progress_bar.py[line:274] - INFO: epoch 003:    194 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.627, ntokens=5117.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.35, wps=419.1, ups=0.08, wpb=5117.2, bsz=1280, num_updates=820, lr=4.62192e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=11207
2024-10-31 11:28:36 - progress_bar.py[line:274] - INFO: epoch 003:    204 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.584, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.99, wps=419, ups=0.08, wpb=5118.5, bsz=1280, num_updates=830, lr=4.61342e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=11330
2024-10-31 11:30:38 - progress_bar.py[line:274] - INFO: epoch 003:    214 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.617, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.27, wps=420.6, ups=0.08, wpb=5118.4, bsz=1280, num_updates=840, lr=4.60493e-05, gnorm=0.009, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=11451
2024-10-31 11:32:40 - progress_bar.py[line:274] - INFO: epoch 003:    224 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.644, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.5, wps=418.7, ups=0.08, wpb=5118.6, bsz=1280, num_updates=850, lr=4.59643e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=11573
2024-10-31 11:34:42 - progress_bar.py[line:274] - INFO: epoch 003:    234 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.64, ntokens=5117, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.46, wps=418.5, ups=0.08, wpb=5117, bsz=1280, num_updates=860, lr=4.58794e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=11696
2024-10-31 11:36:44 - progress_bar.py[line:274] - INFO: epoch 003:    244 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.649, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.54, wps=418.5, ups=0.08, wpb=5118.1, bsz=1280, num_updates=870, lr=4.57944e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=11818
2024-10-31 11:38:47 - progress_bar.py[line:274] - INFO: epoch 003:    254 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.633, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.41, wps=418.9, ups=0.08, wpb=5118.2, bsz=1280, num_updates=880, lr=4.57094e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=11940
2024-10-31 11:40:48 - progress_bar.py[line:274] - INFO: epoch 003:    264 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.634, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.42, wps=420.5, ups=0.08, wpb=5118.2, bsz=1280, num_updates=890, lr=4.56245e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=12062
2024-10-31 11:42:50 - progress_bar.py[line:274] - INFO: epoch 003:    274 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.613, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.24, wps=419.3, ups=0.08, wpb=5118.4, bsz=1280, num_updates=900, lr=4.55395e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=12184
2024-10-31 11:44:52 - progress_bar.py[line:274] - INFO: epoch 003:    284 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.634, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.42, wps=419.9, ups=0.08, wpb=5118.1, bsz=1280, num_updates=910, lr=4.54545e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=12306
2024-10-31 11:46:55 - progress_bar.py[line:274] - INFO: epoch 003:    294 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.635, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.42, wps=417.8, ups=0.08, wpb=5118.1, bsz=1280, num_updates=920, lr=4.53696e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=12428
2024-10-31 11:48:58 - progress_bar.py[line:274] - INFO: epoch 003:    304 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.611, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.22, wps=415.3, ups=0.08, wpb=5118, bsz=1280, num_updates=930, lr=4.52846e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=12552
slice_id 4 seek offset 27359
2024-10-31 11:50:41 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 3 seek offset 20520slice_id 7 seek offset 47876

slice_id 0 seek offset 0
slice_id 2 seek offset 13680
slice_id 5 seek offset 34198
slice_id 1 seek offset 6840
slice_id 6 seek offset 41037
slice_id 2 seek offset 13680
slice_id 4 seek offset 27359
slice_id 3 seek offset 20520
slice_id 1 seek offset 6840
slice_id 6 seek offset 41037
slice_id 5 seek offset 34198
slice_id 0 seek offset 0
slice_id 7 seek offset 47876
2024-10-31 11:59:28 - progress_bar.py[line:282] - INFO: epoch 003 | valid on 'valid' subset | loss 0.007 | loss_v1 0 | loss_v2 0 | nll_loss 3.677 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.79 | score 0.196 | wps 416.1 | wpb 639.7 | bsz 160 | num_updates 939 | best_score 0.196
2024-10-31 11:59:28 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 939 updates
2024-10-31 11:59:28 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
slice_id 4 seek offset 200000
slice_id 3 seek offset 150000
slice_id 5 seek offset 250000
slice_id 2 seek offset 100000
slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
slice_id 6 seek offset 300000
2024-10-31 11:59:39 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-10-31 11:59:50 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 3 @ 939 updates, score 0.196) (writing took 21.886801175773144 seconds)
2024-10-31 11:59:51 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 939 updates
2024-10-31 11:59:51 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 12:00:01 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 12:00:02 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 3 @ 939 updates, score 0) (writing took 11.094180896878242 seconds)
2024-10-31 12:00:02 - train.py[line:336] - INFO: end of epoch 3 (average epoch stats below)
2024-10-31 12:00:02 - progress_bar.py[line:282] - INFO: epoch 003 | loss 0.007 | loss_v1 0 | loss_v2 0 | nll_loss 3.64 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.47 | wps 364.5 | ups 0.07 | wpb 5109.9 | bsz 1278 | num_updates 939 | lr 4.52082e-05 | gnorm 0.007 | clip 0 | loss_scale 256 | train_wall 1099 | gb_free 9.5 | wall 13215
2024-10-31 12:00:02 - trainer.py[line:639] - INFO: loading train data for epoch 4
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-10-31 12:00:05 - trainer.py[line:703] - INFO: begin training epoch 4
2024-10-31 12:00:05 - train.py[line:297] - INFO: Start iterating over samples
2024-10-31 12:00:20 - progress_bar.py[line:274] - INFO: epoch 004:      1 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.615, ntokens=4862.4, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=12.26, wps=71.3, ups=0.01, wpb=4862.4, bsz=1216, num_updates=940, lr=4.51997e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=33, gb_free=9.5, wall=13233
2024-10-31 12:02:23 - progress_bar.py[line:274] - INFO: epoch 004:     11 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.613, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.23, wps=417, ups=0.08, wpb=5117.8, bsz=1280, num_updates=950, lr=4.51147e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=35, gb_free=9.4, wall=13356
2024-10-31 12:04:25 - progress_bar.py[line:274] - INFO: epoch 004:     21 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.618, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.27, wps=418.3, ups=0.08, wpb=5118.3, bsz=1280, num_updates=960, lr=4.50297e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=13479
2024-10-31 12:06:28 - progress_bar.py[line:274] - INFO: epoch 004:     31 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.605, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.17, wps=416.9, ups=0.08, wpb=5117.8, bsz=1280, num_updates=970, lr=4.49448e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=13601
2024-10-31 12:08:30 - progress_bar.py[line:274] - INFO: epoch 004:     41 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.637, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.44, wps=419.1, ups=0.08, wpb=5117.8, bsz=1280, num_updates=980, lr=4.48598e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=13723
2024-10-31 12:10:33 - progress_bar.py[line:274] - INFO: epoch 004:     51 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.648, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.54, wps=415.6, ups=0.08, wpb=5118.2, bsz=1280, num_updates=990, lr=4.47749e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=13847
2024-10-31 12:12:35 - progress_bar.py[line:274] - INFO: epoch 004:     61 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.66, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.64, wps=420, ups=0.08, wpb=5118.5, bsz=1280, num_updates=1000, lr=4.46899e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=35, gb_free=9.5, wall=13968
slice_id 2 seek offset 13680
slice_id 4 seek offset 27359
slice_id 6 seek offset 41037
slice_id 3 seek offset 20520
2024-10-31 12:12:35 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 5 seek offset 34198
slice_id 1 seek offset 6840
slice_id 7 seek offset 47876
slice_id 4 seek offset 27359
slice_id 2 seek offset 13680
slice_id 5 seek offset 34198
slice_id 3 seek offset 20520
slice_id 6 seek offset 41037
slice_id 1 seek offset 6840
slice_id 7 seek offset 47876
slice_id 0 seek offset 0
2024-10-31 12:21:23 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 0.007 | loss_v1 0 | loss_v2 0 | nll_loss 3.697 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.97 | score 0.1961 | wps 415.9 | wpb 639.7 | bsz 160 | num_updates 1000 | best_score 0.1961
2024-10-31 12:21:23 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 1000 updates
2024-10-31 12:21:23 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_4_1000.pt
2024-10-31 12:21:34 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_4_1000.pt
2024-10-31 12:21:53 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_4_1000.pt (epoch 4 @ 1000 updates, score 0.1961) (writing took 30.646928396075964 seconds)
2024-10-31 12:23:42 - progress_bar.py[line:274] - INFO: epoch 004:     71 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.634, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.41, wps=76.7, ups=0.01, wpb=5118.1, bsz=1280, num_updates=1010, lr=4.46049e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=35, gb_free=9.4, wall=14636
2024-10-31 12:25:46 - progress_bar.py[line:274] - INFO: epoch 004:     81 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.643, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.49, wps=415.1, ups=0.08, wpb=5117.3, bsz=1280, num_updates=1020, lr=4.452e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=35, gb_free=9.6, wall=14759
2024-10-31 12:27:49 - progress_bar.py[line:274] - INFO: epoch 004:     91 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.664, ntokens=5118.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.68, wps=416.6, ups=0.08, wpb=5118.8, bsz=1280, num_updates=1030, lr=4.4435e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=35, gb_free=9.4, wall=14882
2024-10-31 12:29:51 - progress_bar.py[line:274] - INFO: epoch 004:    101 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.697, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.97, wps=416.9, ups=0.08, wpb=5118.4, bsz=1280, num_updates=1040, lr=4.435e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=15005
2024-10-31 12:31:54 - progress_bar.py[line:274] - INFO: epoch 004:    111 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.694, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.94, wps=416.5, ups=0.08, wpb=5118.4, bsz=1280, num_updates=1050, lr=4.42651e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=15128
2024-10-31 12:33:57 - progress_bar.py[line:274] - INFO: epoch 004:    121 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.715, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.13, wps=418.6, ups=0.08, wpb=5117.9, bsz=1280, num_updates=1060, lr=4.41801e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=15250
2024-10-31 12:35:58 - progress_bar.py[line:274] - INFO: epoch 004:    131 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.719, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.16, wps=419.6, ups=0.08, wpb=5118.7, bsz=1280, num_updates=1070, lr=4.40952e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=15372
2024-10-31 12:38:02 - progress_bar.py[line:274] - INFO: epoch 004:    141 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.7, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13, wps=414.5, ups=0.08, wpb=5117.4, bsz=1280, num_updates=1080, lr=4.40102e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=15496
2024-10-31 12:40:05 - progress_bar.py[line:274] - INFO: epoch 004:    151 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.711, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.09, wps=417.3, ups=0.08, wpb=5117.7, bsz=1280, num_updates=1090, lr=4.39252e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=35, gb_free=9.6, wall=15618
2024-10-31 12:42:07 - progress_bar.py[line:274] - INFO: epoch 004:    161 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.684, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.85, wps=417.6, ups=0.08, wpb=5117.8, bsz=1280, num_updates=1100, lr=4.38403e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=15741
2024-10-31 12:44:09 - progress_bar.py[line:274] - INFO: epoch 004:    171 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.654, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.58, wps=420.8, ups=0.08, wpb=5117.6, bsz=1280, num_updates=1110, lr=4.37553e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=15862
2024-10-31 12:46:12 - progress_bar.py[line:274] - INFO: epoch 004:    181 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.681, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.83, wps=416.5, ups=0.08, wpb=5117.7, bsz=1280, num_updates=1120, lr=4.36703e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=15985
2024-10-31 12:48:13 - progress_bar.py[line:274] - INFO: epoch 004:    191 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.72, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.18, wps=421.7, ups=0.08, wpb=5117.6, bsz=1280, num_updates=1130, lr=4.35854e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=16107
2024-10-31 12:50:15 - progress_bar.py[line:274] - INFO: epoch 004:    201 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.701, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.01, wps=419.6, ups=0.08, wpb=5118.1, bsz=1280, num_updates=1140, lr=4.35004e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=16229
2024-10-31 12:52:17 - progress_bar.py[line:274] - INFO: epoch 004:    211 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.733, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.29, wps=418, ups=0.08, wpb=5118.2, bsz=1280, num_updates=1150, lr=4.34155e-05, gnorm=0.008, clip=0, loss_scale=512, train_wall=35, gb_free=9.6, wall=16351
2024-10-31 12:54:19 - progress_bar.py[line:274] - INFO: epoch 004:    221 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.744, ntokens=5118.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.4, wps=419.6, ups=0.08, wpb=5118.9, bsz=1280, num_updates=1160, lr=4.33305e-05, gnorm=0.008, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=16473
2024-10-31 12:56:21 - progress_bar.py[line:274] - INFO: epoch 004:    231 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.726, ntokens=5117, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.24, wps=419.4, ups=0.08, wpb=5117, bsz=1280, num_updates=1170, lr=4.32455e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=16595
2024-10-31 12:58:24 - progress_bar.py[line:274] - INFO: epoch 004:    241 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.684, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.85, wps=419.2, ups=0.08, wpb=5118.3, bsz=1280, num_updates=1180, lr=4.31606e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=16717
2024-10-31 13:00:26 - progress_bar.py[line:274] - INFO: epoch 004:    251 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.665, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.68, wps=418.8, ups=0.08, wpb=5117.9, bsz=1280, num_updates=1190, lr=4.30756e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=16839
2024-10-31 13:02:27 - progress_bar.py[line:274] - INFO: epoch 004:    261 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.649, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.54, wps=422.1, ups=0.08, wpb=5118.3, bsz=1280, num_updates=1200, lr=4.29907e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=16961
2024-10-31 13:04:29 - progress_bar.py[line:274] - INFO: epoch 004:    271 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.648, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.54, wps=419.7, ups=0.08, wpb=5118.1, bsz=1280, num_updates=1210, lr=4.29057e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=17083
2024-10-31 13:06:32 - progress_bar.py[line:274] - INFO: epoch 004:    281 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.665, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.68, wps=415.8, ups=0.08, wpb=5118.6, bsz=1280, num_updates=1220, lr=4.28207e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=17206
2024-10-31 13:08:34 - progress_bar.py[line:274] - INFO: epoch 004:    291 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.654, ntokens=5117.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.59, wps=420, ups=0.08, wpb=5117.5, bsz=1280, num_updates=1230, lr=4.27358e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=17328
2024-10-31 13:10:37 - progress_bar.py[line:274] - INFO: epoch 004:    301 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.686, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.87, wps=416, ups=0.08, wpb=5118.7, bsz=1280, num_updates=1240, lr=4.26508e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=17451
2024-10-31 13:12:40 - progress_bar.py[line:274] - INFO: epoch 004:    311 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.711, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.09, wps=416.2, ups=0.08, wpb=5117.8, bsz=1280, num_updates=1250, lr=4.25658e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=17574
slice_id 4 seek offset 27359slice_id 7 seek offset 47876
slice_id 2 seek offset 13680

2024-10-31 13:12:57 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 1 seek offset 6840
slice_id 0 seek offset 0
slice_id 5 seek offset 34198
slice_id 6 seek offset 41037
slice_id 3 seek offset 20520
slice_id 4 seek offset 27359
slice_id 1 seek offset 6840
slice_id 2 seek offset 13680
slice_id 5 seek offset 34198
slice_id 6 seek offset 41037
slice_id 3 seek offset 20520
slice_id 0 seek offset 0
slice_id 7 seek offset 47876
2024-10-31 13:21:44 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 0.007 | loss_v1 0 | loss_v2 0 | nll_loss 3.714 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 13.12 | score 0.2103 | wps 416.2 | wpb 639.7 | bsz 160 | num_updates 1252 | best_score 0.2103
2024-10-31 13:21:44 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 1252 updates
2024-10-31 13:21:44 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping


local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
slice_id 4 seek offset 200000
slice_id 6 seek offset 300000
slice_id 2 seek offset 100000
slice_id 3 seek offset 150000
slice_id 5 seek offset 250000
slice_id 7 seek offset 350000
slice_id 1 seek offset 50000
2024-10-31 13:21:54 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-10-31 13:22:06 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 4 @ 1252 updates, score 0.2103) (writing took 22.014255955815315 seconds)
2024-10-31 13:22:06 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 1252 updates
2024-10-31 13:22:06 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 13:22:17 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 13:22:17 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 4 @ 1252 updates, score 0) (writing took 11.28354561328888 seconds)
2024-10-31 13:22:17 - train.py[line:336] - INFO: end of epoch 4 (average epoch stats below)
2024-10-31 13:22:17 - progress_bar.py[line:282] - INFO: epoch 004 | loss 0.007 | loss_v1 0 | loss_v2 0 | nll_loss 3.676 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.78 | wps 324 | ups 0.06 | wpb 5109.9 | bsz 1278 | num_updates 1252 | lr 4.25489e-05 | gnorm 0.006 | clip 0 | loss_scale 512 | train_wall 1099 | gb_free 9.5 | wall 18151
2024-10-31 13:22:17 - trainer.py[line:639] - INFO: loading train data for epoch 5
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-10-31 13:22:20 - trainer.py[line:703] - INFO: begin training epoch 5
2024-10-31 13:22:20 - train.py[line:297] - INFO: Start iterating over samples
2024-10-31 13:24:01 - progress_bar.py[line:274] - INFO: epoch 005:      8 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.672, ntokens=4862.3, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=12.75, wps=71.4, ups=0.01, wpb=4862.3, bsz=1216, num_updates=1260, lr=4.24809e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=33, gb_free=9.5, wall=18255
2024-10-31 13:26:04 - progress_bar.py[line:274] - INFO: epoch 005:     18 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.635, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.42, wps=417.4, ups=0.08, wpb=5117.9, bsz=1280, num_updates=1270, lr=4.23959e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=18378
2024-10-31 13:28:07 - progress_bar.py[line:274] - INFO: epoch 005:     28 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.62, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.3, wps=416.5, ups=0.08, wpb=5117.7, bsz=1280, num_updates=1280, lr=4.2311e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=18500
2024-10-31 13:30:09 - progress_bar.py[line:274] - INFO: epoch 005:     38 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.623, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.32, wps=419.4, ups=0.08, wpb=5117.9, bsz=1280, num_updates=1290, lr=4.2226e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=18622
2024-10-31 13:32:12 - progress_bar.py[line:274] - INFO: epoch 005:     48 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.617, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.27, wps=416.7, ups=0.08, wpb=5118.2, bsz=1280, num_updates=1300, lr=4.2141e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=35, gb_free=9.6, wall=18745
2024-10-31 13:34:14 - progress_bar.py[line:274] - INFO: epoch 005:     58 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.617, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.27, wps=417.2, ups=0.08, wpb=5118.3, bsz=1280, num_updates=1310, lr=4.20561e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=35, gb_free=9.6, wall=18868
2024-10-31 13:36:17 - progress_bar.py[line:274] - INFO: epoch 005:     68 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.601, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.14, wps=415.9, ups=0.08, wpb=5118.5, bsz=1280, num_updates=1320, lr=4.19711e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=18991
2024-10-31 13:38:20 - progress_bar.py[line:274] - INFO: epoch 005:     78 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.604, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.16, wps=418.4, ups=0.08, wpb=5117.6, bsz=1280, num_updates=1330, lr=4.18862e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=19113
2024-10-31 13:40:22 - progress_bar.py[line:274] - INFO: epoch 005:     88 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.6, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.12, wps=417.3, ups=0.08, wpb=5118.1, bsz=1280, num_updates=1340, lr=4.18012e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=19236
2024-10-31 13:42:25 - progress_bar.py[line:274] - INFO: epoch 005:     98 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.643, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.5, wps=418.7, ups=0.08, wpb=5118.6, bsz=1280, num_updates=1350, lr=4.17162e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=19358
2024-10-31 13:44:28 - progress_bar.py[line:274] - INFO: epoch 005:    108 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.659, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.63, wps=415.1, ups=0.08, wpb=5118.5, bsz=1280, num_updates=1360, lr=4.16313e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=19482
2024-10-31 13:46:31 - progress_bar.py[line:274] - INFO: epoch 005:    118 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.621, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.3, wps=416.9, ups=0.08, wpb=5117.9, bsz=1280, num_updates=1370, lr=4.15463e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=19604
2024-10-31 13:48:33 - progress_bar.py[line:274] - INFO: epoch 005:    128 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.608, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.2, wps=418, ups=0.08, wpb=5118.5, bsz=1280, num_updates=1380, lr=4.14613e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=19727
2024-10-31 13:50:35 - progress_bar.py[line:274] - INFO: epoch 005:    138 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.604, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.16, wps=418.9, ups=0.08, wpb=5118.1, bsz=1280, num_updates=1390, lr=4.13764e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.6, wall=19849
2024-10-31 13:52:38 - progress_bar.py[line:274] - INFO: epoch 005:    148 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.598, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.11, wps=417.5, ups=0.08, wpb=5117.6, bsz=1280, num_updates=1400, lr=4.12914e-05, gnorm=0.008, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=19971
2024-10-31 13:54:40 - progress_bar.py[line:274] - INFO: epoch 005:    158 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.56, ntokens=5117.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.8, wps=419.1, ups=0.08, wpb=5117.5, bsz=1280, num_updates=1410, lr=4.12065e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=20094
2024-10-31 13:56:44 - progress_bar.py[line:274] - INFO: epoch 005:    168 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.568, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.86, wps=413.9, ups=0.08, wpb=5118.1, bsz=1280, num_updates=1420, lr=4.11215e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=20217
2024-10-31 13:58:46 - progress_bar.py[line:274] - INFO: epoch 005:    178 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.594, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.08, wps=418.9, ups=0.08, wpb=5117.3, bsz=1280, num_updates=1430, lr=4.10365e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.4, wall=20339
2024-10-31 14:00:48 - progress_bar.py[line:274] - INFO: epoch 005:    188 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.605, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.17, wps=420, ups=0.08, wpb=5117.7, bsz=1280, num_updates=1440, lr=4.09516e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=20461
2024-10-31 14:02:50 - progress_bar.py[line:274] - INFO: epoch 005:    198 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.617, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.27, wps=417.1, ups=0.08, wpb=5117.7, bsz=1280, num_updates=1450, lr=4.08666e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.4, wall=20584
2024-10-31 14:04:53 - progress_bar.py[line:274] - INFO: epoch 005:    208 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.642, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.49, wps=416.2, ups=0.08, wpb=5118.2, bsz=1280, num_updates=1460, lr=4.07816e-05, gnorm=0.008, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=20707
2024-10-31 14:06:56 - progress_bar.py[line:274] - INFO: epoch 005:    218 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.62, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.29, wps=417.7, ups=0.08, wpb=5118.6, bsz=1280, num_updates=1470, lr=4.06967e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=20829
2024-10-31 14:08:58 - progress_bar.py[line:274] - INFO: epoch 005:    228 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.638, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.45, wps=418.6, ups=0.08, wpb=5118.1, bsz=1280, num_updates=1480, lr=4.06117e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=20952
2024-10-31 14:11:00 - progress_bar.py[line:274] - INFO: epoch 005:    238 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.622, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.31, wps=419.2, ups=0.08, wpb=5117.4, bsz=1280, num_updates=1490, lr=4.05268e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=21074
2024-10-31 14:13:03 - progress_bar.py[line:274] - INFO: epoch 005:    248 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.648, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.53, wps=417.9, ups=0.08, wpb=5118.4, bsz=1280, num_updates=1500, lr=4.04418e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=21196
2024-10-31 14:15:05 - progress_bar.py[line:274] - INFO: epoch 005:    258 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.652, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.57, wps=417, ups=0.08, wpb=5118, bsz=1280, num_updates=1510, lr=4.03568e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=21319
2024-10-31 14:17:08 - progress_bar.py[line:274] - INFO: epoch 005:    268 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.669, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.72, wps=417.7, ups=0.08, wpb=5117.8, bsz=1280, num_updates=1520, lr=4.02719e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=21442
2024-10-31 14:19:10 - progress_bar.py[line:274] - INFO: epoch 005:    278 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.663, ntokens=5118.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.67, wps=418.5, ups=0.08, wpb=5118.8, bsz=1280, num_updates=1530, lr=4.01869e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.5, wall=21564
2024-10-31 14:21:12 - progress_bar.py[line:274] - INFO: epoch 005:    288 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.676, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.78, wps=419.1, ups=0.08, wpb=5117.7, bsz=1280, num_updates=1540, lr=4.0102e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=21686
2024-10-31 14:23:14 - progress_bar.py[line:274] - INFO: epoch 005:    298 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.663, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.66, wps=419.9, ups=0.08, wpb=5118.7, bsz=1280, num_updates=1550, lr=4.0017e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=21808
2024-10-31 14:25:16 - progress_bar.py[line:274] - INFO: epoch 005:    308 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.643, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.5, wps=418.5, ups=0.08, wpb=5118, bsz=1280, num_updates=1560, lr=3.9932e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=35, gb_free=9.4, wall=21930
2024-10-31 14:26:10 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 6 seek offset 41037
slice_id 7 seek offset 47876slice_id 4 seek offset 27359

slice_id 5 seek offset 34198
slice_id 1 seek offset 6840slice_id 2 seek offset 13680slice_id 3 seek offset 20520


slice_id 2 seek offset 13680
slice_id 4 seek offset 27359
slice_id 6 seek offset 41037
slice_id 3 seek offset 20520
slice_id 1 seek offset 6840
slice_id 5 seek offset 34198
slice_id 7 seek offset 47876
slice_id 0 seek offset 0
2024-10-31 14:34:58 - progress_bar.py[line:282] - INFO: epoch 005 | valid on 'valid' subset | loss 0.007 | loss_v1 0 | loss_v2 0 | nll_loss 3.703 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 13.02 | score 0.2424 | wps 415.9 | wpb 639.7 | bsz 160 | num_updates 1565 | best_score 0.2424
2024-10-31 14:34:58 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 1565 updates
2024-10-31 14:34:58 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping



local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
slice_id 7 seek offset 350000
slice_id 4 seek offset 200000
slice_id 1 seek offset 50000
slice_id 2 seek offset 100000
slice_id 5 seek offset 250000
slice_id 3 seek offset 150000
slice_id 6 seek offset 300000
2024-10-31 14:35:09 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-10-31 14:35:22 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 5 @ 1565 updates, score 0.2424) (writing took 23.89168491959572 seconds)
2024-10-31 14:35:22 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 1565 updates
2024-10-31 14:35:22 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 14:35:33 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 14:35:33 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 5 @ 1565 updates, score 0) (writing took 11.322316788136959 seconds)
2024-10-31 14:35:33 - train.py[line:336] - INFO: end of epoch 5 (average epoch stats below)
2024-10-31 14:35:33 - progress_bar.py[line:282] - INFO: epoch 005 | loss 0.006 | loss_v1 0 | loss_v2 0 | nll_loss 3.626 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.35 | wps 363.8 | ups 0.07 | wpb 5109.9 | bsz 1278 | num_updates 1565 | lr 3.98895e-05 | gnorm 0.006 | clip 0 | loss_scale 1024 | train_wall 1098 | gb_free 9.5 | wall 22547
2024-10-31 14:35:33 - trainer.py[line:639] - INFO: loading train data for epoch 6
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-10-31 14:35:36 - trainer.py[line:703] - INFO: begin training epoch 6
2024-10-31 14:35:36 - train.py[line:297] - INFO: Start iterating over samples
2024-10-31 14:36:41 - progress_bar.py[line:274] - INFO: epoch 006:      5 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.653, ntokens=4862, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=12.58, wps=71.1, ups=0.01, wpb=4862, bsz=1216, num_updates=1570, lr=3.98471e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=34, gb_free=9.5, wall=22614
2024-10-31 14:38:43 - progress_bar.py[line:274] - INFO: epoch 006:     15 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.638, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.45, wps=417.6, ups=0.08, wpb=5118.3, bsz=1280, num_updates=1580, lr=3.97621e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=22737
2024-10-31 14:40:45 - progress_bar.py[line:274] - INFO: epoch 006:     25 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.634, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.41, wps=418.8, ups=0.08, wpb=5117.6, bsz=1280, num_updates=1590, lr=3.96771e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=22859
2024-10-31 14:42:48 - progress_bar.py[line:274] - INFO: epoch 006:     35 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.624, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.33, wps=417.9, ups=0.08, wpb=5117.6, bsz=1280, num_updates=1600, lr=3.95922e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=22981
2024-10-31 14:44:50 - progress_bar.py[line:274] - INFO: epoch 006:     45 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.63, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.38, wps=418.4, ups=0.08, wpb=5118, bsz=1280, num_updates=1610, lr=3.95072e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=23104
2024-10-31 14:46:53 - progress_bar.py[line:274] - INFO: epoch 006:     55 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.59, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.04, wps=417.4, ups=0.08, wpb=5118.7, bsz=1280, num_updates=1620, lr=3.94223e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=23226
2024-10-31 14:48:55 - progress_bar.py[line:274] - INFO: epoch 006:     65 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.618, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.27, wps=419.2, ups=0.08, wpb=5118.1, bsz=1280, num_updates=1630, lr=3.93373e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.6, wall=23348
2024-10-31 14:50:57 - progress_bar.py[line:274] - INFO: epoch 006:     75 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.651, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.56, wps=418.9, ups=0.08, wpb=5117.8, bsz=1280, num_updates=1640, lr=3.92523e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=23471
2024-10-31 14:52:59 - progress_bar.py[line:274] - INFO: epoch 006:     85 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.657, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.62, wps=420, ups=0.08, wpb=5118.2, bsz=1280, num_updates=1650, lr=3.91674e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=23593
2024-10-31 14:55:01 - progress_bar.py[line:274] - INFO: epoch 006:     95 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.644, ntokens=5118.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.5, wps=418.8, ups=0.08, wpb=5118.9, bsz=1280, num_updates=1660, lr=3.90824e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=35, gb_free=9.6, wall=23715
2024-10-31 14:57:04 - progress_bar.py[line:274] - INFO: epoch 006:    105 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.655, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.6, wps=416.4, ups=0.08, wpb=5118.2, bsz=1280, num_updates=1670, lr=3.89975e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=23838
2024-10-31 14:59:07 - progress_bar.py[line:274] - INFO: epoch 006:    115 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.641, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.47, wps=415.7, ups=0.08, wpb=5117.8, bsz=1280, num_updates=1680, lr=3.89125e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=23961
2024-10-31 15:01:10 - progress_bar.py[line:274] - INFO: epoch 006:    125 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.618, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.27, wps=416.8, ups=0.08, wpb=5118.5, bsz=1280, num_updates=1690, lr=3.88275e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=24084
2024-10-31 15:03:11 - progress_bar.py[line:274] - INFO: epoch 006:    135 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.63, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.38, wps=421.1, ups=0.08, wpb=5118.4, bsz=1280, num_updates=1700, lr=3.87426e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=24205
2024-10-31 15:05:14 - progress_bar.py[line:274] - INFO: epoch 006:    145 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.655, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.6, wps=418.4, ups=0.08, wpb=5117.4, bsz=1280, num_updates=1710, lr=3.86576e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=24327
2024-10-31 15:07:16 - progress_bar.py[line:274] - INFO: epoch 006:    155 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.631, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.39, wps=418.5, ups=0.08, wpb=5117.4, bsz=1280, num_updates=1720, lr=3.85726e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=24450
2024-10-31 15:09:18 - progress_bar.py[line:274] - INFO: epoch 006:    165 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.642, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.49, wps=419.1, ups=0.08, wpb=5117.7, bsz=1280, num_updates=1730, lr=3.84877e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=24572
2024-10-31 15:11:20 - progress_bar.py[line:274] - INFO: epoch 006:    175 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.663, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.67, wps=419.6, ups=0.08, wpb=5118.2, bsz=1280, num_updates=1740, lr=3.84027e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=35, gb_free=9.4, wall=24694
2024-10-31 15:13:23 - progress_bar.py[line:274] - INFO: epoch 006:    185 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.676, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.78, wps=416.3, ups=0.08, wpb=5117.4, bsz=1280, num_updates=1750, lr=3.83178e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=24817
2024-10-31 15:15:26 - progress_bar.py[line:274] - INFO: epoch 006:    195 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.687, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.88, wps=417.6, ups=0.08, wpb=5117.4, bsz=1280, num_updates=1760, lr=3.82328e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=24939
2024-10-31 15:17:27 - progress_bar.py[line:274] - INFO: epoch 006:    205 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.68, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.81, wps=421.2, ups=0.08, wpb=5118.6, bsz=1280, num_updates=1770, lr=3.81478e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=25061
2024-10-31 15:19:30 - progress_bar.py[line:274] - INFO: epoch 006:    215 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.663, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.67, wps=417.5, ups=0.08, wpb=5118.5, bsz=1280, num_updates=1780, lr=3.80629e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=25183
2024-10-31 15:21:31 - progress_bar.py[line:274] - INFO: epoch 006:    225 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.635, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.43, wps=421.5, ups=0.08, wpb=5118.3, bsz=1280, num_updates=1790, lr=3.79779e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=25305
2024-10-31 15:23:33 - progress_bar.py[line:274] - INFO: epoch 006:    235 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.659, ntokens=5117.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.64, wps=418.5, ups=0.08, wpb=5117.1, bsz=1280, num_updates=1800, lr=3.78929e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=25427
2024-10-31 15:25:36 - progress_bar.py[line:274] - INFO: epoch 006:    245 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.7, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.99, wps=417, ups=0.08, wpb=5118.1, bsz=1280, num_updates=1810, lr=3.7808e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=25550
2024-10-31 15:27:39 - progress_bar.py[line:274] - INFO: epoch 006:    255 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.687, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.88, wps=417.9, ups=0.08, wpb=5118.2, bsz=1280, num_updates=1820, lr=3.7723e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=25672
2024-10-31 15:29:41 - progress_bar.py[line:274] - INFO: epoch 006:    265 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.657, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.61, wps=420, ups=0.08, wpb=5118, bsz=1280, num_updates=1830, lr=3.76381e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=25794
2024-10-31 15:31:43 - progress_bar.py[line:274] - INFO: epoch 006:    275 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.63, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.38, wps=418.7, ups=0.08, wpb=5118.7, bsz=1280, num_updates=1840, lr=3.75531e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=25916
2024-10-31 15:33:45 - progress_bar.py[line:274] - INFO: epoch 006:    285 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.667, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.71, wps=419.1, ups=0.08, wpb=5118, bsz=1280, num_updates=1850, lr=3.74681e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=26039
2024-10-31 15:35:47 - progress_bar.py[line:274] - INFO: epoch 006:    295 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.65, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.55, wps=420, ups=0.08, wpb=5118.3, bsz=1280, num_updates=1860, lr=3.73832e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=26160
2024-10-31 15:37:49 - progress_bar.py[line:274] - INFO: epoch 006:    305 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.665, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.69, wps=419.6, ups=0.08, wpb=5117.8, bsz=1280, num_updates=1870, lr=3.72982e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=38, gb_free=9.5, wall=26282
2024-10-31 15:39:19 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0slice_id 1 seek offset 6840

slice_id 7 seek offset 47876
slice_id 3 seek offset 20520
slice_id 6 seek offset 41037
slice_id 5 seek offset 34198
slice_id 4 seek offset 27359
slice_id 2 seek offset 13680
slice_id 2 seek offset 13680
slice_id 1 seek offset 6840
slice_id 3 seek offset 20520
slice_id 4 seek offset 27359
slice_id 5 seek offset 34198
slice_id 6 seek offset 41037
slice_id 0 seek offset 0
slice_id 7 seek offset 47876
2024-10-31 15:48:07 - progress_bar.py[line:282] - INFO: epoch 006 | valid on 'valid' subset | loss 0.006 | loss_v1 0 | loss_v2 0 | nll_loss 3.73 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 13.27 | score 0.2916 | wps 416.1 | wpb 639.7 | bsz 160 | num_updates 1878 | best_score 0.2916
2024-10-31 15:48:07 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 1878 updates
2024-10-31 15:48:07 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping



local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
slice_id 1 seek offset 50000
slice_id 2 seek offset 100000
slice_id 4 seek offset 200000
slice_id 3 seek offset 150000
slice_id 6 seek offset 300000
slice_id 7 seek offset 350000
slice_id 5 seek offset 250000
2024-10-31 15:48:17 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-10-31 15:48:29 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 6 @ 1878 updates, score 0.2916) (writing took 22.67909688875079 seconds)
2024-10-31 15:48:29 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 1878 updates
2024-10-31 15:48:29 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 15:48:40 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 15:48:40 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 6 @ 1878 updates, score 0) (writing took 11.163946352899075 seconds)
2024-10-31 15:48:40 - train.py[line:336] - INFO: end of epoch 6 (average epoch stats below)
2024-10-31 15:48:40 - progress_bar.py[line:282] - INFO: epoch 006 | loss 0.006 | loss_v1 0 | loss_v2 0 | nll_loss 3.65 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.55 | wps 364.6 | ups 0.07 | wpb 5109.9 | bsz 1278 | num_updates 1878 | lr 3.72302e-05 | gnorm 0.006 | clip 0 | loss_scale 1024 | train_wall 1105 | gb_free 9.5 | wall 26934
2024-10-31 15:48:40 - trainer.py[line:639] - INFO: loading train data for epoch 7
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-10-31 15:48:43 - trainer.py[line:703] - INFO: begin training epoch 7
2024-10-31 15:48:43 - train.py[line:297] - INFO: Start iterating over samples
2024-10-31 15:49:11 - progress_bar.py[line:274] - INFO: epoch 007:      2 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.679, ntokens=4862.4, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=12.81, wps=71.3, ups=0.01, wpb=4862.4, bsz=1216, num_updates=1880, lr=3.72133e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=36, gb_free=9.5, wall=26964
2024-10-31 15:51:14 - progress_bar.py[line:274] - INFO: epoch 007:     12 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.673, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.75, wps=416.6, ups=0.08, wpb=5118, bsz=1280, num_updates=1890, lr=3.71283e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.4, wall=27087
2024-10-31 15:53:16 - progress_bar.py[line:274] - INFO: epoch 007:     22 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.637, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.44, wps=418.3, ups=0.08, wpb=5118, bsz=1280, num_updates=1900, lr=3.70433e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=27210
2024-10-31 15:55:18 - progress_bar.py[line:274] - INFO: epoch 007:     32 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.6, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.12, wps=419.3, ups=0.08, wpb=5117.9, bsz=1280, num_updates=1910, lr=3.69584e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=27332
2024-10-31 15:57:21 - progress_bar.py[line:274] - INFO: epoch 007:     42 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.591, ntokens=5117.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.05, wps=415.8, ups=0.08, wpb=5117.5, bsz=1280, num_updates=1920, lr=3.68734e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=27455
2024-10-31 15:59:24 - progress_bar.py[line:274] - INFO: epoch 007:     52 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.598, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.11, wps=415.2, ups=0.08, wpb=5118.4, bsz=1280, num_updates=1930, lr=3.67884e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=27578
2024-10-31 16:01:27 - progress_bar.py[line:274] - INFO: epoch 007:     62 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.652, ntokens=5118.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.57, wps=416, ups=0.08, wpb=5118.8, bsz=1280, num_updates=1940, lr=3.67035e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=27701
2024-10-31 16:03:30 - progress_bar.py[line:274] - INFO: epoch 007:     72 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.626, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.35, wps=418.8, ups=0.08, wpb=5117.7, bsz=1280, num_updates=1950, lr=3.66185e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=27823
2024-10-31 16:05:32 - progress_bar.py[line:274] - INFO: epoch 007:     82 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.639, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.45, wps=416.7, ups=0.08, wpb=5117.6, bsz=1280, num_updates=1960, lr=3.65336e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=27946
2024-10-31 16:07:35 - progress_bar.py[line:274] - INFO: epoch 007:     92 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.674, ntokens=5118.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.76, wps=416.6, ups=0.08, wpb=5118.8, bsz=1280, num_updates=1970, lr=3.64486e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=28069
2024-10-31 16:09:38 - progress_bar.py[line:274] - INFO: epoch 007:    102 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.68, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.82, wps=416.6, ups=0.08, wpb=5118.3, bsz=1280, num_updates=1980, lr=3.63636e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=35, gb_free=9.6, wall=28192
2024-10-31 16:11:41 - progress_bar.py[line:274] - INFO: epoch 007:    112 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.663, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.67, wps=417.3, ups=0.08, wpb=5118.4, bsz=1280, num_updates=1990, lr=3.62787e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=28314
2024-10-31 16:13:44 - progress_bar.py[line:274] - INFO: epoch 007:    122 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.636, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.43, wps=416.7, ups=0.08, wpb=5118, bsz=1280, num_updates=2000, lr=3.61937e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=35, gb_free=9.4, wall=28437
slice_id 6 seek offset 41037
slice_id 4 seek offset 27359
slice_id 7 seek offset 47876
slice_id 5 seek offset 34198
slice_id 3 seek offset 20520
2024-10-31 16:13:44 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 1 seek offset 6840
slice_id 2 seek offset 13680
slice_id 2 seek offset 13680
slice_id 1 seek offset 6840
slice_id 5 seek offset 34198
slice_id 3 seek offset 20520
slice_id 6 seek offset 41037
slice_id 4 seek offset 27359
slice_id 7 seek offset 47876
slice_id 0 seek offset 0
2024-10-31 16:22:31 - progress_bar.py[line:282] - INFO: epoch 007 | valid on 'valid' subset | loss 0.006 | loss_v1 0 | loss_v2 0 | nll_loss 3.597 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.1 | score 0.3425 | wps 416.6 | wpb 639.7 | bsz 160 | num_updates 2000 | best_score 0.3425
2024-10-31 16:22:31 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 2000 updates
2024-10-31 16:22:31 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_7_2000.pt
2024-10-31 16:22:42 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_7_2000.pt
2024-10-31 16:23:00 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_7_2000.pt (epoch 7 @ 2000 updates, score 0.3425) (writing took 29.19587180018425 seconds)
2024-10-31 16:24:50 - progress_bar.py[line:274] - INFO: epoch 007:    132 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.613, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.23, wps=76.8, ups=0.02, wpb=5118.6, bsz=1280, num_updates=2010, lr=3.61088e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=29104
2024-10-31 16:26:51 - progress_bar.py[line:274] - INFO: epoch 007:    142 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.658, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.63, wps=421.4, ups=0.08, wpb=5117.3, bsz=1280, num_updates=2020, lr=3.60238e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=29225
2024-10-31 16:28:55 - progress_bar.py[line:274] - INFO: epoch 007:    152 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.623, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.32, wps=415.6, ups=0.08, wpb=5117.7, bsz=1280, num_updates=2030, lr=3.59388e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=29348
2024-10-31 16:30:58 - progress_bar.py[line:274] - INFO: epoch 007:    162 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.565, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.83, wps=416.3, ups=0.08, wpb=5118.1, bsz=1280, num_updates=2040, lr=3.58539e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=35, gb_free=9.5, wall=29471
2024-10-31 16:33:00 - progress_bar.py[line:274] - INFO: epoch 007:    172 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.619, ntokens=5117.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.29, wps=418.1, ups=0.08, wpb=5117.5, bsz=1280, num_updates=2050, lr=3.57689e-05, gnorm=0.011, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=29594
2024-10-31 16:35:02 - progress_bar.py[line:274] - INFO: epoch 007:    182 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.603, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.15, wps=418.9, ups=0.08, wpb=5117.7, bsz=1280, num_updates=2060, lr=3.56839e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=35, gb_free=9.6, wall=29716
2024-10-31 16:37:05 - progress_bar.py[line:274] - INFO: epoch 007:    192 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.611, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.22, wps=415.9, ups=0.08, wpb=5117.4, bsz=1280, num_updates=2070, lr=3.5599e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=29839
2024-10-31 16:39:08 - progress_bar.py[line:274] - INFO: epoch 007:    202 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.634, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.41, wps=416.9, ups=0.08, wpb=5118.3, bsz=1280, num_updates=2080, lr=3.5514e-05, gnorm=0.006, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=29962
2024-10-31 16:41:11 - progress_bar.py[line:274] - INFO: epoch 007:    212 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.61, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.21, wps=415.7, ups=0.08, wpb=5118.1, bsz=1280, num_updates=2090, lr=3.54291e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=30085
2024-10-31 16:43:13 - progress_bar.py[line:274] - INFO: epoch 007:    222 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.565, ntokens=5118.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.83, wps=419.6, ups=0.08, wpb=5118.9, bsz=1280, num_updates=2100, lr=3.53441e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=30207
2024-10-31 16:45:15 - progress_bar.py[line:274] - INFO: epoch 007:    232 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.581, ntokens=5117, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.96, wps=419.5, ups=0.08, wpb=5117, bsz=1280, num_updates=2110, lr=3.52591e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=30329
2024-10-31 16:47:17 - progress_bar.py[line:274] - INFO: epoch 007:    242 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.538, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.62, wps=420.9, ups=0.08, wpb=5118.4, bsz=1280, num_updates=2120, lr=3.51742e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=30450
2024-10-31 16:49:19 - progress_bar.py[line:274] - INFO: epoch 007:    252 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.563, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.82, wps=419.9, ups=0.08, wpb=5117.9, bsz=1280, num_updates=2130, lr=3.50892e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=35, gb_free=9.6, wall=30572
2024-10-31 16:51:21 - progress_bar.py[line:274] - INFO: epoch 007:    262 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.537, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.61, wps=419.3, ups=0.08, wpb=5118.2, bsz=1280, num_updates=2140, lr=3.50042e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=30694
2024-10-31 16:53:23 - progress_bar.py[line:274] - INFO: epoch 007:    272 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.553, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.73, wps=418.5, ups=0.08, wpb=5118.2, bsz=1280, num_updates=2150, lr=3.49193e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.6, wall=30817
2024-10-31 16:55:26 - progress_bar.py[line:274] - INFO: epoch 007:    282 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.508, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.37, wps=417.2, ups=0.08, wpb=5118.4, bsz=1280, num_updates=2160, lr=3.48343e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=30939
2024-10-31 16:57:29 - progress_bar.py[line:274] - INFO: epoch 007:    292 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.455, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.97, wps=416, ups=0.08, wpb=5117.8, bsz=1280, num_updates=2170, lr=3.47494e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.6, wall=31062
2024-10-31 16:59:32 - progress_bar.py[line:274] - INFO: epoch 007:    302 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.499, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.31, wps=415.6, ups=0.08, wpb=5118.6, bsz=1280, num_updates=2180, lr=3.46644e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.4, wall=31185
2024-10-31 17:01:34 - progress_bar.py[line:274] - INFO: epoch 007:    312 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.491, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.24, wps=419.7, ups=0.08, wpb=5117.9, bsz=1280, num_updates=2190, lr=3.45794e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=31307
slice_id 7 seek offset 478762024-10-31 17:01:38 - train.py[line:449] - INFO: begin validation on "valid" subset

slice_id 0 seek offset 0
slice_id 3 seek offset 20520slice_id 6 seek offset 41037

slice_id 1 seek offset 6840slice_id 5 seek offset 34198

slice_id 4 seek offset 27359
slice_id 2 seek offset 13680
slice_id 2 seek offset 13680
slice_id 1 seek offset 6840
slice_id 5 seek offset 34198
slice_id 6 seek offset 41037
slice_id 4 seek offset 27359
slice_id 3 seek offset 20520
slice_id 0 seek offset 0
slice_id 7 seek offset 47876
2024-10-31 17:10:27 - progress_bar.py[line:282] - INFO: epoch 007 | valid on 'valid' subset | loss 0.006 | loss_v1 0 | loss_v2 0 | nll_loss 3.501 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.32 | score 0.3849 | wps 415.5 | wpb 639.7 | bsz 160 | num_updates 2191 | best_score 0.3849
2024-10-31 17:10:27 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 2191 updates
2024-10-31 17:10:27 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
slice_id 3 seek offset 150000
slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
slice_id 2 seek offset 100000
slice_id 6 seek offset 300000
slice_id 5 seek offset 250000
slice_id 4 seek offset 200000
2024-10-31 17:10:38 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-10-31 17:10:51 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 7 @ 2191 updates, score 0.3849) (writing took 24.04730636253953 seconds)
2024-10-31 17:10:51 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 2191 updates
2024-10-31 17:10:51 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 17:11:02 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 17:11:02 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 7 @ 2191 updates, score 0) (writing took 11.385007161647081 seconds)
2024-10-31 17:11:02 - train.py[line:336] - INFO: end of epoch 7 (average epoch stats below)
2024-10-31 17:11:02 - progress_bar.py[line:282] - INFO: epoch 007 | loss 0.006 | loss_v1 0 | loss_v2 0 | nll_loss 3.597 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.1 | wps 323.7 | ups 0.06 | wpb 5109.9 | bsz 1278 | num_updates 2191 | lr 3.45709e-05 | gnorm 0.008 | clip 0 | loss_scale 2048 | train_wall 1099 | gb_free 9.5 | wall 31876
2024-10-31 17:11:02 - trainer.py[line:639] - INFO: loading train data for epoch 8
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-10-31 17:11:05 - trainer.py[line:703] - INFO: begin training epoch 8
2024-10-31 17:11:05 - train.py[line:297] - INFO: Start iterating over samples
2024-10-31 17:12:59 - progress_bar.py[line:274] - INFO: epoch 008:      9 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.513, ntokens=4862, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=11.42, wps=71, ups=0.01, wpb=4862, bsz=1216, num_updates=2200, lr=3.44945e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=34, gb_free=9.4, wall=31993
2024-10-31 17:15:02 - progress_bar.py[line:274] - INFO: epoch 008:     19 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.506, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.36, wps=414.8, ups=0.08, wpb=5118.1, bsz=1280, num_updates=2210, lr=3.44095e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.4, wall=32116
2024-10-31 17:17:06 - progress_bar.py[line:274] - INFO: epoch 008:     29 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.495, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.28, wps=413.9, ups=0.08, wpb=5117.7, bsz=1280, num_updates=2220, lr=3.43246e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=32240
2024-10-31 17:19:09 - progress_bar.py[line:274] - INFO: epoch 008:     39 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.513, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.41, wps=414.6, ups=0.08, wpb=5118, bsz=1280, num_updates=2230, lr=3.42396e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=32363
2024-10-31 17:21:12 - progress_bar.py[line:274] - INFO: epoch 008:     49 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.504, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.35, wps=417.4, ups=0.08, wpb=5118, bsz=1280, num_updates=2240, lr=3.41546e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=32486
2024-10-31 17:23:16 - progress_bar.py[line:274] - INFO: epoch 008:     59 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.496, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.28, wps=414, ups=0.08, wpb=5118.4, bsz=1280, num_updates=2250, lr=3.40697e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=32609
2024-10-31 17:25:20 - progress_bar.py[line:274] - INFO: epoch 008:     69 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.527, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.53, wps=412.1, ups=0.08, wpb=5118.4, bsz=1280, num_updates=2260, lr=3.39847e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=32733
2024-10-31 17:27:22 - progress_bar.py[line:274] - INFO: epoch 008:     79 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.478, ntokens=5117.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.14, wps=417.5, ups=0.08, wpb=5117.5, bsz=1280, num_updates=2270, lr=3.38997e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.6, wall=32856
2024-10-31 17:29:25 - progress_bar.py[line:274] - INFO: epoch 008:     89 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.471, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.09, wps=417.7, ups=0.08, wpb=5118.4, bsz=1280, num_updates=2280, lr=3.38148e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.4, wall=32979
2024-10-31 17:31:28 - progress_bar.py[line:274] - INFO: epoch 008:     99 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.48, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.16, wps=414.5, ups=0.08, wpb=5118.4, bsz=1280, num_updates=2290, lr=3.37298e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=33102
2024-10-31 17:33:31 - progress_bar.py[line:274] - INFO: epoch 008:    109 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.507, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.37, wps=417.3, ups=0.08, wpb=5118.4, bsz=1280, num_updates=2300, lr=3.36449e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=33225
2024-10-31 17:35:34 - progress_bar.py[line:274] - INFO: epoch 008:    119 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.528, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.54, wps=415.1, ups=0.08, wpb=5117.9, bsz=1280, num_updates=2310, lr=3.35599e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=33348
2024-10-31 17:37:37 - progress_bar.py[line:274] - INFO: epoch 008:    129 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.512, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.41, wps=416.2, ups=0.08, wpb=5118.7, bsz=1280, num_updates=2320, lr=3.34749e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=33471
2024-10-31 17:39:40 - progress_bar.py[line:274] - INFO: epoch 008:    139 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.509, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.39, wps=418.2, ups=0.08, wpb=5117.9, bsz=1280, num_updates=2330, lr=3.339e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=33593
2024-10-31 17:41:43 - progress_bar.py[line:274] - INFO: epoch 008:    149 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.512, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.41, wps=415.9, ups=0.08, wpb=5117.6, bsz=1280, num_updates=2340, lr=3.3305e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=33716
2024-10-31 17:43:46 - progress_bar.py[line:274] - INFO: epoch 008:    159 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.5, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.31, wps=414, ups=0.08, wpb=5117.6, bsz=1280, num_updates=2350, lr=3.32201e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=33840
2024-10-31 17:45:50 - progress_bar.py[line:274] - INFO: epoch 008:    169 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.527, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.53, wps=412.8, ups=0.08, wpb=5118.1, bsz=1280, num_updates=2360, lr=3.31351e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=33964
2024-10-31 17:47:53 - progress_bar.py[line:274] - INFO: epoch 008:    179 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.555, ntokens=5116.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.75, wps=418.1, ups=0.08, wpb=5116.9, bsz=1280, num_updates=2370, lr=3.30501e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=34086
2024-10-31 17:49:54 - progress_bar.py[line:274] - INFO: epoch 008:    189 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.588, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.02, wps=420.4, ups=0.08, wpb=5117.9, bsz=1280, num_updates=2380, lr=3.29652e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=34208
2024-10-31 17:51:57 - progress_bar.py[line:274] - INFO: epoch 008:    199 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.559, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.79, wps=417.7, ups=0.08, wpb=5117.9, bsz=1280, num_updates=2390, lr=3.28802e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.6, wall=34331
2024-10-31 17:54:01 - progress_bar.py[line:274] - INFO: epoch 008:    209 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.586, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.01, wps=411.7, ups=0.08, wpb=5118.4, bsz=1280, num_updates=2400, lr=3.27952e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=34455
2024-10-31 17:56:05 - progress_bar.py[line:274] - INFO: epoch 008:    219 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.596, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.09, wps=414.3, ups=0.08, wpb=5118.5, bsz=1280, num_updates=2410, lr=3.27103e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=34578
2024-10-31 17:58:08 - progress_bar.py[line:274] - INFO: epoch 008:    229 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.577, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.93, wps=414, ups=0.08, wpb=5117.9, bsz=1280, num_updates=2420, lr=3.26253e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=34702
2024-10-31 18:00:12 - progress_bar.py[line:274] - INFO: epoch 008:    239 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.533, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.58, wps=414, ups=0.08, wpb=5117.6, bsz=1280, num_updates=2430, lr=3.25404e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=34826
2024-10-31 18:02:15 - progress_bar.py[line:274] - INFO: epoch 008:    249 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.565, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.84, wps=415.2, ups=0.08, wpb=5118.2, bsz=1280, num_updates=2440, lr=3.24554e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=35, gb_free=9.4, wall=34949
2024-10-31 18:04:18 - progress_bar.py[line:274] - INFO: epoch 008:    259 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.569, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.87, wps=417.3, ups=0.08, wpb=5118, bsz=1280, num_updates=2450, lr=3.23704e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=35072
2024-10-31 18:06:21 - progress_bar.py[line:274] - INFO: epoch 008:    269 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.58, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.96, wps=414.6, ups=0.08, wpb=5118, bsz=1280, num_updates=2460, lr=3.22855e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=35195
2024-10-31 18:08:24 - progress_bar.py[line:274] - INFO: epoch 008:    279 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.538, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.61, wps=416.8, ups=0.08, wpb=5118.6, bsz=1280, num_updates=2470, lr=3.22005e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=35318
2024-10-31 18:10:28 - progress_bar.py[line:274] - INFO: epoch 008:    289 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.535, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.59, wps=413.5, ups=0.08, wpb=5117.6, bsz=1280, num_updates=2480, lr=3.21155e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=35442
2024-10-31 18:12:32 - progress_bar.py[line:274] - INFO: epoch 008:    299 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.524, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.5, wps=414.3, ups=0.08, wpb=5118.7, bsz=1280, num_updates=2490, lr=3.20306e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=35565
2024-10-31 18:14:36 - progress_bar.py[line:274] - INFO: epoch 008:    309 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.545, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.67, wps=412.7, ups=0.08, wpb=5118.3, bsz=1280, num_updates=2500, lr=3.19456e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=35689
slice_id 4 seek offset 27359slice_id 6 seek offset 41037

slice_id 2 seek offset 136802024-10-31 18:15:17 - train.py[line:449] - INFO: begin validation on "valid" subset

slice_id 7 seek offset 47876
slice_id 0 seek offset 0
slice_id 5 seek offset 34198slice_id 3 seek offset 20520

slice_id 1 seek offset 6840
slice_id 1 seek offset 6840
slice_id 2 seek offset 13680
slice_id 5 seek offset 34198
slice_id 4 seek offset 27359
slice_id 6 seek offset 41037
slice_id 0 seek offset 0
slice_id 7 seek offset 47876
slice_id 3 seek offset 20520
2024-10-31 18:24:07 - progress_bar.py[line:282] - INFO: epoch 008 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.616 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.26 | score 0.4325 | wps 414.3 | wpb 639.7 | bsz 160 | num_updates 2504 | best_score 0.4325
2024-10-31 18:24:07 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 8 @ 2504 updates
2024-10-31 18:24:07 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping


local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
slice_id 5 seek offset 250000
slice_id 4 seek offset 200000
slice_id 7 seek offset 350000
slice_id 2 seek offset 100000
slice_id 6 seek offset 300000
slice_id 1 seek offset 50000
slice_id 3 seek offset 150000
2024-10-31 18:24:17 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-10-31 18:25:05 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 8 @ 2504 updates, score 0.4325) (writing took 58.56430350244045 seconds)
2024-10-31 18:25:05 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 8 @ 2504 updates
2024-10-31 18:25:05 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 18:25:16 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 18:25:16 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 8 @ 2504 updates, score 0) (writing took 10.967837143689394 seconds)
2024-10-31 18:25:16 - train.py[line:336] - INFO: end of epoch 8 (average epoch stats below)
2024-10-31 18:25:16 - progress_bar.py[line:282] - INFO: epoch 008 | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.53 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.56 | wps 359.1 | ups 0.07 | wpb 5109.9 | bsz 1278 | num_updates 2504 | lr 3.19116e-05 | gnorm 0.009 | clip 0 | loss_scale 2048 | train_wall 1100 | gb_free 9.5 | wall 36330
2024-10-31 18:25:16 - trainer.py[line:639] - INFO: loading train data for epoch 9
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-10-31 18:25:19 - trainer.py[line:703] - INFO: begin training epoch 9
2024-10-31 18:25:19 - train.py[line:297] - INFO: Start iterating over samples
2024-10-31 18:26:35 - progress_bar.py[line:274] - INFO: epoch 009:      6 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.589, ntokens=4862.1, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=12.03, wps=67.6, ups=0.01, wpb=4862.1, bsz=1216, num_updates=2510, lr=3.18607e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=33, gb_free=9.5, wall=36409
2024-10-31 18:28:38 - progress_bar.py[line:274] - INFO: epoch 009:     16 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.587, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.01, wps=416.8, ups=0.08, wpb=5118, bsz=1280, num_updates=2520, lr=3.17757e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=36532
2024-10-31 18:30:41 - progress_bar.py[line:274] - INFO: epoch 009:     26 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.568, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.86, wps=416, ups=0.08, wpb=5117.6, bsz=1280, num_updates=2530, lr=3.16907e-05, gnorm=0.011, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=36655
2024-10-31 18:32:44 - progress_bar.py[line:274] - INFO: epoch 009:     36 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.577, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.94, wps=415.2, ups=0.08, wpb=5117.8, bsz=1280, num_updates=2540, lr=3.16058e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=36778
2024-10-31 18:34:46 - progress_bar.py[line:274] - INFO: epoch 009:     46 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.597, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.1, wps=419, ups=0.08, wpb=5118, bsz=1280, num_updates=2550, lr=3.15208e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.5, wall=36900
2024-10-31 18:36:49 - progress_bar.py[line:274] - INFO: epoch 009:     56 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.579, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.95, wps=417.3, ups=0.08, wpb=5118.7, bsz=1280, num_updates=2560, lr=3.14359e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=37023
2024-10-31 18:38:51 - progress_bar.py[line:274] - INFO: epoch 009:     66 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.573, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.9, wps=420, ups=0.08, wpb=5118.2, bsz=1280, num_updates=2570, lr=3.13509e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.4, wall=37145
2024-10-31 18:40:54 - progress_bar.py[line:274] - INFO: epoch 009:     76 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.573, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.9, wps=416.2, ups=0.08, wpb=5117.8, bsz=1280, num_updates=2580, lr=3.12659e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.4, wall=37268
2024-10-31 18:42:57 - progress_bar.py[line:274] - INFO: epoch 009:     86 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.551, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.72, wps=416.7, ups=0.08, wpb=5117.9, bsz=1280, num_updates=2590, lr=3.1181e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=37390
2024-10-31 18:44:59 - progress_bar.py[line:274] - INFO: epoch 009:     96 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.524, ntokens=5119.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.5, wps=419, ups=0.08, wpb=5119.1, bsz=1280, num_updates=2600, lr=3.1096e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=37513
2024-10-31 18:47:01 - progress_bar.py[line:274] - INFO: epoch 009:    106 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.547, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.69, wps=417.8, ups=0.08, wpb=5118.1, bsz=1280, num_updates=2610, lr=3.1011e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=37635
2024-10-31 18:49:03 - progress_bar.py[line:274] - INFO: epoch 009:    116 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.553, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.74, wps=419.9, ups=0.08, wpb=5117.9, bsz=1280, num_updates=2620, lr=3.09261e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=37757
2024-10-31 18:51:05 - progress_bar.py[line:274] - INFO: epoch 009:    126 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.589, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.03, wps=419.3, ups=0.08, wpb=5118.2, bsz=1280, num_updates=2630, lr=3.08411e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=37879
2024-10-31 18:53:08 - progress_bar.py[line:274] - INFO: epoch 009:    136 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.576, ntokens=5118.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.93, wps=417.9, ups=0.08, wpb=5118.8, bsz=1280, num_updates=2640, lr=3.07562e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=38001
2024-10-31 18:55:10 - progress_bar.py[line:274] - INFO: epoch 009:    146 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.58, ntokens=5117.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.96, wps=417.9, ups=0.08, wpb=5117.2, bsz=1280, num_updates=2650, lr=3.06712e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=38124
2024-10-31 18:57:13 - progress_bar.py[line:274] - INFO: epoch 009:    156 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.605, ntokens=5117.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.17, wps=417.9, ups=0.08, wpb=5117.5, bsz=1280, num_updates=2660, lr=3.05862e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=38246
2024-10-31 18:59:16 - progress_bar.py[line:274] - INFO: epoch 009:    166 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.595, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.08, wps=415.7, ups=0.08, wpb=5117.7, bsz=1280, num_updates=2670, lr=3.05013e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=38369
2024-10-31 19:01:19 - progress_bar.py[line:274] - INFO: epoch 009:    176 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.603, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.15, wps=415.7, ups=0.08, wpb=5117.9, bsz=1280, num_updates=2680, lr=3.04163e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.4, wall=38493
2024-10-31 19:03:22 - progress_bar.py[line:274] - INFO: epoch 009:    186 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.59, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.04, wps=415.8, ups=0.08, wpb=5117.8, bsz=1280, num_updates=2690, lr=3.03314e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.4, wall=38616
2024-10-31 19:05:25 - progress_bar.py[line:274] - INFO: epoch 009:    196 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.616, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.26, wps=417.3, ups=0.08, wpb=5117.3, bsz=1280, num_updates=2700, lr=3.02464e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=38738
2024-10-31 19:07:28 - progress_bar.py[line:274] - INFO: epoch 009:    206 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.622, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.31, wps=416.2, ups=0.08, wpb=5118.4, bsz=1280, num_updates=2710, lr=3.01614e-05, gnorm=0.012, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=38861
2024-10-31 19:09:30 - progress_bar.py[line:274] - INFO: epoch 009:    216 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.657, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.61, wps=418.1, ups=0.08, wpb=5118.5, bsz=1280, num_updates=2720, lr=3.00765e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=38984
2024-10-31 19:11:32 - progress_bar.py[line:274] - INFO: epoch 009:    226 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.637, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.44, wps=418.9, ups=0.08, wpb=5118.2, bsz=1280, num_updates=2730, lr=2.99915e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.4, wall=39106
2024-10-31 19:13:35 - progress_bar.py[line:274] - INFO: epoch 009:    236 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.597, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.1, wps=416.1, ups=0.08, wpb=5117.3, bsz=1280, num_updates=2740, lr=2.99065e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=39229
2024-10-31 19:15:37 - progress_bar.py[line:274] - INFO: epoch 009:    246 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.566, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.84, wps=422, ups=0.08, wpb=5118.3, bsz=1280, num_updates=2750, lr=2.98216e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=39350
2024-10-31 19:17:40 - progress_bar.py[line:274] - INFO: epoch 009:    256 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.618, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.28, wps=415.5, ups=0.08, wpb=5118.1, bsz=1280, num_updates=2760, lr=2.97366e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.4, wall=39473
2024-10-31 19:19:42 - progress_bar.py[line:274] - INFO: epoch 009:    266 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.636, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.43, wps=418.5, ups=0.08, wpb=5117.6, bsz=1280, num_updates=2770, lr=2.96517e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=39596
2024-10-31 19:21:44 - progress_bar.py[line:274] - INFO: epoch 009:    276 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.619, ntokens=5119, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.28, wps=419.9, ups=0.08, wpb=5119, bsz=1280, num_updates=2780, lr=2.95667e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=39718
2024-10-31 19:23:46 - progress_bar.py[line:274] - INFO: epoch 009:    286 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.629, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.37, wps=418.9, ups=0.08, wpb=5118.1, bsz=1280, num_updates=2790, lr=2.94817e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=39840
2024-10-31 19:25:49 - progress_bar.py[line:274] - INFO: epoch 009:    296 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.617, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.27, wps=416.6, ups=0.08, wpb=5118.3, bsz=1280, num_updates=2800, lr=2.93968e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=39963
2024-10-31 19:27:52 - progress_bar.py[line:274] - INFO: epoch 009:    306 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.629, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.37, wps=417.2, ups=0.08, wpb=5117.8, bsz=1280, num_updates=2810, lr=2.93118e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=40085
slice_id 2 seek offset 136802024-10-31 19:29:10 - train.py[line:449] - INFO: begin validation on "valid" subset

slice_id 3 seek offset 20520
slice_id 4 seek offset 27359slice_id 0 seek offset 0

slice_id 6 seek offset 41037
slice_id 5 seek offset 34198
slice_id 7 seek offset 47876
slice_id 1 seek offset 6840
slice_id 2 seek offset 13680
slice_id 1 seek offset 6840
slice_id 4 seek offset 27359
slice_id 6 seek offset 41037
slice_id 5 seek offset 34198
slice_id 0 seek offset 0
slice_id 3 seek offset 20520
slice_id 7 seek offset 47876
2024-10-31 19:37:58 - progress_bar.py[line:282] - INFO: epoch 009 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.651 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.56 | score 0.4606 | wps 415.6 | wpb 639.7 | bsz 160 | num_updates 2817 | best_score 0.4606
2024-10-31 19:37:58 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 9 @ 2817 updates
2024-10-31 19:37:58 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping


local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
slice_id 7 seek offset 350000
slice_id 6 seek offset 300000
slice_id 3 seek offset 150000
slice_id 1 seek offset 50000
slice_id 4 seek offset 200000
slice_id 2 seek offset 100000
slice_id 5 seek offset 250000
2024-10-31 19:38:08 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-10-31 19:39:16 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 9 @ 2817 updates, score 0.4606) (writing took 78.04410004988313 seconds)
2024-10-31 19:39:16 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 9 @ 2817 updates
2024-10-31 19:39:16 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 19:39:27 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 19:39:27 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 9 @ 2817 updates, score 0) (writing took 11.495203979313374 seconds)
2024-10-31 19:39:27 - train.py[line:336] - INFO: end of epoch 9 (average epoch stats below)
2024-10-31 19:39:27 - progress_bar.py[line:282] - INFO: epoch 009 | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.594 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.08 | wps 359.3 | ups 0.07 | wpb 5109.9 | bsz 1278 | num_updates 2817 | lr 2.92523e-05 | gnorm 0.009 | clip 0 | loss_scale 4096 | train_wall 1099 | gb_free 9.5 | wall 40781
2024-10-31 19:39:27 - trainer.py[line:639] - INFO: loading train data for epoch 10
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-10-31 19:39:30 - trainer.py[line:703] - INFO: begin training epoch 10
2024-10-31 19:39:30 - train.py[line:297] - INFO: Start iterating over samples
2024-10-31 19:40:10 - progress_bar.py[line:274] - INFO: epoch 010:      3 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.607, ntokens=4862.4, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=12.18, wps=65.8, ups=0.01, wpb=4862.4, bsz=1216, num_updates=2820, lr=2.92268e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=33, gb_free=9.5, wall=40824
2024-10-31 19:42:13 - progress_bar.py[line:274] - INFO: epoch 010:     13 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.621, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.31, wps=415.9, ups=0.08, wpb=5117.9, bsz=1280, num_updates=2830, lr=2.91419e-05, gnorm=0.012, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=40947
2024-10-31 19:44:16 - progress_bar.py[line:274] - INFO: epoch 010:     23 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.616, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.26, wps=416.7, ups=0.08, wpb=5117.9, bsz=1280, num_updates=2840, lr=2.90569e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=41070
2024-10-31 19:46:18 - progress_bar.py[line:274] - INFO: epoch 010:     33 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.592, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.06, wps=419.2, ups=0.08, wpb=5117.8, bsz=1280, num_updates=2850, lr=2.8972e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=41192
2024-10-31 19:48:22 - progress_bar.py[line:274] - INFO: epoch 010:     43 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.602, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.14, wps=414.4, ups=0.08, wpb=5117.6, bsz=1280, num_updates=2860, lr=2.8887e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=41315
2024-10-31 19:50:25 - progress_bar.py[line:274] - INFO: epoch 010:     53 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.597, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.1, wps=414.1, ups=0.08, wpb=5118.6, bsz=1280, num_updates=2870, lr=2.8802e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=41439
2024-10-31 19:52:28 - progress_bar.py[line:274] - INFO: epoch 010:     63 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.64, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.47, wps=415.9, ups=0.08, wpb=5118.4, bsz=1280, num_updates=2880, lr=2.87171e-05, gnorm=0.012, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=41562
2024-10-31 19:54:31 - progress_bar.py[line:274] - INFO: epoch 010:     73 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.62, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.3, wps=415.5, ups=0.08, wpb=5117.9, bsz=1280, num_updates=2890, lr=2.86321e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=41685
2024-10-31 19:56:36 - progress_bar.py[line:274] - INFO: epoch 010:     83 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.625, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.34, wps=412.6, ups=0.08, wpb=5117.8, bsz=1280, num_updates=2900, lr=2.85472e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=41809
2024-10-31 19:58:39 - progress_bar.py[line:274] - INFO: epoch 010:     93 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.61, ntokens=5118.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.21, wps=413.5, ups=0.08, wpb=5118.9, bsz=1280, num_updates=2910, lr=2.84622e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=41933
2024-10-31 20:00:42 - progress_bar.py[line:274] - INFO: epoch 010:    103 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.605, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.17, wps=416, ups=0.08, wpb=5118.2, bsz=1280, num_updates=2920, lr=2.83772e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=42056
2024-10-31 20:02:46 - progress_bar.py[line:274] - INFO: epoch 010:    113 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.605, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.17, wps=413.3, ups=0.08, wpb=5118.4, bsz=1280, num_updates=2930, lr=2.82923e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=42180
2024-10-31 20:04:50 - progress_bar.py[line:274] - INFO: epoch 010:    123 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.624, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.33, wps=414.8, ups=0.08, wpb=5118, bsz=1280, num_updates=2940, lr=2.82073e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=42303
2024-10-31 20:06:53 - progress_bar.py[line:274] - INFO: epoch 010:    133 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.627, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.36, wps=415.6, ups=0.08, wpb=5118.6, bsz=1280, num_updates=2950, lr=2.81223e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=42426
2024-10-31 20:08:57 - progress_bar.py[line:274] - INFO: epoch 010:    143 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.642, ntokens=5117.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.49, wps=413.2, ups=0.08, wpb=5117.2, bsz=1280, num_updates=2960, lr=2.80374e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=42550
2024-10-31 20:11:01 - progress_bar.py[line:274] - INFO: epoch 010:    153 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.632, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.4, wps=412.4, ups=0.08, wpb=5117.6, bsz=1280, num_updates=2970, lr=2.79524e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=42674
2024-10-31 20:13:04 - progress_bar.py[line:274] - INFO: epoch 010:    163 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.619, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.29, wps=416.5, ups=0.08, wpb=5118.2, bsz=1280, num_updates=2980, lr=2.78675e-05, gnorm=0.013, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=42797
2024-10-31 20:15:07 - progress_bar.py[line:274] - INFO: epoch 010:    173 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.614, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.24, wps=415.8, ups=0.08, wpb=5117.3, bsz=1280, num_updates=2990, lr=2.77825e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=42920
2024-10-31 20:17:10 - progress_bar.py[line:274] - INFO: epoch 010:    183 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.613, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.23, wps=414.8, ups=0.08, wpb=5118, bsz=1280, num_updates=3000, lr=2.76975e-05, gnorm=0.012, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=43044
slice_id 3 seek offset 20520
slice_id 7 seek offset 47876
slice_id 4 seek offset 27359
slice_id 5 seek offset 34198
2024-10-31 20:17:10 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 2 seek offset 13680
slice_id 6 seek offset 41037
slice_id 1 seek offset 6840
slice_id 2 seek offset 13680
slice_id 4 seek offset 27359
slice_id 1 seek offset 6840
slice_id 3 seek offset 20520
slice_id 6 seek offset 41037
slice_id 5 seek offset 34198
slice_id 7 seek offset 47876
slice_id 0 seek offset 0
2024-10-31 20:25:52 - progress_bar.py[line:282] - INFO: epoch 010 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.628 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.36 | score 0.4666 | wps 420.4 | wpb 639.7 | bsz 160 | num_updates 3000 | best_score 0.4666
2024-10-31 20:25:52 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 10 @ 3000 updates
2024-10-31 20:25:52 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_10_3000.pt
2024-10-31 20:26:06 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_10_3000.pt
2024-10-31 20:26:28 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_10_3000.pt (epoch 10 @ 3000 updates, score 0.4666) (writing took 36.039553206413984 seconds)
2024-10-31 20:28:17 - progress_bar.py[line:274] - INFO: epoch 010:    193 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.581, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.97, wps=76.7, ups=0.01, wpb=5117.3, bsz=1280, num_updates=3010, lr=2.76126e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=43711
2024-10-31 20:30:21 - progress_bar.py[line:274] - INFO: epoch 010:    203 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.63, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.38, wps=415.6, ups=0.08, wpb=5118.1, bsz=1280, num_updates=3020, lr=2.75276e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=43834
2024-10-31 20:32:24 - progress_bar.py[line:274] - INFO: epoch 010:    213 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.611, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.22, wps=416.4, ups=0.08, wpb=5118.5, bsz=1280, num_updates=3030, lr=2.74427e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=43957
2024-10-31 20:34:27 - progress_bar.py[line:274] - INFO: epoch 010:    223 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.636, ntokens=5118.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.43, wps=413.7, ups=0.08, wpb=5118.8, bsz=1280, num_updates=3040, lr=2.73577e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=44081
2024-10-31 20:36:30 - progress_bar.py[line:274] - INFO: epoch 010:    233 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.641, ntokens=5116.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.48, wps=418.7, ups=0.08, wpb=5116.9, bsz=1280, num_updates=3050, lr=2.72727e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=44203
2024-10-31 20:38:32 - progress_bar.py[line:274] - INFO: epoch 010:    243 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.624, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.33, wps=416.3, ups=0.08, wpb=5118.2, bsz=1280, num_updates=3060, lr=2.71878e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=44326
2024-10-31 20:40:35 - progress_bar.py[line:274] - INFO: epoch 010:    253 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.604, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.16, wps=417.3, ups=0.08, wpb=5118.2, bsz=1280, num_updates=3070, lr=2.71028e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=44449
2024-10-31 20:42:37 - progress_bar.py[line:274] - INFO: epoch 010:    263 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.611, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.22, wps=419.7, ups=0.08, wpb=5118.2, bsz=1280, num_updates=3080, lr=2.70178e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=44571
2024-10-31 20:44:40 - progress_bar.py[line:274] - INFO: epoch 010:    273 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.601, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.14, wps=415.7, ups=0.08, wpb=5118.2, bsz=1280, num_updates=3090, lr=2.69329e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=44694
2024-10-31 20:45:30 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2024-10-31 20:46:56 - progress_bar.py[line:274] - INFO: epoch 010:    284 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.599, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.12, wps=377.2, ups=0.07, wpb=5118.3, bsz=1280, num_updates=3100, lr=2.68479e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=39, gb_free=9.5, wall=44830
2024-10-31 20:48:59 - progress_bar.py[line:274] - INFO: epoch 010:    294 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.633, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.4, wps=415.3, ups=0.08, wpb=5118.1, bsz=1280, num_updates=3110, lr=2.6763e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=44953
2024-10-31 20:51:01 - progress_bar.py[line:274] - INFO: epoch 010:    304 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.603, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.15, wps=419, ups=0.08, wpb=5118, bsz=1280, num_updates=3120, lr=2.6678e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=45075
slice_id 6 seek offset 41037
slice_id 4 seek offset 27359
slice_id 7 seek offset 47876slice_id 1 seek offset 6840

slice_id 5 seek offset 34198
slice_id 2 seek offset 13680
slice_id 3 seek offset 20520
2024-10-31 20:52:44 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 2 seek offset 13680
slice_id 4 seek offset 27359
slice_id 1 seek offset 6840
slice_id 6 seek offset 41037
slice_id 5 seek offset 34198
slice_id 3 seek offset 20520
slice_id 7 seek offset 47876
slice_id 0 seek offset 0
2024-10-31 21:01:36 - progress_bar.py[line:282] - INFO: epoch 010 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.606 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.18 | score 0.4723 | wps 413.4 | wpb 639.7 | bsz 160 | num_updates 3129 | best_score 0.4723
2024-10-31 21:01:36 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 10 @ 3129 updates
2024-10-31 21:01:36 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping



local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
slice_id 6 seek offset 300000
slice_id 4 seek offset 200000
slice_id 3 seek offset 150000
slice_id 2 seek offset 100000
slice_id 5 seek offset 250000
2024-10-31 21:01:46 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-10-31 21:02:03 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 10 @ 3129 updates, score 0.4723) (writing took 27.05599605664611 seconds)
2024-10-31 21:02:03 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 10 @ 3129 updates
2024-10-31 21:02:03 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 21:02:13 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 21:02:13 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 10 @ 3129 updates, score 0) (writing took 10.276617124676704 seconds)
2024-10-31 21:02:13 - train.py[line:336] - INFO: end of epoch 10 (average epoch stats below)
2024-10-31 21:02:13 - progress_bar.py[line:282] - INFO: epoch 010 | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.615 | ntokens 5109.85 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.25 | wps 321.1 | ups 0.06 | wpb 5109.8 | bsz 1277.9 | num_updates 3129 | lr 2.66015e-05 | gnorm 0.01 | clip 0 | loss_scale 4096 | train_wall 1100 | gb_free 9.5 | wall 45747
2024-10-31 21:02:13 - trainer.py[line:639] - INFO: loading train data for epoch 11
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-10-31 21:02:16 - trainer.py[line:703] - INFO: begin training epoch 11
2024-10-31 21:02:16 - train.py[line:297] - INFO: Start iterating over samples
2024-10-31 21:02:31 - progress_bar.py[line:274] - INFO: epoch 011:      1 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.584, ntokens=4862.4, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=11.99, wps=70.5, ups=0.01, wpb=4862.4, bsz=1216, num_updates=3130, lr=2.6593e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=33, gb_free=9.5, wall=45765
2024-10-31 21:04:34 - progress_bar.py[line:274] - INFO: epoch 011:     11 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.594, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.08, wps=415.4, ups=0.08, wpb=5117.8, bsz=1280, num_updates=3140, lr=2.65081e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.4, wall=45888
2024-10-31 21:06:38 - progress_bar.py[line:274] - INFO: epoch 011:     21 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.615, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.25, wps=415.1, ups=0.08, wpb=5118.3, bsz=1280, num_updates=3150, lr=2.64231e-05, gnorm=0.012, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=46011
2024-10-31 21:08:42 - progress_bar.py[line:274] - INFO: epoch 011:     31 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.63, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.38, wps=413.4, ups=0.08, wpb=5117.8, bsz=1280, num_updates=3160, lr=2.63381e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=46135
2024-10-31 21:10:44 - progress_bar.py[line:274] - INFO: epoch 011:     41 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.638, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.45, wps=418, ups=0.08, wpb=5117.8, bsz=1280, num_updates=3170, lr=2.62532e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=46258
2024-10-31 21:12:46 - progress_bar.py[line:274] - INFO: epoch 011:     51 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.619, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.28, wps=418, ups=0.08, wpb=5118.2, bsz=1280, num_updates=3180, lr=2.61682e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=46380
2024-10-31 21:14:49 - progress_bar.py[line:274] - INFO: epoch 011:     61 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.659, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.63, wps=417, ups=0.08, wpb=5118.5, bsz=1280, num_updates=3190, lr=2.60833e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=46503
2024-10-31 21:16:52 - progress_bar.py[line:274] - INFO: epoch 011:     71 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.616, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.26, wps=417.6, ups=0.08, wpb=5118.1, bsz=1280, num_updates=3200, lr=2.59983e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.4, wall=46625
2024-10-31 21:18:56 - progress_bar.py[line:274] - INFO: epoch 011:     81 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.62, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.29, wps=411.2, ups=0.08, wpb=5117.3, bsz=1280, num_updates=3210, lr=2.59133e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=46750
2024-10-31 21:21:00 - progress_bar.py[line:274] - INFO: epoch 011:     91 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.641, ntokens=5118.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.47, wps=414.1, ups=0.08, wpb=5118.8, bsz=1280, num_updates=3220, lr=2.58284e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.4, wall=46873
2024-10-31 21:23:03 - progress_bar.py[line:274] - INFO: epoch 011:    101 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.604, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.16, wps=415.1, ups=0.08, wpb=5118.4, bsz=1280, num_updates=3230, lr=2.57434e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=46997
2024-10-31 21:25:06 - progress_bar.py[line:274] - INFO: epoch 011:    111 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.606, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.17, wps=417.4, ups=0.08, wpb=5118.4, bsz=1280, num_updates=3240, lr=2.56585e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=47119
2024-10-31 21:27:08 - progress_bar.py[line:274] - INFO: epoch 011:    121 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.573, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.9, wps=419.7, ups=0.08, wpb=5117.9, bsz=1280, num_updates=3250, lr=2.55735e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=47241
2024-10-31 21:29:11 - progress_bar.py[line:274] - INFO: epoch 011:    131 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.598, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.11, wps=416.4, ups=0.08, wpb=5118.7, bsz=1280, num_updates=3260, lr=2.54885e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=47364
2024-10-31 21:31:14 - progress_bar.py[line:274] - INFO: epoch 011:    141 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.591, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.05, wps=415, ups=0.08, wpb=5117.4, bsz=1280, num_updates=3270, lr=2.54036e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=47488
2024-10-31 21:33:17 - progress_bar.py[line:274] - INFO: epoch 011:    151 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.584, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.99, wps=415.3, ups=0.08, wpb=5117.7, bsz=1280, num_updates=3280, lr=2.53186e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=47611
2024-10-31 21:35:21 - progress_bar.py[line:274] - INFO: epoch 011:    161 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.586, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.01, wps=414.2, ups=0.08, wpb=5117.8, bsz=1280, num_updates=3290, lr=2.52336e-05, gnorm=0.012, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=47734
2024-10-31 21:37:24 - progress_bar.py[line:274] - INFO: epoch 011:    171 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.618, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.27, wps=415.9, ups=0.08, wpb=5117.6, bsz=1280, num_updates=3300, lr=2.51487e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=47857
2024-10-31 21:39:26 - progress_bar.py[line:274] - INFO: epoch 011:    181 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.632, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.4, wps=419.1, ups=0.08, wpb=5117.7, bsz=1280, num_updates=3310, lr=2.50637e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=47979
2024-10-31 21:41:28 - progress_bar.py[line:274] - INFO: epoch 011:    191 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.626, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.35, wps=417.4, ups=0.08, wpb=5117.6, bsz=1280, num_updates=3320, lr=2.49788e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=48102
2024-10-31 21:43:32 - progress_bar.py[line:274] - INFO: epoch 011:    201 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.628, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.36, wps=415.2, ups=0.08, wpb=5118.1, bsz=1280, num_updates=3330, lr=2.48938e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=48225
2024-10-31 21:45:34 - progress_bar.py[line:274] - INFO: epoch 011:    211 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.636, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.43, wps=417.2, ups=0.08, wpb=5118.2, bsz=1280, num_updates=3340, lr=2.48088e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=48348
2024-10-31 21:47:38 - progress_bar.py[line:274] - INFO: epoch 011:    221 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.653, ntokens=5118.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.58, wps=415, ups=0.08, wpb=5118.9, bsz=1280, num_updates=3350, lr=2.47239e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=48471
2024-10-31 21:49:41 - progress_bar.py[line:274] - INFO: epoch 011:    231 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.659, ntokens=5117, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.63, wps=414, ups=0.08, wpb=5117, bsz=1280, num_updates=3360, lr=2.46389e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=48595
2024-10-31 21:51:44 - progress_bar.py[line:274] - INFO: epoch 011:    241 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.629, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.37, wps=415.6, ups=0.08, wpb=5118.3, bsz=1280, num_updates=3370, lr=2.4554e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=48718
2024-10-31 21:53:47 - progress_bar.py[line:274] - INFO: epoch 011:    251 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.621, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.3, wps=416.8, ups=0.08, wpb=5117.9, bsz=1280, num_updates=3380, lr=2.4469e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=48841
2024-10-31 21:55:49 - progress_bar.py[line:274] - INFO: epoch 011:    261 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.654, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.59, wps=421, ups=0.08, wpb=5118.3, bsz=1280, num_updates=3390, lr=2.4384e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=48962
2024-10-31 21:57:51 - progress_bar.py[line:274] - INFO: epoch 011:    271 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.643, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.49, wps=418.5, ups=0.08, wpb=5118.1, bsz=1280, num_updates=3400, lr=2.42991e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=49085
2024-10-31 21:59:54 - progress_bar.py[line:274] - INFO: epoch 011:    281 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.622, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.31, wps=417.4, ups=0.08, wpb=5118.6, bsz=1280, num_updates=3410, lr=2.42141e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=49207
2024-10-31 22:01:56 - progress_bar.py[line:274] - INFO: epoch 011:    291 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.628, ntokens=5117.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.37, wps=418.4, ups=0.08, wpb=5117.5, bsz=1280, num_updates=3420, lr=2.41291e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=49330
2024-10-31 22:03:58 - progress_bar.py[line:274] - INFO: epoch 011:    301 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.627, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.35, wps=418.6, ups=0.08, wpb=5118.7, bsz=1280, num_updates=3430, lr=2.40442e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=49452
2024-10-31 22:06:02 - progress_bar.py[line:274] - INFO: epoch 011:    311 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.644, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.5, wps=414.4, ups=0.08, wpb=5117.8, bsz=1280, num_updates=3440, lr=2.39592e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=49576
slice_id 4 seek offset 27359slice_id 7 seek offset 47876

2024-10-31 22:06:18 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 6 seek offset 41037slice_id 0 seek offset 0

slice_id 2 seek offset 13680
slice_id 1 seek offset 6840
slice_id 3 seek offset 20520
slice_id 5 seek offset 34198
slice_id 4 seek offset 27359
slice_id 2 seek offset 13680
slice_id 3 seek offset 20520
slice_id 1 seek offset 6840
slice_id 5 seek offset 34198
slice_id 6 seek offset 41037
slice_id 7 seek offset 47876
slice_id 0 seek offset 0
2024-10-31 22:15:07 - progress_bar.py[line:282] - INFO: epoch 011 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.667 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.7 | score 0.4802 | wps 414.9 | wpb 639.7 | bsz 160 | num_updates 3442 | best_score 0.4802
2024-10-31 22:15:07 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 11 @ 3442 updates
2024-10-31 22:15:07 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
slice_id 5 seek offset 250000
slice_id 4 seek offset 200000
slice_id 3 seek offset 150000
slice_id 2 seek offset 100000
slice_id 7 seek offset 350000
slice_id 1 seek offset 50000
slice_id 6 seek offset 300000
2024-10-31 22:15:18 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-10-31 22:15:52 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 11 @ 3442 updates, score 0.4802) (writing took 45.014452528208494 seconds)
2024-10-31 22:15:52 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 11 @ 3442 updates
2024-10-31 22:15:52 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 22:16:03 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 22:16:03 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 11 @ 3442 updates, score 0) (writing took 10.868594836443663 seconds)
2024-10-31 22:16:03 - train.py[line:336] - INFO: end of epoch 11 (average epoch stats below)
2024-10-31 22:16:03 - progress_bar.py[line:282] - INFO: epoch 011 | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.622 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.31 | wps 361 | ups 0.07 | wpb 5109.9 | bsz 1278 | num_updates 3442 | lr 2.39422e-05 | gnorm 0.009 | clip 0 | loss_scale 4096 | train_wall 1099 | gb_free 9.5 | wall 50177
2024-10-31 22:16:03 - trainer.py[line:639] - INFO: loading train data for epoch 12
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-10-31 22:16:06 - trainer.py[line:703] - INFO: begin training epoch 12
2024-10-31 22:16:06 - train.py[line:297] - INFO: Start iterating over samples
2024-10-31 22:17:48 - progress_bar.py[line:274] - INFO: epoch 012:      8 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.646, ntokens=4862.3, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=12.52, wps=68.9, ups=0.01, wpb=4862.3, bsz=1216, num_updates=3450, lr=2.38743e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=33, gb_free=9.5, wall=50282
2024-10-31 22:19:51 - progress_bar.py[line:274] - INFO: epoch 012:     18 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.619, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.29, wps=416.2, ups=0.08, wpb=5117.9, bsz=1280, num_updates=3460, lr=2.37893e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=50405
2024-10-31 22:21:54 - progress_bar.py[line:274] - INFO: epoch 012:     28 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.617, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.27, wps=416.8, ups=0.08, wpb=5117.7, bsz=1280, num_updates=3470, lr=2.37043e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=50527
2024-10-31 22:23:56 - progress_bar.py[line:274] - INFO: epoch 012:     38 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.612, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.23, wps=418.2, ups=0.08, wpb=5117.9, bsz=1280, num_updates=3480, lr=2.36194e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=50650
2024-10-31 22:25:59 - progress_bar.py[line:274] - INFO: epoch 012:     48 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.596, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.09, wps=416.8, ups=0.08, wpb=5118.2, bsz=1280, num_updates=3490, lr=2.35344e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=50772
2024-10-31 22:28:01 - progress_bar.py[line:274] - INFO: epoch 012:     58 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.608, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.19, wps=420.3, ups=0.08, wpb=5118.3, bsz=1280, num_updates=3500, lr=2.34494e-05, gnorm=0.016, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=50894
2024-10-31 22:30:04 - progress_bar.py[line:274] - INFO: epoch 012:     68 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.638, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.45, wps=416, ups=0.08, wpb=5118.5, bsz=1280, num_updates=3510, lr=2.33645e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=51017
2024-10-31 22:32:06 - progress_bar.py[line:274] - INFO: epoch 012:     78 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.609, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.2, wps=418.3, ups=0.08, wpb=5117.6, bsz=1280, num_updates=3520, lr=2.32795e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=51140
2024-10-31 22:34:08 - progress_bar.py[line:274] - INFO: epoch 012:     88 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.613, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.23, wps=418.2, ups=0.08, wpb=5118.1, bsz=1280, num_updates=3530, lr=2.31946e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=51262
2024-10-31 22:36:11 - progress_bar.py[line:274] - INFO: epoch 012:     98 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.62, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.3, wps=416.8, ups=0.08, wpb=5118.6, bsz=1280, num_updates=3540, lr=2.31096e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=51385
2024-10-31 22:38:13 - progress_bar.py[line:274] - INFO: epoch 012:    108 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.587, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.02, wps=419, ups=0.08, wpb=5118.5, bsz=1280, num_updates=3550, lr=2.30246e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=51507
2024-10-31 22:40:16 - progress_bar.py[line:274] - INFO: epoch 012:    118 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.601, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.13, wps=418.7, ups=0.08, wpb=5117.9, bsz=1280, num_updates=3560, lr=2.29397e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=51629
2024-10-31 22:42:18 - progress_bar.py[line:274] - INFO: epoch 012:    128 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.62, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.3, wps=419, ups=0.08, wpb=5118.5, bsz=1280, num_updates=3570, lr=2.28547e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=51751
2024-10-31 22:44:21 - progress_bar.py[line:274] - INFO: epoch 012:    138 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.604, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.16, wps=414.8, ups=0.08, wpb=5118.1, bsz=1280, num_updates=3580, lr=2.27698e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=51875
2024-10-31 22:46:24 - progress_bar.py[line:274] - INFO: epoch 012:    148 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.61, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.21, wps=416.2, ups=0.08, wpb=5117.6, bsz=1280, num_updates=3590, lr=2.26848e-05, gnorm=0.006, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=51998
2024-10-31 22:48:27 - progress_bar.py[line:274] - INFO: epoch 012:    158 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.629, ntokens=5117.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.37, wps=417.5, ups=0.08, wpb=5117.5, bsz=1280, num_updates=3600, lr=2.25998e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=52120
2024-10-31 22:50:29 - progress_bar.py[line:274] - INFO: epoch 012:    168 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.663, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.66, wps=418.8, ups=0.08, wpb=5118.1, bsz=1280, num_updates=3610, lr=2.25149e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=52243
2024-10-31 22:52:32 - progress_bar.py[line:274] - INFO: epoch 012:    178 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.642, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.48, wps=415.2, ups=0.08, wpb=5117.3, bsz=1280, num_updates=3620, lr=2.24299e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.4, wall=52366
2024-10-31 22:54:35 - progress_bar.py[line:274] - INFO: epoch 012:    188 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.637, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.44, wps=417.5, ups=0.08, wpb=5117.7, bsz=1280, num_updates=3630, lr=2.23449e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=52488
2024-10-31 22:56:37 - progress_bar.py[line:274] - INFO: epoch 012:    198 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.64, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.47, wps=418.1, ups=0.08, wpb=5117.7, bsz=1280, num_updates=3640, lr=2.226e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.4, wall=52611
2024-10-31 22:58:40 - progress_bar.py[line:274] - INFO: epoch 012:    208 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.624, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.33, wps=415.8, ups=0.08, wpb=5118.2, bsz=1280, num_updates=3650, lr=2.2175e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=52734
2024-10-31 23:00:43 - progress_bar.py[line:274] - INFO: epoch 012:    218 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.623, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.32, wps=416.5, ups=0.08, wpb=5118.6, bsz=1280, num_updates=3660, lr=2.20901e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=52857
2024-10-31 23:02:46 - progress_bar.py[line:274] - INFO: epoch 012:    228 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.635, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.42, wps=415.4, ups=0.08, wpb=5118.1, bsz=1280, num_updates=3670, lr=2.20051e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=52980
2024-10-31 23:04:50 - progress_bar.py[line:274] - INFO: epoch 012:    238 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.636, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.43, wps=415, ups=0.08, wpb=5117.4, bsz=1280, num_updates=3680, lr=2.19201e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=53103
2024-10-31 23:06:51 - progress_bar.py[line:274] - INFO: epoch 012:    248 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.613, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.23, wps=420.6, ups=0.08, wpb=5118.4, bsz=1280, num_updates=3690, lr=2.18352e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=53225
2024-10-31 23:08:54 - progress_bar.py[line:274] - INFO: epoch 012:    258 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.639, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.46, wps=416, ups=0.08, wpb=5118, bsz=1280, num_updates=3700, lr=2.17502e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=53348
2024-10-31 23:10:57 - progress_bar.py[line:274] - INFO: epoch 012:    268 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.607, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.18, wps=418.2, ups=0.08, wpb=5117.8, bsz=1280, num_updates=3710, lr=2.16653e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=53470
2024-10-31 23:13:00 - progress_bar.py[line:274] - INFO: epoch 012:    278 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.588, ntokens=5118.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.02, wps=416.7, ups=0.08, wpb=5118.8, bsz=1280, num_updates=3720, lr=2.15803e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=53593
2024-10-31 23:15:01 - progress_bar.py[line:274] - INFO: epoch 012:    288 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.587, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.02, wps=420.4, ups=0.08, wpb=5117.7, bsz=1280, num_updates=3730, lr=2.14953e-05, gnorm=0.014, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=53715
2024-10-31 23:17:04 - progress_bar.py[line:274] - INFO: epoch 012:    298 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.608, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.19, wps=419.1, ups=0.08, wpb=5118.7, bsz=1280, num_updates=3740, lr=2.14104e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=53837
2024-10-31 23:19:06 - progress_bar.py[line:274] - INFO: epoch 012:    308 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.603, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.15, wps=418.6, ups=0.08, wpb=5118, bsz=1280, num_updates=3750, lr=2.13254e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=35, gb_free=9.4, wall=53959
slice_id 6 seek offset 41037
slice_id 7 seek offset 47876
2024-10-31 23:19:59 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 5 seek offset 34198
slice_id 0 seek offset 0
slice_id 2 seek offset 13680
slice_id 4 seek offset 27359
slice_id 3 seek offset 20520
slice_id 1 seek offset 6840
slice_id 2 seek offset 13680
slice_id 4 seek offset 27359
slice_id 3 seek offset 20520
slice_id 5 seek offset 34198
slice_id 1 seek offset 6840
slice_id 6 seek offset 41037
slice_id 0 seek offset 0
slice_id 7 seek offset 47876
2024-10-31 23:28:47 - progress_bar.py[line:282] - INFO: epoch 012 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.658 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.62 | score 0.4826 | wps 415.9 | wpb 639.7 | bsz 160 | num_updates 3755 | best_score 0.4826
2024-10-31 23:28:47 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 12 @ 3755 updates
2024-10-31 23:28:47 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
slice_id 1 seek offset 50000
slice_id 4 seek offset 200000
slice_id 6 seek offset 300000
slice_id 7 seek offset 350000
slice_id 2 seek offset 100000
slice_id 5 seek offset 250000
slice_id 3 seek offset 150000
2024-10-31 23:28:58 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-10-31 23:29:10 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 12 @ 3755 updates, score 0.4826) (writing took 23.291988492012024 seconds)
2024-10-31 23:29:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 12 @ 3755 updates
2024-10-31 23:29:11 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 23:29:22 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-10-31 23:29:22 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 12 @ 3755 updates, score 0) (writing took 11.666039701551199 seconds)
2024-10-31 23:29:22 - train.py[line:336] - INFO: end of epoch 12 (average epoch stats below)
2024-10-31 23:29:22 - progress_bar.py[line:282] - INFO: epoch 012 | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.618 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.28 | wps 363.6 | ups 0.07 | wpb 5109.9 | bsz 1278 | num_updates 3755 | lr 2.12829e-05 | gnorm 0.009 | clip 0 | loss_scale 8192 | train_wall 1099 | gb_free 9.5 | wall 54576
2024-10-31 23:29:22 - trainer.py[line:639] - INFO: loading train data for epoch 13
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-10-31 23:29:25 - trainer.py[line:703] - INFO: begin training epoch 13
2024-10-31 23:29:25 - train.py[line:297] - INFO: Start iterating over samples
2024-10-31 23:30:30 - progress_bar.py[line:274] - INFO: epoch 013:      5 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.627, ntokens=4862, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=12.35, wps=71.1, ups=0.01, wpb=4862, bsz=1216, num_updates=3760, lr=2.12404e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=33, gb_free=9.5, wall=54643
2024-10-31 23:32:32 - progress_bar.py[line:274] - INFO: epoch 013:     15 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.62, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.3, wps=418, ups=0.08, wpb=5118.3, bsz=1280, num_updates=3770, lr=2.11555e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=54766
2024-10-31 23:34:35 - progress_bar.py[line:274] - INFO: epoch 013:     25 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.617, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.27, wps=417, ups=0.08, wpb=5117.6, bsz=1280, num_updates=3780, lr=2.10705e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=54888
2024-10-31 23:36:37 - progress_bar.py[line:274] - INFO: epoch 013:     35 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.618, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.28, wps=418.5, ups=0.08, wpb=5117.6, bsz=1280, num_updates=3790, lr=2.09856e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=55011
2024-10-31 23:38:39 - progress_bar.py[line:274] - INFO: epoch 013:     45 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.617, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.27, wps=418.3, ups=0.08, wpb=5118, bsz=1280, num_updates=3800, lr=2.09006e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=55133
2024-10-31 23:40:43 - progress_bar.py[line:274] - INFO: epoch 013:     55 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.579, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.95, wps=415.3, ups=0.08, wpb=5118.7, bsz=1280, num_updates=3810, lr=2.08156e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=55256
2024-10-31 23:42:45 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2024-10-31 23:42:58 - progress_bar.py[line:274] - INFO: epoch 013:     66 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.579, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.95, wps=379.1, ups=0.07, wpb=5118.3, bsz=1280, num_updates=3820, lr=2.07307e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=39, gb_free=9.4, wall=55391
2024-10-31 23:45:00 - progress_bar.py[line:274] - INFO: epoch 013:     76 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.604, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.16, wps=419.1, ups=0.08, wpb=5117.8, bsz=1280, num_updates=3830, lr=2.06457e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.4, wall=55513
2024-10-31 23:47:02 - progress_bar.py[line:274] - INFO: epoch 013:     86 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.57, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.88, wps=418.7, ups=0.08, wpb=5117.9, bsz=1280, num_updates=3840, lr=2.05607e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=55636
2024-10-31 23:49:05 - progress_bar.py[line:274] - INFO: epoch 013:     96 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.58, ntokens=5119.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.96, wps=417.5, ups=0.08, wpb=5119.1, bsz=1280, num_updates=3850, lr=2.04758e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=55758
2024-10-31 23:51:07 - progress_bar.py[line:274] - INFO: epoch 013:    106 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.593, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.07, wps=419.5, ups=0.08, wpb=5118.1, bsz=1280, num_updates=3860, lr=2.03908e-05, gnorm=0.012, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=55880
2024-10-31 23:53:10 - progress_bar.py[line:274] - INFO: epoch 013:    116 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.626, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.35, wps=415.9, ups=0.08, wpb=5117.9, bsz=1280, num_updates=3870, lr=2.03059e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=56003
2024-10-31 23:55:12 - progress_bar.py[line:274] - INFO: epoch 013:    126 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.642, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.48, wps=419.2, ups=0.08, wpb=5118.2, bsz=1280, num_updates=3880, lr=2.02209e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=56125
2024-10-31 23:57:14 - progress_bar.py[line:274] - INFO: epoch 013:    136 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.641, ntokens=5118.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.48, wps=419.5, ups=0.08, wpb=5118.8, bsz=1280, num_updates=3890, lr=2.01359e-05, gnorm=0.012, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=56247
2024-10-31 23:59:15 - progress_bar.py[line:274] - INFO: epoch 013:    146 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.651, ntokens=5117.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.56, wps=421.3, ups=0.08, wpb=5117.2, bsz=1280, num_updates=3900, lr=2.0051e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=56369
2024-11-01 00:01:18 - progress_bar.py[line:274] - INFO: epoch 013:    156 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.641, ntokens=5117.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.47, wps=416, ups=0.08, wpb=5117.5, bsz=1280, num_updates=3910, lr=1.9966e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=56492
2024-11-01 00:03:22 - progress_bar.py[line:274] - INFO: epoch 013:    166 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.657, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.61, wps=414.6, ups=0.08, wpb=5117.7, bsz=1280, num_updates=3920, lr=1.98811e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=56615
2024-11-01 00:05:25 - progress_bar.py[line:274] - INFO: epoch 013:    176 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.649, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.55, wps=416.1, ups=0.08, wpb=5117.9, bsz=1280, num_updates=3930, lr=1.97961e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.4, wall=56738
2024-11-01 00:07:27 - progress_bar.py[line:274] - INFO: epoch 013:    186 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.65, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.56, wps=416.9, ups=0.08, wpb=5117.8, bsz=1280, num_updates=3940, lr=1.97111e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.4, wall=56861
2024-11-01 00:09:30 - progress_bar.py[line:274] - INFO: epoch 013:    196 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.661, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.65, wps=417.7, ups=0.08, wpb=5117.3, bsz=1280, num_updates=3950, lr=1.96262e-05, gnorm=0.014, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=56984
2024-11-01 00:11:33 - progress_bar.py[line:274] - INFO: epoch 013:    206 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.657, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.62, wps=417.4, ups=0.08, wpb=5118.4, bsz=1280, num_updates=3960, lr=1.95412e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=57106
2024-11-01 00:13:35 - progress_bar.py[line:274] - INFO: epoch 013:    216 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.653, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.58, wps=416.6, ups=0.08, wpb=5118.5, bsz=1280, num_updates=3970, lr=1.94562e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=57229
2024-11-01 00:15:39 - progress_bar.py[line:274] - INFO: epoch 013:    226 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.634, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.42, wps=415.7, ups=0.08, wpb=5118.2, bsz=1280, num_updates=3980, lr=1.93713e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.4, wall=57352
2024-11-01 00:17:41 - progress_bar.py[line:274] - INFO: epoch 013:    236 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.625, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.34, wps=416.7, ups=0.08, wpb=5117.3, bsz=1280, num_updates=3990, lr=1.92863e-05, gnorm=0.012, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=57475
2024-11-01 00:19:44 - progress_bar.py[line:274] - INFO: epoch 013:    246 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.631, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.39, wps=417.2, ups=0.08, wpb=5118.3, bsz=1280, num_updates=4000, lr=1.92014e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=57598
slice_id 7 seek offset 47876slice_id 5 seek offset 34198slice_id 2 seek offset 13680


slice_id 4 seek offset 27359slice_id 6 seek offset 41037

2024-11-01 00:19:44 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 1 seek offset 6840slice_id 0 seek offset 0

slice_id 3 seek offset 20520
slice_id 4 seek offset 27359
slice_id 2 seek offset 13680
slice_id 3 seek offset 20520
slice_id 1 seek offset 6840
slice_id 6 seek offset 41037
slice_id 5 seek offset 34198
slice_id 7 seek offset 47876
slice_id 0 seek offset 0
2024-11-01 00:28:26 - progress_bar.py[line:282] - INFO: epoch 013 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.66 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.64 | score 0.4882 | wps 420.9 | wpb 639.7 | bsz 160 | num_updates 4000 | best_score 0.4882
2024-11-01 00:28:26 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 13 @ 4000 updates
2024-11-01 00:28:26 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_13_4000.pt
2024-11-01 00:28:39 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_13_4000.pt
2024-11-01 00:29:43 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_13_4000.pt (epoch 13 @ 4000 updates, score 0.4882) (writing took 77.14128312468529 seconds)
2024-11-01 00:31:32 - progress_bar.py[line:274] - INFO: epoch 013:    256 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.621, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.3, wps=72.3, ups=0.01, wpb=5118.1, bsz=1280, num_updates=4010, lr=1.91164e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.4, wall=58306
2024-11-01 00:33:34 - progress_bar.py[line:274] - INFO: epoch 013:    266 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.643, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.49, wps=418.8, ups=0.08, wpb=5117.6, bsz=1280, num_updates=4020, lr=1.90314e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=58428
2024-11-01 00:35:37 - progress_bar.py[line:274] - INFO: epoch 013:    276 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.623, ntokens=5119, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.32, wps=417.8, ups=0.08, wpb=5119, bsz=1280, num_updates=4030, lr=1.89465e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=58551
2024-11-01 00:37:40 - progress_bar.py[line:274] - INFO: epoch 013:    286 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.639, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.45, wps=416.9, ups=0.08, wpb=5118.1, bsz=1280, num_updates=4040, lr=1.88615e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=58673
2024-11-01 00:39:43 - progress_bar.py[line:274] - INFO: epoch 013:    296 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.64, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.47, wps=414.2, ups=0.08, wpb=5118.3, bsz=1280, num_updates=4050, lr=1.87766e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=58797
2024-11-01 00:41:46 - progress_bar.py[line:274] - INFO: epoch 013:    306 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.626, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.34, wps=418.2, ups=0.08, wpb=5117.8, bsz=1280, num_updates=4060, lr=1.86916e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=58919
slice_id 4 seek offset 27359
2024-11-01 00:43:04 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 7 seek offset 47876slice_id 0 seek offset 0

slice_id 5 seek offset 34198slice_id 6 seek offset 41037
slice_id 2 seek offset 13680

slice_id 1 seek offset 6840
slice_id 3 seek offset 20520
slice_id 2 seek offset 13680
slice_id 4 seek offset 27359
slice_id 3 seek offset 20520
slice_id 1 seek offset 6840
slice_id 6 seek offset 41037
slice_id 5 seek offset 34198
slice_id 7 seek offset 47876
slice_id 0 seek offset 0
2024-11-01 00:51:53 - progress_bar.py[line:282] - INFO: epoch 013 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.662 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.66 | score 0.4893 | wps 415 | wpb 639.7 | bsz 160 | num_updates 4067 | best_score 0.4893
2024-11-01 00:51:53 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 13 @ 4067 updates
2024-11-01 00:51:53 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping



local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
slice_id 3 seek offset 150000
slice_id 2 seek offset 100000
slice_id 5 seek offset 250000
slice_id 1 seek offset 50000
slice_id 4 seek offset 200000
slice_id 7 seek offset 350000
slice_id 6 seek offset 300000
2024-11-01 00:52:05 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-11-01 00:52:18 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 13 @ 4067 updates, score 0.4893) (writing took 24.91537181288004 seconds)
2024-11-01 00:52:18 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 13 @ 4067 updates
2024-11-01 00:52:18 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-01 00:52:29 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-01 00:52:29 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 13 @ 4067 updates, score 0) (writing took 11.447955962270498 seconds)
2024-11-01 00:52:29 - train.py[line:336] - INFO: end of epoch 13 (average epoch stats below)
2024-11-01 00:52:29 - progress_bar.py[line:282] - INFO: epoch 013 | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.627 | ntokens 5109.84 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.35 | wps 319.7 | ups 0.06 | wpb 5109.8 | bsz 1277.9 | num_updates 4067 | lr 1.86321e-05 | gnorm 0.009 | clip 0 | loss_scale 4096 | train_wall 1100 | gb_free 9.5 | wall 59563
2024-11-01 00:52:29 - trainer.py[line:639] - INFO: loading train data for epoch 14
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-01 00:52:32 - trainer.py[line:703] - INFO: begin training epoch 14
2024-11-01 00:52:32 - train.py[line:297] - INFO: Start iterating over samples
2024-11-01 00:53:12 - progress_bar.py[line:274] - INFO: epoch 014:      3 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.631, ntokens=4862.4, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=12.39, wps=70.9, ups=0.01, wpb=4862.4, bsz=1216, num_updates=4070, lr=1.86066e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=33, gb_free=9.5, wall=59606
2024-11-01 00:55:16 - progress_bar.py[line:274] - INFO: epoch 014:     13 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.617, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.27, wps=412.9, ups=0.08, wpb=5117.9, bsz=1280, num_updates=4080, lr=1.85217e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=59730
2024-11-01 00:57:18 - progress_bar.py[line:274] - INFO: epoch 014:     23 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.628, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.36, wps=418.8, ups=0.08, wpb=5117.9, bsz=1280, num_updates=4090, lr=1.84367e-05, gnorm=0.012, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=59852
2024-11-01 00:59:20 - progress_bar.py[line:274] - INFO: epoch 014:     33 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.59, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.04, wps=419, ups=0.08, wpb=5117.8, bsz=1280, num_updates=4100, lr=1.83517e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=59974
2024-11-01 01:01:23 - progress_bar.py[line:274] - INFO: epoch 014:     43 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.593, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.07, wps=417.2, ups=0.08, wpb=5117.6, bsz=1280, num_updates=4110, lr=1.82668e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=60097
2024-11-01 01:03:26 - progress_bar.py[line:274] - INFO: epoch 014:     53 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.616, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.26, wps=417.1, ups=0.08, wpb=5118.6, bsz=1280, num_updates=4120, lr=1.81818e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=60219
2024-11-01 01:05:28 - progress_bar.py[line:274] - INFO: epoch 014:     63 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.631, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.39, wps=417.6, ups=0.08, wpb=5118.4, bsz=1280, num_updates=4130, lr=1.80969e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=60342
2024-11-01 01:07:31 - progress_bar.py[line:274] - INFO: epoch 014:     73 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.611, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.22, wps=417.2, ups=0.08, wpb=5117.9, bsz=1280, num_updates=4140, lr=1.80119e-05, gnorm=0.006, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=60465
2024-11-01 01:09:34 - progress_bar.py[line:274] - INFO: epoch 014:     83 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.602, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.14, wps=415.5, ups=0.08, wpb=5117.8, bsz=1280, num_updates=4150, lr=1.79269e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=60588
2024-11-01 01:11:36 - progress_bar.py[line:274] - INFO: epoch 014:     93 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.595, ntokens=5118.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.09, wps=418.4, ups=0.08, wpb=5118.9, bsz=1280, num_updates=4160, lr=1.7842e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=60710
2024-11-01 01:13:40 - progress_bar.py[line:274] - INFO: epoch 014:    103 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.574, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.91, wps=415.2, ups=0.08, wpb=5118.2, bsz=1280, num_updates=4170, lr=1.7757e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=60833
2024-11-01 01:15:42 - progress_bar.py[line:274] - INFO: epoch 014:    113 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.57, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.88, wps=419.4, ups=0.08, wpb=5118.4, bsz=1280, num_updates=4180, lr=1.7672e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=60955
2024-11-01 01:17:44 - progress_bar.py[line:274] - INFO: epoch 014:    123 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.577, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.94, wps=418.4, ups=0.08, wpb=5118, bsz=1280, num_updates=4190, lr=1.75871e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=61078
2024-11-01 01:19:46 - progress_bar.py[line:274] - INFO: epoch 014:    133 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.607, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.19, wps=418.8, ups=0.08, wpb=5118.6, bsz=1280, num_updates=4200, lr=1.75021e-05, gnorm=0.013, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=61200
2024-11-01 01:21:49 - progress_bar.py[line:274] - INFO: epoch 014:    143 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.614, ntokens=5117.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.25, wps=417.1, ups=0.08, wpb=5117.2, bsz=1280, num_updates=4210, lr=1.74172e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=61323
2024-11-01 01:23:52 - progress_bar.py[line:274] - INFO: epoch 014:    153 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.61, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.21, wps=414.9, ups=0.08, wpb=5117.6, bsz=1280, num_updates=4220, lr=1.73322e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=61446
2024-11-01 01:25:55 - progress_bar.py[line:274] - INFO: epoch 014:    163 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.593, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.07, wps=415.8, ups=0.08, wpb=5118.2, bsz=1280, num_updates=4230, lr=1.72472e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=61569
2024-11-01 01:27:58 - progress_bar.py[line:274] - INFO: epoch 014:    173 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.608, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.19, wps=416.4, ups=0.08, wpb=5117.3, bsz=1280, num_updates=4240, lr=1.71623e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=61692
2024-11-01 01:30:01 - progress_bar.py[line:274] - INFO: epoch 014:    183 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.588, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.03, wps=418.1, ups=0.08, wpb=5118, bsz=1280, num_updates=4250, lr=1.70773e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=61814
2024-11-01 01:32:03 - progress_bar.py[line:274] - INFO: epoch 014:    193 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.59, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.04, wps=416.9, ups=0.08, wpb=5117.3, bsz=1280, num_updates=4260, lr=1.69924e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=61937
2024-11-01 01:34:05 - progress_bar.py[line:274] - INFO: epoch 014:    203 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.6, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.12, wps=419.4, ups=0.08, wpb=5118.1, bsz=1280, num_updates=4270, lr=1.69074e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=62059
2024-11-01 01:36:09 - progress_bar.py[line:274] - INFO: epoch 014:    213 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.618, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.27, wps=413.8, ups=0.08, wpb=5118.5, bsz=1280, num_updates=4280, lr=1.68224e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=62183
2024-11-01 01:38:12 - progress_bar.py[line:274] - INFO: epoch 014:    223 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.595, ntokens=5118.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.08, wps=417.3, ups=0.08, wpb=5118.8, bsz=1280, num_updates=4290, lr=1.67375e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=62305
2024-11-01 01:40:15 - progress_bar.py[line:274] - INFO: epoch 014:    233 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.616, ntokens=5116.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.26, wps=417.1, ups=0.08, wpb=5116.9, bsz=1280, num_updates=4300, lr=1.66525e-05, gnorm=0.006, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=62428
2024-11-01 01:42:18 - progress_bar.py[line:274] - INFO: epoch 014:    243 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.599, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.12, wps=416.1, ups=0.08, wpb=5118.2, bsz=1280, num_updates=4310, lr=1.65675e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=62551
2024-11-01 01:44:20 - progress_bar.py[line:274] - INFO: epoch 014:    253 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.588, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.03, wps=416.4, ups=0.08, wpb=5118.2, bsz=1280, num_updates=4320, lr=1.64826e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=62674
2024-11-01 01:46:23 - progress_bar.py[line:274] - INFO: epoch 014:    263 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.579, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.95, wps=417.1, ups=0.08, wpb=5118.2, bsz=1280, num_updates=4330, lr=1.63976e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.5, wall=62797
2024-11-01 01:48:26 - progress_bar.py[line:274] - INFO: epoch 014:    273 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.571, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.88, wps=417, ups=0.08, wpb=5118.2, bsz=1280, num_updates=4340, lr=1.63127e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=62920
2024-11-01 01:50:29 - progress_bar.py[line:274] - INFO: epoch 014:    283 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.578, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.94, wps=416.9, ups=0.08, wpb=5118.5, bsz=1280, num_updates=4350, lr=1.62277e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=63042
2024-11-01 01:52:31 - progress_bar.py[line:274] - INFO: epoch 014:    293 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.59, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.04, wps=417.6, ups=0.08, wpb=5117.7, bsz=1280, num_updates=4360, lr=1.61427e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=63165
2024-11-01 01:54:35 - progress_bar.py[line:274] - INFO: epoch 014:    303 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.596, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.09, wps=414.5, ups=0.08, wpb=5118.2, bsz=1280, num_updates=4370, lr=1.60578e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=63288
2024-11-01 01:56:30 - progress_bar.py[line:274] - INFO: epoch 014:    313 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.603, ntokens=4862.1, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=12.15, wps=423.4, ups=0.09, wpb=4862.1, bsz=1216, num_updates=4380, lr=1.59728e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=33, gb_free=9.5, wall=63403
slice_id 4 seek offset 27359slice_id 6 seek offset 41037

slice_id 1 seek offset 6840
2024-11-01 01:56:30 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 2 seek offset 13680
slice_id 7 seek offset 47876
slice_id 3 seek offset 20520
slice_id 5 seek offset 34198
slice_id 1 seek offset 6840
slice_id 2 seek offset 13680
slice_id 4 seek offset 27359
slice_id 3 seek offset 20520
slice_id 6 seek offset 41037
slice_id 5 seek offset 34198
slice_id 7 seek offset 47876
slice_id 0 seek offset 0
2024-11-01 02:05:18 - progress_bar.py[line:282] - INFO: epoch 014 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.623 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.32 | score 0.4941 | wps 415.3 | wpb 639.7 | bsz 160 | num_updates 4380 | best_score 0.4941
2024-11-01 02:05:18 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 14 @ 4380 updates
2024-11-01 02:05:18 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping





local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
slice_id 4 seek offset 200000
slice_id 5 seek offset 250000
slice_id 7 seek offset 350000
slice_id 3 seek offset 150000
slice_id 1 seek offset 50000
slice_id 6 seek offset 300000
slice_id 2 seek offset 100000
2024-11-01 02:05:29 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-11-01 02:05:42 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 14 @ 4380 updates, score 0.4941) (writing took 23.662959314882755 seconds)
2024-11-01 02:05:42 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 14 @ 4380 updates
2024-11-01 02:05:42 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-01 02:05:53 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-01 02:05:53 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 14 @ 4380 updates, score 0) (writing took 11.136195555329323 seconds)
2024-11-01 02:05:53 - train.py[line:336] - INFO: end of epoch 14 (average epoch stats below)
2024-11-01 02:05:53 - progress_bar.py[line:282] - INFO: epoch 014 | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.598 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.11 | wps 363.2 | ups 0.07 | wpb 5109.9 | bsz 1278 | num_updates 4380 | lr 1.59728e-05 | gnorm 0.009 | clip 0 | loss_scale 8192 | train_wall 1100 | gb_free 9.5 | wall 63967
2024-11-01 02:05:53 - trainer.py[line:639] - INFO: loading train data for epoch 15
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-01 02:05:56 - trainer.py[line:703] - INFO: begin training epoch 15
2024-11-01 02:05:56 - train.py[line:297] - INFO: Start iterating over samples
2024-11-01 02:08:02 - progress_bar.py[line:274] - INFO: epoch 015:     10 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.584, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.99, wps=73.9, ups=0.01, wpb=5117.9, bsz=1280, num_updates=4390, lr=1.58879e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=64095
2024-11-01 02:10:05 - progress_bar.py[line:274] - INFO: epoch 015:     20 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.597, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.1, wps=416, ups=0.08, wpb=5118.4, bsz=1280, num_updates=4400, lr=1.58029e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=64218
2024-11-01 02:12:07 - progress_bar.py[line:274] - INFO: epoch 015:     30 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.602, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.14, wps=417.1, ups=0.08, wpb=5117.7, bsz=1280, num_updates=4410, lr=1.57179e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=64341
2024-11-01 02:14:10 - progress_bar.py[line:274] - INFO: epoch 015:     40 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.6, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.13, wps=418, ups=0.08, wpb=5117.7, bsz=1280, num_updates=4420, lr=1.5633e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=64463
2024-11-01 02:16:12 - progress_bar.py[line:274] - INFO: epoch 015:     50 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.591, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.05, wps=417.9, ups=0.08, wpb=5118.3, bsz=1280, num_updates=4430, lr=1.5548e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=64586
2024-11-01 02:18:15 - progress_bar.py[line:274] - INFO: epoch 015:     60 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.601, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.14, wps=418.1, ups=0.08, wpb=5118.4, bsz=1280, num_updates=4440, lr=1.5463e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=64708
2024-11-01 02:20:18 - progress_bar.py[line:274] - INFO: epoch 015:     70 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.591, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.05, wps=414.2, ups=0.08, wpb=5118.4, bsz=1280, num_updates=4450, lr=1.53781e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=35, gb_free=9.6, wall=64832
2024-11-01 02:22:22 - progress_bar.py[line:274] - INFO: epoch 015:     80 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.6, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.13, wps=414.2, ups=0.08, wpb=5117.3, bsz=1280, num_updates=4460, lr=1.52931e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=64955
2024-11-01 02:24:26 - progress_bar.py[line:274] - INFO: epoch 015:     90 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.591, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.05, wps=413.7, ups=0.08, wpb=5118.6, bsz=1280, num_updates=4470, lr=1.52082e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=35, gb_free=9.6, wall=65079
2024-11-01 02:26:29 - progress_bar.py[line:274] - INFO: epoch 015:    100 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.592, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.06, wps=413.8, ups=0.08, wpb=5118.3, bsz=1280, num_updates=4480, lr=1.51232e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=65203
2024-11-01 02:28:32 - progress_bar.py[line:274] - INFO: epoch 015:    110 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.588, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.03, wps=416.9, ups=0.08, wpb=5118.6, bsz=1280, num_updates=4490, lr=1.50382e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=65326
2024-11-01 02:30:34 - progress_bar.py[line:274] - INFO: epoch 015:    120 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.578, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.94, wps=418.6, ups=0.08, wpb=5117.7, bsz=1280, num_updates=4500, lr=1.49533e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=65448
2024-11-01 02:32:37 - progress_bar.py[line:274] - INFO: epoch 015:    130 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.591, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.05, wps=416.8, ups=0.08, wpb=5118.7, bsz=1280, num_updates=4510, lr=1.48683e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.4, wall=65571
2024-11-01 02:34:39 - progress_bar.py[line:274] - INFO: epoch 015:    140 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.607, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.19, wps=418.2, ups=0.08, wpb=5117.9, bsz=1280, num_updates=4520, lr=1.47833e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.6, wall=65693
2024-11-01 02:36:42 - progress_bar.py[line:274] - INFO: epoch 015:    150 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.622, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.31, wps=416.4, ups=0.08, wpb=5117.6, bsz=1280, num_updates=4530, lr=1.46984e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=35, gb_free=9.6, wall=65816
2024-11-01 02:38:45 - progress_bar.py[line:274] - INFO: epoch 015:    160 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.611, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.22, wps=416.7, ups=0.08, wpb=5117.6, bsz=1280, num_updates=4540, lr=1.46134e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=35, gb_free=9.4, wall=65939
2024-11-01 02:40:47 - progress_bar.py[line:274] - INFO: epoch 015:    170 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.624, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.33, wps=419.7, ups=0.08, wpb=5117.7, bsz=1280, num_updates=4550, lr=1.45285e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=66061
2024-11-01 02:42:51 - progress_bar.py[line:274] - INFO: epoch 015:    180 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.644, ntokens=5117.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.5, wps=413.1, ups=0.08, wpb=5117.5, bsz=1280, num_updates=4560, lr=1.44435e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=66185
2024-11-01 02:44:53 - progress_bar.py[line:274] - INFO: epoch 015:    190 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.609, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.2, wps=418.1, ups=0.08, wpb=5117.7, bsz=1280, num_updates=4570, lr=1.43585e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=66307
2024-11-01 02:46:56 - progress_bar.py[line:274] - INFO: epoch 015:    200 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.595, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.09, wps=419.2, ups=0.08, wpb=5118, bsz=1280, num_updates=4580, lr=1.42736e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=66429
2024-11-01 02:48:58 - progress_bar.py[line:274] - INFO: epoch 015:    210 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.606, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.17, wps=418, ups=0.08, wpb=5118.2, bsz=1280, num_updates=4590, lr=1.41886e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=66552
2024-11-01 02:51:00 - progress_bar.py[line:274] - INFO: epoch 015:    220 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.628, ntokens=5118.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.36, wps=419.2, ups=0.08, wpb=5118.8, bsz=1280, num_updates=4600, lr=1.41037e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=66674
2024-11-01 02:53:03 - progress_bar.py[line:274] - INFO: epoch 015:    230 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.613, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.24, wps=417.2, ups=0.08, wpb=5117.4, bsz=1280, num_updates=4610, lr=1.40187e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=66796
2024-11-01 02:55:05 - progress_bar.py[line:274] - INFO: epoch 015:    240 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.598, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.11, wps=418.3, ups=0.08, wpb=5117.9, bsz=1280, num_updates=4620, lr=1.39337e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=66919
2024-11-01 02:57:08 - progress_bar.py[line:274] - INFO: epoch 015:    250 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.578, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.94, wps=417.6, ups=0.08, wpb=5118.2, bsz=1280, num_updates=4630, lr=1.38488e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=67041
2024-11-01 02:59:09 - progress_bar.py[line:274] - INFO: epoch 015:    260 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.572, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.89, wps=420.6, ups=0.08, wpb=5118.1, bsz=1280, num_updates=4640, lr=1.37638e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=67163
2024-11-01 03:01:12 - progress_bar.py[line:274] - INFO: epoch 015:    270 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.579, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.95, wps=415.9, ups=0.08, wpb=5118.1, bsz=1280, num_updates=4650, lr=1.36788e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=67286
2024-11-01 03:03:14 - progress_bar.py[line:274] - INFO: epoch 015:    280 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.59, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.04, wps=419.7, ups=0.08, wpb=5118.6, bsz=1280, num_updates=4660, lr=1.35939e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=67408
2024-11-01 03:05:16 - progress_bar.py[line:274] - INFO: epoch 015:    290 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.592, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.06, wps=418.9, ups=0.08, wpb=5117.6, bsz=1280, num_updates=4670, lr=1.35089e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=67530
2024-11-01 03:07:20 - progress_bar.py[line:274] - INFO: epoch 015:    300 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.613, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.23, wps=414.4, ups=0.08, wpb=5118.7, bsz=1280, num_updates=4680, lr=1.3424e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=67654
2024-11-01 03:09:23 - progress_bar.py[line:274] - INFO: epoch 015:    310 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.599, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.12, wps=416.8, ups=0.08, wpb=5118.2, bsz=1280, num_updates=4690, lr=1.3339e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=67776
slice_id 6 seek offset 41037
slice_id 4 seek offset 27359slice_id 7 seek offset 47876

slice_id 1 seek offset 68402024-11-01 03:09:52 - train.py[line:449] - INFO: begin validation on "valid" subset

slice_id 0 seek offset 0
slice_id 2 seek offset 13680
slice_id 5 seek offset 34198
slice_id 3 seek offset 20520
slice_id 4 seek offset 27359
slice_id 1 seek offset 6840
slice_id 2 seek offset 13680
slice_id 5 seek offset 34198
slice_id 6 seek offset 41037
slice_id 0 seek offset 0
slice_id 7 seek offset 47876
slice_id 3 seek offset 20520
2024-11-01 03:18:44 - progress_bar.py[line:282] - INFO: epoch 015 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.633 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.41 | score 0.4962 | wps 412.8 | wpb 639.7 | bsz 160 | num_updates 4693 | best_score 0.4962
2024-11-01 03:18:44 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 15 @ 4693 updates
2024-11-01 03:18:44 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping



local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
slice_id 4 seek offset 200000
slice_id 3 seek offset 150000
slice_id 5 seek offset 250000
slice_id 7 seek offset 350000
slice_id 2 seek offset 100000
slice_id 1 seek offset 50000
slice_id 6 seek offset 300000
2024-11-01 03:18:56 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-11-01 03:19:30 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 15 @ 4693 updates, score 0.4962) (writing took 46.26966064050794 seconds)
2024-11-01 03:19:30 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 15 @ 4693 updates
2024-11-01 03:19:30 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-01 03:19:41 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-01 03:19:41 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 15 @ 4693 updates, score 0) (writing took 11.29522629827261 seconds)
2024-11-01 03:19:41 - train.py[line:336] - INFO: end of epoch 15 (average epoch stats below)
2024-11-01 03:19:41 - progress_bar.py[line:282] - INFO: epoch 015 | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.6 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.12 | wps 361.2 | ups 0.07 | wpb 5109.9 | bsz 1278 | num_updates 4693 | lr 1.33135e-05 | gnorm 0.008 | clip 0 | loss_scale 8192 | train_wall 1100 | gb_free 9.5 | wall 68395
2024-11-01 03:19:41 - trainer.py[line:639] - INFO: loading train data for epoch 16
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-01 03:19:44 - trainer.py[line:703] - INFO: begin training epoch 16
2024-11-01 03:19:44 - train.py[line:297] - INFO: Start iterating over samples
2024-11-01 03:21:12 - progress_bar.py[line:274] - INFO: epoch 016:      7 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.598, ntokens=4862, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=12.11, wps=68.6, ups=0.01, wpb=4862, bsz=1216, num_updates=4700, lr=1.3254e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=33, gb_free=9.5, wall=68486
2024-11-01 03:23:15 - progress_bar.py[line:274] - INFO: epoch 016:     17 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.584, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12, wps=416, ups=0.08, wpb=5118.1, bsz=1280, num_updates=4710, lr=1.31691e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=68609
2024-11-01 03:25:17 - progress_bar.py[line:274] - INFO: epoch 016:     27 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.591, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.05, wps=418.5, ups=0.08, wpb=5117.6, bsz=1280, num_updates=4720, lr=1.30841e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=68731
2024-11-01 03:27:20 - progress_bar.py[line:274] - INFO: epoch 016:     37 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.585, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12, wps=418.2, ups=0.08, wpb=5117.6, bsz=1280, num_updates=4730, lr=1.29992e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=68853
2024-11-01 03:29:22 - progress_bar.py[line:274] - INFO: epoch 016:     47 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.596, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.09, wps=418.8, ups=0.08, wpb=5118.2, bsz=1280, num_updates=4740, lr=1.29142e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=68976
2024-11-01 03:31:25 - progress_bar.py[line:274] - INFO: epoch 016:     57 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.592, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.06, wps=414.7, ups=0.08, wpb=5118.4, bsz=1280, num_updates=4750, lr=1.28292e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=69099
2024-11-01 03:33:27 - progress_bar.py[line:274] - INFO: epoch 016:     67 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.591, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.05, wps=419.6, ups=0.08, wpb=5118.4, bsz=1280, num_updates=4760, lr=1.27443e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=69221
2024-11-01 03:35:29 - progress_bar.py[line:274] - INFO: epoch 016:     77 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.581, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.97, wps=419.2, ups=0.08, wpb=5117.7, bsz=1280, num_updates=4770, lr=1.26593e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=69343
2024-11-01 03:37:33 - progress_bar.py[line:274] - INFO: epoch 016:     87 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.593, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.07, wps=414.6, ups=0.08, wpb=5118.1, bsz=1280, num_updates=4780, lr=1.25743e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=69466
2024-11-01 03:39:36 - progress_bar.py[line:274] - INFO: epoch 016:     97 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.615, ntokens=5118.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.26, wps=414.9, ups=0.08, wpb=5118.9, bsz=1280, num_updates=4790, lr=1.24894e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=69590
2024-11-01 03:41:38 - progress_bar.py[line:274] - INFO: epoch 016:    107 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.615, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.25, wps=419.1, ups=0.08, wpb=5118.3, bsz=1280, num_updates=4800, lr=1.24044e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=69712
2024-11-01 03:43:41 - progress_bar.py[line:274] - INFO: epoch 016:    117 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.621, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.3, wps=418.4, ups=0.08, wpb=5117.8, bsz=1280, num_updates=4810, lr=1.23195e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=69834
2024-11-01 03:45:42 - progress_bar.py[line:274] - INFO: epoch 016:    127 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.633, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.4, wps=420.5, ups=0.08, wpb=5118.3, bsz=1280, num_updates=4820, lr=1.22345e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=69956
2024-11-01 03:47:46 - progress_bar.py[line:274] - INFO: epoch 016:    137 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.62, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.3, wps=415, ups=0.08, wpb=5118.4, bsz=1280, num_updates=4830, lr=1.21495e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=70079
2024-11-01 03:49:50 - progress_bar.py[line:274] - INFO: epoch 016:    147 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.625, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.34, wps=413.2, ups=0.08, wpb=5117.4, bsz=1280, num_updates=4840, lr=1.20646e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=35, gb_free=9.5, wall=70203
2024-11-01 03:51:54 - progress_bar.py[line:274] - INFO: epoch 016:    157 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.61, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.21, wps=412.4, ups=0.08, wpb=5117.6, bsz=1280, num_updates=4850, lr=1.19796e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=35, gb_free=9.6, wall=70327
2024-11-01 03:53:57 - progress_bar.py[line:274] - INFO: epoch 016:    167 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.617, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.27, wps=415.1, ups=0.08, wpb=5117.9, bsz=1280, num_updates=4860, lr=1.18946e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=35, gb_free=9.5, wall=70451
2024-11-01 03:56:00 - progress_bar.py[line:274] - INFO: epoch 016:    177 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.616, ntokens=5117.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.26, wps=416.5, ups=0.08, wpb=5117.5, bsz=1280, num_updates=4870, lr=1.18097e-05, gnorm=0.009, clip=0, loss_scale=16384, train_wall=35, gb_free=9.5, wall=70573
