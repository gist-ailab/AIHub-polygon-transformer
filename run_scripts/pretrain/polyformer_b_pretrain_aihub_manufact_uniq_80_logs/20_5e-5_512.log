/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launch.py:188: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  FutureWarning,
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2024-11-08 11:10:34 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 11:10:34 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 11:10:34 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 11:10:34 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 11:10:34 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 11:10:34 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 11:10:34 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 11:10:34 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 11:10:36 - utils.py[line:258] - INFO: distributed init (rank 2): env://
2024-11-08 11:10:36 - utils.py[line:261] - INFO: Start init
2024-11-08 11:10:36 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 2
2024-11-08 11:10:36 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2024-11-08 11:10:36 - utils.py[line:261] - INFO: Start init
2024-11-08 11:10:36 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2024-11-08 11:10:36 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2024-11-08 11:10:36 - utils.py[line:261] - INFO: Start init
2024-11-08 11:10:36 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2024-11-08 11:10:36 - utils.py[line:258] - INFO: distributed init (rank 3): env://
2024-11-08 11:10:36 - utils.py[line:261] - INFO: Start init
2024-11-08 11:10:36 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 3
2024-11-08 11:10:36 - utils.py[line:258] - INFO: distributed init (rank 7): env://
2024-11-08 11:10:36 - utils.py[line:261] - INFO: Start init
2024-11-08 11:10:36 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 7
2024-11-08 11:10:36 - utils.py[line:258] - INFO: distributed init (rank 4): env://
2024-11-08 11:10:36 - utils.py[line:261] - INFO: Start init
2024-11-08 11:10:36 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 4
2024-11-08 11:10:36 - utils.py[line:258] - INFO: distributed init (rank 5): env://
2024-11-08 11:10:36 - utils.py[line:261] - INFO: Start init
2024-11-08 11:10:36 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 5
2024-11-08 11:10:36 - utils.py[line:258] - INFO: distributed init (rank 6): env://
2024-11-08 11:10:36 - utils.py[line:261] - INFO: Start init
2024-11-08 11:10:36 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 6
2024-11-08 11:10:36 - distributed_c10d.py[line:354] - INFO: Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 11:10:36 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 6
single-machine distributed training is initialized.
2024-11-08 11:10:36 - distributed_c10d.py[line:354] - INFO: Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 11:10:36 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 4
single-machine distributed training is initialized.
2024-11-08 11:10:36 - distributed_c10d.py[line:354] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 11:10:36 - distributed_c10d.py[line:354] - INFO: Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 11:10:36 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 0
single-machine distributed training is initialized.
2024-11-08 11:10:36 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 2
single-machine distributed training is initialized.
2024-11-08 11:10:36 - distributed_c10d.py[line:354] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 11:10:36 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 1
single-machine distributed training is initialized.
2024-11-08 11:10:36 - distributed_c10d.py[line:354] - INFO: Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 11:10:36 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 5
single-machine distributed training is initialized.
2024-11-08 11:10:36 - distributed_c10d.py[line:354] - INFO: Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 11:10:36 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 7
single-machine distributed training is initialized.
2024-11-08 11:10:36 - distributed_c10d.py[line:354] - INFO: Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 11:10:36 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 3
single-machine distributed training is initialized.
2024-11-08 11:10:41 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../polyformer_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 1000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 20, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 20, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 1000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'score', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='polyformer_b', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='polyformer_b', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid=20, best_checkpoint_metric='score', bf16=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, cls_weight=0.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../datasets/pretrain/train_aihub_manufact_80.tsv,../../datasets/pretrain/val_aihub_manufact_80.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, det_weight=1.0, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_acc=True, eval_args='{"beam":5,"min_len":2,"max_len_a":0,"max_len_b":2}', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=20, max_image_size=512, max_source_positions=1024, max_src_length=80, max_target_positions=1024, max_tgt_length=420, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=8, num_bins=64, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', out_index=3, pad=1, patch_image_size=512, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, restore_file='checkpoint_last.pt', sample_patch_num=196, save_dir='./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512', save_interval=1, save_interval_updates=1000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', scst=False, scst_args='{}', seed=1, selected_cols='0,3,1,2', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='refcoco_pretrain', tensorboard_logdir=None, threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[8], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../polyformer_module', uses_ema=False, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=1000, vis_encoder_type='swin-base', wandb_project=None, warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'refcoco_pretrain', 'data': '../../datasets/pretrain/train_aihub_manufact_80.tsv,../../datasets/pretrain/val_aihub_manufact_80.tsv', 'selected_cols': '0,3,1,2', 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 80, 'max_tgt_length': 420, 'code_dict_size': 8192, 'patch_image_size': 512, 'num_bins': 64, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': True, 'eval_args': '{"beam":5,"min_len":2,"max_len_a":0,"max_len_b":2}', 'uses_ema': False, 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'det_weight': 1.0, 'cls_weight': 0.0, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2024-11-08 11:10:41 - base_task.py[line:187] - INFO: source dictionary: 4100 types
2024-11-08 11:10:41 - base_task.py[line:188] - INFO: target dictionary: 4100 types
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
The model and loaded state dict do not match exactly

unexpected key in source state_dict: norm.weight, norm.bias, head.weight, head.bias, layers.0.blocks.1.attn_mask, layers.1.blocks.1.attn_mask, layers.2.blocks.1.attn_mask, layers.2.blocks.3.attn_mask, layers.2.blocks.5.attn_mask, layers.2.blocks.7.attn_mask, layers.2.blocks.9.attn_mask, layers.2.blocks.11.attn_mask, layers.2.blocks.13.attn_mask, layers.2.blocks.15.attn_mask, layers.2.blocks.17.attn_mask

missing keys in source state_dict: norm3.weight, norm3.bias

Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
local datafile ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 4 row count 6955 total row count 55640
local datafile ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 2 row count 6955 total row count 55640
local datafile ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
The model and loaded state dict do not match exactly

unexpected key in source state_dict: norm.weight, norm.bias, head.weight, head.bias, layers.0.blocks.1.attn_mask, layers.1.blocks.1.attn_mask, layers.2.blocks.1.attn_mask, layers.2.blocks.3.attn_mask, layers.2.blocks.5.attn_mask, layers.2.blocks.7.attn_mask, layers.2.blocks.9.attn_mask, layers.2.blocks.11.attn_mask, layers.2.blocks.13.attn_mask, layers.2.blocks.15.attn_mask, layers.2.blocks.17.attn_mask

missing keys in source state_dict: norm3.weight, norm3.bias

local datafile ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 7 row count 6955 total row count 55640
2024-11-08 11:10:55 - train.py[line:101] - INFO: PolyFormerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(4100, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): SwinTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (pos_drop): Dropout(p=0.0, inplace=False)
      (layers): ModuleList(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): Identity()
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.009)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=512, out_features=256, bias=False)
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=256, out_features=256, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.017)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=256, out_features=1024, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1024, out_features=256, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=256, out_features=256, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.026)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=256, out_features=1024, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1024, out_features=256, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=1024, out_features=512, bias=False)
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.035)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.043)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (2): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.052)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (3): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.061)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (4): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.070)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (5): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.078)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (6): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.087)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (7): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.096)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (8): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.104)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (9): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.113)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (10): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.122)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (11): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.130)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (12): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.139)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (13): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.148)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (14): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.157)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (15): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.165)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (16): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.174)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (17): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.183)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=2048, out_features=1024, bias=False)
            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.191)
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.200)
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
      )
      (norm3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
    (bert): XLMRobertaForMaskedLM(
      (roberta): XLMRobertaModel(
        (embeddings): XLMRobertaEmbeddings(
          (word_embeddings): Embedding(250002, 768, padding_idx=1)
          (position_embeddings): Embedding(514, 768, padding_idx=1)
          (token_type_embeddings): Embedding(1, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): XLMRobertaEncoder(
          (layer): ModuleList(
            (0): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
      )
      (lm_head): XLMRobertaLMHead(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (decoder): Linear(in_features=768, out_features=250002, bias=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(4100, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (reg_head): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): Linear(in_features=768, out_features=768, bias=True)
        (2): Linear(in_features=768, out_features=2, bias=True)
      )
    )
    (cls_head): Linear(in_features=768, out_features=3, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2024-11-08 11:10:55 - train.py[line:102] - INFO: task: RefcocoPretrainTask
2024-11-08 11:10:55 - train.py[line:103] - INFO: model: PolyFormerModel
2024-11-08 11:10:55 - train.py[line:104] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2024-11-08 11:10:55 - train.py[line:108] - INFO: num. shared model params: 478,547,732 (num. trained: 478,547,732)
2024-11-08 11:10:55 - train.py[line:115] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 1 row count 6955 total row count 55640
local datafile ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 0 row count 6955 total row count 55640
local datafile ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 3 row count 6955 total row count 55640
local datafile ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 6 row count 6955 total row count 55640
local datafile ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_manufact_80.tsv slice_id 5 row count 6955 total row count 55640
2024-11-08 11:10:57 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2024-11-08 11:10:57 - distributed_c10d.py[line:354] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-11-08 11:10:57 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2024-11-08 11:10:57 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.layers.0.downsample.reduction.bias <- encoder.embed_images.layers.1.downsample.reduction.bias
2024-11-08 11:10:57 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.layers.0.downsample.reduction.bias <- encoder.embed_images.layers.2.downsample.reduction.bias
2024-11-08 11:10:57 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.layers.0.downsample.reduction.bias <- decoder.cls_head.bias
2024-11-08 11:10:57 - trainer.py[line:124] - INFO: detected shared parameter: encoder.bert.roberta.embeddings.word_embeddings.weight <- encoder.bert.lm_head.decoder.weight
2024-11-08 11:10:57 - trainer.py[line:124] - INFO: detected shared parameter: encoder.bert.lm_head.bias <- encoder.bert.lm_head.decoder.bias
2024-11-08 11:11:00 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 8 workers***********************
2024-11-08 11:11:00 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 11:11:00 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 11:11:00 - utils.py[line:765] - INFO: rank   2: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 11:11:00 - utils.py[line:765] - INFO: rank   3: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 11:11:00 - utils.py[line:765] - INFO: rank   4: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 11:11:00 - utils.py[line:765] - INFO: rank   5: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 11:11:00 - utils.py[line:765] - INFO: rank   6: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 11:11:00 - utils.py[line:765] - INFO: rank   7: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 11:11:00 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 8 workers***********************
2024-11-08 11:11:00 - train.py[line:145] - INFO: training on 8 devices (GPUs/TPUs)
2024-11-08 11:11:00 - train.py[line:151] - INFO: max tokens per device = None and max sentences per device = 20
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
2024-11-08 11:11:00 - trainer.py[line:458] - INFO: Preparing to load checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2024-11-08 11:11:00 - trainer.py[line:624] - INFO: No existing checkpoint found ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 11:11:00 - trainer.py[line:639] - INFO: loading train data for epoch 1
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 row count 50000 total row count 400000
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
slice_id 5 seek offset 250000
slice_id 6 seek offset 300000
slice_id 1 seek offset 50000
slice_id 0 seek offset 0
slice_id 4 seek offset 200000
slice_id 7 seek offset 350000
slice_id 2 seek offset 100000
slice_id 3 seek offset 150000
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
2024-11-08 11:11:04 - trainer.py[line:703] - INFO: begin training epoch 1
2024-11-08 11:11:04 - train.py[line:297] - INFO: Start iterating over samples
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
loss_reg: 0.1470947265625 loss_cls: 0.0
loss_reg: 0.1357421875 loss_cls: 0.0
loss_reg: 0.1470947265625 loss_cls: 0.0
loss_reg: 0.1558837890625 loss_cls: 0.0
loss_reg: 0.151611328125 loss_cls: 0.0
loss_reg: 0.15478515625 loss_cls: 0.0
loss_reg: 0.1458740234375 loss_cls: 0.0
loss_reg: 0.16650390625 loss_cls: 0.0
loss_reg: 0.1370849609375 loss_cls: 0.0
loss_reg: 0.134765625 loss_cls: 0.0
loss_reg: 0.1396484375 loss_cls: 0.0
loss_reg: 0.15478515625 loss_cls: 0.0
loss_reg: 0.1431884765625 loss_cls: 0.0
loss_reg: 0.14404296875 loss_cls: 0.0
loss_reg: 0.141357421875 loss_cls: 0.0
loss_reg: 0.134521484375 loss_cls: 0.0
loss_reg: 0.15185546875 loss_cls: 0.0
loss_reg: 0.1483154296875 loss_cls: 0.0
loss_reg: 0.1636962890625 loss_cls: 0.0
loss_reg: 0.1641845703125 loss_cls: 0.0
loss_reg: 0.1363525390625 loss_cls: 0.0
loss_reg: 0.1470947265625 loss_cls: 0.0
loss_reg: 0.16064453125 loss_cls: 0.0
loss_reg: 0.1806640625 loss_cls: 0.0
loss_reg: 0.1632080078125 loss_cls: 0.0
loss_reg: 0.175537109375 loss_cls: 0.0
loss_reg: 0.1639404296875 loss_cls: 0.0
loss_reg: 0.155517578125 loss_cls: 0.0
loss_reg: 0.1781005859375 loss_cls: 0.0
loss_reg: 0.144287109375 loss_cls: 0.0
loss_reg: 0.15673828125 loss_cls: 0.0
loss_reg: 0.15673828125 loss_cls: 0.0
loss_reg: 0.144287109375 loss_cls: 0.0
loss_reg: 0.131591796875 loss_cls: 0.0
loss_reg: 0.16064453125 loss_cls: 0.0
loss_reg: 0.1427001953125 loss_cls: 0.0
loss_reg: 0.1612548828125 loss_cls: 0.0
loss_reg: 0.1566162109375 loss_cls: 0.0
loss_reg: 0.17626953125 loss_cls: 0.0
loss_reg: 0.16845703125 loss_cls: 0.0
loss_reg: 0.159912109375 loss_cls: 0.0
loss_reg: 0.16650390625 loss_cls: 0.0
loss_reg: 0.1307373046875 loss_cls: 0.0
loss_reg: 0.131591796875 loss_cls: 0.0
loss_reg: 0.133056640625 loss_cls: 0.0
loss_reg: 0.1309814453125 loss_cls: 0.0
loss_reg: 0.148193359375 loss_cls: 0.0
loss_reg: 0.146484375 loss_cls: 0.0
loss_reg: 0.17333984375 loss_cls: 0.0
loss_reg: 0.1553955078125 loss_cls: 0.0
loss_reg: 0.13671875 loss_cls: 0.0
loss_reg: 0.148193359375 loss_cls: 0.0
loss_reg: 0.135009765625 loss_cls: 0.0
loss_reg: 0.1414794921875 loss_cls: 0.0
loss_reg: 0.1573486328125 loss_cls: 0.0
loss_reg: 0.140869140625 loss_cls: 0.0
loss_reg: 0.146728515625 loss_cls: 0.0
loss_reg: 0.14404296875 loss_cls: 0.0
loss_reg: 0.1943359375 loss_cls: 0.0
loss_reg: 0.1651611328125 loss_cls: 0.0
loss_reg: 0.130859375 loss_cls: 0.0
loss_reg: 0.154296875 loss_cls: 0.0
loss_reg: 0.1810302734375 loss_cls: 0.0
loss_reg: 0.1729736328125 loss_cls: 0.0
2024-11-08 11:12:54 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=2.989, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=7.94, wps=500.6, ups=0.1, wpb=5119.9, bsz=1280, num_updates=10, lr=1.33333e-06, gnorm=0.022, clip=0, loss_scale=128, train_wall=55, gb_free=9.7, wall=115
2024-11-08 11:14:38 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=2.961, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=7.79, wps=494, ups=0.1, wpb=5120, bsz=1280, num_updates=20, lr=2.66667e-06, gnorm=0.008, clip=0, loss_scale=128, train_wall=82, gb_free=9.7, wall=218
2024-11-08 11:16:22 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.167, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.98, wps=493.1, ups=0.1, wpb=5120, bsz=1280, num_updates=30, lr=4e-06, gnorm=0.006, clip=0, loss_scale=128, train_wall=103, gb_free=9.7, wall=322
2024-11-08 11:18:06 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 313 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=3.477, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.14, wps=492.7, ups=0.1, wpb=5120, bsz=1280, num_updates=40, lr=5.33333e-06, gnorm=0.005, clip=0, loss_scale=128, train_wall=104, gb_free=9.7, wall=426
2024-11-08 11:19:49 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.698, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.98, wps=496.6, ups=0.1, wpb=5120, bsz=1280, num_updates=50, lr=6.66667e-06, gnorm=0.006, clip=0, loss_scale=128, train_wall=103, gb_free=9.7, wall=529
2024-11-08 11:21:32 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.702, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.02, wps=494.6, ups=0.1, wpb=5120, bsz=1280, num_updates=60, lr=8e-06, gnorm=0.007, clip=0, loss_scale=128, train_wall=103, gb_free=9.6, wall=633
2024-11-08 11:23:15 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.721, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.19, wps=499.2, ups=0.1, wpb=5120, bsz=1280, num_updates=70, lr=9.33333e-06, gnorm=0.006, clip=0, loss_scale=128, train_wall=102, gb_free=9.7, wall=735
2024-11-08 11:24:58 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.699, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.98, wps=495.1, ups=0.1, wpb=5120, bsz=1280, num_updates=80, lr=1.06667e-05, gnorm=0.009, clip=0, loss_scale=128, train_wall=103, gb_free=9.7, wall=839
2024-11-08 11:26:41 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.658, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.62, wps=498.9, ups=0.1, wpb=5120, bsz=1280, num_updates=90, lr=1.2e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=103, gb_free=9.7, wall=941
2024-11-08 11:28:25 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.735, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=13.31, wps=492.9, ups=0.1, wpb=5120, bsz=1280, num_updates=100, lr=1.33333e-05, gnorm=0.008, clip=0, loss_scale=128, train_wall=104, gb_free=9.7, wall=1045
2024-11-08 11:30:08 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.59, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.05, wps=495, ups=0.1, wpb=5119.9, bsz=1280, num_updates=110, lr=1.46667e-05, gnorm=0.011, clip=0, loss_scale=128, train_wall=103, gb_free=9.6, wall=1149
2024-11-08 11:31:52 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 313 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=3.548, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.7, wps=492.4, ups=0.1, wpb=5120, bsz=1280, num_updates=120, lr=1.6e-05, gnorm=0.015, clip=0, loss_scale=128, train_wall=104, gb_free=9.6, wall=1253
2024-11-08 11:33:35 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.618, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.27, wps=496.6, ups=0.1, wpb=5120, bsz=1280, num_updates=130, lr=1.73333e-05, gnorm=0.018, clip=0, loss_scale=128, train_wall=103, gb_free=9.7, wall=1356
2024-11-08 11:35:19 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.668, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.71, wps=493.5, ups=0.1, wpb=5119.9, bsz=1280, num_updates=140, lr=1.86667e-05, gnorm=0.012, clip=0, loss_scale=128, train_wall=104, gb_free=9.7, wall=1459
2024-11-08 11:37:03 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.516, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.44, wps=495.1, ups=0.1, wpb=5119.9, bsz=1280, num_updates=150, lr=2e-05, gnorm=0.013, clip=0, loss_scale=128, train_wall=103, gb_free=9.7, wall=1563
2024-11-08 11:38:46 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.409, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.62, wps=496.9, ups=0.1, wpb=5120, bsz=1280, num_updates=160, lr=2.13333e-05, gnorm=0.012, clip=0, loss_scale=128, train_wall=103, gb_free=9.7, wall=1666
2024-11-08 11:40:29 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.356, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.24, wps=496.5, ups=0.1, wpb=5120, bsz=1280, num_updates=170, lr=2.26667e-05, gnorm=0.009, clip=0, loss_scale=128, train_wall=103, gb_free=9.7, wall=1769
2024-11-08 11:42:12 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.405, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.6, wps=494.1, ups=0.1, wpb=5120, bsz=1280, num_updates=180, lr=2.4e-05, gnorm=0.008, clip=0, loss_scale=128, train_wall=104, gb_free=9.7, wall=1873
2024-11-08 11:43:57 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.434, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.81, wps=490, ups=0.1, wpb=5120, bsz=1280, num_updates=190, lr=2.53333e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=104, gb_free=9.7, wall=1977
2024-11-08 11:45:41 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.375, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.38, wps=492, ups=0.1, wpb=5119.8, bsz=1280, num_updates=200, lr=2.66667e-05, gnorm=0.008, clip=0, loss_scale=128, train_wall=104, gb_free=9.7, wall=2081
2024-11-08 11:47:25 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.381, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.42, wps=490, ups=0.1, wpb=5119.9, bsz=1280, num_updates=210, lr=2.8e-05, gnorm=0.008, clip=0, loss_scale=128, train_wall=104, gb_free=9.7, wall=2186
2024-11-08 11:49:09 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.434, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.81, wps=495.6, ups=0.1, wpb=5120, bsz=1280, num_updates=220, lr=2.93333e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=103, gb_free=9.7, wall=2289
2024-11-08 11:50:52 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.5, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.31, wps=495.5, ups=0.1, wpb=5119.8, bsz=1280, num_updates=230, lr=3.06667e-05, gnorm=0.008, clip=0, loss_scale=128, train_wall=103, gb_free=9.7, wall=2392
2024-11-08 11:52:36 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.494, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.27, wps=493, ups=0.1, wpb=5119.9, bsz=1280, num_updates=240, lr=3.2e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=104, gb_free=9.6, wall=2496
2024-11-08 11:54:19 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.37, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.34, wps=494.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=250, lr=3.33333e-05, gnorm=0.008, clip=0, loss_scale=128, train_wall=103, gb_free=9.7, wall=2600
2024-11-08 11:56:02 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.288, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.77, wps=499.3, ups=0.1, wpb=5120, bsz=1280, num_updates=260, lr=3.46667e-05, gnorm=0.009, clip=0, loss_scale=128, train_wall=102, gb_free=9.7, wall=2702
2024-11-08 11:57:45 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.224, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.34, wps=494.7, ups=0.1, wpb=5120, bsz=1280, num_updates=270, lr=3.6e-05, gnorm=0.008, clip=0, loss_scale=128, train_wall=103, gb_free=9.7, wall=2806
2024-11-08 11:59:28 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.286, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.76, wps=496.9, ups=0.1, wpb=5120, bsz=1280, num_updates=280, lr=3.73333e-05, gnorm=0.008, clip=0, loss_scale=128, train_wall=103, gb_free=9.7, wall=2909
2024-11-08 12:01:12 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.372, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.36, wps=492.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=290, lr=3.86667e-05, gnorm=0.006, clip=0, loss_scale=128, train_wall=104, gb_free=9.6, wall=3013
2024-11-08 12:02:55 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.406, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.6, wps=497.2, ups=0.1, wpb=5120, bsz=1280, num_updates=300, lr=4e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=103, gb_free=9.6, wall=3116
2024-11-08 12:04:38 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.324, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.02, wps=498.2, ups=0.1, wpb=5119.9, bsz=1280, num_updates=310, lr=4.13333e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=103, gb_free=9.6, wall=3218
slice_id 6 seek offset 41730
slice_id 5 seek offset 34775slice_id 7 seek offset 48685

2024-11-08 12:05:02 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 2 seek offset 13910
slice_id 3 seek offset 20865
slice_id 1 seek offset 6955
slice_id 4 seek offset 27820
slice_id 5 seek offset 34775
slice_id 7 seek offset 48685
slice_id 6 seek offset 41730
slice_id 3 seek offset 20865
slice_id 1 seek offset 6955
slice_id 0 seek offset 0
slice_id 4 seek offset 27820
slice_id 2 seek offset 13910
2024-11-08 12:12:32 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.004 | loss_v1 0 | loss_v2 0 | nll_loss 3.284 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.74 | score 0.0099 | wps 496.3 | wpb 639.5 | bsz 159.9 | num_updates 313
2024-11-08 12:12:32 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 313 updates
2024-11-08 12:12:32 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 row count 50000 total row count 400000
slice_id 7 seek offset 350000
slice_id 5 seek offset 250000
slice_id 6 seek offset 300000
slice_id 4 seek offset 200000
slice_id 2 seek offset 100000
slice_id 1 seek offset 50000
slice_id 3 seek offset 150000
2024-11-08 12:12:43 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-11-08 12:12:55 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 1 @ 313 updates, score 0.0099) (writing took 22.44521149600041 seconds)
2024-11-08 12:12:55 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 313 updates
2024-11-08 12:12:55 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 12:14:25 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 12:14:25 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 1 @ 313 updates, score 0) (writing took 90.73527778399875 seconds)
2024-11-08 12:14:25 - train.py[line:336] - INFO: end of epoch 1 (average epoch stats below)
2024-11-08 12:14:25 - progress_bar.py[line:282] - INFO: epoch 001 | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.444 | ntokens 5111.78 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 10.88 | wps 421.6 | ups 0.08 | wpb 5111.8 | bsz 1278 | num_updates 313 | lr 4.17333e-05 | gnorm 0.009 | clip 0 | loss_scale 128 | train_wall 3157 | gb_free 9.7 | wall 3806
2024-11-08 12:14:25 - trainer.py[line:639] - INFO: loading train data for epoch 2
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 12:14:28 - trainer.py[line:703] - INFO: begin training epoch 2
2024-11-08 12:14:28 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 12:15:41 - progress_bar.py[line:274] - INFO: epoch 002:      7 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.287, ntokens=4863.9, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=9.76, wps=73.4, ups=0.02, wpb=4863.9, bsz=1216, num_updates=320, lr=4.26667e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=48, gb_free=9.6, wall=3881
2024-11-08 12:17:21 - progress_bar.py[line:274] - INFO: epoch 002:     17 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.286, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.75, wps=509.7, ups=0.1, wpb=5120, bsz=1280, num_updates=330, lr=4.4e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=35, gb_free=9.7, wall=3982
2024-11-08 12:19:03 - progress_bar.py[line:274] - INFO: epoch 002:     27 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.318, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.97, wps=504.1, ups=0.1, wpb=5120, bsz=1280, num_updates=340, lr=4.53333e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=39, gb_free=9.7, wall=4083
2024-11-08 12:20:47 - progress_bar.py[line:274] - INFO: epoch 002:     37 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.358, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.25, wps=493.4, ups=0.1, wpb=5120, bsz=1280, num_updates=350, lr=4.66667e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=73, gb_free=9.7, wall=4187
2024-11-08 12:22:30 - progress_bar.py[line:274] - INFO: epoch 002:     47 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.406, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.6, wps=493.8, ups=0.1, wpb=5120, bsz=1280, num_updates=360, lr=4.8e-05, gnorm=0.006, clip=0, loss_scale=128, train_wall=102, gb_free=9.6, wall=4291
2024-11-08 12:24:14 - progress_bar.py[line:274] - INFO: epoch 002:     57 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.386, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.45, wps=493.5, ups=0.1, wpb=5120, bsz=1280, num_updates=370, lr=4.93333e-05, gnorm=0.006, clip=0, loss_scale=128, train_wall=104, gb_free=9.6, wall=4394
2024-11-08 12:25:58 - progress_bar.py[line:274] - INFO: epoch 002:     67 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.374, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.37, wps=494.4, ups=0.1, wpb=5120, bsz=1280, num_updates=380, lr=4.99575e-05, gnorm=0.006, clip=0, loss_scale=128, train_wall=103, gb_free=9.7, wall=4498
2024-11-08 12:27:41 - progress_bar.py[line:274] - INFO: epoch 002:     77 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.406, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.6, wps=495.6, ups=0.1, wpb=5120, bsz=1280, num_updates=390, lr=4.98726e-05, gnorm=0.006, clip=0, loss_scale=128, train_wall=103, gb_free=9.6, wall=4601
2024-11-08 12:29:25 - progress_bar.py[line:274] - INFO: epoch 002:     87 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.416, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.68, wps=491.8, ups=0.1, wpb=5120, bsz=1280, num_updates=400, lr=4.97876e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=104, gb_free=9.6, wall=4705
2024-11-08 12:31:09 - progress_bar.py[line:274] - INFO: epoch 002:     97 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.428, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.76, wps=493.7, ups=0.1, wpb=5120, bsz=1280, num_updates=410, lr=4.97026e-05, gnorm=0.006, clip=0, loss_scale=128, train_wall=104, gb_free=9.6, wall=4809
2024-11-08 12:32:52 - progress_bar.py[line:274] - INFO: epoch 002:    107 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.488, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.22, wps=495.6, ups=0.1, wpb=5119.9, bsz=1280, num_updates=420, lr=4.96177e-05, gnorm=0.006, clip=0, loss_scale=128, train_wall=103, gb_free=9.7, wall=4912
2024-11-08 12:34:36 - progress_bar.py[line:274] - INFO: epoch 002:    117 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.531, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.56, wps=492.4, ups=0.1, wpb=5120, bsz=1280, num_updates=430, lr=4.95327e-05, gnorm=0.006, clip=0, loss_scale=128, train_wall=104, gb_free=9.7, wall=5016
2024-11-08 12:36:20 - progress_bar.py[line:274] - INFO: epoch 002:    127 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.492, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.25, wps=493.3, ups=0.1, wpb=5120, bsz=1280, num_updates=440, lr=4.94477e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=104, gb_free=9.7, wall=5120
2024-11-08 12:38:04 - progress_bar.py[line:274] - INFO: epoch 002:    137 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.422, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.72, wps=492.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=450, lr=4.93628e-05, gnorm=0.006, clip=0, loss_scale=128, train_wall=104, gb_free=9.6, wall=5224
2024-11-08 12:39:48 - progress_bar.py[line:274] - INFO: epoch 002:    147 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.421, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.71, wps=493.1, ups=0.1, wpb=5120, bsz=1280, num_updates=460, lr=4.92778e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=104, gb_free=9.7, wall=5328
2024-11-08 12:41:31 - progress_bar.py[line:274] - INFO: epoch 002:    157 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.433, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.8, wps=494.2, ups=0.1, wpb=5119.9, bsz=1280, num_updates=470, lr=4.91929e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=104, gb_free=9.7, wall=5432
2024-11-08 12:43:15 - progress_bar.py[line:274] - INFO: epoch 002:    167 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.453, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.95, wps=493.1, ups=0.1, wpb=5120, bsz=1280, num_updates=480, lr=4.91079e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=104, gb_free=9.7, wall=5535
2024-11-08 12:44:59 - progress_bar.py[line:274] - INFO: epoch 002:    177 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.52, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.47, wps=491.3, ups=0.1, wpb=5120, bsz=1280, num_updates=490, lr=4.90229e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=104, gb_free=9.7, wall=5640
2024-11-08 12:46:43 - progress_bar.py[line:274] - INFO: epoch 002:    187 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.536, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.6, wps=493.7, ups=0.1, wpb=5120, bsz=1280, num_updates=500, lr=4.8938e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=104, gb_free=9.6, wall=5743
2024-11-08 12:48:27 - progress_bar.py[line:274] - INFO: epoch 002:    197 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.541, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.64, wps=493.3, ups=0.1, wpb=5119.9, bsz=1280, num_updates=510, lr=4.8853e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=104, gb_free=9.7, wall=5847
2024-11-08 12:50:10 - progress_bar.py[line:274] - INFO: epoch 002:    207 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.514, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.42, wps=494.2, ups=0.1, wpb=5119.8, bsz=1280, num_updates=520, lr=4.87681e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=104, gb_free=9.6, wall=5951
2024-11-08 12:51:56 - progress_bar.py[line:274] - INFO: epoch 002:    217 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.453, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.95, wps=486.7, ups=0.1, wpb=5120, bsz=1280, num_updates=530, lr=4.86831e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=105, gb_free=9.7, wall=6056
2024-11-08 12:53:40 - progress_bar.py[line:274] - INFO: epoch 002:    227 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.518, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.46, wps=491, ups=0.1, wpb=5119.8, bsz=1280, num_updates=540, lr=4.85981e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=104, gb_free=9.6, wall=6160
2024-11-08 12:55:24 - progress_bar.py[line:274] - INFO: epoch 002:    237 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.522, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.49, wps=492.5, ups=0.1, wpb=5120, bsz=1280, num_updates=550, lr=4.85132e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=104, gb_free=9.7, wall=6264
2024-11-08 12:57:08 - progress_bar.py[line:274] - INFO: epoch 002:    247 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.444, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.88, wps=493.5, ups=0.1, wpb=5119.8, bsz=1280, num_updates=560, lr=4.84282e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=104, gb_free=9.6, wall=6368
2024-11-08 12:58:50 - progress_bar.py[line:274] - INFO: epoch 002:    257 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.363, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.29, wps=498.7, ups=0.1, wpb=5120, bsz=1280, num_updates=570, lr=4.83432e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=103, gb_free=9.7, wall=6470
2024-11-08 13:00:33 - progress_bar.py[line:274] - INFO: epoch 002:    267 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.356, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.24, wps=496.6, ups=0.1, wpb=5120, bsz=1280, num_updates=580, lr=4.82583e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=103, gb_free=9.7, wall=6574
2024-11-08 13:02:17 - progress_bar.py[line:274] - INFO: epoch 002:    277 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.419, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.7, wps=496.4, ups=0.1, wpb=5120, bsz=1280, num_updates=590, lr=4.81733e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=103, gb_free=9.6, wall=6677
2024-11-08 13:04:00 - progress_bar.py[line:274] - INFO: epoch 002:    287 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.415, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.67, wps=493.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=600, lr=4.80884e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=104, gb_free=9.6, wall=6780
2024-11-08 13:05:44 - progress_bar.py[line:274] - INFO: epoch 002:    297 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.39, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.48, wps=492.4, ups=0.1, wpb=5120, bsz=1280, num_updates=610, lr=4.80034e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=104, gb_free=9.7, wall=6884
2024-11-08 13:07:28 - progress_bar.py[line:274] - INFO: epoch 002:    307 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.392, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=10.5, wps=493.5, ups=0.1, wpb=5119.9, bsz=1280, num_updates=620, lr=4.79184e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=104, gb_free=9.7, wall=6988
slice_id 6 seek offset 41730
slice_id 7 seek offset 48685
slice_id 5 seek offset 34775
slice_id 4 seek offset 278202024-11-08 13:08:23 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 1 seek offset 6955

slice_id 0 seek offset 0
slice_id 2 seek offset 13910slice_id 3 seek offset 20865

slice_id 7 seek offset 48685
slice_id 5 seek offset 34775
slice_id 3 seek offset 20865
slice_id 6 seek offset 41730
slice_id 1 seek offset 6955
slice_id 2 seek offset 13910
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-08 13:15:51 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss 0.004 | loss_v1 0 | loss_v2 0 | nll_loss 3.384 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 10.44 | score 0.016 | wps 499 | wpb 639.5 | bsz 159.9 | num_updates 626 | best_score 0.016
2024-11-08 13:15:51 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 626 updates
2024-11-08 13:15:51 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 row count 50000 total row count 400000file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 row count 50000 total row count 400000

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 row count 50000 total row count 400000
slice_id 6 seek offset 300000
slice_id 5 seek offset 250000
slice_id 2 seek offset 100000
slice_id 4 seek offset 200000
slice_id 3 seek offset 150000
slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
2024-11-08 13:16:52 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-11-08 13:18:05 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 2 @ 626 updates, score 0.016) (writing took 134.34493280301103 seconds)
2024-11-08 13:18:06 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 626 updates
2024-11-08 13:18:06 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 13:19:30 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 13:19:30 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 2 @ 626 updates, score 0) (writing took 84.21466907998547 seconds)
2024-11-08 13:19:30 - train.py[line:336] - INFO: end of epoch 2 (average epoch stats below)
2024-11-08 13:19:30 - progress_bar.py[line:282] - INFO: epoch 002 | loss 0.004 | loss_v1 0 | loss_v2 0 | nll_loss 3.429 | ntokens 5111.78 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 10.77 | wps 409.7 | ups 0.08 | wpb 5111.8 | bsz 1278 | num_updates 626 | lr 4.78675e-05 | gnorm 0.005 | clip 0 | loss_scale 256 | train_wall 3024 | gb_free 9.7 | wall 7710
2024-11-08 13:19:30 - trainer.py[line:639] - INFO: loading train data for epoch 3
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 13:19:33 - trainer.py[line:703] - INFO: begin training epoch 3
2024-11-08 13:19:33 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 13:20:16 - progress_bar.py[line:274] - INFO: epoch 003:      4 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.349, ntokens=4864, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=10.19, wps=63.4, ups=0.01, wpb=4864, bsz=1216, num_updates=630, lr=4.78335e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=70, gb_free=9.7, wall=7756
2024-11-08 13:21:55 - progress_bar.py[line:274] - INFO: epoch 003:     14 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.301, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.85, wps=512.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=640, lr=4.77485e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=35, gb_free=9.6, wall=7856
2024-11-08 13:23:38 - progress_bar.py[line:274] - INFO: epoch 003:     24 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.273, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.67, wps=500.7, ups=0.1, wpb=5120, bsz=1280, num_updates=650, lr=4.76636e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=37, gb_free=9.7, wall=7958
2024-11-08 13:25:22 - progress_bar.py[line:274] - INFO: epoch 003:     34 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.264, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.61, wps=489.7, ups=0.1, wpb=5120, bsz=1280, num_updates=660, lr=4.75786e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=75, gb_free=9.7, wall=8062
2024-11-08 13:27:06 - progress_bar.py[line:274] - INFO: epoch 003:     44 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.2, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.19, wps=491.3, ups=0.1, wpb=5120, bsz=1280, num_updates=670, lr=4.74936e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=103, gb_free=9.6, wall=8167
2024-11-08 13:28:51 - progress_bar.py[line:274] - INFO: epoch 003:     54 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.187, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.11, wps=491.5, ups=0.1, wpb=5120, bsz=1280, num_updates=680, lr=4.74087e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=104, gb_free=9.7, wall=8271
2024-11-08 13:30:35 - progress_bar.py[line:274] - INFO: epoch 003:     64 / 313 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=3.174, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.03, wps=490.4, ups=0.1, wpb=5120, bsz=1280, num_updates=690, lr=4.73237e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=104, gb_free=9.6, wall=8375
2024-11-08 13:32:20 - progress_bar.py[line:274] - INFO: epoch 003:     74 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.135, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.79, wps=488, ups=0.1, wpb=5120, bsz=1280, num_updates=700, lr=4.72387e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=105, gb_free=9.7, wall=8480
2024-11-08 13:34:04 - progress_bar.py[line:274] - INFO: epoch 003:     84 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.205, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.22, wps=492.1, ups=0.1, wpb=5120, bsz=1280, num_updates=710, lr=4.71538e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=104, gb_free=9.7, wall=8584
2024-11-08 13:35:48 - progress_bar.py[line:274] - INFO: epoch 003:     94 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.179, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.06, wps=494.6, ups=0.1, wpb=5120, bsz=1280, num_updates=720, lr=4.70688e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=103, gb_free=9.6, wall=8688
2024-11-08 13:37:31 - progress_bar.py[line:274] - INFO: epoch 003:    104 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.159, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.93, wps=495.9, ups=0.1, wpb=5119.9, bsz=1280, num_updates=730, lr=4.69839e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=103, gb_free=9.6, wall=8791
2024-11-08 13:39:15 - progress_bar.py[line:274] - INFO: epoch 003:    114 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.193, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.15, wps=493.3, ups=0.1, wpb=5120, bsz=1280, num_updates=740, lr=4.68989e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=104, gb_free=9.6, wall=8895
2024-11-08 13:40:59 - progress_bar.py[line:274] - INFO: epoch 003:    124 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.208, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.24, wps=491.7, ups=0.1, wpb=5120, bsz=1280, num_updates=750, lr=4.68139e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=104, gb_free=9.7, wall=8999
2024-11-08 13:42:42 - progress_bar.py[line:274] - INFO: epoch 003:    134 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.149, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.87, wps=496.6, ups=0.1, wpb=5120, bsz=1280, num_updates=760, lr=4.6729e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=103, gb_free=9.6, wall=9102
2024-11-08 13:44:26 - progress_bar.py[line:274] - INFO: epoch 003:    144 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.15, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.88, wps=493.5, ups=0.1, wpb=5119.9, bsz=1280, num_updates=770, lr=4.6644e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=104, gb_free=9.6, wall=9206
2024-11-08 13:46:09 - progress_bar.py[line:274] - INFO: epoch 003:    154 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.171, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9, wps=494.3, ups=0.1, wpb=5119.9, bsz=1280, num_updates=780, lr=4.6559e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=104, gb_free=9.6, wall=9309
2024-11-08 13:47:53 - progress_bar.py[line:274] - INFO: epoch 003:    164 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.141, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.82, wps=495, ups=0.1, wpb=5120, bsz=1280, num_updates=790, lr=4.64741e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=103, gb_free=9.7, wall=9413
2024-11-08 13:49:36 - progress_bar.py[line:274] - INFO: epoch 003:    174 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.148, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.86, wps=494, ups=0.1, wpb=5120, bsz=1280, num_updates=800, lr=4.63891e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=104, gb_free=9.7, wall=9516
2024-11-08 13:51:20 - progress_bar.py[line:274] - INFO: epoch 003:    184 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.133, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.77, wps=492.6, ups=0.1, wpb=5120, bsz=1280, num_updates=810, lr=4.63042e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=104, gb_free=9.7, wall=9620
2024-11-08 13:53:04 - progress_bar.py[line:274] - INFO: epoch 003:    194 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.161, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.95, wps=491.5, ups=0.1, wpb=5120, bsz=1280, num_updates=820, lr=4.62192e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=104, gb_free=9.6, wall=9725
2024-11-08 13:54:48 - progress_bar.py[line:274] - INFO: epoch 003:    204 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.107, ntokens=5119.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.62, wps=494.1, ups=0.1, wpb=5119.7, bsz=1280, num_updates=830, lr=4.61342e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=104, gb_free=9.7, wall=9828
2024-11-08 13:56:31 - progress_bar.py[line:274] - INFO: epoch 003:    214 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.098, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.56, wps=496.7, ups=0.1, wpb=5120, bsz=1280, num_updates=840, lr=4.60493e-05, gnorm=0.009, clip=0, loss_scale=256, train_wall=103, gb_free=9.6, wall=9931
2024-11-08 13:58:15 - progress_bar.py[line:274] - INFO: epoch 003:    224 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.166, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.97, wps=492.9, ups=0.1, wpb=5119.9, bsz=1280, num_updates=850, lr=4.59643e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=104, gb_free=9.6, wall=10035
2024-11-08 13:59:59 - progress_bar.py[line:274] - INFO: epoch 003:    234 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.203, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.21, wps=492.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=860, lr=4.58794e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=104, gb_free=9.6, wall=10139
2024-11-08 14:01:43 - progress_bar.py[line:274] - INFO: epoch 003:    244 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.175, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.03, wps=491.9, ups=0.1, wpb=5119.8, bsz=1280, num_updates=870, lr=4.57944e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=104, gb_free=9.7, wall=10243
2024-11-08 14:03:28 - progress_bar.py[line:274] - INFO: epoch 003:    254 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.161, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.94, wps=489.3, ups=0.1, wpb=5120, bsz=1280, num_updates=880, lr=4.57094e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=105, gb_free=9.5, wall=10348
2024-11-08 14:05:11 - progress_bar.py[line:274] - INFO: epoch 003:    264 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.114, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.66, wps=493.2, ups=0.1, wpb=5120, bsz=1280, num_updates=890, lr=4.56245e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=104, gb_free=9.7, wall=10452
2024-11-08 14:06:57 - progress_bar.py[line:274] - INFO: epoch 003:    274 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.107, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.61, wps=486.8, ups=0.1, wpb=5120, bsz=1280, num_updates=900, lr=4.55395e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=105, gb_free=9.7, wall=10557
2024-11-08 14:08:42 - progress_bar.py[line:274] - INFO: epoch 003:    284 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.213, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.28, wps=486.7, ups=0.1, wpb=5120, bsz=1280, num_updates=910, lr=4.54545e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=105, gb_free=9.6, wall=10662
2024-11-08 14:10:27 - progress_bar.py[line:274] - INFO: epoch 003:    294 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.214, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.28, wps=485.8, ups=0.09, wpb=5119.9, bsz=1280, num_updates=920, lr=4.53696e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=105, gb_free=9.6, wall=10767
2024-11-08 14:12:11 - progress_bar.py[line:274] - INFO: epoch 003:    304 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.233, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.41, wps=492.6, ups=0.1, wpb=5119.9, bsz=1280, num_updates=930, lr=4.52846e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=104, gb_free=9.7, wall=10871
slice_id 6 seek offset 41730
slice_id 5 seek offset 34775
slice_id 7 seek offset 48685
2024-11-08 14:13:37 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 4 seek offset 27820
slice_id 2 seek offset 13910
slice_id 1 seek offset 6955
slice_id 3 seek offset 20865
slice_id 5 seek offset 34775
slice_id 3 seek offset 20865
slice_id 7 seek offset 48685
slice_id 6 seek offset 41730
slice_id 1 seek offset 6955
slice_id 2 seek offset 13910
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-08 14:21:05 - progress_bar.py[line:282] - INFO: epoch 003 | valid on 'valid' subset | loss 0.003 | loss_v1 0 | loss_v2 0 | nll_loss 3.166 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 8.97 | score 0.0427 | wps 498.9 | wpb 639.5 | bsz 159.9 | num_updates 939 | best_score 0.0427
2024-11-08 14:21:05 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 939 updates
2024-11-08 14:21:05 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 row count 50000 total row count 400000
slice_id 5 seek offset 250000
slice_id 2 seek offset 100000
slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
slice_id 4 seek offset 200000
slice_id 3 seek offset 150000
slice_id 6 seek offset 300000
2024-11-08 14:22:06 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-11-08 14:23:19 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 3 @ 939 updates, score 0.0427) (writing took 133.88399145100266 seconds)
2024-11-08 14:23:20 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 939 updates
2024-11-08 14:23:20 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 14:24:47 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 14:24:47 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 3 @ 939 updates, score 0) (writing took 87.39747114601778 seconds)
2024-11-08 14:24:47 - train.py[line:336] - INFO: end of epoch 3 (average epoch stats below)
2024-11-08 14:24:47 - progress_bar.py[line:282] - INFO: epoch 003 | loss 0.003 | loss_v1 0 | loss_v2 0 | nll_loss 3.179 | ntokens 5111.78 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.06 | wps 408.5 | ups 0.08 | wpb 5111.8 | bsz 1278 | num_updates 939 | lr 4.52082e-05 | gnorm 0.007 | clip 0 | loss_scale 256 | train_wall 3052 | gb_free 9.7 | wall 11627
2024-11-08 14:24:47 - trainer.py[line:639] - INFO: loading train data for epoch 4
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 14:24:50 - trainer.py[line:703] - INFO: begin training epoch 4
2024-11-08 14:24:50 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 14:25:03 - progress_bar.py[line:274] - INFO: epoch 004:      1 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.189, ntokens=4864, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=9.12, wps=63, ups=0.01, wpb=4864, bsz=1216, num_updates=940, lr=4.51997e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=90, gb_free=9.6, wall=11643
2024-11-08 14:26:43 - progress_bar.py[line:274] - INFO: epoch 004:     11 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.129, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.75, wps=510.6, ups=0.1, wpb=5119.9, bsz=1280, num_updates=950, lr=4.51147e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=35, gb_free=9.6, wall=11743
2024-11-08 14:28:24 - progress_bar.py[line:274] - INFO: epoch 004:     21 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.146, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.85, wps=508.8, ups=0.1, wpb=5120, bsz=1280, num_updates=960, lr=4.50297e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=11844
2024-11-08 14:30:04 - progress_bar.py[line:274] - INFO: epoch 004:     31 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.1, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.57, wps=508.5, ups=0.1, wpb=5120, bsz=1280, num_updates=970, lr=4.49448e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=35, gb_free=9.6, wall=11945
2024-11-08 14:31:48 - progress_bar.py[line:274] - INFO: epoch 004:     41 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.11, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.63, wps=493.1, ups=0.1, wpb=5120, bsz=1280, num_updates=980, lr=4.48598e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=42, gb_free=9.7, wall=12048
2024-11-08 14:33:32 - progress_bar.py[line:274] - INFO: epoch 004:     51 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.139, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.81, wps=492.1, ups=0.1, wpb=5120, bsz=1280, num_updates=990, lr=4.47749e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=52, gb_free=9.7, wall=12152
2024-11-08 14:35:15 - progress_bar.py[line:274] - INFO: epoch 004:     61 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.168, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.99, wps=497.4, ups=0.1, wpb=5120, bsz=1280, num_updates=1000, lr=4.46899e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=78, gb_free=9.7, wall=12255
slice_id 2 seek offset 13910slice_id 5 seek offset 34775

slice_id 6 seek offset 41730
2024-11-08 14:35:15 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 4 seek offset 27820
slice_id 1 seek offset 6955
slice_id 7 seek offset 48685
slice_id 3 seek offset 20865
slice_id 6 seek offset 41730
slice_id 7 seek offset 48685
slice_id 2 seek offset 13910
slice_id 3 seek offset 20865
slice_id 5 seek offset 34775
slice_id 1 seek offset 6955
slice_id 0 seek offset 0
slice_id 4 seek offset 27820
2024-11-08 14:42:48 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 0.003 | loss_v1 0 | loss_v2 0 | nll_loss 3.089 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 8.51 | score 0.0488 | wps 493.4 | wpb 639.5 | bsz 159.9 | num_updates 1000 | best_score 0.0488
2024-11-08 14:42:48 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 1000 updates
2024-11-08 14:42:48 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_4_1000.pt
2024-11-08 14:42:59 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_4_1000.pt
2024-11-08 14:45:37 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_4_1000.pt (epoch 4 @ 1000 updates, score 0.0488) (writing took 169.05678805499338 seconds)
2024-11-08 14:47:07 - progress_bar.py[line:274] - INFO: epoch 004:     71 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.165, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.97, wps=71.9, ups=0.01, wpb=5120, bsz=1280, num_updates=1010, lr=4.46049e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=12968
2024-11-08 14:48:50 - progress_bar.py[line:274] - INFO: epoch 004:     81 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.137, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.8, wps=500, ups=0.1, wpb=5120, bsz=1280, num_updates=1020, lr=4.452e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=45, gb_free=9.6, wall=13070
2024-11-08 14:50:34 - progress_bar.py[line:274] - INFO: epoch 004:     91 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.206, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.23, wps=492.7, ups=0.1, wpb=5120, bsz=1280, num_updates=1030, lr=4.4435e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=81, gb_free=9.6, wall=13174
2024-11-08 14:52:17 - progress_bar.py[line:274] - INFO: epoch 004:    101 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.204, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.22, wps=495.8, ups=0.1, wpb=5120, bsz=1280, num_updates=1040, lr=4.435e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=103, gb_free=9.6, wall=13277
2024-11-08 14:54:01 - progress_bar.py[line:274] - INFO: epoch 004:    111 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.189, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.12, wps=493, ups=0.1, wpb=5119.9, bsz=1280, num_updates=1050, lr=4.42651e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=104, gb_free=9.7, wall=13381
2024-11-08 14:55:45 - progress_bar.py[line:274] - INFO: epoch 004:    121 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.227, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.36, wps=491, ups=0.1, wpb=5120, bsz=1280, num_updates=1060, lr=4.41801e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=104, gb_free=9.7, wall=13485
2024-11-08 14:57:29 - progress_bar.py[line:274] - INFO: epoch 004:    131 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.2, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.19, wps=493.3, ups=0.1, wpb=5120, bsz=1280, num_updates=1070, lr=4.40952e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=104, gb_free=9.7, wall=13589
2024-11-08 14:59:12 - progress_bar.py[line:274] - INFO: epoch 004:    141 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.194, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.15, wps=494.5, ups=0.1, wpb=5119.9, bsz=1280, num_updates=1080, lr=4.40102e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=103, gb_free=9.7, wall=13693
2024-11-08 15:00:57 - progress_bar.py[line:274] - INFO: epoch 004:    151 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.182, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.07, wps=490.4, ups=0.1, wpb=5119.9, bsz=1280, num_updates=1090, lr=4.39252e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=104, gb_free=9.7, wall=13797
2024-11-08 15:02:40 - progress_bar.py[line:274] - INFO: epoch 004:    161 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.158, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.93, wps=494.9, ups=0.1, wpb=5120, bsz=1280, num_updates=1100, lr=4.38403e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=103, gb_free=9.7, wall=13900
2024-11-08 15:04:25 - progress_bar.py[line:274] - INFO: epoch 004:    171 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.165, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.97, wps=491, ups=0.1, wpb=5120, bsz=1280, num_updates=1110, lr=4.37553e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=104, gb_free=9.7, wall=14005
2024-11-08 15:06:08 - progress_bar.py[line:274] - INFO: epoch 004:    181 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.157, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.92, wps=495, ups=0.1, wpb=5120, bsz=1280, num_updates=1120, lr=4.36703e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=103, gb_free=9.6, wall=14108
2024-11-08 15:07:52 - progress_bar.py[line:274] - INFO: epoch 004:    191 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.127, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.73, wps=492.3, ups=0.1, wpb=5120, bsz=1280, num_updates=1130, lr=4.35854e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=104, gb_free=9.7, wall=14212
2024-11-08 15:09:36 - progress_bar.py[line:274] - INFO: epoch 004:    201 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.169, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.99, wps=492.5, ups=0.1, wpb=5119.8, bsz=1280, num_updates=1140, lr=4.35004e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=104, gb_free=9.6, wall=14316
2024-11-08 15:11:20 - progress_bar.py[line:274] - INFO: epoch 004:    211 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.149, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.87, wps=493.6, ups=0.1, wpb=5119.9, bsz=1280, num_updates=1150, lr=4.34155e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=104, gb_free=9.7, wall=14420
2024-11-08 15:13:03 - progress_bar.py[line:274] - INFO: epoch 004:    221 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.201, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.19, wps=497.5, ups=0.1, wpb=5120, bsz=1280, num_updates=1160, lr=4.33305e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=103, gb_free=9.6, wall=14523
2024-11-08 15:14:47 - progress_bar.py[line:274] - INFO: epoch 004:    231 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.19, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.13, wps=492.5, ups=0.1, wpb=5119.8, bsz=1280, num_updates=1170, lr=4.32455e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=104, gb_free=9.7, wall=14627
2024-11-08 15:16:30 - progress_bar.py[line:274] - INFO: epoch 004:    241 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.211, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.26, wps=492.5, ups=0.1, wpb=5119.9, bsz=1280, num_updates=1180, lr=4.31606e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=104, gb_free=9.6, wall=14731
2024-11-08 15:18:14 - progress_bar.py[line:274] - INFO: epoch 004:    251 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.182, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.08, wps=494.7, ups=0.1, wpb=5119.9, bsz=1280, num_updates=1190, lr=4.30756e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=103, gb_free=9.7, wall=14834
2024-11-08 15:19:57 - progress_bar.py[line:274] - INFO: epoch 004:    261 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.115, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.66, wps=496.9, ups=0.1, wpb=5120, bsz=1280, num_updates=1200, lr=4.29907e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=103, gb_free=9.7, wall=14937
2024-11-08 15:21:41 - progress_bar.py[line:274] - INFO: epoch 004:    271 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.121, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.7, wps=493.1, ups=0.1, wpb=5120, bsz=1280, num_updates=1210, lr=4.29057e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=104, gb_free=9.7, wall=15041
2024-11-08 15:23:25 - progress_bar.py[line:274] - INFO: epoch 004:    281 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.124, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.72, wps=491.8, ups=0.1, wpb=5120, bsz=1280, num_updates=1220, lr=4.28207e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=104, gb_free=9.6, wall=15145
2024-11-08 15:25:09 - progress_bar.py[line:274] - INFO: epoch 004:    291 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.132, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.77, wps=490.6, ups=0.1, wpb=5119.9, bsz=1280, num_updates=1230, lr=4.27358e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=104, gb_free=9.7, wall=15250
2024-11-08 15:26:54 - progress_bar.py[line:274] - INFO: epoch 004:    301 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.106, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.61, wps=489.5, ups=0.1, wpb=5119.9, bsz=1280, num_updates=1240, lr=4.26508e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=105, gb_free=9.7, wall=15354
2024-11-08 15:28:38 - progress_bar.py[line:274] - INFO: epoch 004:    311 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.132, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.77, wps=493.6, ups=0.1, wpb=5120, bsz=1280, num_updates=1250, lr=4.25658e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=104, gb_free=9.6, wall=15458
slice_id 6 seek offset 41730
2024-11-08 15:28:51 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 7 seek offset 48685
slice_id 5 seek offset 34775
slice_id 0 seek offset 0
slice_id 2 seek offset 13910slice_id 1 seek offset 6955

slice_id 4 seek offset 27820slice_id 3 seek offset 20865

slice_id 3 seek offset 20865
slice_id 7 seek offset 48685
slice_id 5 seek offset 34775
slice_id 6 seek offset 41730
slice_id 1 seek offset 6955
slice_id 2 seek offset 13910
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-08 15:36:18 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 0.003 | loss_v1 0 | loss_v2 0 | nll_loss 3.165 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 8.97 | score 0.0793 | wps 500.5 | wpb 639.5 | bsz 159.9 | num_updates 1252 | best_score 0.0793
2024-11-08 15:36:18 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 1252 updates
2024-11-08 15:36:18 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 row count 50000 total row count 400000
slice_id 7 seek offset 350000
slice_id 2 seek offset 100000
slice_id 4 seek offset 200000
slice_id 6 seek offset 300000
slice_id 5 seek offset 250000
slice_id 1 seek offset 50000
slice_id 3 seek offset 150000
2024-11-08 15:37:18 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-11-08 15:38:30 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 4 @ 1252 updates, score 0.0793) (writing took 132.29205885896226 seconds)
2024-11-08 15:38:31 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 1252 updates
2024-11-08 15:38:31 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 15:39:55 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 15:39:55 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 4 @ 1252 updates, score 0) (writing took 84.31857714400394 seconds)
2024-11-08 15:39:55 - train.py[line:336] - INFO: end of epoch 4 (average epoch stats below)
2024-11-08 15:39:55 - progress_bar.py[line:282] - INFO: epoch 004 | loss 0.003 | loss_v1 0 | loss_v2 0 | nll_loss 3.16 | ntokens 5111.78 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 8.94 | wps 354.9 | ups 0.07 | wpb 5111.8 | bsz 1278 | num_updates 1252 | lr 4.25489e-05 | gnorm 0.006 | clip 0 | loss_scale 512 | train_wall 2736 | gb_free 9.7 | wall 16135
2024-11-08 15:39:55 - trainer.py[line:639] - INFO: loading train data for epoch 5
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 15:39:57 - trainer.py[line:703] - INFO: begin training epoch 5
2024-11-08 15:39:57 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 15:41:20 - progress_bar.py[line:274] - INFO: epoch 005:      8 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.165, ntokens=4863.9, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=8.97, wps=63.8, ups=0.01, wpb=4863.9, bsz=1216, num_updates=1260, lr=4.24809e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=41, gb_free=9.7, wall=16220
2024-11-08 15:43:00 - progress_bar.py[line:274] - INFO: epoch 005:     18 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.155, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.91, wps=513, ups=0.1, wpb=5120, bsz=1280, num_updates=1270, lr=4.23959e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.6, wall=16320
2024-11-08 15:44:40 - progress_bar.py[line:274] - INFO: epoch 005:     28 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.136, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.79, wps=511.8, ups=0.1, wpb=5120, bsz=1280, num_updates=1280, lr=4.2311e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=16420
2024-11-08 15:46:21 - progress_bar.py[line:274] - INFO: epoch 005:     38 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.146, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.85, wps=506.2, ups=0.1, wpb=5120, bsz=1280, num_updates=1290, lr=4.2226e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=37, gb_free=9.7, wall=16521
2024-11-08 15:48:04 - progress_bar.py[line:274] - INFO: epoch 005:     48 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.113, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.65, wps=496.8, ups=0.1, wpb=5120, bsz=1280, num_updates=1300, lr=4.2141e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=59, gb_free=9.7, wall=16625
2024-11-08 15:49:47 - progress_bar.py[line:274] - INFO: epoch 005:     58 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.133, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.77, wps=498.5, ups=0.1, wpb=5120, bsz=1280, num_updates=1310, lr=4.20561e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=86, gb_free=9.6, wall=16727
2024-11-08 15:51:31 - progress_bar.py[line:274] - INFO: epoch 005:     68 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.129, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.75, wps=493.9, ups=0.1, wpb=5120, bsz=1280, num_updates=1320, lr=4.19711e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=103, gb_free=9.7, wall=16831
2024-11-08 15:53:14 - progress_bar.py[line:274] - INFO: epoch 005:     78 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.09, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.51, wps=496.1, ups=0.1, wpb=5120, bsz=1280, num_updates=1330, lr=4.18862e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=103, gb_free=9.7, wall=16934
2024-11-08 15:54:57 - progress_bar.py[line:274] - INFO: epoch 005:     88 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.087, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.5, wps=496.6, ups=0.1, wpb=5120, bsz=1280, num_updates=1340, lr=4.18012e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=103, gb_free=9.7, wall=17037
2024-11-08 15:56:41 - progress_bar.py[line:274] - INFO: epoch 005:     98 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.078, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.44, wps=493.5, ups=0.1, wpb=5120, bsz=1280, num_updates=1350, lr=4.17162e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=104, gb_free=9.7, wall=17141
2024-11-08 15:58:24 - progress_bar.py[line:274] - INFO: epoch 005:    108 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.087, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.5, wps=494.4, ups=0.1, wpb=5119.9, bsz=1280, num_updates=1360, lr=4.16313e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=103, gb_free=9.6, wall=17245
2024-11-08 16:00:08 - progress_bar.py[line:274] - INFO: epoch 005:    118 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.104, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.6, wps=495.3, ups=0.1, wpb=5120, bsz=1280, num_updates=1370, lr=4.15463e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=103, gb_free=9.7, wall=17348
2024-11-08 16:01:51 - progress_bar.py[line:274] - INFO: epoch 005:    128 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.077, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.44, wps=496.3, ups=0.1, wpb=5120, bsz=1280, num_updates=1380, lr=4.14613e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=103, gb_free=9.6, wall=17451
2024-11-08 16:03:34 - progress_bar.py[line:274] - INFO: epoch 005:    138 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.07, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.4, wps=494.2, ups=0.1, wpb=5119.9, bsz=1280, num_updates=1390, lr=4.13764e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=104, gb_free=9.6, wall=17555
2024-11-08 16:05:19 - progress_bar.py[line:274] - INFO: epoch 005:    148 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.09, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.52, wps=489, ups=0.1, wpb=5119.9, bsz=1280, num_updates=1400, lr=4.12914e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=105, gb_free=9.6, wall=17659
2024-11-08 16:07:05 - progress_bar.py[line:274] - INFO: epoch 005:    158 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.11, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.63, wps=485.7, ups=0.09, wpb=5120, bsz=1280, num_updates=1410, lr=4.12065e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=105, gb_free=9.6, wall=17765
2024-11-08 16:08:48 - progress_bar.py[line:274] - INFO: epoch 005:    168 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.134, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.78, wps=493.4, ups=0.1, wpb=5120, bsz=1280, num_updates=1420, lr=4.11215e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=104, gb_free=9.7, wall=17869
2024-11-08 16:10:32 - progress_bar.py[line:274] - INFO: epoch 005:    178 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.131, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.76, wps=494.1, ups=0.1, wpb=5120, bsz=1280, num_updates=1430, lr=4.10365e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=104, gb_free=9.7, wall=17972
2024-11-08 16:12:15 - progress_bar.py[line:274] - INFO: epoch 005:    188 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.123, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.71, wps=497.2, ups=0.1, wpb=5120, bsz=1280, num_updates=1440, lr=4.09516e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=103, gb_free=9.6, wall=18075
2024-11-08 16:13:57 - progress_bar.py[line:274] - INFO: epoch 005:    198 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.11, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.63, wps=499.4, ups=0.1, wpb=5119.9, bsz=1280, num_updates=1450, lr=4.08666e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=102, gb_free=9.7, wall=18178
2024-11-08 16:15:41 - progress_bar.py[line:274] - INFO: epoch 005:    208 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.14, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.81, wps=495.4, ups=0.1, wpb=5119.8, bsz=1280, num_updates=1460, lr=4.07816e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=103, gb_free=9.7, wall=18281
2024-11-08 16:17:24 - progress_bar.py[line:274] - INFO: epoch 005:    218 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.133, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.77, wps=497.2, ups=0.1, wpb=5120, bsz=1280, num_updates=1470, lr=4.06967e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=103, gb_free=9.7, wall=18384
2024-11-08 16:19:07 - progress_bar.py[line:274] - INFO: epoch 005:    228 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.147, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.86, wps=497.3, ups=0.1, wpb=5119.8, bsz=1280, num_updates=1480, lr=4.06117e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=103, gb_free=9.7, wall=18487
2024-11-08 16:20:49 - progress_bar.py[line:274] - INFO: epoch 005:    238 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.211, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.26, wps=498.4, ups=0.1, wpb=5120, bsz=1280, num_updates=1490, lr=4.05268e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=103, gb_free=9.7, wall=18590
2024-11-08 16:22:33 - progress_bar.py[line:274] - INFO: epoch 005:    248 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.192, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.14, wps=496.2, ups=0.1, wpb=5119.8, bsz=1280, num_updates=1500, lr=4.04418e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=103, gb_free=9.6, wall=18693
2024-11-08 16:24:16 - progress_bar.py[line:274] - INFO: epoch 005:    258 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.152, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.89, wps=496.2, ups=0.1, wpb=5120, bsz=1280, num_updates=1510, lr=4.03568e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=103, gb_free=9.7, wall=18796
2024-11-08 16:25:59 - progress_bar.py[line:274] - INFO: epoch 005:    268 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.135, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.79, wps=495.5, ups=0.1, wpb=5120, bsz=1280, num_updates=1520, lr=4.02719e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=103, gb_free=9.6, wall=18899
2024-11-08 16:27:44 - progress_bar.py[line:274] - INFO: epoch 005:    278 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.133, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.77, wps=489.9, ups=0.1, wpb=5120, bsz=1280, num_updates=1530, lr=4.01869e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=104, gb_free=9.7, wall=19004
2024-11-08 16:29:27 - progress_bar.py[line:274] - INFO: epoch 005:    288 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.144, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.84, wps=495.5, ups=0.1, wpb=5119.9, bsz=1280, num_updates=1540, lr=4.0102e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=103, gb_free=9.7, wall=19107
2024-11-08 16:31:10 - progress_bar.py[line:274] - INFO: epoch 005:    298 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.115, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.66, wps=497.2, ups=0.1, wpb=5120, bsz=1280, num_updates=1550, lr=4.0017e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=103, gb_free=9.7, wall=19210
2024-11-08 16:32:53 - progress_bar.py[line:274] - INFO: epoch 005:    308 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.122, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.71, wps=497.9, ups=0.1, wpb=5119.9, bsz=1280, num_updates=1560, lr=3.9932e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=103, gb_free=9.6, wall=19313
2024-11-08 16:33:38 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 5 seek offset 34775slice_id 7 seek offset 48685

slice_id 0 seek offset 0slice_id 4 seek offset 27820

slice_id 1 seek offset 6955
slice_id 3 seek offset 20865slice_id 2 seek offset 13910

slice_id 6 seek offset 41730
slice_id 3 seek offset 20865
slice_id 7 seek offset 48685
slice_id 1 seek offset 6955
slice_id 5 seek offset 34775
slice_id 2 seek offset 13910
slice_id 6 seek offset 41730
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-08 16:41:00 - progress_bar.py[line:282] - INFO: epoch 005 | valid on 'valid' subset | loss 0.002 | loss_v1 0 | loss_v2 0 | nll_loss 3.102 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 8.59 | score 0.1051 | wps 504.4 | wpb 639.5 | bsz 159.9 | num_updates 1565 | best_score 0.1051
2024-11-08 16:41:00 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 1565 updates
2024-11-08 16:41:00 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 row count 50000 total row count 400000
slice_id 2 seek offset 100000
slice_id 5 seek offset 250000
slice_id 6 seek offset 300000
slice_id 4 seek offset 200000
slice_id 3 seek offset 150000
slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
2024-11-08 16:42:02 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-11-08 16:43:13 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 5 @ 1565 updates, score 0.1051) (writing took 132.64340759598417 seconds)
2024-11-08 16:43:14 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 1565 updates
2024-11-08 16:43:14 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 16:44:38 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 16:44:39 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 5 @ 1565 updates, score 0) (writing took 84.83760714600794 seconds)
2024-11-08 16:44:39 - train.py[line:336] - INFO: end of epoch 5 (average epoch stats below)
2024-11-08 16:44:39 - progress_bar.py[line:282] - INFO: epoch 005 | loss 0.003 | loss_v1 0 | loss_v2 0 | nll_loss 3.125 | ntokens 5111.78 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 8.73 | wps 412 | ups 0.08 | wpb 5111.8 | bsz 1278 | num_updates 1565 | lr 3.98895e-05 | gnorm 0.006 | clip 0 | loss_scale 1024 | train_wall 2907 | gb_free 9.7 | wall 20019
2024-11-08 16:44:39 - trainer.py[line:639] - INFO: loading train data for epoch 6
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 16:44:41 - trainer.py[line:703] - INFO: begin training epoch 6
2024-11-08 16:44:41 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 16:45:34 - progress_bar.py[line:274] - INFO: epoch 006:      5 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.114, ntokens=4863.9, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=8.66, wps=63.9, ups=0.01, wpb=4863.9, bsz=1216, num_updates=1570, lr=3.98471e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=62, gb_free=9.6, wall=20075
2024-11-08 16:47:15 - progress_bar.py[line:274] - INFO: epoch 006:     15 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.17, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9, wps=509.8, ups=0.1, wpb=5120, bsz=1280, num_updates=1580, lr=3.97621e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.6, wall=20175
2024-11-08 16:48:55 - progress_bar.py[line:274] - INFO: epoch 006:     25 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.111, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.64, wps=511, ups=0.1, wpb=5120, bsz=1280, num_updates=1590, lr=3.96771e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=20275
2024-11-08 16:50:39 - progress_bar.py[line:274] - INFO: epoch 006:     35 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.126, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.73, wps=494.3, ups=0.1, wpb=5120, bsz=1280, num_updates=1600, lr=3.95922e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=47, gb_free=9.7, wall=20379
2024-11-08 16:52:25 - progress_bar.py[line:274] - INFO: epoch 006:     45 / 313 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=3.178, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.05, wps=480.6, ups=0.09, wpb=5120, bsz=1280, num_updates=1610, lr=3.95072e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=94, gb_free=9.7, wall=20485
2024-11-08 16:54:14 - progress_bar.py[line:274] - INFO: epoch 006:     55 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.186, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.1, wps=471.3, ups=0.09, wpb=5120, bsz=1280, num_updates=1620, lr=3.94223e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=109, gb_free=9.7, wall=20594
2024-11-08 16:56:03 - progress_bar.py[line:274] - INFO: epoch 006:     65 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.168, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.99, wps=470.2, ups=0.09, wpb=5120, bsz=1280, num_updates=1630, lr=3.93373e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=109, gb_free=9.7, wall=20703
2024-11-08 16:57:52 - progress_bar.py[line:274] - INFO: epoch 006:     75 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.147, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.86, wps=469.8, ups=0.09, wpb=5120, bsz=1280, num_updates=1640, lr=3.92523e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=109, gb_free=9.7, wall=20812
2024-11-08 16:59:39 - progress_bar.py[line:274] - INFO: epoch 006:     85 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.152, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.89, wps=475.2, ups=0.09, wpb=5120, bsz=1280, num_updates=1650, lr=3.91674e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=108, gb_free=9.6, wall=20920
2024-11-08 17:01:28 - progress_bar.py[line:274] - INFO: epoch 006:     95 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.164, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.96, wps=469.8, ups=0.09, wpb=5120, bsz=1280, num_updates=1660, lr=3.90824e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=109, gb_free=9.6, wall=21029
2024-11-08 17:03:17 - progress_bar.py[line:274] - INFO: epoch 006:    105 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.153, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.9, wps=471, ups=0.09, wpb=5119.9, bsz=1280, num_updates=1670, lr=3.89975e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=109, gb_free=9.6, wall=21137
2024-11-08 17:05:04 - progress_bar.py[line:274] - INFO: epoch 006:    115 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.15, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.88, wps=478.5, ups=0.09, wpb=5120, bsz=1280, num_updates=1680, lr=3.89125e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=107, gb_free=9.7, wall=21244
2024-11-08 17:06:51 - progress_bar.py[line:274] - INFO: epoch 006:    125 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.154, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.9, wps=480.9, ups=0.09, wpb=5120, bsz=1280, num_updates=1690, lr=3.88275e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=106, gb_free=9.7, wall=21351
2024-11-08 17:08:35 - progress_bar.py[line:274] - INFO: epoch 006:    135 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.122, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.7, wps=489.9, ups=0.1, wpb=5120, bsz=1280, num_updates=1700, lr=3.87426e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=104, gb_free=9.7, wall=21455
2024-11-08 17:10:20 - progress_bar.py[line:274] - INFO: epoch 006:    145 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.161, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.94, wps=487, ups=0.1, wpb=5119.9, bsz=1280, num_updates=1710, lr=3.86576e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=104, gb_free=9.7, wall=21560
2024-11-08 17:12:07 - progress_bar.py[line:274] - INFO: epoch 006:    155 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.155, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.91, wps=477.4, ups=0.09, wpb=5119.9, bsz=1280, num_updates=1720, lr=3.85726e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=107, gb_free=9.6, wall=21668
2024-11-08 17:13:54 - progress_bar.py[line:274] - INFO: epoch 006:    165 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.186, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.1, wps=478.7, ups=0.09, wpb=5120, bsz=1280, num_updates=1730, lr=3.84877e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=107, gb_free=9.7, wall=21775
2024-11-08 17:15:43 - progress_bar.py[line:274] - INFO: epoch 006:    175 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.144, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.84, wps=469.5, ups=0.09, wpb=5120, bsz=1280, num_updates=1740, lr=3.84027e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=109, gb_free=9.7, wall=21884
2024-11-08 17:17:30 - progress_bar.py[line:274] - INFO: epoch 006:    185 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.153, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.9, wps=481, ups=0.09, wpb=5120, bsz=1280, num_updates=1750, lr=3.83178e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=106, gb_free=9.7, wall=21990
2024-11-08 17:19:15 - progress_bar.py[line:274] - INFO: epoch 006:    195 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.131, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.76, wps=487.2, ups=0.1, wpb=5120, bsz=1280, num_updates=1760, lr=3.82328e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=105, gb_free=9.6, wall=22095
2024-11-08 17:20:59 - progress_bar.py[line:274] - INFO: epoch 006:    205 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.108, ntokens=5119.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.62, wps=492.5, ups=0.1, wpb=5119.7, bsz=1280, num_updates=1770, lr=3.81478e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=104, gb_free=9.7, wall=22199
2024-11-08 17:22:44 - progress_bar.py[line:274] - INFO: epoch 006:    215 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.168, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.99, wps=485.2, ups=0.09, wpb=5120, bsz=1280, num_updates=1780, lr=3.80629e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=105, gb_free=9.6, wall=22305
2024-11-08 17:24:31 - progress_bar.py[line:274] - INFO: epoch 006:    225 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.159, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.93, wps=480, ups=0.09, wpb=5119.9, bsz=1280, num_updates=1790, lr=3.79779e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=107, gb_free=9.7, wall=22411
2024-11-08 17:26:19 - progress_bar.py[line:274] - INFO: epoch 006:    235 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.196, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.17, wps=473.4, ups=0.09, wpb=5119.9, bsz=1280, num_updates=1800, lr=3.78929e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=108, gb_free=9.7, wall=22520
2024-11-08 17:28:07 - progress_bar.py[line:274] - INFO: epoch 006:    245 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.157, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.92, wps=476.8, ups=0.09, wpb=5119.8, bsz=1280, num_updates=1810, lr=3.7808e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=107, gb_free=9.6, wall=22627
2024-11-08 17:29:54 - progress_bar.py[line:274] - INFO: epoch 006:    255 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.135, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.78, wps=478.2, ups=0.09, wpb=5120, bsz=1280, num_updates=1820, lr=3.7723e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=107, gb_free=9.7, wall=22734
2024-11-08 17:31:37 - progress_bar.py[line:274] - INFO: epoch 006:    265 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.14, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.81, wps=494, ups=0.1, wpb=5120, bsz=1280, num_updates=1830, lr=3.76381e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=104, gb_free=9.7, wall=22838
2024-11-08 17:33:22 - progress_bar.py[line:274] - INFO: epoch 006:    275 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.14, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.81, wps=488.4, ups=0.1, wpb=5120, bsz=1280, num_updates=1840, lr=3.75531e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=105, gb_free=9.7, wall=22942
2024-11-08 17:35:07 - progress_bar.py[line:274] - INFO: epoch 006:    285 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.154, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.9, wps=488.5, ups=0.1, wpb=5120, bsz=1280, num_updates=1850, lr=3.74681e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=105, gb_free=9.7, wall=23047
2024-11-08 17:36:51 - progress_bar.py[line:274] - INFO: epoch 006:    295 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.149, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.87, wps=492.6, ups=0.1, wpb=5119.9, bsz=1280, num_updates=1860, lr=3.73832e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=104, gb_free=9.7, wall=23151
2024-11-08 17:38:35 - progress_bar.py[line:274] - INFO: epoch 006:    305 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.096, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.55, wps=489.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=1870, lr=3.72982e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=104, gb_free=9.6, wall=23256
slice_id 6 seek offset 41730
slice_id 4 seek offset 27820slice_id 5 seek offset 34775
slice_id 2 seek offset 13910

slice_id 7 seek offset 48685
slice_id 3 seek offset 208652024-11-08 17:39:52 - train.py[line:449] - INFO: begin validation on "valid" subset

slice_id 1 seek offset 6955
slice_id 0 seek offset 0
slice_id 3 seek offset 20865
slice_id 5 seek offset 34775
slice_id 7 seek offset 48685
slice_id 6 seek offset 41730
slice_id 2 seek offset 13910
slice_id 1 seek offset 6955
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-08 17:47:22 - progress_bar.py[line:282] - INFO: epoch 006 | valid on 'valid' subset | loss 0.002 | loss_v1 0 | loss_v2 0 | nll_loss 3.118 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 8.68 | score 0.1464 | wps 495.8 | wpb 639.5 | bsz 159.9 | num_updates 1878 | best_score 0.1464
2024-11-08 17:47:22 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 1878 updates
2024-11-08 17:47:22 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 row count 50000 total row count 400000
slice_id 2 seek offset 100000
slice_id 5 seek offset 250000
slice_id 3 seek offset 150000
slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
slice_id 4 seek offset 200000
slice_id 6 seek offset 300000
2024-11-08 17:48:24 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-11-08 17:49:36 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 6 @ 1878 updates, score 0.1464) (writing took 133.49209345399868 seconds)
2024-11-08 17:49:36 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 1878 updates
2024-11-08 17:49:36 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 17:51:00 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 17:51:01 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 6 @ 1878 updates, score 0) (writing took 84.2564127430087 seconds)
2024-11-08 17:51:01 - train.py[line:336] - INFO: end of epoch 6 (average epoch stats below)
2024-11-08 17:51:01 - progress_bar.py[line:282] - INFO: epoch 006 | loss 0.002 | loss_v1 0 | loss_v2 0 | nll_loss 3.149 | ntokens 5111.78 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 8.87 | wps 401.8 | ups 0.08 | wpb 5111.8 | bsz 1278 | num_updates 1878 | lr 3.72302e-05 | gnorm 0.006 | clip 0 | loss_scale 1024 | train_wall 3070 | gb_free 9.7 | wall 24001
2024-11-08 17:51:01 - trainer.py[line:639] - INFO: loading train data for epoch 7
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 17:51:03 - trainer.py[line:703] - INFO: begin training epoch 7
2024-11-08 17:51:03 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 17:51:26 - progress_bar.py[line:274] - INFO: epoch 007:      2 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.113, ntokens=4864, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=8.65, wps=63.1, ups=0.01, wpb=4864, bsz=1216, num_updates=1880, lr=3.72133e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=83, gb_free=9.6, wall=24026
2024-11-08 17:53:07 - progress_bar.py[line:274] - INFO: epoch 007:     12 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.057, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.32, wps=510.4, ups=0.1, wpb=5119.9, bsz=1280, num_updates=1890, lr=3.71283e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=24127
2024-11-08 17:54:47 - progress_bar.py[line:274] - INFO: epoch 007:     22 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.105, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.6, wps=508.3, ups=0.1, wpb=5120, bsz=1280, num_updates=1900, lr=3.70433e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=24227
2024-11-08 17:56:27 - progress_bar.py[line:274] - INFO: epoch 007:     32 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.125, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.72, wps=511.6, ups=0.1, wpb=5120, bsz=1280, num_updates=1910, lr=3.69584e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=24328
2024-11-08 17:58:10 - progress_bar.py[line:274] - INFO: epoch 007:     42 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.1, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.58, wps=496.6, ups=0.1, wpb=5120, bsz=1280, num_updates=1920, lr=3.68734e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=48, gb_free=9.7, wall=24431
2024-11-08 17:59:54 - progress_bar.py[line:274] - INFO: epoch 007:     52 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.09, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.52, wps=492.5, ups=0.1, wpb=5120, bsz=1280, num_updates=1930, lr=3.67884e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=85, gb_free=9.6, wall=24535
2024-11-08 18:01:40 - progress_bar.py[line:274] - INFO: epoch 007:     62 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.095, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.54, wps=484.9, ups=0.09, wpb=5120, bsz=1280, num_updates=1940, lr=3.67035e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=106, gb_free=9.5, wall=24640
2024-11-08 18:03:24 - progress_bar.py[line:274] - INFO: epoch 007:     72 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.078, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.44, wps=491.5, ups=0.1, wpb=5120, bsz=1280, num_updates=1950, lr=3.66185e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=104, gb_free=9.7, wall=24744
2024-11-08 18:05:08 - progress_bar.py[line:274] - INFO: epoch 007:     82 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.069, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.39, wps=493, ups=0.1, wpb=5120, bsz=1280, num_updates=1960, lr=3.65336e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=104, gb_free=9.6, wall=24848
2024-11-08 18:06:52 - progress_bar.py[line:274] - INFO: epoch 007:     92 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.061, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.34, wps=490.4, ups=0.1, wpb=5120, bsz=1280, num_updates=1970, lr=3.64486e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=104, gb_free=9.7, wall=24953
2024-11-08 18:08:37 - progress_bar.py[line:274] - INFO: epoch 007:    102 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.064, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.36, wps=489.3, ups=0.1, wpb=5120, bsz=1280, num_updates=1980, lr=3.63636e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=105, gb_free=9.7, wall=25057
2024-11-08 18:10:22 - progress_bar.py[line:274] - INFO: epoch 007:    112 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.092, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.52, wps=490, ups=0.1, wpb=5119.9, bsz=1280, num_updates=1990, lr=3.62787e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=104, gb_free=9.7, wall=25162
2024-11-08 18:12:06 - progress_bar.py[line:274] - INFO: epoch 007:    122 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.102, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.59, wps=487.9, ups=0.1, wpb=5120, bsz=1280, num_updates=2000, lr=3.61937e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=105, gb_free=9.6, wall=25267
slice_id 6 seek offset 41730
slice_id 7 seek offset 48685
2024-11-08 18:12:06 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 4 seek offset 27820slice_id 5 seek offset 34775
slice_id 1 seek offset 6955
slice_id 0 seek offset 0

slice_id 2 seek offset 13910
slice_id 3 seek offset 20865
slice_id 5 seek offset 34775
slice_id 7 seek offset 48685
slice_id 1 seek offset 6955
slice_id 2 seek offset 13910
slice_id 3 seek offset 20865
slice_id 6 seek offset 41730
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-08 18:19:42 - progress_bar.py[line:282] - INFO: epoch 007 | valid on 'valid' subset | loss 0.002 | loss_v1 0 | loss_v2 0 | nll_loss 3.077 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 8.44 | score 0.1545 | wps 489.8 | wpb 639.5 | bsz 159.9 | num_updates 2000 | best_score 0.1545
2024-11-08 18:19:42 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 2000 updates
2024-11-08 18:19:43 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_7_2000.pt
2024-11-08 18:19:53 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_7_2000.pt
2024-11-08 18:22:36 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_7_2000.pt (epoch 7 @ 2000 updates, score 0.1545) (writing took 173.53680538601475 seconds)
2024-11-08 18:24:08 - progress_bar.py[line:274] - INFO: epoch 007:    132 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.087, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.5, wps=70.9, ups=0.01, wpb=5120, bsz=1280, num_updates=2010, lr=3.61088e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=25988
2024-11-08 18:25:53 - progress_bar.py[line:274] - INFO: epoch 007:    142 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.079, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.45, wps=489.7, ups=0.1, wpb=5119.9, bsz=1280, num_updates=2020, lr=3.60238e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=60, gb_free=9.7, wall=26093
2024-11-08 18:27:43 - progress_bar.py[line:274] - INFO: epoch 007:    152 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.091, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.52, wps=466.1, ups=0.09, wpb=5119.9, bsz=1280, num_updates=2030, lr=3.59388e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=107, gb_free=9.7, wall=26203
2024-11-08 18:29:30 - progress_bar.py[line:274] - INFO: epoch 007:    162 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.104, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.6, wps=475.7, ups=0.09, wpb=5120, bsz=1280, num_updates=2040, lr=3.58539e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=108, gb_free=9.6, wall=26310
2024-11-08 18:31:19 - progress_bar.py[line:274] - INFO: epoch 007:    172 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.086, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.49, wps=471.5, ups=0.09, wpb=5120, bsz=1280, num_updates=2050, lr=3.57689e-05, gnorm=0.006, clip=0, loss_scale=2048, train_wall=109, gb_free=9.7, wall=26419
2024-11-08 18:33:05 - progress_bar.py[line:274] - INFO: epoch 007:    182 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.069, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.39, wps=480.1, ups=0.09, wpb=5120, bsz=1280, num_updates=2060, lr=3.56839e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=107, gb_free=9.6, wall=26526
2024-11-08 18:34:57 - progress_bar.py[line:274] - INFO: epoch 007:    192 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.063, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.36, wps=457.7, ups=0.09, wpb=5120, bsz=1280, num_updates=2070, lr=3.5599e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=112, gb_free=9.7, wall=26638
2024-11-08 18:36:47 - progress_bar.py[line:274] - INFO: epoch 007:    202 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.073, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.42, wps=468.5, ups=0.09, wpb=5119.8, bsz=1280, num_updates=2080, lr=3.5514e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=109, gb_free=9.7, wall=26747
2024-11-08 18:38:31 - progress_bar.py[line:274] - INFO: epoch 007:    212 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.097, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.56, wps=492.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=2090, lr=3.54291e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=104, gb_free=9.7, wall=26851
2024-11-08 18:40:20 - progress_bar.py[line:274] - INFO: epoch 007:    222 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.12, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.69, wps=467.4, ups=0.09, wpb=5120, bsz=1280, num_updates=2100, lr=3.53441e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=109, gb_free=9.7, wall=26960
2024-11-08 18:42:07 - progress_bar.py[line:274] - INFO: epoch 007:    232 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.145, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.85, wps=478.7, ups=0.09, wpb=5119.8, bsz=1280, num_updates=2110, lr=3.52591e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=107, gb_free=9.7, wall=27067
2024-11-08 18:43:51 - progress_bar.py[line:274] - INFO: epoch 007:    242 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.096, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.55, wps=493.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=2120, lr=3.51742e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=104, gb_free=9.6, wall=27171
2024-11-08 18:45:38 - progress_bar.py[line:274] - INFO: epoch 007:    252 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.063, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.35, wps=476.8, ups=0.09, wpb=5119.9, bsz=1280, num_updates=2130, lr=3.50892e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=107, gb_free=9.6, wall=27278
2024-11-08 18:47:30 - progress_bar.py[line:274] - INFO: epoch 007:    262 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.076, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.43, wps=457.3, ups=0.09, wpb=5120, bsz=1280, num_updates=2140, lr=3.50042e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=112, gb_free=9.6, wall=27390
2024-11-08 18:49:20 - progress_bar.py[line:274] - INFO: epoch 007:    272 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.067, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.38, wps=465.5, ups=0.09, wpb=5120, bsz=1280, num_updates=2150, lr=3.49193e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=110, gb_free=9.6, wall=27500
2024-11-08 18:51:06 - progress_bar.py[line:274] - INFO: epoch 007:    282 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.119, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.69, wps=482.5, ups=0.09, wpb=5120, bsz=1280, num_updates=2160, lr=3.48343e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=106, gb_free=9.6, wall=27606
2024-11-08 18:52:49 - progress_bar.py[line:274] - INFO: epoch 007:    292 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.16, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.94, wps=496.1, ups=0.1, wpb=5119.9, bsz=1280, num_updates=2170, lr=3.47494e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=103, gb_free=9.7, wall=27710
2024-11-08 18:54:35 - progress_bar.py[line:274] - INFO: epoch 007:    302 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.116, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.67, wps=484.8, ups=0.09, wpb=5119.9, bsz=1280, num_updates=2180, lr=3.46644e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=106, gb_free=9.7, wall=27815
2024-11-08 18:56:23 - progress_bar.py[line:274] - INFO: epoch 007:    312 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.078, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.44, wps=475.8, ups=0.09, wpb=5120, bsz=1280, num_updates=2190, lr=3.45794e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=108, gb_free=9.7, wall=27923
slice_id 6 seek offset 41730
slice_id 7 seek offset 486852024-11-08 18:56:26 - train.py[line:449] - INFO: begin validation on "valid" subset

slice_id 4 seek offset 27820slice_id 0 seek offset 0slice_id 5 seek offset 34775slice_id 3 seek offset 20865



slice_id 1 seek offset 6955
slice_id 2 seek offset 13910
slice_id 3 seek offset 20865
slice_id 5 seek offset 34775
slice_id 7 seek offset 48685
slice_id 2 seek offset 13910
slice_id 1 seek offset 6955
slice_id 6 seek offset 41730
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-08 19:03:55 - progress_bar.py[line:282] - INFO: epoch 007 | valid on 'valid' subset | loss 0.002 | loss_v1 0 | loss_v2 0 | nll_loss 3.087 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 8.5 | score 0.1875 | wps 497.6 | wpb 639.5 | bsz 159.9 | num_updates 2191 | best_score 0.1875
2024-11-08 19:03:55 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 2191 updates
2024-11-08 19:03:55 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 row count 50000 total row count 400000file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 row count 50000 total row count 400000file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 row count 50000 total row count 400000


local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 row count 50000 total row count 400000
slice_id 5 seek offset 250000
slice_id 3 seek offset 150000
slice_id 7 seek offset 350000
slice_id 2 seek offset 100000
slice_id 4 seek offset 200000
slice_id 6 seek offset 300000
slice_id 1 seek offset 50000
2024-11-08 19:04:56 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-11-08 19:06:08 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 7 @ 2191 updates, score 0.1875) (writing took 133.46135514200432 seconds)
2024-11-08 19:06:09 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 2191 updates
2024-11-08 19:06:09 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 19:07:34 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 19:07:34 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 7 @ 2191 updates, score 0) (writing took 84.74174360895995 seconds)
2024-11-08 19:07:34 - train.py[line:336] - INFO: end of epoch 7 (average epoch stats below)
2024-11-08 19:07:34 - progress_bar.py[line:282] - INFO: epoch 007 | loss 0.002 | loss_v1 0 | loss_v2 0 | nll_loss 3.091 | ntokens 5111.78 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 8.52 | wps 348.3 | ups 0.07 | wpb 5111.8 | bsz 1278 | num_updates 2191 | lr 3.45709e-05 | gnorm 0.007 | clip 0 | loss_scale 2048 | train_wall 2900 | gb_free 9.7 | wall 28594
2024-11-08 19:07:34 - trainer.py[line:639] - INFO: loading train data for epoch 8
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 19:07:36 - trainer.py[line:703] - INFO: begin training epoch 8
2024-11-08 19:07:36 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 19:09:09 - progress_bar.py[line:274] - INFO: epoch 008:      9 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.086, ntokens=4863.9, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=8.49, wps=63.4, ups=0.01, wpb=4863.9, bsz=1216, num_updates=2200, lr=3.44945e-05, gnorm=0.006, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=28690
2024-11-08 19:10:52 - progress_bar.py[line:274] - INFO: epoch 008:     19 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.105, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.6, wps=498.4, ups=0.1, wpb=5120, bsz=1280, num_updates=2210, lr=3.44095e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=44, gb_free=9.6, wall=28792
2024-11-08 19:12:40 - progress_bar.py[line:274] - INFO: epoch 008:     29 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.154, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.9, wps=474.2, ups=0.09, wpb=5120, bsz=1280, num_updates=2220, lr=3.43246e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=100, gb_free=9.7, wall=28900
2024-11-08 19:14:28 - progress_bar.py[line:274] - INFO: epoch 008:     39 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.136, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.79, wps=472.7, ups=0.09, wpb=5120, bsz=1280, num_updates=2230, lr=3.42396e-05, gnorm=0.006, clip=0, loss_scale=2048, train_wall=108, gb_free=9.7, wall=29009
2024-11-08 19:16:17 - progress_bar.py[line:274] - INFO: epoch 008:     49 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.112, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.64, wps=470.3, ups=0.09, wpb=5120, bsz=1280, num_updates=2240, lr=3.41546e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=109, gb_free=9.7, wall=29118
2024-11-08 19:18:04 - progress_bar.py[line:274] - INFO: epoch 008:     59 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.117, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.68, wps=478.3, ups=0.09, wpb=5120, bsz=1280, num_updates=2250, lr=3.40697e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=107, gb_free=9.7, wall=29225
2024-11-08 19:19:52 - progress_bar.py[line:274] - INFO: epoch 008:     69 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.098, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.56, wps=475.4, ups=0.09, wpb=5120, bsz=1280, num_updates=2260, lr=3.39847e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=108, gb_free=9.7, wall=29332
2024-11-08 19:21:40 - progress_bar.py[line:274] - INFO: epoch 008:     79 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.066, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.38, wps=472.7, ups=0.09, wpb=5120, bsz=1280, num_updates=2270, lr=3.38997e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=108, gb_free=9.7, wall=29441
2024-11-08 19:23:24 - progress_bar.py[line:274] - INFO: epoch 008:     89 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.08, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.46, wps=493.7, ups=0.1, wpb=5120, bsz=1280, num_updates=2280, lr=3.38148e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=104, gb_free=9.7, wall=29544
2024-11-08 19:25:07 - progress_bar.py[line:274] - INFO: epoch 008:     99 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.083, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.47, wps=496.3, ups=0.1, wpb=5120, bsz=1280, num_updates=2290, lr=3.37298e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=103, gb_free=9.6, wall=29647
2024-11-08 19:26:52 - progress_bar.py[line:274] - INFO: epoch 008:    109 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.068, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.39, wps=487.7, ups=0.1, wpb=5119.9, bsz=1280, num_updates=2300, lr=3.36449e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=105, gb_free=9.6, wall=29752
2024-11-08 19:28:40 - progress_bar.py[line:274] - INFO: epoch 008:    119 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.079, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.45, wps=475, ups=0.09, wpb=5120, bsz=1280, num_updates=2310, lr=3.35599e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=108, gb_free=9.7, wall=29860
2024-11-08 19:30:29 - progress_bar.py[line:274] - INFO: epoch 008:    129 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.078, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.44, wps=470.7, ups=0.09, wpb=5120, bsz=1280, num_updates=2320, lr=3.34749e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=109, gb_free=9.7, wall=29969
2024-11-08 19:32:15 - progress_bar.py[line:274] - INFO: epoch 008:    139 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.081, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.46, wps=481.3, ups=0.09, wpb=5119.9, bsz=1280, num_updates=2330, lr=3.339e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=106, gb_free=9.6, wall=30075
2024-11-08 19:33:59 - progress_bar.py[line:274] - INFO: epoch 008:    149 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.09, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.52, wps=494.1, ups=0.1, wpb=5119.9, bsz=1280, num_updates=2340, lr=3.3305e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=104, gb_free=9.7, wall=30179
2024-11-08 19:35:47 - progress_bar.py[line:274] - INFO: epoch 008:    159 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.092, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.53, wps=474.8, ups=0.09, wpb=5120, bsz=1280, num_updates=2350, lr=3.32201e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=108, gb_free=9.7, wall=30287
2024-11-08 19:37:34 - progress_bar.py[line:274] - INFO: epoch 008:    169 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.08, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.46, wps=476.5, ups=0.09, wpb=5120, bsz=1280, num_updates=2360, lr=3.31351e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=107, gb_free=9.7, wall=30394
2024-11-08 19:39:18 - progress_bar.py[line:274] - INFO: epoch 008:    179 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.09, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.52, wps=495.1, ups=0.1, wpb=5120, bsz=1280, num_updates=2370, lr=3.30501e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=103, gb_free=9.7, wall=30498
2024-11-08 19:41:01 - progress_bar.py[line:274] - INFO: epoch 008:    189 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.1, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.57, wps=493.5, ups=0.1, wpb=5120, bsz=1280, num_updates=2380, lr=3.29652e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=104, gb_free=9.6, wall=30602
2024-11-08 19:42:48 - progress_bar.py[line:274] - INFO: epoch 008:    199 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.122, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.7, wps=479, ups=0.09, wpb=5119.8, bsz=1280, num_updates=2390, lr=3.28802e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=107, gb_free=9.7, wall=30708
2024-11-08 19:44:36 - progress_bar.py[line:274] - INFO: epoch 008:    209 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.101, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.58, wps=473.8, ups=0.09, wpb=5119.9, bsz=1280, num_updates=2400, lr=3.27952e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=108, gb_free=9.7, wall=30816
2024-11-08 19:46:23 - progress_bar.py[line:274] - INFO: epoch 008:    219 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.087, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.5, wps=477.3, ups=0.09, wpb=5120, bsz=1280, num_updates=2410, lr=3.27103e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=107, gb_free=9.7, wall=30924
2024-11-08 19:48:12 - progress_bar.py[line:274] - INFO: epoch 008:    229 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.097, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.55, wps=471.2, ups=0.09, wpb=5119.8, bsz=1280, num_updates=2420, lr=3.26253e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=109, gb_free=9.6, wall=31032
2024-11-08 19:50:01 - progress_bar.py[line:274] - INFO: epoch 008:    239 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.125, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.73, wps=469.8, ups=0.09, wpb=5119.9, bsz=1280, num_updates=2430, lr=3.25404e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=109, gb_free=9.7, wall=31141
2024-11-08 19:51:47 - progress_bar.py[line:274] - INFO: epoch 008:    249 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.12, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.7, wps=483.1, ups=0.09, wpb=5119.9, bsz=1280, num_updates=2440, lr=3.24554e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=106, gb_free=9.7, wall=31247
2024-11-08 19:53:30 - progress_bar.py[line:274] - INFO: epoch 008:    259 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.122, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.71, wps=498.2, ups=0.1, wpb=5120, bsz=1280, num_updates=2450, lr=3.23704e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=103, gb_free=9.7, wall=31350
2024-11-08 19:55:12 - progress_bar.py[line:274] - INFO: epoch 008:    269 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.107, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.61, wps=499, ups=0.1, wpb=5120, bsz=1280, num_updates=2460, lr=3.22855e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=103, gb_free=9.7, wall=31453
2024-11-08 19:56:56 - progress_bar.py[line:274] - INFO: epoch 008:    279 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.078, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.44, wps=496.4, ups=0.1, wpb=5120, bsz=1280, num_updates=2470, lr=3.22005e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=103, gb_free=9.7, wall=31556
2024-11-08 19:58:38 - progress_bar.py[line:274] - INFO: epoch 008:    289 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.117, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.68, wps=499, ups=0.1, wpb=5119.9, bsz=1280, num_updates=2480, lr=3.21155e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=103, gb_free=9.6, wall=31658
2024-11-08 20:00:22 - progress_bar.py[line:274] - INFO: epoch 008:    299 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.103, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.59, wps=494.9, ups=0.1, wpb=5120, bsz=1280, num_updates=2490, lr=3.20306e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=103, gb_free=9.6, wall=31762
2024-11-08 20:02:04 - progress_bar.py[line:274] - INFO: epoch 008:    309 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.11, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.64, wps=498.3, ups=0.1, wpb=5119.9, bsz=1280, num_updates=2500, lr=3.19456e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=103, gb_free=9.6, wall=31865
slice_id 4 seek offset 27820slice_id 2 seek offset 13910
slice_id 6 seek offset 41730

slice_id 5 seek offset 34775slice_id 3 seek offset 20865
slice_id 7 seek offset 48685

2024-11-08 20:02:38 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 1 seek offset 6955
slice_id 0 seek offset 0
slice_id 3 seek offset 20865
slice_id 5 seek offset 34775
slice_id 7 seek offset 48685
slice_id 6 seek offset 41730
slice_id 2 seek offset 13910
slice_id 1 seek offset 6955
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-08 20:10:00 - progress_bar.py[line:282] - INFO: epoch 008 | valid on 'valid' subset | loss 0.002 | loss_v1 0 | loss_v2 0 | nll_loss 3.116 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 8.67 | score 0.2644 | wps 505.3 | wpb 639.5 | bsz 159.9 | num_updates 2504 | best_score 0.2644
2024-11-08 20:10:00 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 8 @ 2504 updates
2024-11-08 20:10:00 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 row count 50000 total row count 400000
slice_id 2 seek offset 100000
slice_id 1 seek offset 50000
slice_id 4 seek offset 200000
slice_id 7 seek offset 350000
slice_id 3 seek offset 150000
slice_id 5 seek offset 250000
slice_id 6 seek offset 300000
2024-11-08 20:11:01 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-11-08 20:12:15 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 8 @ 2504 updates, score 0.2644) (writing took 134.3680276889936 seconds)
2024-11-08 20:12:15 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 8 @ 2504 updates
2024-11-08 20:12:15 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 20:13:43 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 20:13:43 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 8 @ 2504 updates, score 0) (writing took 88.00819459196646 seconds)
2024-11-08 20:13:43 - train.py[line:336] - INFO: end of epoch 8 (average epoch stats below)
2024-11-08 20:13:43 - progress_bar.py[line:282] - INFO: epoch 008 | loss 0.002 | loss_v1 0 | loss_v2 0 | nll_loss 3.1 | ntokens 5111.78 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 8.57 | wps 403 | ups 0.08 | wpb 5111.8 | bsz 1278 | num_updates 2504 | lr 3.19116e-05 | gnorm 0.007 | clip 0 | loss_scale 2048 | train_wall 3172 | gb_free 9.7 | wall 32564
2024-11-08 20:13:43 - trainer.py[line:639] - INFO: loading train data for epoch 9
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 20:13:46 - trainer.py[line:703] - INFO: begin training epoch 9
2024-11-08 20:13:46 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 20:14:49 - progress_bar.py[line:274] - INFO: epoch 009:      6 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.131, ntokens=4863.9, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=8.76, wps=63.6, ups=0.01, wpb=4863.9, bsz=1216, num_updates=2510, lr=3.18607e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=55, gb_free=9.7, wall=32629
2024-11-08 20:16:29 - progress_bar.py[line:274] - INFO: epoch 009:     16 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.139, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.81, wps=512.7, ups=0.1, wpb=5120, bsz=1280, num_updates=2520, lr=3.17757e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=32729
2024-11-08 20:18:10 - progress_bar.py[line:274] - INFO: epoch 009:     26 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.164, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.96, wps=506.5, ups=0.1, wpb=5120, bsz=1280, num_updates=2530, lr=3.16907e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=32830
2024-11-08 20:19:50 - progress_bar.py[line:274] - INFO: epoch 009:     36 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.137, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.8, wps=509.5, ups=0.1, wpb=5120, bsz=1280, num_updates=2540, lr=3.16058e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=32930
2024-11-08 20:21:33 - progress_bar.py[line:274] - INFO: epoch 009:     46 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.095, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.54, wps=499.5, ups=0.1, wpb=5120, bsz=1280, num_updates=2550, lr=3.15208e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=49, gb_free=9.7, wall=33033
2024-11-08 20:23:16 - progress_bar.py[line:274] - INFO: epoch 009:     56 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.129, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.75, wps=495.6, ups=0.1, wpb=5120, bsz=1280, num_updates=2560, lr=3.14359e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=76, gb_free=9.7, wall=33136
2024-11-08 20:24:59 - progress_bar.py[line:274] - INFO: epoch 009:     66 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.125, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.72, wps=496.4, ups=0.1, wpb=5120, bsz=1280, num_updates=2570, lr=3.13509e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=102, gb_free=9.7, wall=33239
2024-11-08 20:26:42 - progress_bar.py[line:274] - INFO: epoch 009:     76 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.128, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.74, wps=497.5, ups=0.1, wpb=5120, bsz=1280, num_updates=2580, lr=3.12659e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=33342
2024-11-08 20:28:26 - progress_bar.py[line:274] - INFO: epoch 009:     86 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.164, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.96, wps=494.3, ups=0.1, wpb=5120, bsz=1280, num_updates=2590, lr=3.1181e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=33446
2024-11-08 20:30:09 - progress_bar.py[line:274] - INFO: epoch 009:     96 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.162, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.95, wps=493, ups=0.1, wpb=5120, bsz=1280, num_updates=2600, lr=3.1096e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=104, gb_free=9.6, wall=33550
2024-11-08 20:31:52 - progress_bar.py[line:274] - INFO: epoch 009:    106 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.14, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.81, wps=498.1, ups=0.1, wpb=5119.9, bsz=1280, num_updates=2610, lr=3.1011e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=33652
2024-11-08 20:33:36 - progress_bar.py[line:274] - INFO: epoch 009:    116 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.13, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.75, wps=494.7, ups=0.1, wpb=5120, bsz=1280, num_updates=2620, lr=3.09261e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=33756
2024-11-08 20:35:18 - progress_bar.py[line:274] - INFO: epoch 009:    126 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.147, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.86, wps=498.1, ups=0.1, wpb=5120, bsz=1280, num_updates=2630, lr=3.08411e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=33859
2024-11-08 20:37:02 - progress_bar.py[line:274] - INFO: epoch 009:    136 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.119, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.69, wps=494.5, ups=0.1, wpb=5120, bsz=1280, num_updates=2640, lr=3.07562e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=33962
2024-11-08 20:38:45 - progress_bar.py[line:274] - INFO: epoch 009:    146 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.167, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.98, wps=496.3, ups=0.1, wpb=5119.9, bsz=1280, num_updates=2650, lr=3.06712e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=34065
2024-11-08 20:40:28 - progress_bar.py[line:274] - INFO: epoch 009:    156 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.178, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.05, wps=496.6, ups=0.1, wpb=5119.9, bsz=1280, num_updates=2660, lr=3.05862e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=34169
2024-11-08 20:42:11 - progress_bar.py[line:274] - INFO: epoch 009:    166 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.173, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.02, wps=498.7, ups=0.1, wpb=5120, bsz=1280, num_updates=2670, lr=3.05013e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=34271
2024-11-08 20:43:54 - progress_bar.py[line:274] - INFO: epoch 009:    176 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.157, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.92, wps=497.6, ups=0.1, wpb=5120, bsz=1280, num_updates=2680, lr=3.04163e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=34374
2024-11-08 20:45:37 - progress_bar.py[line:274] - INFO: epoch 009:    186 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.16, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.94, wps=494.3, ups=0.1, wpb=5120, bsz=1280, num_updates=2690, lr=3.03314e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=34478
2024-11-08 20:47:20 - progress_bar.py[line:274] - INFO: epoch 009:    196 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.197, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.17, wps=497.6, ups=0.1, wpb=5119.9, bsz=1280, num_updates=2700, lr=3.02464e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=34581
2024-11-08 20:49:03 - progress_bar.py[line:274] - INFO: epoch 009:    206 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.168, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.99, wps=496.5, ups=0.1, wpb=5119.8, bsz=1280, num_updates=2710, lr=3.01614e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=34684
2024-11-08 20:50:47 - progress_bar.py[line:274] - INFO: epoch 009:    216 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.179, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.06, wps=494.3, ups=0.1, wpb=5120, bsz=1280, num_updates=2720, lr=3.00765e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=34787
2024-11-08 20:52:31 - progress_bar.py[line:274] - INFO: epoch 009:    226 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.187, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.11, wps=494.7, ups=0.1, wpb=5119.8, bsz=1280, num_updates=2730, lr=2.99915e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=34891
2024-11-08 20:54:14 - progress_bar.py[line:274] - INFO: epoch 009:    236 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.225, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.35, wps=494.9, ups=0.1, wpb=5120, bsz=1280, num_updates=2740, lr=2.99065e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=34994
2024-11-08 20:55:57 - progress_bar.py[line:274] - INFO: epoch 009:    246 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.187, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.11, wps=494.8, ups=0.1, wpb=5119.8, bsz=1280, num_updates=2750, lr=2.98216e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=35098
2024-11-08 20:57:40 - progress_bar.py[line:274] - INFO: epoch 009:    256 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.22, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.32, wps=498.3, ups=0.1, wpb=5120, bsz=1280, num_updates=2760, lr=2.97366e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=35200
2024-11-08 20:59:23 - progress_bar.py[line:274] - INFO: epoch 009:    266 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.221, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.32, wps=497.6, ups=0.1, wpb=5120, bsz=1280, num_updates=2770, lr=2.96517e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=35303
2024-11-08 21:01:06 - progress_bar.py[line:274] - INFO: epoch 009:    276 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.173, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.02, wps=496.3, ups=0.1, wpb=5120, bsz=1280, num_updates=2780, lr=2.95667e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=35406
2024-11-08 21:02:49 - progress_bar.py[line:274] - INFO: epoch 009:    286 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.213, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.27, wps=496.3, ups=0.1, wpb=5120, bsz=1280, num_updates=2790, lr=2.94817e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=35510
2024-11-08 21:04:33 - progress_bar.py[line:274] - INFO: epoch 009:    296 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.183, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.08, wps=496.1, ups=0.1, wpb=5119.9, bsz=1280, num_updates=2800, lr=2.93968e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=35613
2024-11-08 21:06:16 - progress_bar.py[line:274] - INFO: epoch 009:    306 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.156, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.91, wps=493.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=2810, lr=2.93118e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=104, gb_free=9.7, wall=35717
slice_id 6 seek offset 41730slice_id 4 seek offset 27820

slice_id 7 seek offset 486852024-11-08 21:07:22 - train.py[line:449] - INFO: begin validation on "valid" subset

slice_id 5 seek offset 34775slice_id 0 seek offset 0

slice_id 1 seek offset 6955slice_id 3 seek offset 20865

slice_id 2 seek offset 13910
slice_id 3 seek offset 20865
slice_id 5 seek offset 34775
slice_id 7 seek offset 48685
slice_id 6 seek offset 41730
slice_id 1 seek offset 6955
slice_id 2 seek offset 13910
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-08 21:14:45 - progress_bar.py[line:282] - INFO: epoch 009 | valid on 'valid' subset | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.174 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.03 | score 0.4322 | wps 503.5 | wpb 639.5 | bsz 159.9 | num_updates 2817 | best_score 0.4322
2024-11-08 21:14:45 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 9 @ 2817 updates
2024-11-08 21:14:45 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 row count 50000 total row count 400000
slice_id 7 seek offset 350000
slice_id 3 seek offset 150000
slice_id 5 seek offset 250000
slice_id 1 seek offset 50000
slice_id 4 seek offset 200000
slice_id 2 seek offset 100000
slice_id 6 seek offset 300000
2024-11-08 21:15:46 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-11-08 21:16:59 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 9 @ 2817 updates, score 0.4322) (writing took 133.17092273395974 seconds)
2024-11-08 21:16:59 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 9 @ 2817 updates
2024-11-08 21:16:59 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 21:18:28 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 21:18:28 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 9 @ 2817 updates, score 0) (writing took 89.01116408099188 seconds)
2024-11-08 21:18:28 - train.py[line:336] - INFO: end of epoch 9 (average epoch stats below)
2024-11-08 21:18:28 - progress_bar.py[line:282] - INFO: epoch 009 | loss 0.002 | loss_v1 0 | loss_v2 0 | nll_loss 3.163 | ntokens 5111.78 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 8.96 | wps 411.9 | ups 0.08 | wpb 5111.8 | bsz 1278 | num_updates 2817 | lr 2.92523e-05 | gnorm 0.008 | clip 0 | loss_scale 4096 | train_wall 2892 | gb_free 9.7 | wall 36449
2024-11-08 21:18:28 - trainer.py[line:639] - INFO: loading train data for epoch 10
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 21:18:31 - trainer.py[line:703] - INFO: begin training epoch 10
2024-11-08 21:18:31 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 21:19:04 - progress_bar.py[line:274] - INFO: epoch 010:      3 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.17, ntokens=4864, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=9, wps=63.4, ups=0.01, wpb=4864, bsz=1216, num_updates=2820, lr=2.92268e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=76, gb_free=9.6, wall=36484
2024-11-08 21:20:43 - progress_bar.py[line:274] - INFO: epoch 010:     13 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.192, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.14, wps=514.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=2830, lr=2.91419e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=36584
2024-11-08 21:22:23 - progress_bar.py[line:274] - INFO: epoch 010:     23 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.194, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.15, wps=512.9, ups=0.1, wpb=5120, bsz=1280, num_updates=2840, lr=2.90569e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=36683
2024-11-08 21:24:05 - progress_bar.py[line:274] - INFO: epoch 010:     33 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.235, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.41, wps=503.7, ups=0.1, wpb=5120, bsz=1280, num_updates=2850, lr=2.8972e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=39, gb_free=9.7, wall=36785
2024-11-08 21:25:48 - progress_bar.py[line:274] - INFO: epoch 010:     43 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.204, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.21, wps=494.1, ups=0.1, wpb=5120, bsz=1280, num_updates=2860, lr=2.8887e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=68, gb_free=9.6, wall=36889
2024-11-08 21:27:32 - progress_bar.py[line:274] - INFO: epoch 010:     53 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.228, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.37, wps=494.7, ups=0.1, wpb=5120, bsz=1280, num_updates=2870, lr=2.8802e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=101, gb_free=9.7, wall=36992
2024-11-08 21:29:15 - progress_bar.py[line:274] - INFO: epoch 010:     63 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.201, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.19, wps=495.2, ups=0.1, wpb=5120, bsz=1280, num_updates=2880, lr=2.87171e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=37096
2024-11-08 21:30:59 - progress_bar.py[line:274] - INFO: epoch 010:     73 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.178, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.05, wps=492.2, ups=0.1, wpb=5120, bsz=1280, num_updates=2890, lr=2.86321e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=104, gb_free=9.6, wall=37200
2024-11-08 21:32:43 - progress_bar.py[line:274] - INFO: epoch 010:     83 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.239, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.44, wps=495.9, ups=0.1, wpb=5120, bsz=1280, num_updates=2900, lr=2.85472e-05, gnorm=0.012, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=37303
2024-11-08 21:34:25 - progress_bar.py[line:274] - INFO: epoch 010:     93 / 313 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.23, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.38, wps=497.8, ups=0.1, wpb=5120, bsz=1280, num_updates=2910, lr=2.84622e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=37406
2024-11-08 21:36:09 - progress_bar.py[line:274] - INFO: epoch 010:    103 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.198, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.17, wps=494.1, ups=0.1, wpb=5120, bsz=1280, num_updates=2920, lr=2.83772e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=104, gb_free=9.6, wall=37509
2024-11-08 21:37:52 - progress_bar.py[line:274] - INFO: epoch 010:    113 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.16, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.94, wps=496.9, ups=0.1, wpb=5119.9, bsz=1280, num_updates=2930, lr=2.82923e-05, gnorm=0.012, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=37612
2024-11-08 21:39:35 - progress_bar.py[line:274] - INFO: epoch 010:    123 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.174, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.03, wps=497.3, ups=0.1, wpb=5120, bsz=1280, num_updates=2940, lr=2.82073e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=37715
2024-11-08 21:41:18 - progress_bar.py[line:274] - INFO: epoch 010:    133 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.147, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.86, wps=495.1, ups=0.1, wpb=5120, bsz=1280, num_updates=2950, lr=2.81223e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=37819
2024-11-08 21:43:02 - progress_bar.py[line:274] - INFO: epoch 010:    143 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.167, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.98, wps=494.9, ups=0.1, wpb=5119.9, bsz=1280, num_updates=2960, lr=2.80374e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=37922
2024-11-08 21:44:45 - progress_bar.py[line:274] - INFO: epoch 010:    153 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.182, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.08, wps=495.4, ups=0.1, wpb=5119.9, bsz=1280, num_updates=2970, lr=2.79524e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=38026
2024-11-08 21:46:28 - progress_bar.py[line:274] - INFO: epoch 010:    163 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.171, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.01, wps=497, ups=0.1, wpb=5120, bsz=1280, num_updates=2980, lr=2.78675e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=38129
2024-11-08 21:48:12 - progress_bar.py[line:274] - INFO: epoch 010:    173 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.161, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.95, wps=494.4, ups=0.1, wpb=5120, bsz=1280, num_updates=2990, lr=2.77825e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=38232
2024-11-08 21:49:56 - progress_bar.py[line:274] - INFO: epoch 010:    183 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.191, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.13, wps=493.6, ups=0.1, wpb=5120, bsz=1280, num_updates=3000, lr=2.76975e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=104, gb_free=9.7, wall=38336
slice_id 4 seek offset 27820
slice_id 7 seek offset 48685
slice_id 5 seek offset 34775
slice_id 6 seek offset 41730
2024-11-08 21:49:56 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 1 seek offset 6955
slice_id 3 seek offset 20865
slice_id 2 seek offset 13910
slice_id 7 seek offset 48685
slice_id 5 seek offset 34775
slice_id 6 seek offset 41730
slice_id 3 seek offset 20865
slice_id 2 seek offset 13910
slice_id 1 seek offset 6955
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-08 21:57:36 - progress_bar.py[line:282] - INFO: epoch 010 | valid on 'valid' subset | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.195 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.16 | score 0.4996 | wps 485.2 | wpb 639.5 | bsz 159.9 | num_updates 3000 | best_score 0.4996
2024-11-08 21:57:36 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 10 @ 3000 updates
2024-11-08 21:57:36 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_10_3000.pt
2024-11-08 21:57:47 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_10_3000.pt
2024-11-08 22:00:36 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_10_3000.pt (epoch 10 @ 3000 updates, score 0.4996) (writing took 179.98640248697484 seconds)
2024-11-08 22:02:07 - progress_bar.py[line:274] - INFO: epoch 010:    193 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.219, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.31, wps=70, ups=0.01, wpb=5120, bsz=1280, num_updates=3010, lr=2.76126e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=39067
2024-11-08 22:03:47 - progress_bar.py[line:274] - INFO: epoch 010:    203 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.212, ntokens=5119.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.27, wps=509.4, ups=0.1, wpb=5119.7, bsz=1280, num_updates=3020, lr=2.75276e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=39167
2024-11-08 22:05:31 - progress_bar.py[line:274] - INFO: epoch 010:    213 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.19, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.13, wps=492.9, ups=0.1, wpb=5120, bsz=1280, num_updates=3030, lr=2.74427e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=57, gb_free=9.6, wall=39271
2024-11-08 22:07:14 - progress_bar.py[line:274] - INFO: epoch 010:    223 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.199, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.18, wps=495.4, ups=0.1, wpb=5120, bsz=1280, num_updates=3040, lr=2.73577e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=91, gb_free=9.5, wall=39375
2024-11-08 22:08:58 - progress_bar.py[line:274] - INFO: epoch 010:    233 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.185, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.09, wps=491.8, ups=0.1, wpb=5119.8, bsz=1280, num_updates=3050, lr=2.72727e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=104, gb_free=9.6, wall=39479
2024-11-08 22:10:42 - progress_bar.py[line:274] - INFO: epoch 010:    243 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.177, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.04, wps=496.7, ups=0.1, wpb=5119.8, bsz=1280, num_updates=3060, lr=2.71878e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=39582
2024-11-08 22:12:25 - progress_bar.py[line:274] - INFO: epoch 010:    253 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.183, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.08, wps=496, ups=0.1, wpb=5120, bsz=1280, num_updates=3070, lr=2.71028e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=39685
2024-11-08 22:14:08 - progress_bar.py[line:274] - INFO: epoch 010:    263 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.199, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.18, wps=496.4, ups=0.1, wpb=5120, bsz=1280, num_updates=3080, lr=2.70178e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=39788
2024-11-08 22:15:51 - progress_bar.py[line:274] - INFO: epoch 010:    273 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.208, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.24, wps=498.5, ups=0.1, wpb=5120, bsz=1280, num_updates=3090, lr=2.69329e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=39891
2024-11-08 22:17:34 - progress_bar.py[line:274] - INFO: epoch 010:    283 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.203, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.21, wps=493.7, ups=0.1, wpb=5120, bsz=1280, num_updates=3100, lr=2.68479e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=39995
2024-11-08 22:19:17 - progress_bar.py[line:274] - INFO: epoch 010:    293 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.2, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.19, wps=497.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=3110, lr=2.6763e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=40097
2024-11-08 22:21:01 - progress_bar.py[line:274] - INFO: epoch 010:    303 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.197, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.17, wps=494.7, ups=0.1, wpb=5119.9, bsz=1280, num_updates=3120, lr=2.6678e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=40201
2024-11-08 22:22:37 - progress_bar.py[line:274] - INFO: epoch 010:    313 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.197, ntokens=4864, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=9.17, wps=504.3, ups=0.1, wpb=4864, bsz=1216, num_updates=3130, lr=2.6593e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=96, gb_free=9.7, wall=40297
slice_id 6 seek offset 41730
slice_id 4 seek offset 27820
slice_id 1 seek offset 6955slice_id 5 seek offset 34775
slice_id 3 seek offset 20865

2024-11-08 22:22:37 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 7 seek offset 48685
slice_id 0 seek offset 0slice_id 2 seek offset 13910

slice_id 3 seek offset 20865
slice_id 7 seek offset 48685
slice_id 5 seek offset 34775
slice_id 6 seek offset 41730
slice_id 1 seek offset 6955
slice_id 2 seek offset 13910
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-08 22:30:02 - progress_bar.py[line:282] - INFO: epoch 010 | valid on 'valid' subset | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.165 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 8.97 | score 0.5203 | wps 502 | wpb 639.5 | bsz 159.9 | num_updates 3130 | best_score 0.5203
2024-11-08 22:30:02 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 10 @ 3130 updates
2024-11-08 22:30:02 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 row count 50000 total row count 400000
slice_id 7 seek offset 350000
slice_id 1 seek offset 50000
slice_id 2 seek offset 100000
slice_id 4 seek offset 200000
slice_id 3 seek offset 150000
slice_id 5 seek offset 250000
slice_id 6 seek offset 300000
2024-11-08 22:31:03 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-11-08 22:32:16 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 10 @ 3130 updates, score 0.5203) (writing took 133.72031339199748 seconds)
2024-11-08 22:32:17 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 10 @ 3130 updates
2024-11-08 22:32:17 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 22:33:45 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 22:33:45 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 10 @ 3130 updates, score 0) (writing took 88.77273221203359 seconds)
2024-11-08 22:33:45 - train.py[line:336] - INFO: end of epoch 10 (average epoch stats below)
2024-11-08 22:33:45 - progress_bar.py[line:282] - INFO: epoch 010 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.194 | ntokens 5111.78 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.15 | wps 354.2 | ups 0.07 | wpb 5111.8 | bsz 1278 | num_updates 3130 | lr 2.6593e-05 | gnorm 0.01 | clip 0 | loss_scale 8192 | train_wall 2770 | gb_free 9.7 | wall 40966
2024-11-08 22:33:45 - trainer.py[line:639] - INFO: loading train data for epoch 11
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 22:33:48 - trainer.py[line:703] - INFO: begin training epoch 11
2024-11-08 22:33:48 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 22:35:31 - progress_bar.py[line:274] - INFO: epoch 011:     10 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.142, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.83, wps=66.2, ups=0.01, wpb=5119.9, bsz=1280, num_updates=3140, lr=2.65081e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=41071
2024-11-08 22:37:11 - progress_bar.py[line:274] - INFO: epoch 011:     20 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.153, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.89, wps=511.9, ups=0.1, wpb=5120, bsz=1280, num_updates=3150, lr=2.64231e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=41171
2024-11-08 22:38:51 - progress_bar.py[line:274] - INFO: epoch 011:     30 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.17, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9, wps=513.4, ups=0.1, wpb=5120, bsz=1280, num_updates=3160, lr=2.63381e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=41271
2024-11-08 22:40:34 - progress_bar.py[line:274] - INFO: epoch 011:     40 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.168, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.98, wps=495.7, ups=0.1, wpb=5120, bsz=1280, num_updates=3170, lr=2.62532e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=55, gb_free=9.7, wall=41374
2024-11-08 22:42:17 - progress_bar.py[line:274] - INFO: epoch 011:     50 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.149, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.87, wps=496.1, ups=0.1, wpb=5120, bsz=1280, num_updates=3180, lr=2.61682e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=94, gb_free=9.7, wall=41477
2024-11-08 22:44:01 - progress_bar.py[line:274] - INFO: epoch 011:     60 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.138, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.8, wps=495.3, ups=0.1, wpb=5120, bsz=1280, num_updates=3190, lr=2.60833e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=41581
2024-11-08 22:45:44 - progress_bar.py[line:274] - INFO: epoch 011:     70 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.137, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.8, wps=495.8, ups=0.1, wpb=5120, bsz=1280, num_updates=3200, lr=2.59983e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=41684
2024-11-08 22:47:27 - progress_bar.py[line:274] - INFO: epoch 011:     80 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.112, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.65, wps=495.9, ups=0.1, wpb=5120, bsz=1280, num_updates=3210, lr=2.59133e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=41787
2024-11-08 22:49:10 - progress_bar.py[line:274] - INFO: epoch 011:     90 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.109, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.63, wps=495.6, ups=0.1, wpb=5120, bsz=1280, num_updates=3220, lr=2.58284e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=41891
2024-11-08 22:50:54 - progress_bar.py[line:274] - INFO: epoch 011:    100 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.096, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.55, wps=493.4, ups=0.1, wpb=5120, bsz=1280, num_updates=3230, lr=2.57434e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=41994
2024-11-08 22:52:38 - progress_bar.py[line:274] - INFO: epoch 011:    110 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.092, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.53, wps=495.5, ups=0.1, wpb=5119.9, bsz=1280, num_updates=3240, lr=2.56585e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=42098
2024-11-08 22:54:22 - progress_bar.py[line:274] - INFO: epoch 011:    120 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.091, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.52, wps=492.2, ups=0.1, wpb=5120, bsz=1280, num_updates=3250, lr=2.55735e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=104, gb_free=9.6, wall=42202
2024-11-08 22:56:04 - progress_bar.py[line:274] - INFO: epoch 011:    130 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.124, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.72, wps=499, ups=0.1, wpb=5120, bsz=1280, num_updates=3260, lr=2.54885e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=42304
2024-11-08 22:57:48 - progress_bar.py[line:274] - INFO: epoch 011:    140 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.142, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.82, wps=493.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=3270, lr=2.54036e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=42408
2024-11-08 22:59:31 - progress_bar.py[line:274] - INFO: epoch 011:    150 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.147, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.86, wps=495.5, ups=0.1, wpb=5119.9, bsz=1280, num_updates=3280, lr=2.53186e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=42511
2024-11-08 23:01:15 - progress_bar.py[line:274] - INFO: epoch 011:    160 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.127, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.74, wps=495, ups=0.1, wpb=5120, bsz=1280, num_updates=3290, lr=2.52336e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=42615
2024-11-08 23:02:59 - progress_bar.py[line:274] - INFO: epoch 011:    170 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.134, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.78, wps=492.8, ups=0.1, wpb=5120, bsz=1280, num_updates=3300, lr=2.51487e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=42719
2024-11-08 23:04:42 - progress_bar.py[line:274] - INFO: epoch 011:    180 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.118, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.68, wps=493.4, ups=0.1, wpb=5120, bsz=1280, num_updates=3310, lr=2.50637e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=42823
2024-11-08 23:06:26 - progress_bar.py[line:274] - INFO: epoch 011:    190 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.135, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.78, wps=492, ups=0.1, wpb=5120, bsz=1280, num_updates=3320, lr=2.49788e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=42927
2024-11-08 23:08:10 - progress_bar.py[line:274] - INFO: epoch 011:    200 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.157, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.92, wps=495.9, ups=0.1, wpb=5119.8, bsz=1280, num_updates=3330, lr=2.48938e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=43030
2024-11-08 23:09:53 - progress_bar.py[line:274] - INFO: epoch 011:    210 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.141, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.82, wps=497, ups=0.1, wpb=5119.9, bsz=1280, num_updates=3340, lr=2.48088e-05, gnorm=0.014, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=43133
2024-11-08 23:11:35 - progress_bar.py[line:274] - INFO: epoch 011:    220 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.131, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.76, wps=498.1, ups=0.1, wpb=5120, bsz=1280, num_updates=3350, lr=2.47239e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=43236
2024-11-08 23:13:19 - progress_bar.py[line:274] - INFO: epoch 011:    230 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.135, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.78, wps=493.8, ups=0.1, wpb=5119.8, bsz=1280, num_updates=3360, lr=2.46389e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=43339
2024-11-08 23:15:03 - progress_bar.py[line:274] - INFO: epoch 011:    240 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.141, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.82, wps=490.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=3370, lr=2.4554e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=104, gb_free=9.6, wall=43444
2024-11-08 23:16:47 - progress_bar.py[line:274] - INFO: epoch 011:    250 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.116, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.67, wps=496.6, ups=0.1, wpb=5119.9, bsz=1280, num_updates=3380, lr=2.4469e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=43547
2024-11-08 23:18:30 - progress_bar.py[line:274] - INFO: epoch 011:    260 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.105, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.6, wps=496.5, ups=0.1, wpb=5120, bsz=1280, num_updates=3390, lr=2.4384e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=43650
2024-11-08 23:20:13 - progress_bar.py[line:274] - INFO: epoch 011:    270 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.126, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.73, wps=496.1, ups=0.1, wpb=5120, bsz=1280, num_updates=3400, lr=2.42991e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=43753
2024-11-08 23:21:57 - progress_bar.py[line:274] - INFO: epoch 011:    280 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.125, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.72, wps=491.8, ups=0.1, wpb=5120, bsz=1280, num_updates=3410, lr=2.42141e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=43857
2024-11-08 23:23:40 - progress_bar.py[line:274] - INFO: epoch 011:    290 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.135, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.79, wps=496, ups=0.1, wpb=5119.9, bsz=1280, num_updates=3420, lr=2.41291e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=43960
2024-11-08 23:25:23 - progress_bar.py[line:274] - INFO: epoch 011:    300 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.112, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.64, wps=496.4, ups=0.1, wpb=5120, bsz=1280, num_updates=3430, lr=2.40442e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=44064
2024-11-08 23:27:07 - progress_bar.py[line:274] - INFO: epoch 011:    310 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.117, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.67, wps=494.6, ups=0.1, wpb=5119.9, bsz=1280, num_updates=3440, lr=2.39592e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=44167
slice_id 6 seek offset 41730slice_id 4 seek offset 27820
slice_id 2 seek offset 13910
slice_id 1 seek offset 6955

slice_id 5 seek offset 347752024-11-08 23:27:31 - train.py[line:449] - INFO: begin validation on "valid" subset

slice_id 7 seek offset 48685
slice_id 0 seek offset 0
slice_id 3 seek offset 20865
slice_id 3 seek offset 20865
slice_id 7 seek offset 48685
slice_id 5 seek offset 34775
slice_id 1 seek offset 6955
slice_id 2 seek offset 13910
slice_id 6 seek offset 41730
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-08 23:34:56 - progress_bar.py[line:282] - INFO: epoch 011 | valid on 'valid' subset | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.132 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 8.77 | score 0.5943 | wps 502.2 | wpb 639.5 | bsz 159.9 | num_updates 3443 | best_score 0.5943
2024-11-08 23:34:56 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 11 @ 3443 updates
2024-11-08 23:34:56 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 row count 50000 total row count 400000
slice_id 5 seek offset 250000
slice_id 2 seek offset 100000
slice_id 4 seek offset 200000
slice_id 1 seek offset 50000
slice_id 6 seek offset 300000
slice_id 3 seek offset 150000
slice_id 7 seek offset 350000
2024-11-08 23:35:56 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-11-08 23:37:11 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 11 @ 3443 updates, score 0.5943) (writing took 134.83259834599448 seconds)
2024-11-08 23:37:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 11 @ 3443 updates
2024-11-08 23:37:11 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 23:38:38 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-08 23:38:39 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 11 @ 3443 updates, score 0) (writing took 87.46570821403293 seconds)
2024-11-08 23:38:39 - train.py[line:336] - INFO: end of epoch 11 (average epoch stats below)
2024-11-08 23:38:39 - progress_bar.py[line:282] - INFO: epoch 011 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.13 | ntokens 5111.78 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 8.75 | wps 411 | ups 0.08 | wpb 5111.8 | bsz 1278 | num_updates 3443 | lr 2.39337e-05 | gnorm 0.011 | clip 0 | loss_scale 8192 | train_wall 2965 | gb_free 9.7 | wall 44859
2024-11-08 23:38:39 - trainer.py[line:639] - INFO: loading train data for epoch 12
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 23:38:41 - trainer.py[line:703] - INFO: begin training epoch 12
2024-11-08 23:38:41 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 23:39:54 - progress_bar.py[line:274] - INFO: epoch 012:      7 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.124, ntokens=4863.9, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=8.72, wps=63.4, ups=0.01, wpb=4863.9, bsz=1216, num_updates=3450, lr=2.38743e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=48, gb_free=9.6, wall=44934
2024-11-08 23:41:34 - progress_bar.py[line:274] - INFO: epoch 012:     17 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.167, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.98, wps=514.2, ups=0.1, wpb=5120, bsz=1280, num_updates=3460, lr=2.37893e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=45034
2024-11-08 23:43:14 - progress_bar.py[line:274] - INFO: epoch 012:     27 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.174, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.02, wps=509.2, ups=0.1, wpb=5120, bsz=1280, num_updates=3470, lr=2.37043e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=45135
2024-11-08 23:44:56 - progress_bar.py[line:274] - INFO: epoch 012:     37 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.17, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9, wps=503.9, ups=0.1, wpb=5120, bsz=1280, num_updates=3480, lr=2.36194e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=38, gb_free=9.7, wall=45236
2024-11-08 23:46:39 - progress_bar.py[line:274] - INFO: epoch 012:     47 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.169, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9, wps=495.3, ups=0.1, wpb=5120, bsz=1280, num_updates=3490, lr=2.35344e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=69, gb_free=9.6, wall=45340
2024-11-08 23:48:23 - progress_bar.py[line:274] - INFO: epoch 012:     57 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.183, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.08, wps=494.2, ups=0.1, wpb=5120, bsz=1280, num_updates=3500, lr=2.34494e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=100, gb_free=9.6, wall=45443
2024-11-08 23:50:06 - progress_bar.py[line:274] - INFO: epoch 012:     67 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.169, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.99, wps=494.3, ups=0.1, wpb=5120, bsz=1280, num_updates=3510, lr=2.33645e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=45547
2024-11-08 23:51:50 - progress_bar.py[line:274] - INFO: epoch 012:     77 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.173, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.02, wps=494.1, ups=0.1, wpb=5120, bsz=1280, num_updates=3520, lr=2.32795e-05, gnorm=0.015, clip=0, loss_scale=8192, train_wall=104, gb_free=9.6, wall=45650
2024-11-08 23:53:33 - progress_bar.py[line:274] - INFO: epoch 012:     87 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.147, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.86, wps=497.6, ups=0.1, wpb=5120, bsz=1280, num_updates=3530, lr=2.31946e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=45753
2024-11-08 23:55:16 - progress_bar.py[line:274] - INFO: epoch 012:     97 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.171, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.01, wps=497, ups=0.1, wpb=5120, bsz=1280, num_updates=3540, lr=2.31096e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=45856
2024-11-08 23:56:59 - progress_bar.py[line:274] - INFO: epoch 012:    107 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.152, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.89, wps=495.7, ups=0.1, wpb=5119.9, bsz=1280, num_updates=3550, lr=2.30246e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=45959
2024-11-08 23:58:43 - progress_bar.py[line:274] - INFO: epoch 012:    117 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.138, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.8, wps=493.3, ups=0.1, wpb=5120, bsz=1280, num_updates=3560, lr=2.29397e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=46063
2024-11-09 00:00:26 - progress_bar.py[line:274] - INFO: epoch 012:    127 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.156, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.92, wps=496.7, ups=0.1, wpb=5120, bsz=1280, num_updates=3570, lr=2.28547e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=46166
2024-11-09 00:02:10 - progress_bar.py[line:274] - INFO: epoch 012:    137 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.146, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.85, wps=493.7, ups=0.1, wpb=5119.9, bsz=1280, num_updates=3580, lr=2.27698e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=104, gb_free=9.6, wall=46270
2024-11-09 00:03:54 - progress_bar.py[line:274] - INFO: epoch 012:    147 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.18, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.06, wps=493.3, ups=0.1, wpb=5120, bsz=1280, num_updates=3590, lr=2.26848e-05, gnorm=0.011, clip=0, loss_scale=16384, train_wall=104, gb_free=9.7, wall=46374
2024-11-09 00:05:37 - progress_bar.py[line:274] - INFO: epoch 012:    157 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.179, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.06, wps=495, ups=0.1, wpb=5119.9, bsz=1280, num_updates=3600, lr=2.25998e-05, gnorm=0.011, clip=0, loss_scale=16384, train_wall=103, gb_free=9.7, wall=46477
2024-11-09 00:07:21 - progress_bar.py[line:274] - INFO: epoch 012:    167 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.172, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.01, wps=494.1, ups=0.1, wpb=5120, bsz=1280, num_updates=3610, lr=2.25149e-05, gnorm=0.012, clip=0, loss_scale=16384, train_wall=104, gb_free=9.7, wall=46581
2024-11-09 00:09:04 - progress_bar.py[line:274] - INFO: epoch 012:    177 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.177, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.05, wps=493.2, ups=0.1, wpb=5120, bsz=1280, num_updates=3620, lr=2.24299e-05, gnorm=0.011, clip=0, loss_scale=16384, train_wall=104, gb_free=9.7, wall=46685
2024-11-09 00:10:48 - progress_bar.py[line:274] - INFO: epoch 012:    187 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.165, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.97, wps=496.5, ups=0.1, wpb=5120, bsz=1280, num_updates=3630, lr=2.23449e-05, gnorm=0.01, clip=0, loss_scale=16384, train_wall=103, gb_free=9.6, wall=46788
2024-11-09 00:12:31 - progress_bar.py[line:274] - INFO: epoch 012:    197 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.189, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.12, wps=496, ups=0.1, wpb=5119.9, bsz=1280, num_updates=3640, lr=2.226e-05, gnorm=0.012, clip=0, loss_scale=16384, train_wall=103, gb_free=9.7, wall=46891
2024-11-09 00:14:15 - progress_bar.py[line:274] - INFO: epoch 012:    207 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.178, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.05, wps=493.5, ups=0.1, wpb=5119.8, bsz=1280, num_updates=3650, lr=2.2175e-05, gnorm=0.01, clip=0, loss_scale=16384, train_wall=104, gb_free=9.6, wall=46995
2024-11-09 00:15:58 - progress_bar.py[line:274] - INFO: epoch 012:    217 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.19, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.13, wps=496.1, ups=0.1, wpb=5120, bsz=1280, num_updates=3660, lr=2.20901e-05, gnorm=0.011, clip=0, loss_scale=16384, train_wall=103, gb_free=9.7, wall=47098
2024-11-09 00:17:42 - progress_bar.py[line:274] - INFO: epoch 012:    227 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.206, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.23, wps=492.6, ups=0.1, wpb=5119.8, bsz=1280, num_updates=3670, lr=2.20051e-05, gnorm=0.011, clip=0, loss_scale=16384, train_wall=104, gb_free=9.6, wall=47202
2024-11-09 00:19:25 - progress_bar.py[line:274] - INFO: epoch 012:    237 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.219, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.31, wps=494.2, ups=0.1, wpb=5120, bsz=1280, num_updates=3680, lr=2.19201e-05, gnorm=0.012, clip=0, loss_scale=16384, train_wall=104, gb_free=9.7, wall=47306
2024-11-09 00:21:08 - progress_bar.py[line:274] - INFO: epoch 012:    247 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.227, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.37, wps=496.4, ups=0.1, wpb=5119.8, bsz=1280, num_updates=3690, lr=2.18352e-05, gnorm=0.01, clip=0, loss_scale=16384, train_wall=103, gb_free=9.6, wall=47409
2024-11-09 00:22:52 - progress_bar.py[line:274] - INFO: epoch 012:    257 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.21, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.25, wps=494.2, ups=0.1, wpb=5120, bsz=1280, num_updates=3700, lr=2.17502e-05, gnorm=0.012, clip=0, loss_scale=16384, train_wall=104, gb_free=9.7, wall=47512
2024-11-09 00:24:35 - progress_bar.py[line:274] - INFO: epoch 012:    267 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.204, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.21, wps=495.9, ups=0.1, wpb=5120, bsz=1280, num_updates=3710, lr=2.16653e-05, gnorm=0.01, clip=0, loss_scale=16384, train_wall=103, gb_free=9.7, wall=47616
2024-11-09 00:26:19 - progress_bar.py[line:274] - INFO: epoch 012:    277 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.175, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.03, wps=493, ups=0.1, wpb=5120, bsz=1280, num_updates=3720, lr=2.15803e-05, gnorm=0.009, clip=0, loss_scale=16384, train_wall=104, gb_free=9.6, wall=47719
2024-11-09 00:28:03 - progress_bar.py[line:274] - INFO: epoch 012:    287 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.2, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.19, wps=491.3, ups=0.1, wpb=5119.9, bsz=1280, num_updates=3730, lr=2.14953e-05, gnorm=0.012, clip=0, loss_scale=16384, train_wall=104, gb_free=9.6, wall=47824
2024-11-09 00:29:47 - progress_bar.py[line:274] - INFO: epoch 012:    297 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.19, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.13, wps=495.9, ups=0.1, wpb=5120, bsz=1280, num_updates=3740, lr=2.14104e-05, gnorm=0.012, clip=0, loss_scale=16384, train_wall=103, gb_free=9.7, wall=47927
2024-11-09 00:31:29 - progress_bar.py[line:274] - INFO: epoch 012:    307 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.199, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.18, wps=497.9, ups=0.1, wpb=5119.9, bsz=1280, num_updates=3750, lr=2.13254e-05, gnorm=0.01, clip=0, loss_scale=16384, train_wall=103, gb_free=9.7, wall=48030
slice_id 6 seek offset 41730
slice_id 4 seek offset 27820slice_id 2 seek offset 13910

slice_id 1 seek offset 6955
slice_id 5 seek offset 34775slice_id 7 seek offset 486852024-11-09 00:32:24 - train.py[line:449] - INFO: begin validation on "valid" subset


slice_id 3 seek offset 20865
slice_id 0 seek offset 0
slice_id 3 seek offset 20865
slice_id 5 seek offset 34775
slice_id 7 seek offset 48685
slice_id 1 seek offset 6955
slice_id 2 seek offset 13910
slice_id 6 seek offset 41730
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-09 00:39:50 - progress_bar.py[line:282] - INFO: epoch 012 | valid on 'valid' subset | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.194 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.15 | score 0.6499 | wps 500.4 | wpb 639.5 | bsz 159.9 | num_updates 3756 | best_score 0.6499
2024-11-09 00:39:50 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 12 @ 3756 updates
2024-11-09 00:39:50 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 row count 50000 total row count 400000
slice_id 5 seek offset 250000
slice_id 2 seek offset 100000
slice_id 3 seek offset 150000
slice_id 7 seek offset 350000
slice_id 4 seek offset 200000
slice_id 1 seek offset 50000
slice_id 6 seek offset 300000
2024-11-09 00:40:51 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-11-09 00:42:04 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 12 @ 3756 updates, score 0.6499) (writing took 133.90554334095214 seconds)
2024-11-09 00:42:05 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 12 @ 3756 updates
2024-11-09 00:42:05 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-09 00:43:33 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-09 00:43:33 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 12 @ 3756 updates, score 0) (writing took 88.5688601199654 seconds)
2024-11-09 00:43:33 - train.py[line:336] - INFO: end of epoch 12 (average epoch stats below)
2024-11-09 00:43:33 - progress_bar.py[line:282] - INFO: epoch 012 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.178 | ntokens 5111.78 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.05 | wps 410.8 | ups 0.08 | wpb 5111.8 | bsz 1278 | num_updates 3756 | lr 2.12744e-05 | gnorm 0.011 | clip 0 | loss_scale 16384 | train_wall 2941 | gb_free 9.7 | wall 48754
2024-11-09 00:43:33 - trainer.py[line:639] - INFO: loading train data for epoch 13
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-09 00:43:36 - trainer.py[line:703] - INFO: begin training epoch 13
2024-11-09 00:43:36 - train.py[line:297] - INFO: Start iterating over samples
2024-11-09 00:44:19 - progress_bar.py[line:274] - INFO: epoch 013:      4 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.198, ntokens=4864, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=9.18, wps=63.2, ups=0.01, wpb=4864, bsz=1216, num_updates=3760, lr=2.12404e-05, gnorm=0.011, clip=0, loss_scale=16384, train_wall=68, gb_free=9.7, wall=48799
2024-11-09 00:45:59 - progress_bar.py[line:274] - INFO: epoch 013:     14 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.224, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.35, wps=510.7, ups=0.1, wpb=5119.9, bsz=1280, num_updates=3770, lr=2.11555e-05, gnorm=0.013, clip=0, loss_scale=16384, train_wall=35, gb_free=9.6, wall=48900
2024-11-09 00:47:40 - progress_bar.py[line:274] - INFO: epoch 013:     24 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.216, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.29, wps=510.6, ups=0.1, wpb=5120, bsz=1280, num_updates=3780, lr=2.10705e-05, gnorm=0.01, clip=0, loss_scale=16384, train_wall=35, gb_free=9.7, wall=49000
2024-11-09 00:49:22 - progress_bar.py[line:274] - INFO: epoch 013:     34 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.225, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.35, wps=500.8, ups=0.1, wpb=5120, bsz=1280, num_updates=3790, lr=2.09856e-05, gnorm=0.012, clip=0, loss_scale=16384, train_wall=35, gb_free=9.7, wall=49102
2024-11-09 00:51:05 - progress_bar.py[line:274] - INFO: epoch 013:     44 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.189, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.12, wps=497, ups=0.1, wpb=5120, bsz=1280, num_updates=3800, lr=2.09006e-05, gnorm=0.016, clip=0, loss_scale=16384, train_wall=45, gb_free=9.6, wall=49205
2024-11-09 00:52:48 - progress_bar.py[line:274] - INFO: epoch 013:     54 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.214, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.28, wps=496.3, ups=0.1, wpb=5120, bsz=1280, num_updates=3810, lr=2.08156e-05, gnorm=0.011, clip=0, loss_scale=16384, train_wall=81, gb_free=9.7, wall=49308
2024-11-09 00:54:32 - progress_bar.py[line:274] - INFO: epoch 013:     64 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.206, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.23, wps=493.3, ups=0.1, wpb=5120, bsz=1280, num_updates=3820, lr=2.07307e-05, gnorm=0.011, clip=0, loss_scale=16384, train_wall=103, gb_free=9.6, wall=49412
2024-11-09 00:56:15 - progress_bar.py[line:274] - INFO: epoch 013:     74 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.199, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.18, wps=494.7, ups=0.1, wpb=5120, bsz=1280, num_updates=3830, lr=2.06457e-05, gnorm=0.012, clip=0, loss_scale=16384, train_wall=103, gb_free=9.7, wall=49516
2024-11-09 00:57:58 - progress_bar.py[line:274] - INFO: epoch 013:     84 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.22, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.32, wps=496, ups=0.1, wpb=5120, bsz=1280, num_updates=3840, lr=2.05607e-05, gnorm=0.01, clip=0, loss_scale=16384, train_wall=103, gb_free=9.7, wall=49619
2024-11-09 00:59:42 - progress_bar.py[line:274] - INFO: epoch 013:     94 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.22, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.32, wps=495.8, ups=0.1, wpb=5120, bsz=1280, num_updates=3850, lr=2.04758e-05, gnorm=0.012, clip=0, loss_scale=16384, train_wall=103, gb_free=9.6, wall=49722
2024-11-09 01:01:25 - progress_bar.py[line:274] - INFO: epoch 013:    104 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.21, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.25, wps=495.2, ups=0.1, wpb=5119.9, bsz=1280, num_updates=3860, lr=2.03908e-05, gnorm=0.009, clip=0, loss_scale=16384, train_wall=103, gb_free=9.6, wall=49825
2024-11-09 01:03:09 - progress_bar.py[line:274] - INFO: epoch 013:    114 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.191, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.13, wps=493.6, ups=0.1, wpb=5120, bsz=1280, num_updates=3870, lr=2.03059e-05, gnorm=0.012, clip=0, loss_scale=16384, train_wall=104, gb_free=9.6, wall=49929
2024-11-09 01:04:52 - progress_bar.py[line:274] - INFO: epoch 013:    124 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.202, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.2, wps=495.2, ups=0.1, wpb=5120, bsz=1280, num_updates=3880, lr=2.02209e-05, gnorm=0.011, clip=0, loss_scale=16384, train_wall=103, gb_free=9.7, wall=50033
2024-11-09 01:06:35 - progress_bar.py[line:274] - INFO: epoch 013:    134 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.208, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.24, wps=496.5, ups=0.1, wpb=5120, bsz=1280, num_updates=3890, lr=2.01359e-05, gnorm=0.01, clip=0, loss_scale=16384, train_wall=103, gb_free=9.6, wall=50136
2024-11-09 01:08:19 - progress_bar.py[line:274] - INFO: epoch 013:    144 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.223, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.34, wps=492.7, ups=0.1, wpb=5119.9, bsz=1280, num_updates=3900, lr=2.0051e-05, gnorm=0.012, clip=0, loss_scale=16384, train_wall=104, gb_free=9.6, wall=50240
2024-11-09 01:09:42 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8192.0
2024-11-09 01:10:13 - progress_bar.py[line:274] - INFO: epoch 013:    155 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.209, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.25, wps=449.6, ups=0.09, wpb=5119.9, bsz=1280, num_updates=3910, lr=1.9966e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=114, gb_free=9.6, wall=50353
2024-11-09 01:11:57 - progress_bar.py[line:274] - INFO: epoch 013:    165 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.198, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.18, wps=495.4, ups=0.1, wpb=5120, bsz=1280, num_updates=3920, lr=1.98811e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=50457
2024-11-09 01:13:40 - progress_bar.py[line:274] - INFO: epoch 013:    175 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.193, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.15, wps=493.8, ups=0.1, wpb=5120, bsz=1280, num_updates=3930, lr=1.97961e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=50560
2024-11-09 01:15:24 - progress_bar.py[line:274] - INFO: epoch 013:    185 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.184, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.09, wps=495.2, ups=0.1, wpb=5120, bsz=1280, num_updates=3940, lr=1.97111e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=50664
2024-11-09 01:17:08 - progress_bar.py[line:274] - INFO: epoch 013:    195 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.191, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.13, wps=492.7, ups=0.1, wpb=5120, bsz=1280, num_updates=3950, lr=1.96262e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=104, gb_free=9.6, wall=50768
2024-11-09 01:18:51 - progress_bar.py[line:274] - INFO: epoch 013:    205 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.176, ntokens=5119.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.04, wps=497.1, ups=0.1, wpb=5119.7, bsz=1280, num_updates=3960, lr=1.95412e-05, gnorm=0.015, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=50871
2024-11-09 01:20:34 - progress_bar.py[line:274] - INFO: epoch 013:    215 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.191, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.13, wps=495.9, ups=0.1, wpb=5120, bsz=1280, num_updates=3970, lr=1.94562e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=50974
2024-11-09 01:22:18 - progress_bar.py[line:274] - INFO: epoch 013:    225 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.185, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.09, wps=493.2, ups=0.1, wpb=5119.9, bsz=1280, num_updates=3980, lr=1.93713e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=51078
2024-11-09 01:24:03 - progress_bar.py[line:274] - INFO: epoch 013:    235 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.199, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.18, wps=487.3, ups=0.1, wpb=5119.9, bsz=1280, num_updates=3990, lr=1.92863e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=105, gb_free=9.7, wall=51183
2024-11-09 01:25:46 - progress_bar.py[line:274] - INFO: epoch 013:    245 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.191, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.13, wps=496.7, ups=0.1, wpb=5119.8, bsz=1280, num_updates=4000, lr=1.92014e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=51286
slice_id 6 seek offset 41730
slice_id 5 seek offset 34775slice_id 4 seek offset 27820

2024-11-09 01:25:46 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 7 seek offset 48685
slice_id 2 seek offset 13910slice_id 0 seek offset 0

slice_id 3 seek offset 20865
slice_id 1 seek offset 6955
slice_id 5 seek offset 34775
slice_id 7 seek offset 48685
slice_id 3 seek offset 20865
slice_id 2 seek offset 13910
slice_id 6 seek offset 41730
slice_id 1 seek offset 6955
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-09 01:33:19 - progress_bar.py[line:282] - INFO: epoch 013 | valid on 'valid' subset | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.196 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.16 | score 0.6741 | wps 492.9 | wpb 639.5 | bsz 159.9 | num_updates 4000 | best_score 0.6741
2024-11-09 01:33:19 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 13 @ 4000 updates
2024-11-09 01:33:19 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_13_4000.pt
2024-11-09 01:33:30 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_13_4000.pt
2024-11-09 01:36:18 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_13_4000.pt (epoch 13 @ 4000 updates, score 0.6741) (writing took 179.11844543903135 seconds)
2024-11-09 01:37:49 - progress_bar.py[line:274] - INFO: epoch 013:    255 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.216, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.3, wps=70.8, ups=0.01, wpb=5120, bsz=1280, num_updates=4010, lr=1.91164e-05, gnorm=0.017, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=52009
2024-11-09 01:39:29 - progress_bar.py[line:274] - INFO: epoch 013:    265 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.173, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.02, wps=513.5, ups=0.1, wpb=5120, bsz=1280, num_updates=4020, lr=1.90314e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=52109
2024-11-09 01:41:12 - progress_bar.py[line:274] - INFO: epoch 013:    275 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.181, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.07, wps=497.4, ups=0.1, wpb=5120, bsz=1280, num_updates=4030, lr=1.89465e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=48, gb_free=9.7, wall=52212
2024-11-09 01:42:55 - progress_bar.py[line:274] - INFO: epoch 013:    285 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.203, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.21, wps=492.9, ups=0.1, wpb=5120, bsz=1280, num_updates=4040, lr=1.88615e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=88, gb_free=9.7, wall=52316
2024-11-09 01:44:39 - progress_bar.py[line:274] - INFO: epoch 013:    295 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.204, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.22, wps=493.9, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4050, lr=1.87766e-05, gnorm=0.015, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=52419
2024-11-09 01:46:22 - progress_bar.py[line:274] - INFO: epoch 013:    305 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.2, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.19, wps=497.3, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4060, lr=1.86916e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=52522
slice_id 6 seek offset 41730
slice_id 2 seek offset 13910slice_id 4 seek offset 27820slice_id 1 seek offset 6955


slice_id 7 seek offset 48685
2024-11-09 01:47:37 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 5 seek offset 34775
slice_id 0 seek offset 0slice_id 3 seek offset 20865

slice_id 3 seek offset 20865
slice_id 5 seek offset 34775
slice_id 7 seek offset 48685
slice_id 1 seek offset 6955
slice_id 2 seek offset 13910
slice_id 6 seek offset 41730
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-09 01:55:04 - progress_bar.py[line:282] - INFO: epoch 013 | valid on 'valid' subset | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.208 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.24 | score 0.6659 | wps 500.4 | wpb 639.5 | bsz 159.9 | num_updates 4068 | best_score 0.6741
2024-11-09 01:55:04 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 13 @ 4068 updates
2024-11-09 01:55:04 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 row count 50000 total row count 400000
slice_id 5 seek offset 250000
slice_id 2 seek offset 100000
slice_id 4 seek offset 200000
slice_id 3 seek offset 150000
slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
slice_id 6 seek offset 300000
2024-11-09 01:56:04 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-09 01:56:05 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 13 @ 4068 updates, score 0.6659) (writing took 60.84757033002097 seconds)
2024-11-09 01:56:05 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 13 @ 4068 updates
2024-11-09 01:56:05 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-09 01:57:05 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-09 01:57:05 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 13 @ 4068 updates, score 0) (writing took 60.650364095985424 seconds)
2024-11-09 01:57:05 - train.py[line:336] - INFO: end of epoch 13 (average epoch stats below)
2024-11-09 01:57:05 - progress_bar.py[line:282] - INFO: epoch 013 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.202 | ntokens 5111.75 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.2 | wps 361.5 | ups 0.07 | wpb 5111.8 | bsz 1277.9 | num_updates 4068 | lr 1.86236e-05 | gnorm 0.012 | clip 0 | loss_scale 8192 | train_wall 2706 | gb_free 9.7 | wall 53165
2024-11-09 01:57:05 - trainer.py[line:639] - INFO: loading train data for epoch 14
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-09 01:57:08 - trainer.py[line:703] - INFO: begin training epoch 14
2024-11-09 01:57:08 - train.py[line:297] - INFO: Start iterating over samples
2024-11-09 01:57:31 - progress_bar.py[line:274] - INFO: epoch 014:      2 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.218, ntokens=4864, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=9.3, wps=72.7, ups=0.01, wpb=4864, bsz=1216, num_updates=4070, lr=1.86066e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=82, gb_free=9.6, wall=53191
2024-11-09 01:59:11 - progress_bar.py[line:274] - INFO: epoch 014:     12 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.209, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.25, wps=512, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4080, lr=1.85217e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=53291
2024-11-09 02:00:52 - progress_bar.py[line:274] - INFO: epoch 014:     22 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.208, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.24, wps=508.3, ups=0.1, wpb=5120, bsz=1280, num_updates=4090, lr=1.84367e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=53392
2024-11-09 02:02:32 - progress_bar.py[line:274] - INFO: epoch 014:     32 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.201, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.2, wps=511.1, ups=0.1, wpb=5120, bsz=1280, num_updates=4100, lr=1.83517e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=53492
2024-11-09 02:04:12 - progress_bar.py[line:274] - INFO: epoch 014:     42 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.205, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.22, wps=508.7, ups=0.1, wpb=5120, bsz=1280, num_updates=4110, lr=1.82668e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=36, gb_free=9.7, wall=53593
2024-11-09 02:05:55 - progress_bar.py[line:274] - INFO: epoch 014:     52 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.221, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.32, wps=498.2, ups=0.1, wpb=5120, bsz=1280, num_updates=4120, lr=1.81818e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=55, gb_free=9.6, wall=53695
2024-11-09 02:07:40 - progress_bar.py[line:274] - INFO: epoch 014:     62 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.205, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.22, wps=488.4, ups=0.1, wpb=5120, bsz=1280, num_updates=4130, lr=1.80969e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=90, gb_free=9.5, wall=53800
2024-11-09 02:09:25 - progress_bar.py[line:274] - INFO: epoch 014:     72 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.185, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.09, wps=488.5, ups=0.1, wpb=5120, bsz=1280, num_updates=4140, lr=1.80119e-05, gnorm=0.016, clip=0, loss_scale=8192, train_wall=105, gb_free=9.7, wall=53905
2024-11-09 02:11:09 - progress_bar.py[line:274] - INFO: epoch 014:     82 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.192, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.14, wps=493.9, ups=0.1, wpb=5120, bsz=1280, num_updates=4150, lr=1.79269e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=104, gb_free=9.6, wall=54009
2024-11-09 02:12:53 - progress_bar.py[line:274] - INFO: epoch 014:     92 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.226, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.35, wps=491.1, ups=0.1, wpb=5120, bsz=1280, num_updates=4160, lr=1.7842e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=54113
2024-11-09 02:14:36 - progress_bar.py[line:274] - INFO: epoch 014:    102 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.196, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.16, wps=494.3, ups=0.1, wpb=5120, bsz=1280, num_updates=4170, lr=1.7757e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=54217
2024-11-09 02:16:19 - progress_bar.py[line:274] - INFO: epoch 014:    112 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.194, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.15, wps=496.9, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4180, lr=1.7672e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=54320
2024-11-09 02:18:02 - progress_bar.py[line:274] - INFO: epoch 014:    122 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.172, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.01, wps=498.4, ups=0.1, wpb=5120, bsz=1280, num_updates=4190, lr=1.75871e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=54422
2024-11-09 02:19:45 - progress_bar.py[line:274] - INFO: epoch 014:    132 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.167, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=8.98, wps=497.4, ups=0.1, wpb=5120, bsz=1280, num_updates=4200, lr=1.75021e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=54525
2024-11-09 02:21:28 - progress_bar.py[line:274] - INFO: epoch 014:    142 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.175, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.03, wps=496.9, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4210, lr=1.74172e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=54628
2024-11-09 02:23:11 - progress_bar.py[line:274] - INFO: epoch 014:    152 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.211, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.26, wps=498.4, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4220, lr=1.73322e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=54731
2024-11-09 02:24:53 - progress_bar.py[line:274] - INFO: epoch 014:    162 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.202, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.2, wps=499.2, ups=0.1, wpb=5120, bsz=1280, num_updates=4230, lr=1.72472e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=102, gb_free=9.6, wall=54834
2024-11-09 02:26:36 - progress_bar.py[line:274] - INFO: epoch 014:    172 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.199, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.18, wps=499.3, ups=0.1, wpb=5120, bsz=1280, num_updates=4240, lr=1.71623e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=102, gb_free=9.7, wall=54936
2024-11-09 02:28:20 - progress_bar.py[line:274] - INFO: epoch 014:    182 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.209, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.25, wps=492.8, ups=0.1, wpb=5120, bsz=1280, num_updates=4250, lr=1.70773e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=104, gb_free=9.6, wall=55040
2024-11-09 02:30:03 - progress_bar.py[line:274] - INFO: epoch 014:    192 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.19, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.12, wps=494.1, ups=0.1, wpb=5120, bsz=1280, num_updates=4260, lr=1.69924e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=55144
2024-11-09 02:31:46 - progress_bar.py[line:274] - INFO: epoch 014:    202 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.194, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.15, wps=497.7, ups=0.1, wpb=5119.8, bsz=1280, num_updates=4270, lr=1.69074e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=55247
2024-11-09 02:33:30 - progress_bar.py[line:274] - INFO: epoch 014:    212 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.199, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.18, wps=494, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4280, lr=1.68224e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=55350
2024-11-09 02:35:14 - progress_bar.py[line:274] - INFO: epoch 014:    222 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.211, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.26, wps=494, ups=0.1, wpb=5120, bsz=1280, num_updates=4290, lr=1.67375e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=55454
2024-11-09 02:36:57 - progress_bar.py[line:274] - INFO: epoch 014:    232 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.208, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.24, wps=494.2, ups=0.1, wpb=5119.8, bsz=1280, num_updates=4300, lr=1.66525e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=55557
2024-11-09 02:38:40 - progress_bar.py[line:274] - INFO: epoch 014:    242 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.211, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.26, wps=499.1, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4310, lr=1.65675e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=102, gb_free=9.6, wall=55660
2024-11-09 02:40:23 - progress_bar.py[line:274] - INFO: epoch 014:    252 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.225, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.35, wps=497.1, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4320, lr=1.64826e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=55763
2024-11-09 02:42:06 - progress_bar.py[line:274] - INFO: epoch 014:    262 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.201, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.2, wps=493.7, ups=0.1, wpb=5120, bsz=1280, num_updates=4330, lr=1.63976e-05, gnorm=0.014, clip=0, loss_scale=8192, train_wall=104, gb_free=9.6, wall=55867
2024-11-09 02:43:50 - progress_bar.py[line:274] - INFO: epoch 014:    272 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.213, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.27, wps=494.9, ups=0.1, wpb=5120, bsz=1280, num_updates=4340, lr=1.63127e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=55970
2024-11-09 02:45:32 - progress_bar.py[line:274] - INFO: epoch 014:    282 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.218, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.31, wps=499.5, ups=0.1, wpb=5120, bsz=1280, num_updates=4350, lr=1.62277e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=102, gb_free=9.6, wall=56073
2024-11-09 02:47:16 - progress_bar.py[line:274] - INFO: epoch 014:    292 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.215, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.28, wps=494.5, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4360, lr=1.61427e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=56176
2024-11-09 02:48:59 - progress_bar.py[line:274] - INFO: epoch 014:    302 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.191, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.13, wps=496.2, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4370, lr=1.60578e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=56279
2024-11-09 02:50:42 - progress_bar.py[line:274] - INFO: epoch 014:    312 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.209, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.24, wps=496.1, ups=0.1, wpb=5120, bsz=1280, num_updates=4380, lr=1.59728e-05, gnorm=0.014, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=56383
slice_id 2 seek offset 13910slice_id 1 seek offset 6955slice_id 7 seek offset 48685slice_id 5 seek offset 34775



2024-11-09 02:50:46 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 4 seek offset 27820
slice_id 3 seek offset 20865
slice_id 6 seek offset 41730
slice_id 5 seek offset 34775
slice_id 7 seek offset 48685
slice_id 3 seek offset 20865
slice_id 2 seek offset 13910
slice_id 1 seek offset 6955
slice_id 6 seek offset 41730
slice_id 0 seek offset 0
slice_id 4 seek offset 27820
2024-11-09 02:58:11 - progress_bar.py[line:282] - INFO: epoch 014 | valid on 'valid' subset | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.213 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.27 | score 0.7002 | wps 501.2 | wpb 639.5 | bsz 159.9 | num_updates 4381 | best_score 0.7002
2024-11-09 02:58:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 14 @ 4381 updates
2024-11-09 02:58:11 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 row count 50000 total row count 400000
slice_id 2 seek offset 100000
slice_id 3 seek offset 150000
slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
slice_id 5 seek offset 250000
slice_id 6 seek offset 300000
slice_id 4 seek offset 200000
2024-11-09 02:59:12 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-11-09 03:00:26 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 14 @ 4381 updates, score 0.7002) (writing took 134.28877332701813 seconds)
2024-11-09 03:00:26 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 14 @ 4381 updates
2024-11-09 03:00:26 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-09 03:01:55 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-09 03:01:55 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 14 @ 4381 updates, score 0) (writing took 88.30224499001633 seconds)
2024-11-09 03:01:55 - train.py[line:336] - INFO: end of epoch 14 (average epoch stats below)
2024-11-09 03:01:55 - progress_bar.py[line:282] - INFO: epoch 014 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.202 | ntokens 5111.78 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.2 | wps 411.4 | ups 0.08 | wpb 5111.8 | bsz 1278 | num_updates 4381 | lr 1.59643e-05 | gnorm 0.011 | clip 0 | loss_scale 8192 | train_wall 2876 | gb_free 9.7 | wall 57055
2024-11-09 03:01:55 - trainer.py[line:639] - INFO: loading train data for epoch 15
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-09 03:01:57 - trainer.py[line:703] - INFO: begin training epoch 15
2024-11-09 03:01:57 - train.py[line:297] - INFO: Start iterating over samples
2024-11-09 03:03:30 - progress_bar.py[line:274] - INFO: epoch 015:      9 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.207, ntokens=4863.9, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=9.24, wps=63.4, ups=0.01, wpb=4863.9, bsz=1216, num_updates=4390, lr=1.58879e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=57150
2024-11-09 03:05:09 - progress_bar.py[line:274] - INFO: epoch 015:     19 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.211, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.26, wps=513, ups=0.1, wpb=5120, bsz=1280, num_updates=4400, lr=1.58029e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=35, gb_free=9.6, wall=57250
2024-11-09 03:06:50 - progress_bar.py[line:274] - INFO: epoch 015:     29 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.193, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.15, wps=510.6, ups=0.1, wpb=5120, bsz=1280, num_updates=4410, lr=1.57179e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=57350
2024-11-09 03:08:32 - progress_bar.py[line:274] - INFO: epoch 015:     39 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.208, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.24, wps=499.8, ups=0.1, wpb=5120, bsz=1280, num_updates=4420, lr=1.5633e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=45, gb_free=9.7, wall=57452
2024-11-09 03:10:15 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8192.0
2024-11-09 03:10:25 - progress_bar.py[line:274] - INFO: epoch 015:     50 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.203, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.21, wps=452.7, ups=0.09, wpb=5120, bsz=1280, num_updates=4430, lr=1.5548e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=79, gb_free=9.7, wall=57566
2024-11-09 03:12:08 - progress_bar.py[line:274] - INFO: epoch 015:     60 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.21, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.25, wps=497.1, ups=0.1, wpb=5120, bsz=1280, num_updates=4440, lr=1.5463e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=98, gb_free=9.6, wall=57669
2024-11-09 03:13:52 - progress_bar.py[line:274] - INFO: epoch 015:     70 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.208, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.24, wps=495.9, ups=0.1, wpb=5120, bsz=1280, num_updates=4450, lr=1.53781e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=57772
2024-11-09 03:15:35 - progress_bar.py[line:274] - INFO: epoch 015:     80 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.193, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.14, wps=494.3, ups=0.1, wpb=5120, bsz=1280, num_updates=4460, lr=1.52931e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=57875
2024-11-09 03:17:18 - progress_bar.py[line:274] - INFO: epoch 015:     90 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.208, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.24, wps=495.6, ups=0.1, wpb=5120, bsz=1280, num_updates=4470, lr=1.52082e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=57979
2024-11-09 03:19:02 - progress_bar.py[line:274] - INFO: epoch 015:    100 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.208, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.24, wps=494.4, ups=0.1, wpb=5120, bsz=1280, num_updates=4480, lr=1.51232e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=58082
2024-11-09 03:20:45 - progress_bar.py[line:274] - INFO: epoch 015:    110 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.196, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.17, wps=496.7, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4490, lr=1.50382e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=58185
2024-11-09 03:22:28 - progress_bar.py[line:274] - INFO: epoch 015:    120 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.22, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.32, wps=497.3, ups=0.1, wpb=5120, bsz=1280, num_updates=4500, lr=1.49533e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=58288
2024-11-09 03:24:11 - progress_bar.py[line:274] - INFO: epoch 015:    130 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.207, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.23, wps=495.2, ups=0.1, wpb=5120, bsz=1280, num_updates=4510, lr=1.48683e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=58392
2024-11-09 03:25:54 - progress_bar.py[line:274] - INFO: epoch 015:    140 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.212, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.27, wps=496.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4520, lr=1.47833e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=58495
2024-11-09 03:27:38 - progress_bar.py[line:274] - INFO: epoch 015:    150 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.224, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.35, wps=495.4, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4530, lr=1.46984e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=58598
2024-11-09 03:29:21 - progress_bar.py[line:274] - INFO: epoch 015:    160 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.236, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.42, wps=498.2, ups=0.1, wpb=5120, bsz=1280, num_updates=4540, lr=1.46134e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=58701
2024-11-09 03:31:04 - progress_bar.py[line:274] - INFO: epoch 015:    170 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.239, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.44, wps=494.9, ups=0.1, wpb=5120, bsz=1280, num_updates=4550, lr=1.45285e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=58804
2024-11-09 03:32:48 - progress_bar.py[line:274] - INFO: epoch 015:    180 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.249, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.51, wps=494.1, ups=0.1, wpb=5120, bsz=1280, num_updates=4560, lr=1.44435e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=58908
2024-11-09 03:34:31 - progress_bar.py[line:274] - INFO: epoch 015:    190 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.242, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.46, wps=493.4, ups=0.1, wpb=5120, bsz=1280, num_updates=4570, lr=1.43585e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=59012
2024-11-09 03:36:15 - progress_bar.py[line:274] - INFO: epoch 015:    200 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.238, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.43, wps=494, ups=0.1, wpb=5119.8, bsz=1280, num_updates=4580, lr=1.42736e-05, gnorm=0.014, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=59115
2024-11-09 03:37:58 - progress_bar.py[line:274] - INFO: epoch 015:    210 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.24, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.45, wps=496.7, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4590, lr=1.41886e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=59218
2024-11-09 03:39:42 - progress_bar.py[line:274] - INFO: epoch 015:    220 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.251, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.52, wps=493.1, ups=0.1, wpb=5120, bsz=1280, num_updates=4600, lr=1.41037e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=59322
2024-11-09 03:41:25 - progress_bar.py[line:274] - INFO: epoch 015:    230 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.258, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.57, wps=495, ups=0.1, wpb=5119.8, bsz=1280, num_updates=4610, lr=1.40187e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=59426
2024-11-09 03:43:08 - progress_bar.py[line:274] - INFO: epoch 015:    240 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.243, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.47, wps=497.6, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4620, lr=1.39337e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=59529
2024-11-09 03:44:52 - progress_bar.py[line:274] - INFO: epoch 015:    250 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.224, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.34, wps=495.1, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4630, lr=1.38488e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=59632
2024-11-09 03:46:35 - progress_bar.py[line:274] - INFO: epoch 015:    260 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.227, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.36, wps=497.3, ups=0.1, wpb=5120, bsz=1280, num_updates=4640, lr=1.37638e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=59735
2024-11-09 03:48:18 - progress_bar.py[line:274] - INFO: epoch 015:    270 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.212, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.27, wps=496, ups=0.1, wpb=5120, bsz=1280, num_updates=4650, lr=1.36788e-05, gnorm=0.015, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=59838
2024-11-09 03:50:01 - progress_bar.py[line:274] - INFO: epoch 015:    280 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.234, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.41, wps=495.3, ups=0.1, wpb=5120, bsz=1280, num_updates=4660, lr=1.35939e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=59941
2024-11-09 03:51:44 - progress_bar.py[line:274] - INFO: epoch 015:    290 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.213, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.27, wps=497.7, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4670, lr=1.35089e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=60044
2024-11-09 03:53:27 - progress_bar.py[line:274] - INFO: epoch 015:    300 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.212, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.26, wps=497.4, ups=0.1, wpb=5120, bsz=1280, num_updates=4680, lr=1.3424e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=60147
2024-11-09 03:55:11 - progress_bar.py[line:274] - INFO: epoch 015:    310 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.213, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.27, wps=494.9, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4690, lr=1.3339e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=60251
slice_id 3 seek offset 20865slice_id 1 seek offset 6955
slice_id 2 seek offset 13910
2024-11-09 03:55:34 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 7 seek offset 48685
slice_id 5 seek offset 34775

slice_id 0 seek offset 0
slice_id 6 seek offset 41730
slice_id 4 seek offset 27820
slice_id 3 seek offset 20865
slice_id 7 seek offset 48685
slice_id 5 seek offset 34775
slice_id 1 seek offset 6955
slice_id 2 seek offset 13910
slice_id 6 seek offset 41730
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-09 04:03:00 - progress_bar.py[line:282] - INFO: epoch 015 | valid on 'valid' subset | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.211 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.26 | score 0.7209 | wps 501.3 | wpb 639.5 | bsz 159.9 | num_updates 4693 | best_score 0.7209
2024-11-09 04:03:00 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 15 @ 4693 updates
2024-11-09 04:03:00 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 row count 50000 total row count 400000
slice_id 5 seek offset 250000
slice_id 2 seek offset 100000
slice_id 3 seek offset 150000
slice_id 1 seek offset 50000
slice_id 4 seek offset 200000
slice_id 6 seek offset 300000
slice_id 7 seek offset 350000
2024-11-09 04:04:01 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-11-09 04:05:13 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 15 @ 4693 updates, score 0.7209) (writing took 133.64674755599117 seconds)
2024-11-09 04:05:14 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 15 @ 4693 updates
2024-11-09 04:05:14 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-09 04:06:43 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-09 04:06:43 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 15 @ 4693 updates, score 0) (writing took 88.778011566028 seconds)
2024-11-09 04:06:43 - train.py[line:336] - INFO: end of epoch 15 (average epoch stats below)
2024-11-09 04:06:43 - progress_bar.py[line:282] - INFO: epoch 015 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.221 | ntokens 5111.75 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.32 | wps 410.2 | ups 0.08 | wpb 5111.8 | bsz 1277.9 | num_updates 4693 | lr 1.33135e-05 | gnorm 0.011 | clip 0 | loss_scale 8192 | train_wall 2926 | gb_free 9.7 | wall 60943
2024-11-09 04:06:43 - trainer.py[line:639] - INFO: loading train data for epoch 16
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-09 04:06:45 - trainer.py[line:703] - INFO: begin training epoch 16
2024-11-09 04:06:45 - train.py[line:297] - INFO: Start iterating over samples
2024-11-09 04:07:58 - progress_bar.py[line:274] - INFO: epoch 016:      7 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.205, ntokens=4863.9, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=9.22, wps=63.3, ups=0.01, wpb=4863.9, bsz=1216, num_updates=4700, lr=1.3254e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=48, gb_free=9.6, wall=61019
2024-11-09 04:09:39 - progress_bar.py[line:274] - INFO: epoch 016:     17 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.218, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.31, wps=509.6, ups=0.1, wpb=5120, bsz=1280, num_updates=4710, lr=1.31691e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=61119
2024-11-09 04:11:19 - progress_bar.py[line:274] - INFO: epoch 016:     27 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.196, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.16, wps=509.5, ups=0.1, wpb=5120, bsz=1280, num_updates=4720, lr=1.30841e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=61220
2024-11-09 04:13:00 - progress_bar.py[line:274] - INFO: epoch 016:     37 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.198, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.17, wps=507.9, ups=0.1, wpb=5120, bsz=1280, num_updates=4730, lr=1.29992e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=61320
2024-11-09 04:14:43 - progress_bar.py[line:274] - INFO: epoch 016:     47 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.191, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.13, wps=497.1, ups=0.1, wpb=5120, bsz=1280, num_updates=4740, lr=1.29142e-05, gnorm=0.014, clip=0, loss_scale=8192, train_wall=49, gb_free=9.6, wall=61423
2024-11-09 04:16:26 - progress_bar.py[line:274] - INFO: epoch 016:     57 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.199, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.18, wps=496.8, ups=0.1, wpb=5120, bsz=1280, num_updates=4750, lr=1.28292e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=79, gb_free=9.6, wall=61526
2024-11-09 04:18:10 - progress_bar.py[line:274] - INFO: epoch 016:     67 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.217, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.3, wps=491.4, ups=0.1, wpb=5120, bsz=1280, num_updates=4760, lr=1.27443e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=61631
2024-11-09 04:19:54 - progress_bar.py[line:274] - INFO: epoch 016:     77 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.19, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.12, wps=496.3, ups=0.1, wpb=5120, bsz=1280, num_updates=4770, lr=1.26593e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=61734
2024-11-09 04:21:37 - progress_bar.py[line:274] - INFO: epoch 016:     87 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.203, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.21, wps=494.9, ups=0.1, wpb=5120, bsz=1280, num_updates=4780, lr=1.25743e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=61837
2024-11-09 04:23:20 - progress_bar.py[line:274] - INFO: epoch 016:     97 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.201, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.2, wps=495.6, ups=0.1, wpb=5120, bsz=1280, num_updates=4790, lr=1.24894e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=61941
2024-11-09 04:25:03 - progress_bar.py[line:274] - INFO: epoch 016:    107 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.189, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.12, wps=496.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4800, lr=1.24044e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=62044
2024-11-09 04:26:46 - progress_bar.py[line:274] - INFO: epoch 016:    117 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.177, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.04, wps=497.4, ups=0.1, wpb=5120, bsz=1280, num_updates=4810, lr=1.23195e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=62147
2024-11-09 04:28:30 - progress_bar.py[line:274] - INFO: epoch 016:    127 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.199, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.18, wps=495.4, ups=0.1, wpb=5120, bsz=1280, num_updates=4820, lr=1.22345e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=62250
2024-11-09 04:30:14 - progress_bar.py[line:274] - INFO: epoch 016:    137 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.194, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.15, wps=492.7, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4830, lr=1.21495e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=104, gb_free=9.6, wall=62354
2024-11-09 04:31:57 - progress_bar.py[line:274] - INFO: epoch 016:    147 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.204, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.21, wps=494.2, ups=0.1, wpb=5120, bsz=1280, num_updates=4840, lr=1.20646e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=62457
2024-11-09 04:33:41 - progress_bar.py[line:274] - INFO: epoch 016:    157 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.197, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.17, wps=494.9, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4850, lr=1.19796e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=62561
2024-11-09 04:35:24 - progress_bar.py[line:274] - INFO: epoch 016:    167 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.211, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.26, wps=495.6, ups=0.1, wpb=5120, bsz=1280, num_updates=4860, lr=1.18946e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=62664
2024-11-09 04:37:07 - progress_bar.py[line:274] - INFO: epoch 016:    177 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.194, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.15, wps=496.1, ups=0.1, wpb=5120, bsz=1280, num_updates=4870, lr=1.18097e-05, gnorm=0.014, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=62767
2024-11-09 04:38:50 - progress_bar.py[line:274] - INFO: epoch 016:    187 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.201, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.19, wps=496.4, ups=0.1, wpb=5120, bsz=1280, num_updates=4880, lr=1.17247e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=62871
2024-11-09 04:40:34 - progress_bar.py[line:274] - INFO: epoch 016:    197 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.228, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.37, wps=494.3, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4890, lr=1.16398e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=62974
2024-11-09 04:42:18 - progress_bar.py[line:274] - INFO: epoch 016:    207 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.222, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.33, wps=492.9, ups=0.1, wpb=5119.8, bsz=1280, num_updates=4900, lr=1.15548e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=104, gb_free=9.6, wall=63078
2024-11-09 04:44:01 - progress_bar.py[line:274] - INFO: epoch 016:    217 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.231, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.39, wps=497, ups=0.1, wpb=5120, bsz=1280, num_updates=4910, lr=1.14698e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=63181
2024-11-09 04:45:44 - progress_bar.py[line:274] - INFO: epoch 016:    227 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.24, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.45, wps=493.7, ups=0.1, wpb=5119.8, bsz=1280, num_updates=4920, lr=1.13849e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=104, gb_free=9.6, wall=63285
2024-11-09 04:47:29 - progress_bar.py[line:274] - INFO: epoch 016:    237 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.224, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.34, wps=491.4, ups=0.1, wpb=5120, bsz=1280, num_updates=4930, lr=1.12999e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=63389
2024-11-09 04:49:11 - progress_bar.py[line:274] - INFO: epoch 016:    247 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.221, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.32, wps=498.5, ups=0.1, wpb=5119.8, bsz=1280, num_updates=4940, lr=1.1215e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=63492
2024-11-09 04:50:55 - progress_bar.py[line:274] - INFO: epoch 016:    257 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.23, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.38, wps=492.3, ups=0.1, wpb=5120, bsz=1280, num_updates=4950, lr=1.113e-05, gnorm=0.01, clip=0, loss_scale=16384, train_wall=104, gb_free=9.7, wall=63596
2024-11-09 04:52:39 - progress_bar.py[line:274] - INFO: epoch 016:    267 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.226, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.36, wps=494.8, ups=0.1, wpb=5120, bsz=1280, num_updates=4960, lr=1.1045e-05, gnorm=0.01, clip=0, loss_scale=16384, train_wall=103, gb_free=9.7, wall=63699
2024-11-09 04:54:22 - progress_bar.py[line:274] - INFO: epoch 016:    277 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.213, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.27, wps=494, ups=0.1, wpb=5120, bsz=1280, num_updates=4970, lr=1.09601e-05, gnorm=0.013, clip=0, loss_scale=16384, train_wall=104, gb_free=9.6, wall=63803
2024-11-09 04:56:06 - progress_bar.py[line:274] - INFO: epoch 016:    287 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.224, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.34, wps=494.2, ups=0.1, wpb=5119.9, bsz=1280, num_updates=4980, lr=1.08751e-05, gnorm=0.018, clip=0, loss_scale=16384, train_wall=104, gb_free=9.6, wall=63906
2024-11-09 04:57:50 - progress_bar.py[line:274] - INFO: epoch 016:    297 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.208, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.24, wps=493.4, ups=0.1, wpb=5120, bsz=1280, num_updates=4990, lr=1.07901e-05, gnorm=0.011, clip=0, loss_scale=16384, train_wall=104, gb_free=9.7, wall=64010
2024-11-09 04:59:33 - progress_bar.py[line:274] - INFO: epoch 016:    307 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.209, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.25, wps=495.9, ups=0.1, wpb=5119.9, bsz=1280, num_updates=5000, lr=1.07052e-05, gnorm=0.013, clip=0, loss_scale=16384, train_wall=103, gb_free=9.7, wall=64113
slice_id 2 seek offset 13910slice_id 5 seek offset 34775slice_id 4 seek offset 27820


slice_id 6 seek offset 41730
2024-11-09 04:59:33 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 7 seek offset 48685
slice_id 3 seek offset 20865
slice_id 1 seek offset 6955
slice_id 7 seek offset 48685
slice_id 5 seek offset 34775
slice_id 3 seek offset 20865
slice_id 2 seek offset 13910
slice_id 6 seek offset 41730
slice_id 1 seek offset 6955
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-09 05:07:04 - progress_bar.py[line:282] - INFO: epoch 016 | valid on 'valid' subset | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.212 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.27 | score 0.7383 | wps 494.9 | wpb 639.5 | bsz 159.9 | num_updates 5000 | best_score 0.7383
2024-11-09 05:07:04 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 16 @ 5000 updates
2024-11-09 05:07:04 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_16_5000.pt
2024-11-09 05:07:15 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_16_5000.pt
2024-11-09 05:10:00 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_16_5000.pt (epoch 16 @ 5000 updates, score 0.7383) (writing took 175.41072346502915 seconds)
2024-11-09 05:10:04 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8192.0
slice_id 5 seek offset 34775
slice_id 2 seek offset 13910
slice_id 6 seek offset 41730
slice_id 4 seek offset 27820
slice_id 7 seek offset 486852024-11-09 05:10:04 - train.py[line:449] - INFO: begin validation on "valid" subset

slice_id 3 seek offset 20865
slice_id 0 seek offset 0
slice_id 1 seek offset 6955
slice_id 3 seek offset 20865
slice_id 5 seek offset 34775
slice_id 2 seek offset 13910
slice_id 1 seek offset 6955
slice_id 6 seek offset 41730
slice_id 7 seek offset 48685
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-09 05:17:37 - progress_bar.py[line:282] - INFO: epoch 016 | valid on 'valid' subset | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.212 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.27 | score 0.7383 | wps 493.4 | wpb 639.5 | bsz 159.9 | num_updates 5000 | best_score 0.7383
2024-11-09 05:17:37 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 16 @ 5000 updates
2024-11-09 05:17:37 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_16_5000.pt
2024-11-09 05:18:37 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_16_5000.pt
2024-11-09 05:21:25 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_16_5000.pt (epoch 16 @ 5000 updates, score 0.7383) (writing took 227.7261032339884 seconds)
loss_reg: 0.0095672607421875 loss_cls: 0.0
loss_reg: 0.00977325439453125 loss_cls: 0.0
loss_reg: 0.007686614990234375 loss_cls: 0.0
loss_reg: 0.00923919677734375 loss_cls: 0.0
loss_reg: 0.01352691650390625 loss_cls: 0.0
loss_reg: 0.0168304443359375 loss_cls: 0.0
loss_reg: 0.0111236572265625 loss_cls: 0.0
loss_reg: 0.021575927734375 loss_cls: 0.0
loss_reg: 0.015411376953125 loss_cls: 0.0
loss_reg: 0.0111846923828125 loss_cls: 0.0
loss_reg: 0.019012451171875 loss_cls: 0.0
loss_reg: 0.01512908935546875 loss_cls: 0.0
loss_reg: 0.00970458984375 loss_cls: 0.0
loss_reg: 0.0094146728515625 loss_cls: 0.0
loss_reg: 0.0131378173828125 loss_cls: 0.0
loss_reg: 0.01416015625 loss_cls: 0.0
loss_reg: 0.008270263671875 loss_cls: 0.0
loss_reg: 0.0148162841796875 loss_cls: 0.0
loss_reg: 0.03924560546875 loss_cls: 0.0
loss_reg: 0.021636962890625 loss_cls: 0.0
loss_reg: 0.024017333984375 loss_cls: 0.0
loss_reg: 0.0224151611328125 loss_cls: 0.0
loss_reg: 0.0090179443359375 loss_cls: 0.0
loss_reg: 0.0183258056640625 loss_cls: 0.0
loss_reg: 0.013336181640625 loss_cls: 0.0
loss_reg: 0.0103912353515625 loss_cls: 0.0
loss_reg: 0.0118865966796875 loss_cls: 0.0
loss_reg: 0.0280303955078125 loss_cls: 0.0
loss_reg: 0.017974853515625 loss_cls: 0.0
loss_reg: 0.016204833984375 loss_cls: 0.0
loss_reg: 0.0159912109375 loss_cls: 0.0
loss_reg: 0.01137542724609375 loss_cls: 0.0
loss_reg: 0.0185699462890625 loss_cls: 0.0
loss_reg: 0.01226043701171875 loss_cls: 0.0
loss_reg: 0.00937652587890625 loss_cls: 0.0
loss_reg: 0.01044464111328125 loss_cls: 0.0
loss_reg: 0.0164642333984375 loss_cls: 0.0
loss_reg: 0.0196533203125 loss_cls: 0.0
loss_reg: 0.0256805419921875 loss_cls: 0.0
loss_reg: 0.0188751220703125 loss_cls: 0.0
loss_reg: 0.0198516845703125 loss_cls: 0.0
loss_reg: 0.01473236083984375 loss_cls: 0.0
loss_reg: 0.0384521484375 loss_cls: 0.0
loss_reg: 0.0183563232421875 loss_cls: 0.0
loss_reg: 0.015625 loss_cls: 0.0
loss_reg: 0.0146026611328125 loss_cls: 0.0
loss_reg: 0.01235198974609375 loss_cls: 0.0
loss_reg: 0.01200103759765625 loss_cls: 0.0
loss_reg: 0.008087158203125 loss_cls: 0.0
loss_reg: 0.01380157470703125 loss_cls: 0.0
loss_reg: 0.013641357421875 loss_cls: 0.0
loss_reg: 0.00798797607421875 loss_cls: 0.0
loss_reg: 0.0256195068359375 loss_cls: 0.0
loss_reg: 0.02740478515625 loss_cls: 0.0
loss_reg: 0.014984130859375 loss_cls: 0.0
loss_reg: 0.00798797607421875 loss_cls: 0.0
loss_reg: 0.0110931396484375 loss_cls: 0.0
loss_reg: 0.0174560546875 loss_cls: 0.0
loss_reg: 0.0086517333984375 loss_cls: 0.0
loss_reg: 0.0088653564453125 loss_cls: 0.0
loss_reg: 0.0211944580078125 loss_cls: 0.0
loss_reg: 0.0228729248046875 loss_cls: 0.0
loss_reg: 0.0243377685546875 loss_cls: 0.0
loss_reg: 0.01001739501953125 loss_cls: 0.0
slice_id 2 seek offset 13910slice_id 4 seek offset 27820
slice_id 1 seek offset 6955
2024-11-09 05:21:57 - train.py[line:449] - INFO: begin validation on "valid" subset

slice_id 7 seek offset 48685slice_id 5 seek offset 34775
slice_id 6 seek offset 41730
slice_id 0 seek offset 0slice_id 3 seek offset 20865


slice_id 3 seek offset 20865
slice_id 7 seek offset 48685
slice_id 5 seek offset 34775
slice_id 2 seek offset 13910
slice_id 6 seek offset 41730
slice_id 1 seek offset 6955
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-09 05:29:20 - progress_bar.py[line:282] - INFO: epoch 016 | valid on 'valid' subset | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.213 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.28 | score 0.7344 | wps 504.2 | wpb 639.5 | bsz 159.9 | num_updates 5005 | best_score 0.7383
2024-11-09 05:29:20 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 16 @ 5005 updates
2024-11-09 05:29:20 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 row count 50000 total row count 400000file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 row count 50000 total row count 400000

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 row count 50000 total row count 400000file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 row count 50000 total row count 400000

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 row count 50000 total row count 400000
slice_id 2 seek offset 100000
slice_id 6 seek offset 300000
slice_id 7 seek offset 350000
slice_id 5 seek offset 250000
slice_id 3 seek offset 150000
slice_id 4 seek offset 200000
slice_id 1 seek offset 50000
2024-11-09 05:30:21 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-09 05:30:21 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 16 @ 5005 updates, score 0.7344) (writing took 60.84706921799807 seconds)
2024-11-09 05:30:21 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 16 @ 5005 updates
2024-11-09 05:30:21 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-09 05:31:22 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-09 05:31:22 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 16 @ 5005 updates, score 0) (writing took 60.7381773860543 seconds)
2024-11-09 05:31:22 - train.py[line:336] - INFO: end of epoch 16 (average epoch stats below)
2024-11-09 05:31:22 - progress_bar.py[line:282] - INFO: epoch 016 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.208 | ntokens 5111.75 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.24 | wps 314 | ups 0.06 | wpb 5111.8 | bsz 1277.9 | num_updates 5005 | lr 1.06627e-05 | gnorm 0.012 | clip 0 | loss_scale 8192 | train_wall 2860 | gb_free 9.7 | wall 66022
2024-11-09 05:31:22 - trainer.py[line:639] - INFO: loading train data for epoch 17
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-09 05:31:25 - trainer.py[line:703] - INFO: begin training epoch 17
2024-11-09 05:31:25 - train.py[line:297] - INFO: Start iterating over samples
2024-11-09 05:32:17 - progress_bar.py[line:274] - INFO: epoch 017:      5 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.202, ntokens=4863.9, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=9.2, wps=24.8, ups=0.01, wpb=4863.9, bsz=1216, num_updates=5010, lr=1.06202e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=36, gb_free=9.6, wall=66078
2024-11-09 05:33:58 - progress_bar.py[line:274] - INFO: epoch 017:     15 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.215, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.29, wps=511.4, ups=0.1, wpb=5120, bsz=1280, num_updates=5020, lr=1.05353e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=36, gb_free=9.6, wall=66178
2024-11-09 05:35:37 - progress_bar.py[line:274] - INFO: epoch 017:     25 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.194, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.15, wps=513.6, ups=0.1, wpb=5120, bsz=1280, num_updates=5030, lr=1.04503e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=66278
2024-11-09 05:37:19 - progress_bar.py[line:274] - INFO: epoch 017:     35 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.217, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.3, wps=504.6, ups=0.1, wpb=5120, bsz=1280, num_updates=5040, lr=1.03653e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=66379
2024-11-09 05:39:02 - progress_bar.py[line:274] - INFO: epoch 017:     45 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.223, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.34, wps=497.7, ups=0.1, wpb=5120, bsz=1280, num_updates=5050, lr=1.02804e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=47, gb_free=9.7, wall=66482
2024-11-09 05:40:45 - progress_bar.py[line:274] - INFO: epoch 017:     55 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.209, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.25, wps=493.7, ups=0.1, wpb=5120, bsz=1280, num_updates=5060, lr=1.01954e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=78, gb_free=9.7, wall=66586
2024-11-09 05:42:28 - progress_bar.py[line:274] - INFO: epoch 017:     65 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.207, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.23, wps=500.1, ups=0.1, wpb=5120, bsz=1280, num_updates=5070, lr=1.01105e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=100, gb_free=9.7, wall=66688
2024-11-09 05:44:11 - progress_bar.py[line:274] - INFO: epoch 017:     75 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.198, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.17, wps=496.8, ups=0.1, wpb=5120, bsz=1280, num_updates=5080, lr=1.00255e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=66791
2024-11-09 05:45:54 - progress_bar.py[line:274] - INFO: epoch 017:     85 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.189, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.12, wps=495, ups=0.1, wpb=5120, bsz=1280, num_updates=5090, lr=9.94053e-06, gnorm=0.012, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=66894
2024-11-09 05:47:37 - progress_bar.py[line:274] - INFO: epoch 017:     95 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.211, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.26, wps=496.6, ups=0.1, wpb=5120, bsz=1280, num_updates=5100, lr=9.85556e-06, gnorm=0.009, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=66998
2024-11-09 05:49:20 - progress_bar.py[line:274] - INFO: epoch 017:    105 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.205, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.22, wps=499.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=5110, lr=9.7706e-06, gnorm=0.011, clip=0, loss_scale=8192, train_wall=102, gb_free=9.6, wall=67100
2024-11-09 05:51:02 - progress_bar.py[line:274] - INFO: epoch 017:    115 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.205, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.22, wps=498.3, ups=0.1, wpb=5120, bsz=1280, num_updates=5120, lr=9.68564e-06, gnorm=0.009, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=67203
2024-11-09 05:52:45 - progress_bar.py[line:274] - INFO: epoch 017:    125 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.219, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.31, wps=497.7, ups=0.1, wpb=5120, bsz=1280, num_updates=5130, lr=9.60068e-06, gnorm=0.014, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=67306
2024-11-09 05:54:28 - progress_bar.py[line:274] - INFO: epoch 017:    135 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.207, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.24, wps=497, ups=0.1, wpb=5120, bsz=1280, num_updates=5140, lr=9.51572e-06, gnorm=0.016, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=67409
2024-11-09 05:56:12 - progress_bar.py[line:274] - INFO: epoch 017:    145 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.199, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.18, wps=494.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=5150, lr=9.43076e-06, gnorm=0.015, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=67512
2024-11-09 05:57:55 - progress_bar.py[line:274] - INFO: epoch 017:    155 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.191, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.13, wps=495.9, ups=0.1, wpb=5119.9, bsz=1280, num_updates=5160, lr=9.34579e-06, gnorm=0.017, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=67615
2024-11-09 05:59:38 - progress_bar.py[line:274] - INFO: epoch 017:    165 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.216, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.29, wps=498, ups=0.1, wpb=5120, bsz=1280, num_updates=5170, lr=9.26083e-06, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=67718
2024-11-09 06:01:21 - progress_bar.py[line:274] - INFO: epoch 017:    175 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.206, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.23, wps=495.2, ups=0.1, wpb=5120, bsz=1280, num_updates=5180, lr=9.17587e-06, gnorm=0.014, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=67822
2024-11-09 06:03:05 - progress_bar.py[line:274] - INFO: epoch 017:    185 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.2, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.19, wps=493.4, ups=0.1, wpb=5120, bsz=1280, num_updates=5190, lr=9.09091e-06, gnorm=0.01, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=67925
2024-11-09 06:04:49 - progress_bar.py[line:274] - INFO: epoch 017:    195 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.211, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.26, wps=492.2, ups=0.1, wpb=5120, bsz=1280, num_updates=5200, lr=9.00595e-06, gnorm=0.012, clip=0, loss_scale=8192, train_wall=104, gb_free=9.6, wall=68029
2024-11-09 06:06:33 - progress_bar.py[line:274] - INFO: epoch 017:    205 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.191, ntokens=5119.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.13, wps=494.8, ups=0.1, wpb=5119.7, bsz=1280, num_updates=5210, lr=8.92099e-06, gnorm=0.012, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=68133
2024-11-09 06:08:16 - progress_bar.py[line:274] - INFO: epoch 017:    215 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.193, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.14, wps=496, ups=0.1, wpb=5120, bsz=1280, num_updates=5220, lr=8.83602e-06, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=68236
2024-11-09 06:10:00 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2024-11-09 06:10:10 - progress_bar.py[line:274] - INFO: epoch 017:    226 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.197, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.17, wps=447.8, ups=0.09, wpb=5119.8, bsz=1280, num_updates=5230, lr=8.75106e-06, gnorm=0.012, clip=0, loss_scale=4096, train_wall=114, gb_free=9.7, wall=68350
2024-11-09 06:11:54 - progress_bar.py[line:274] - INFO: epoch 017:    236 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.189, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.12, wps=494.3, ups=0.1, wpb=5120, bsz=1280, num_updates=5240, lr=8.6661e-06, gnorm=0.008, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=68454
2024-11-09 06:13:37 - progress_bar.py[line:274] - INFO: epoch 017:    246 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.207, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.24, wps=494.7, ups=0.1, wpb=5119.8, bsz=1280, num_updates=5250, lr=8.58114e-06, gnorm=0.011, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=68557
2024-11-09 06:15:20 - progress_bar.py[line:274] - INFO: epoch 017:    256 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.217, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.3, wps=496.6, ups=0.1, wpb=5120, bsz=1280, num_updates=5260, lr=8.49618e-06, gnorm=0.012, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=68661
2024-11-09 06:17:03 - progress_bar.py[line:274] - INFO: epoch 017:    266 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.206, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.23, wps=496.9, ups=0.1, wpb=5120, bsz=1280, num_updates=5270, lr=8.41121e-06, gnorm=0.009, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=68764
2024-11-09 06:18:47 - progress_bar.py[line:274] - INFO: epoch 017:    276 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.212, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.27, wps=495.1, ups=0.1, wpb=5120, bsz=1280, num_updates=5280, lr=8.32625e-06, gnorm=0.01, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=68867
2024-11-09 06:20:30 - progress_bar.py[line:274] - INFO: epoch 017:    286 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.228, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.37, wps=496.4, ups=0.1, wpb=5120, bsz=1280, num_updates=5290, lr=8.24129e-06, gnorm=0.011, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=68970
2024-11-09 06:22:13 - progress_bar.py[line:274] - INFO: epoch 017:    296 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.221, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.33, wps=495.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=5300, lr=8.15633e-06, gnorm=0.012, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=69073
2024-11-09 06:23:56 - progress_bar.py[line:274] - INFO: epoch 017:    306 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.225, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.35, wps=495.9, ups=0.1, wpb=5119.9, bsz=1280, num_updates=5310, lr=8.07137e-06, gnorm=0.012, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=69177
slice_id 2 seek offset 13910
slice_id 3 seek offset 20865
slice_id 4 seek offset 27820slice_id 1 seek offset 6955
slice_id 7 seek offset 48685

slice_id 6 seek offset 41730
2024-11-09 06:25:02 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 5 seek offset 34775
slice_id 3 seek offset 20865
slice_id 7 seek offset 48685
slice_id 5 seek offset 34775
slice_id 2 seek offset 13910
slice_id 6 seek offset 41730
slice_id 1 seek offset 6955
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-09 06:32:29 - progress_bar.py[line:282] - INFO: epoch 017 | valid on 'valid' subset | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.224 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.35 | score 0.7526 | wps 499.8 | wpb 639.5 | bsz 159.9 | num_updates 5317 | best_score 0.7526
2024-11-09 06:32:29 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 17 @ 5317 updates
2024-11-09 06:32:29 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 row count 50000 total row count 400000
slice_id 4 seek offset 200000
slice_id 2 seek offset 100000
slice_id 3 seek offset 150000
slice_id 6 seek offset 300000
slice_id 5 seek offset 250000
slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
2024-11-09 06:33:30 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-11-09 06:34:43 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 17 @ 5317 updates, score 0.7526) (writing took 134.26492151600542 seconds)
2024-11-09 06:34:44 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 17 @ 5317 updates
2024-11-09 06:34:44 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-09 06:36:12 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-09 06:36:12 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 17 @ 5317 updates, score 0) (writing took 88.29011989099672 seconds)
2024-11-09 06:36:12 - train.py[line:336] - INFO: end of epoch 17 (average epoch stats below)
2024-11-09 06:36:12 - progress_bar.py[line:282] - INFO: epoch 017 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.207 | ntokens 5111.75 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.24 | wps 410 | ups 0.08 | wpb 5111.8 | bsz 1277.9 | num_updates 5317 | lr 8.01189e-06 | gnorm 0.012 | clip 0 | loss_scale 4096 | train_wall 2898 | gb_free 9.7 | wall 69912
2024-11-09 06:36:12 - trainer.py[line:639] - INFO: loading train data for epoch 18
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-09 06:36:14 - trainer.py[line:703] - INFO: begin training epoch 18
2024-11-09 06:36:14 - train.py[line:297] - INFO: Start iterating over samples
2024-11-09 06:36:47 - progress_bar.py[line:274] - INFO: epoch 018:      3 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.223, ntokens=4864, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=9.34, wps=63.1, ups=0.01, wpb=4864, bsz=1216, num_updates=5320, lr=7.98641e-06, gnorm=0.011, clip=0, loss_scale=4096, train_wall=75, gb_free=9.6, wall=69948
2024-11-09 06:38:27 - progress_bar.py[line:274] - INFO: epoch 018:     13 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.22, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.32, wps=515.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=5330, lr=7.90144e-06, gnorm=0.013, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=70047
2024-11-09 06:40:07 - progress_bar.py[line:274] - INFO: epoch 018:     23 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.219, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.31, wps=512.5, ups=0.1, wpb=5120, bsz=1280, num_updates=5340, lr=7.81648e-06, gnorm=0.012, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=70147
2024-11-09 06:41:48 - progress_bar.py[line:274] - INFO: epoch 018:     33 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.222, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.33, wps=505.2, ups=0.1, wpb=5120, bsz=1280, num_updates=5350, lr=7.73152e-06, gnorm=0.011, clip=0, loss_scale=4096, train_wall=39, gb_free=9.7, wall=70248
2024-11-09 06:43:31 - progress_bar.py[line:274] - INFO: epoch 018:     43 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.222, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.33, wps=495, ups=0.1, wpb=5120, bsz=1280, num_updates=5360, lr=7.64656e-06, gnorm=0.01, clip=0, loss_scale=4096, train_wall=72, gb_free=9.6, wall=70352
2024-11-09 06:45:15 - progress_bar.py[line:274] - INFO: epoch 018:     53 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.238, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.43, wps=494.8, ups=0.1, wpb=5120, bsz=1280, num_updates=5370, lr=7.5616e-06, gnorm=0.011, clip=0, loss_scale=4096, train_wall=102, gb_free=9.7, wall=70455
2024-11-09 06:46:58 - progress_bar.py[line:274] - INFO: epoch 018:     63 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.225, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.35, wps=494.6, ups=0.1, wpb=5120, bsz=1280, num_updates=5380, lr=7.47664e-06, gnorm=0.012, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=70559
2024-11-09 06:48:42 - progress_bar.py[line:274] - INFO: epoch 018:     73 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.222, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.33, wps=493.5, ups=0.1, wpb=5120, bsz=1280, num_updates=5390, lr=7.39167e-06, gnorm=0.012, clip=0, loss_scale=4096, train_wall=104, gb_free=9.6, wall=70662
2024-11-09 06:50:26 - progress_bar.py[line:274] - INFO: epoch 018:     83 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.219, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.31, wps=494.6, ups=0.1, wpb=5120, bsz=1280, num_updates=5400, lr=7.30671e-06, gnorm=0.01, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=70766
2024-11-09 06:52:09 - progress_bar.py[line:274] - INFO: epoch 018:     93 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.241, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.46, wps=496.3, ups=0.1, wpb=5120, bsz=1280, num_updates=5410, lr=7.22175e-06, gnorm=0.013, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=70869
2024-11-09 06:53:52 - progress_bar.py[line:274] - INFO: epoch 018:    103 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.231, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.39, wps=495.4, ups=0.1, wpb=5120, bsz=1280, num_updates=5420, lr=7.13679e-06, gnorm=0.012, clip=0, loss_scale=4096, train_wall=103, gb_free=9.6, wall=70972
2024-11-09 06:55:36 - progress_bar.py[line:274] - INFO: epoch 018:    113 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.229, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.38, wps=492.9, ups=0.1, wpb=5119.9, bsz=1280, num_updates=5430, lr=7.05183e-06, gnorm=0.01, clip=0, loss_scale=4096, train_wall=104, gb_free=9.7, wall=71076
2024-11-09 06:57:21 - progress_bar.py[line:274] - INFO: epoch 018:    123 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.231, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.39, wps=488.2, ups=0.1, wpb=5120, bsz=1280, num_updates=5440, lr=6.96686e-06, gnorm=0.016, clip=0, loss_scale=4096, train_wall=105, gb_free=9.7, wall=71181
2024-11-09 06:59:05 - progress_bar.py[line:274] - INFO: epoch 018:    133 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.231, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.39, wps=490.3, ups=0.1, wpb=5120, bsz=1280, num_updates=5450, lr=6.8819e-06, gnorm=0.016, clip=0, loss_scale=4096, train_wall=104, gb_free=9.6, wall=71286
2024-11-09 07:00:51 - progress_bar.py[line:274] - INFO: epoch 018:    143 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.244, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.48, wps=486.2, ups=0.09, wpb=5119.9, bsz=1280, num_updates=5460, lr=6.79694e-06, gnorm=0.011, clip=0, loss_scale=4096, train_wall=105, gb_free=9.7, wall=71391
2024-11-09 07:02:35 - progress_bar.py[line:274] - INFO: epoch 018:    153 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.248, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.5, wps=488.9, ups=0.1, wpb=5119.9, bsz=1280, num_updates=5470, lr=6.71198e-06, gnorm=0.011, clip=0, loss_scale=4096, train_wall=105, gb_free=9.6, wall=71496
2024-11-09 07:04:20 - progress_bar.py[line:274] - INFO: epoch 018:    163 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.247, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.49, wps=488.4, ups=0.1, wpb=5120, bsz=1280, num_updates=5480, lr=6.62702e-06, gnorm=0.009, clip=0, loss_scale=4096, train_wall=105, gb_free=9.7, wall=71600
2024-11-09 07:06:06 - progress_bar.py[line:274] - INFO: epoch 018:    173 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.232, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.39, wps=483.9, ups=0.09, wpb=5120, bsz=1280, num_updates=5490, lr=6.54206e-06, gnorm=0.011, clip=0, loss_scale=4096, train_wall=106, gb_free=9.6, wall=71706
2024-11-09 07:07:51 - progress_bar.py[line:274] - INFO: epoch 018:    183 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.24, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.45, wps=488.5, ups=0.1, wpb=5120, bsz=1280, num_updates=5500, lr=6.45709e-06, gnorm=0.011, clip=0, loss_scale=4096, train_wall=105, gb_free=9.7, wall=71811
2024-11-09 07:09:36 - progress_bar.py[line:274] - INFO: epoch 018:    193 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.252, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.53, wps=485.6, ups=0.09, wpb=5120, bsz=1280, num_updates=5510, lr=6.37213e-06, gnorm=0.011, clip=0, loss_scale=4096, train_wall=105, gb_free=9.7, wall=71916
2024-11-09 07:11:22 - progress_bar.py[line:274] - INFO: epoch 018:    203 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.247, ntokens=5119.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.49, wps=486.2, ups=0.09, wpb=5119.7, bsz=1280, num_updates=5520, lr=6.28717e-06, gnorm=0.009, clip=0, loss_scale=4096, train_wall=105, gb_free=9.6, wall=72022
2024-11-09 07:13:07 - progress_bar.py[line:274] - INFO: epoch 018:    213 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.243, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.47, wps=487.5, ups=0.1, wpb=5120, bsz=1280, num_updates=5530, lr=6.20221e-06, gnorm=0.012, clip=0, loss_scale=4096, train_wall=105, gb_free=9.6, wall=72127
2024-11-09 07:14:52 - progress_bar.py[line:274] - INFO: epoch 018:    223 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.251, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.52, wps=487, ups=0.1, wpb=5120, bsz=1280, num_updates=5540, lr=6.11725e-06, gnorm=0.009, clip=0, loss_scale=4096, train_wall=105, gb_free=9.5, wall=72232
2024-11-09 07:16:37 - progress_bar.py[line:274] - INFO: epoch 018:    233 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.244, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.47, wps=486.2, ups=0.09, wpb=5119.8, bsz=1280, num_updates=5550, lr=6.03229e-06, gnorm=0.008, clip=0, loss_scale=4096, train_wall=105, gb_free=9.6, wall=72337
2024-11-09 07:18:23 - progress_bar.py[line:274] - INFO: epoch 018:    243 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.244, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.48, wps=482.5, ups=0.09, wpb=5119.8, bsz=1280, num_updates=5560, lr=5.94732e-06, gnorm=0.016, clip=0, loss_scale=4096, train_wall=106, gb_free=9.7, wall=72443
2024-11-09 07:20:09 - progress_bar.py[line:274] - INFO: epoch 018:    253 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.248, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.5, wps=484, ups=0.09, wpb=5120, bsz=1280, num_updates=5570, lr=5.86236e-06, gnorm=0.014, clip=0, loss_scale=4096, train_wall=106, gb_free=9.7, wall=72549
2024-11-09 07:21:54 - progress_bar.py[line:274] - INFO: epoch 018:    263 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.245, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.48, wps=489.3, ups=0.1, wpb=5120, bsz=1280, num_updates=5580, lr=5.7774e-06, gnorm=0.01, clip=0, loss_scale=4096, train_wall=105, gb_free=9.7, wall=72654
2024-11-09 07:23:38 - progress_bar.py[line:274] - INFO: epoch 018:    273 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.243, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.47, wps=488.3, ups=0.1, wpb=5120, bsz=1280, num_updates=5590, lr=5.69244e-06, gnorm=0.01, clip=0, loss_scale=4096, train_wall=105, gb_free=9.6, wall=72759
2024-11-09 07:25:23 - progress_bar.py[line:274] - INFO: epoch 018:    283 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.234, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.41, wps=489.9, ups=0.1, wpb=5120, bsz=1280, num_updates=5600, lr=5.60748e-06, gnorm=0.011, clip=0, loss_scale=4096, train_wall=104, gb_free=9.7, wall=72863
2024-11-09 07:27:07 - progress_bar.py[line:274] - INFO: epoch 018:    293 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.235, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.41, wps=491.2, ups=0.1, wpb=5119.9, bsz=1280, num_updates=5610, lr=5.52251e-06, gnorm=0.013, clip=0, loss_scale=4096, train_wall=104, gb_free=9.7, wall=72967
2024-11-09 07:28:52 - progress_bar.py[line:274] - INFO: epoch 018:    303 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.221, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.32, wps=489.9, ups=0.1, wpb=5119.9, bsz=1280, num_updates=5620, lr=5.43755e-06, gnorm=0.012, clip=0, loss_scale=4096, train_wall=104, gb_free=9.7, wall=73072
2024-11-09 07:30:29 - progress_bar.py[line:274] - INFO: epoch 018:    313 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.227, ntokens=4864, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=9.36, wps=497.5, ups=0.1, wpb=4864, bsz=1216, num_updates=5630, lr=5.35259e-06, gnorm=0.011, clip=0, loss_scale=4096, train_wall=98, gb_free=9.7, wall=73170
slice_id 7 seek offset 48685
slice_id 4 seek offset 27820
slice_id 5 seek offset 34775
2024-11-09 07:30:29 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 3 seek offset 20865
slice_id 0 seek offset 0
slice_id 6 seek offset 41730
slice_id 2 seek offset 13910
slice_id 1 seek offset 6955
slice_id 7 seek offset 48685
slice_id 3 seek offset 20865
slice_id 5 seek offset 34775
slice_id 6 seek offset 41730
slice_id 2 seek offset 13910
slice_id 1 seek offset 6955
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-09 07:38:03 - progress_bar.py[line:282] - INFO: epoch 018 | valid on 'valid' subset | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.232 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.39 | score 0.7559 | wps 492.8 | wpb 639.5 | bsz 159.9 | num_updates 5630 | best_score 0.7559
2024-11-09 07:38:03 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 18 @ 5630 updates
2024-11-09 07:38:03 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 row count 50000 total row count 400000
slice_id 5 seek offset 250000
slice_id 3 seek offset 150000
slice_id 7 seek offset 350000
slice_id 6 seek offset 300000
slice_id 2 seek offset 100000
slice_id 4 seek offset 200000
slice_id 1 seek offset 50000
2024-11-09 07:39:04 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-11-09 07:40:18 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 18 @ 5630 updates, score 0.7559) (writing took 135.00528836000012 seconds)
2024-11-09 07:40:18 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 18 @ 5630 updates
2024-11-09 07:40:18 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-09 07:41:46 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-09 07:41:46 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 18 @ 5630 updates, score 0) (writing took 87.5501233850373 seconds)
2024-11-09 07:41:46 - train.py[line:336] - INFO: end of epoch 18 (average epoch stats below)
2024-11-09 07:41:46 - progress_bar.py[line:282] - INFO: epoch 018 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.235 | ntokens 5111.78 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.42 | wps 406.7 | ups 0.08 | wpb 5111.8 | bsz 1278 | num_updates 5630 | lr 5.35259e-06 | gnorm 0.011 | clip 0 | loss_scale 4096 | train_wall 3006 | gb_free 9.7 | wall 73846
2024-11-09 07:41:46 - trainer.py[line:639] - INFO: loading train data for epoch 19
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-09 07:41:49 - trainer.py[line:703] - INFO: begin training epoch 19
2024-11-09 07:41:49 - train.py[line:297] - INFO: Start iterating over samples
2024-11-09 07:43:33 - progress_bar.py[line:274] - INFO: epoch 019:     10 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.223, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.34, wps=65.3, ups=0.01, wpb=5119.9, bsz=1280, num_updates=5640, lr=5.26763e-06, gnorm=0.017, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=73953
2024-11-09 07:45:16 - progress_bar.py[line:274] - INFO: epoch 019:     20 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.215, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.28, wps=499.8, ups=0.1, wpb=5120, bsz=1280, num_updates=5650, lr=5.18267e-06, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=74056
2024-11-09 07:46:56 - progress_bar.py[line:274] - INFO: epoch 019:     30 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.227, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.37, wps=508.8, ups=0.1, wpb=5120, bsz=1280, num_updates=5660, lr=5.09771e-06, gnorm=0.012, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=74156
2024-11-09 07:48:37 - progress_bar.py[line:274] - INFO: epoch 019:     40 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.234, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.41, wps=508.8, ups=0.1, wpb=5120, bsz=1280, num_updates=5670, lr=5.01274e-06, gnorm=0.007, clip=0, loss_scale=4096, train_wall=36, gb_free=9.7, wall=74257
2024-11-09 07:50:21 - progress_bar.py[line:274] - INFO: epoch 019:     50 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.232, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.4, wps=493.7, ups=0.1, wpb=5120, bsz=1280, num_updates=5680, lr=4.92778e-06, gnorm=0.01, clip=0, loss_scale=4096, train_wall=57, gb_free=9.7, wall=74361
2024-11-09 07:52:04 - progress_bar.py[line:274] - INFO: epoch 019:     60 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.233, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.4, wps=493.5, ups=0.1, wpb=5120, bsz=1280, num_updates=5690, lr=4.84282e-06, gnorm=0.011, clip=0, loss_scale=4096, train_wall=92, gb_free=9.6, wall=74465
2024-11-09 07:53:49 - progress_bar.py[line:274] - INFO: epoch 019:     70 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.243, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.47, wps=489.9, ups=0.1, wpb=5120, bsz=1280, num_updates=5700, lr=4.75786e-06, gnorm=0.009, clip=0, loss_scale=4096, train_wall=104, gb_free=9.7, wall=74569
2024-11-09 07:55:32 - progress_bar.py[line:274] - INFO: epoch 019:     80 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.229, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.38, wps=494.2, ups=0.1, wpb=5120, bsz=1280, num_updates=5710, lr=4.6729e-06, gnorm=0.012, clip=0, loss_scale=4096, train_wall=104, gb_free=9.7, wall=74673
2024-11-09 07:57:16 - progress_bar.py[line:274] - INFO: epoch 019:     90 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.248, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.5, wps=495.2, ups=0.1, wpb=5120, bsz=1280, num_updates=5720, lr=4.58794e-06, gnorm=0.009, clip=0, loss_scale=4096, train_wall=103, gb_free=9.7, wall=74776
2024-11-09 07:59:00 - progress_bar.py[line:274] - INFO: epoch 019:    100 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.238, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.43, wps=493.4, ups=0.1, wpb=5120, bsz=1280, num_updates=5730, lr=4.50297e-06, gnorm=0.011, clip=0, loss_scale=4096, train_wall=104, gb_free=9.7, wall=74880
2024-11-09 08:00:44 - progress_bar.py[line:274] - INFO: epoch 019:    110 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.24, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.45, wps=490.7, ups=0.1, wpb=5119.9, bsz=1280, num_updates=5740, lr=4.41801e-06, gnorm=0.01, clip=0, loss_scale=4096, train_wall=104, gb_free=9.6, wall=74984
2024-11-09 08:02:27 - progress_bar.py[line:274] - INFO: epoch 019:    120 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.238, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.44, wps=494.1, ups=0.1, wpb=5120, bsz=1280, num_updates=5750, lr=4.33305e-06, gnorm=0.01, clip=0, loss_scale=8192, train_wall=104, gb_free=9.6, wall=75088
2024-11-09 08:04:11 - progress_bar.py[line:274] - INFO: epoch 019:    130 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.228, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.37, wps=493.3, ups=0.1, wpb=5120, bsz=1280, num_updates=5760, lr=4.24809e-06, gnorm=0.011, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=75192
2024-11-09 08:05:55 - progress_bar.py[line:274] - INFO: epoch 019:    140 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.23, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.38, wps=493.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=5770, lr=4.16313e-06, gnorm=0.011, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=75295
2024-11-09 08:07:39 - progress_bar.py[line:274] - INFO: epoch 019:    150 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.238, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.44, wps=491.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=5780, lr=4.07816e-06, gnorm=0.008, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=75399
2024-11-09 08:09:24 - progress_bar.py[line:274] - INFO: epoch 019:    160 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.234, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.41, wps=489.7, ups=0.1, wpb=5120, bsz=1280, num_updates=5790, lr=3.9932e-06, gnorm=0.011, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=75504
2024-11-09 08:11:07 - progress_bar.py[line:274] - INFO: epoch 019:    170 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.231, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.39, wps=496.2, ups=0.1, wpb=5120, bsz=1280, num_updates=5800, lr=3.90824e-06, gnorm=0.009, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=75607
2024-11-09 08:12:50 - progress_bar.py[line:274] - INFO: epoch 019:    180 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.24, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.45, wps=495.6, ups=0.1, wpb=5120, bsz=1280, num_updates=5810, lr=3.82328e-06, gnorm=0.012, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=75710
2024-11-09 08:14:33 - progress_bar.py[line:274] - INFO: epoch 019:    190 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.24, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.45, wps=495.9, ups=0.1, wpb=5120, bsz=1280, num_updates=5820, lr=3.73832e-06, gnorm=0.008, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=75814
2024-11-09 08:16:17 - progress_bar.py[line:274] - INFO: epoch 019:    200 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.242, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.46, wps=495.3, ups=0.1, wpb=5119.8, bsz=1280, num_updates=5830, lr=3.65336e-06, gnorm=0.009, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=75917
2024-11-09 08:18:00 - progress_bar.py[line:274] - INFO: epoch 019:    210 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.236, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.42, wps=494.7, ups=0.1, wpb=5119.9, bsz=1280, num_updates=5840, lr=3.56839e-06, gnorm=0.014, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=76021
2024-11-09 08:19:44 - progress_bar.py[line:274] - INFO: epoch 019:    220 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.247, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.5, wps=495.2, ups=0.1, wpb=5120, bsz=1280, num_updates=5850, lr=3.48343e-06, gnorm=0.008, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=76124
2024-11-09 08:21:27 - progress_bar.py[line:274] - INFO: epoch 019:    230 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.249, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.51, wps=495.4, ups=0.1, wpb=5119.8, bsz=1280, num_updates=5860, lr=3.39847e-06, gnorm=0.013, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=76227
2024-11-09 08:23:10 - progress_bar.py[line:274] - INFO: epoch 019:    240 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.245, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.48, wps=495, ups=0.1, wpb=5119.9, bsz=1280, num_updates=5870, lr=3.31351e-06, gnorm=0.009, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=76331
2024-11-09 08:24:54 - progress_bar.py[line:274] - INFO: epoch 019:    250 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.233, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.4, wps=495.6, ups=0.1, wpb=5119.9, bsz=1280, num_updates=5880, lr=3.22855e-06, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=76434
2024-11-09 08:26:37 - progress_bar.py[line:274] - INFO: epoch 019:    260 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.24, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.45, wps=495.8, ups=0.1, wpb=5120, bsz=1280, num_updates=5890, lr=3.14359e-06, gnorm=0.014, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=76537
2024-11-09 08:28:20 - progress_bar.py[line:274] - INFO: epoch 019:    270 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.244, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.47, wps=497.9, ups=0.1, wpb=5120, bsz=1280, num_updates=5900, lr=3.05862e-06, gnorm=0.009, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=76640
2024-11-09 08:30:03 - progress_bar.py[line:274] - INFO: epoch 019:    280 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.246, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.49, wps=493.9, ups=0.1, wpb=5120, bsz=1280, num_updates=5910, lr=2.97366e-06, gnorm=0.01, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=76744
2024-11-09 08:31:47 - progress_bar.py[line:274] - INFO: epoch 019:    290 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.241, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.46, wps=496, ups=0.1, wpb=5119.9, bsz=1280, num_updates=5920, lr=2.8887e-06, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=76847
2024-11-09 08:33:30 - progress_bar.py[line:274] - INFO: epoch 019:    300 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.231, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.39, wps=497.9, ups=0.1, wpb=5120, bsz=1280, num_updates=5930, lr=2.80374e-06, gnorm=0.012, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=76950
2024-11-09 08:35:14 - progress_bar.py[line:274] - INFO: epoch 019:    310 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.229, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.38, wps=491.9, ups=0.1, wpb=5119.9, bsz=1280, num_updates=5940, lr=2.71878e-06, gnorm=0.009, clip=0, loss_scale=8192, train_wall=104, gb_free=9.6, wall=77054
slice_id 2 seek offset 13910slice_id 1 seek offset 6955slice_id 7 seek offset 48685

slice_id 4 seek offset 27820slice_id 3 seek offset 20865
2024-11-09 08:35:37 - train.py[line:449] - INFO: begin validation on "valid" subset

slice_id 5 seek offset 34775

slice_id 0 seek offset 0
slice_id 6 seek offset 41730
slice_id 3 seek offset 20865
slice_id 5 seek offset 34775
slice_id 7 seek offset 48685
slice_id 1 seek offset 6955
slice_id 6 seek offset 41730
slice_id 2 seek offset 13910
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-09 08:43:06 - progress_bar.py[line:282] - INFO: epoch 019 | valid on 'valid' subset | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.242 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.46 | score 0.7657 | wps 497.5 | wpb 639.5 | bsz 159.9 | num_updates 5943 | best_score 0.7657
2024-11-09 08:43:06 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 19 @ 5943 updates
2024-11-09 08:43:06 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 row count 50000 total row count 400000file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 row count 50000 total row count 400000

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 row count 50000 total row count 400000
slice_id 5 seek offset 250000
slice_id 3 seek offset 150000
slice_id 6 seek offset 300000
slice_id 2 seek offset 100000
slice_id 4 seek offset 200000
slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
2024-11-09 08:44:07 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-11-09 08:45:22 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 19 @ 5943 updates, score 0.7657) (writing took 135.37552183197113 seconds)
2024-11-09 08:45:22 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 19 @ 5943 updates
2024-11-09 08:45:22 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-09 08:46:49 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-09 08:46:50 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 19 @ 5943 updates, score 0) (writing took 87.29233952600043 seconds)
2024-11-09 08:46:50 - train.py[line:336] - INFO: end of epoch 19 (average epoch stats below)
2024-11-09 08:46:50 - progress_bar.py[line:282] - INFO: epoch 019 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.236 | ntokens 5111.78 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.42 | wps 409.9 | ups 0.08 | wpb 5111.8 | bsz 1278 | num_updates 5943 | lr 2.69329e-06 | gnorm 0.011 | clip 0 | loss_scale 8192 | train_wall 2900 | gb_free 9.7 | wall 77750
2024-11-09 08:46:50 - trainer.py[line:639] - INFO: loading train data for epoch 20
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-09 08:46:52 - trainer.py[line:703] - INFO: begin training epoch 20
2024-11-09 08:46:52 - train.py[line:297] - INFO: Start iterating over samples
2024-11-09 08:48:05 - progress_bar.py[line:274] - INFO: epoch 020:      7 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.233, ntokens=4863.9, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=9.4, wps=63.1, ups=0.01, wpb=4863.9, bsz=1216, num_updates=5950, lr=2.63381e-06, gnorm=0.013, clip=0, loss_scale=8192, train_wall=48, gb_free=9.6, wall=77825
2024-11-09 08:49:45 - progress_bar.py[line:274] - INFO: epoch 020:     17 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.229, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.38, wps=512.2, ups=0.1, wpb=5120, bsz=1280, num_updates=5960, lr=2.54885e-06, gnorm=0.012, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=77925
2024-11-09 08:51:28 - progress_bar.py[line:274] - INFO: epoch 020:     27 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.233, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.4, wps=496.7, ups=0.1, wpb=5120, bsz=1280, num_updates=5970, lr=2.46389e-06, gnorm=0.02, clip=0, loss_scale=8192, train_wall=47, gb_free=9.7, wall=78028
2024-11-09 08:53:13 - progress_bar.py[line:274] - INFO: epoch 020:     37 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.244, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.47, wps=485.4, ups=0.09, wpb=5120, bsz=1280, num_updates=5980, lr=2.37893e-06, gnorm=0.015, clip=0, loss_scale=8192, train_wall=95, gb_free=9.7, wall=78134
2024-11-09 08:54:58 - progress_bar.py[line:274] - INFO: epoch 020:     47 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.241, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.46, wps=490.2, ups=0.1, wpb=5120, bsz=1280, num_updates=5990, lr=2.29397e-06, gnorm=0.013, clip=0, loss_scale=8192, train_wall=104, gb_free=9.6, wall=78238
2024-11-09 08:56:41 - progress_bar.py[line:274] - INFO: epoch 020:     57 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.251, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.52, wps=495.5, ups=0.1, wpb=5120, bsz=1280, num_updates=6000, lr=2.20901e-06, gnorm=0.012, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=78341
slice_id 4 seek offset 27820
slice_id 5 seek offset 34775
slice_id 3 seek offset 20865
2024-11-09 08:56:41 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 6 seek offset 41730
slice_id 7 seek offset 48685
slice_id 1 seek offset 6955
slice_id 2 seek offset 13910
slice_id 5 seek offset 34775
slice_id 7 seek offset 48685
slice_id 6 seek offset 41730
slice_id 3 seek offset 20865
slice_id 1 seek offset 6955
slice_id 2 seek offset 13910
slice_id 0 seek offset 0
slice_id 4 seek offset 27820
2024-11-09 09:04:14 - progress_bar.py[line:282] - INFO: epoch 020 | valid on 'valid' subset | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.25 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.51 | score 0.7739 | wps 493.1 | wpb 639.5 | bsz 159.9 | num_updates 6000 | best_score 0.7739
2024-11-09 09:04:14 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 20 @ 6000 updates
2024-11-09 09:04:14 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_20_6000.pt
2024-11-09 09:04:25 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_20_6000.pt
2024-11-09 09:07:13 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_20_6000.pt (epoch 20 @ 6000 updates, score 0.7739) (writing took 178.49513216601918 seconds)
2024-11-09 09:08:44 - progress_bar.py[line:274] - INFO: epoch 020:     67 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.243, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.47, wps=70.9, ups=0.01, wpb=5120, bsz=1280, num_updates=6010, lr=2.12404e-06, gnorm=0.013, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=79064
2024-11-09 09:10:24 - progress_bar.py[line:274] - INFO: epoch 020:     77 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.239, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.44, wps=509.4, ups=0.1, wpb=5120, bsz=1280, num_updates=6020, lr=2.03908e-06, gnorm=0.01, clip=0, loss_scale=8192, train_wall=35, gb_free=9.6, wall=79165
2024-11-09 09:12:06 - progress_bar.py[line:274] - INFO: epoch 020:     87 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.241, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.45, wps=501.4, ups=0.1, wpb=5120, bsz=1280, num_updates=6030, lr=1.95412e-06, gnorm=0.014, clip=0, loss_scale=8192, train_wall=42, gb_free=9.6, wall=79267
2024-11-09 09:13:50 - progress_bar.py[line:274] - INFO: epoch 020:     97 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.245, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.48, wps=496.2, ups=0.1, wpb=5120, bsz=1280, num_updates=6040, lr=1.86916e-06, gnorm=0.01, clip=0, loss_scale=8192, train_wall=69, gb_free=9.6, wall=79370
2024-11-09 09:15:32 - progress_bar.py[line:274] - INFO: epoch 020:    107 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.242, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.46, wps=497.8, ups=0.1, wpb=5119.9, bsz=1280, num_updates=6050, lr=1.7842e-06, gnorm=0.01, clip=0, loss_scale=8192, train_wall=95, gb_free=9.7, wall=79473
2024-11-09 09:17:15 - progress_bar.py[line:274] - INFO: epoch 020:    117 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.241, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.45, wps=497.8, ups=0.1, wpb=5120, bsz=1280, num_updates=6060, lr=1.69924e-06, gnorm=0.008, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=79576
2024-11-09 09:18:58 - progress_bar.py[line:274] - INFO: epoch 020:    127 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.239, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.44, wps=496.3, ups=0.1, wpb=5120, bsz=1280, num_updates=6070, lr=1.61427e-06, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=79679
2024-11-09 09:20:42 - progress_bar.py[line:274] - INFO: epoch 020:    137 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.234, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.41, wps=492.4, ups=0.1, wpb=5119.9, bsz=1280, num_updates=6080, lr=1.52931e-06, gnorm=0.012, clip=0, loss_scale=8192, train_wall=104, gb_free=9.6, wall=79783
2024-11-09 09:22:26 - progress_bar.py[line:274] - INFO: epoch 020:    147 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.234, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.41, wps=494.6, ups=0.1, wpb=5120, bsz=1280, num_updates=6090, lr=1.44435e-06, gnorm=0.008, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=79886
2024-11-09 09:24:09 - progress_bar.py[line:274] - INFO: epoch 020:    157 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.233, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.4, wps=496.7, ups=0.1, wpb=5119.9, bsz=1280, num_updates=6100, lr=1.35939e-06, gnorm=0.013, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=79989
2024-11-09 09:25:53 - progress_bar.py[line:274] - INFO: epoch 020:    167 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.227, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.36, wps=494.7, ups=0.1, wpb=5120, bsz=1280, num_updates=6110, lr=1.27443e-06, gnorm=0.008, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=80093
2024-11-09 09:27:36 - progress_bar.py[line:274] - INFO: epoch 020:    177 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.226, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.36, wps=496.4, ups=0.1, wpb=5120, bsz=1280, num_updates=6120, lr=1.18946e-06, gnorm=0.012, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=80196
2024-11-09 09:29:19 - progress_bar.py[line:274] - INFO: epoch 020:    187 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.228, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.37, wps=495.5, ups=0.1, wpb=5120, bsz=1280, num_updates=6130, lr=1.1045e-06, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=80299
2024-11-09 09:31:03 - progress_bar.py[line:274] - INFO: epoch 020:    197 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.232, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.4, wps=493.5, ups=0.1, wpb=5119.9, bsz=1280, num_updates=6140, lr=1.01954e-06, gnorm=0.011, clip=0, loss_scale=8192, train_wall=104, gb_free=9.7, wall=80403
2024-11-09 09:32:46 - progress_bar.py[line:274] - INFO: epoch 020:    207 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.228, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.37, wps=497.2, ups=0.1, wpb=5119.8, bsz=1280, num_updates=6150, lr=9.34579e-07, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=80506
2024-11-09 09:34:29 - progress_bar.py[line:274] - INFO: epoch 020:    217 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.234, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.41, wps=497.7, ups=0.1, wpb=5120, bsz=1280, num_updates=6160, lr=8.49618e-07, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=80609
2024-11-09 09:36:12 - progress_bar.py[line:274] - INFO: epoch 020:    227 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.242, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.46, wps=492.8, ups=0.1, wpb=5119.8, bsz=1280, num_updates=6170, lr=7.64656e-07, gnorm=0.008, clip=0, loss_scale=8192, train_wall=104, gb_free=9.6, wall=80713
2024-11-09 09:37:56 - progress_bar.py[line:274] - INFO: epoch 020:    237 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.242, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.46, wps=496.2, ups=0.1, wpb=5120, bsz=1280, num_updates=6180, lr=6.79694e-07, gnorm=0.011, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=80816
2024-11-09 09:39:39 - progress_bar.py[line:274] - INFO: epoch 020:    247 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.223, ntokens=5119.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.34, wps=495.5, ups=0.1, wpb=5119.8, bsz=1280, num_updates=6190, lr=5.94732e-07, gnorm=0.009, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=80919
2024-11-09 09:41:22 - progress_bar.py[line:274] - INFO: epoch 020:    257 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.229, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.37, wps=497.3, ups=0.1, wpb=5120, bsz=1280, num_updates=6200, lr=5.09771e-07, gnorm=0.009, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=81022
2024-11-09 09:43:05 - progress_bar.py[line:274] - INFO: epoch 020:    267 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.223, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.34, wps=495.9, ups=0.1, wpb=5120, bsz=1280, num_updates=6210, lr=4.24809e-07, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=81125
2024-11-09 09:44:49 - progress_bar.py[line:274] - INFO: epoch 020:    277 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.224, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.35, wps=494, ups=0.1, wpb=5120, bsz=1280, num_updates=6220, lr=3.39847e-07, gnorm=0.008, clip=0, loss_scale=8192, train_wall=104, gb_free=9.6, wall=81229
2024-11-09 09:46:32 - progress_bar.py[line:274] - INFO: epoch 020:    287 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.237, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.43, wps=497.5, ups=0.1, wpb=5119.9, bsz=1280, num_updates=6230, lr=2.54885e-07, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.6, wall=81332
2024-11-09 09:48:15 - progress_bar.py[line:274] - INFO: epoch 020:    297 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.233, ntokens=5120, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.4, wps=496.3, ups=0.1, wpb=5120, bsz=1280, num_updates=6240, lr=1.69924e-07, gnorm=0.01, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=81435
2024-11-09 09:49:58 - progress_bar.py[line:274] - INFO: epoch 020:    307 / 313 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.236, ntokens=5119.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=9.42, wps=498, ups=0.1, wpb=5119.9, bsz=1280, num_updates=6250, lr=8.49618e-08, gnorm=0.008, clip=0, loss_scale=8192, train_wall=103, gb_free=9.7, wall=81538
slice_id 2 seek offset 13910slice_id 3 seek offset 20865
slice_id 1 seek offset 6955slice_id 4 seek offset 27820


2024-11-09 09:50:52 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 6 seek offset 41730slice_id 5 seek offset 34775

slice_id 0 seek offset 0
slice_id 7 seek offset 48685
slice_id 3 seek offset 20865
slice_id 5 seek offset 34775
slice_id 7 seek offset 48685
slice_id 6 seek offset 41730
slice_id 1 seek offset 6955
slice_id 2 seek offset 13910
slice_id 4 seek offset 27820
slice_id 0 seek offset 0
2024-11-09 09:58:14 - progress_bar.py[line:282] - INFO: epoch 020 | valid on 'valid' subset | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.242 | ntokens 639.537 | nsentences 159.885 | sample_size 159.885 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.46 | score 0.7739 | wps 505.7 | wpb 639.5 | bsz 159.9 | num_updates 6256 | best_score 0.7739
2024-11-09 09:58:14 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 20 @ 6256 updates
2024-11-09 09:58:14 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 2 row count 50000 total row count 400000file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 3 row count 50000 total row count 400000file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 6 row count 50000 total row count 400000


local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 1 row count 50000 total row count 400000
slice_id 1 seek offset 50000
slice_id 3 seek offset 150000
slice_id 5 seek offset 250000
slice_id 6 seek offset 300000
slice_id 2 seek offset 100000
slice_id 4 seek offset 200000
slice_id 7 seek offset 350000
2024-11-09 09:59:15 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt
2024-11-09 10:00:11 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_best.pt (epoch 20 @ 6256 updates, score 0.7739) (writing took 116.88871533301426 seconds)
2024-11-09 10:00:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 20 @ 6256 updates
2024-11-09 10:00:11 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-09 10:01:12 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt
2024-11-09 10:01:12 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_manufact_uniq_80_checkpoints/20_5e-5_512/checkpoint_last.pt (epoch 20 @ 6256 updates, score 0) (writing took 60.79110795602901 seconds)
2024-11-09 10:01:12 - train.py[line:336] - INFO: end of epoch 20 (average epoch stats below)
2024-11-09 10:01:12 - progress_bar.py[line:282] - INFO: epoch 020 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 3.235 | ntokens 5111.78 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.41 | wps 358.6 | ups 0.07 | wpb 5111.8 | bsz 1278 | num_updates 6256 | lr 3.39847e-08 | gnorm 0.011 | clip 0 | loss_scale 16384 | train_wall 2801 | gb_free 9.7 | wall 82212
2024-11-09 10:01:12 - trainer.py[line:639] - INFO: loading train data for epoch 21
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_manufact_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-09 10:01:15 - train.py[line:206] - INFO: done training in 82210.2 seconds
