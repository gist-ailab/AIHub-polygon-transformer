/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launch.py:188: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  FutureWarning,
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2024-11-01 18:17:57 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-01 18:17:57 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-01 18:17:57 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-01 18:17:57 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-01 18:17:57 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-01 18:17:57 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-01 18:17:57 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-01 18:17:57 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-01 18:18:00 - utils.py[line:258] - INFO: distributed init (rank 3): env://
2024-11-01 18:18:00 - utils.py[line:261] - INFO: Start init
2024-11-01 18:18:00 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 3
2024-11-01 18:18:00 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2024-11-01 18:18:00 - utils.py[line:261] - INFO: Start init
2024-11-01 18:18:00 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2024-11-01 18:18:00 - utils.py[line:258] - INFO: distributed init (rank 7): env://
2024-11-01 18:18:00 - utils.py[line:261] - INFO: Start init
2024-11-01 18:18:00 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 7
2024-11-01 18:18:00 - utils.py[line:258] - INFO: distributed init (rank 2): env://
2024-11-01 18:18:00 - utils.py[line:261] - INFO: Start init
2024-11-01 18:18:00 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 2
2024-11-01 18:18:00 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2024-11-01 18:18:00 - utils.py[line:261] - INFO: Start init
2024-11-01 18:18:00 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2024-11-01 18:18:00 - utils.py[line:258] - INFO: distributed init (rank 6): env://
2024-11-01 18:18:00 - utils.py[line:261] - INFO: Start init
2024-11-01 18:18:00 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 6
2024-11-01 18:18:00 - utils.py[line:258] - INFO: distributed init (rank 4): env://
2024-11-01 18:18:00 - utils.py[line:261] - INFO: Start init
2024-11-01 18:18:00 - utils.py[line:258] - INFO: distributed init (rank 5): env://
2024-11-01 18:18:00 - utils.py[line:261] - INFO: Start init
2024-11-01 18:18:00 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 5
2024-11-01 18:18:00 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 4
2024-11-01 18:18:00 - distributed_c10d.py[line:354] - INFO: Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-01 18:18:00 - distributed_c10d.py[line:354] - INFO: Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-01 18:18:00 - utils.py[line:274] - INFO: initialized host ip-172-31-38-178 as rank 4
single-machine distributed training is initialized.
2024-11-01 18:18:00 - utils.py[line:274] - INFO: initialized host ip-172-31-38-178 as rank 5
single-machine distributed training is initialized.
2024-11-01 18:18:00 - distributed_c10d.py[line:354] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-01 18:18:00 - utils.py[line:274] - INFO: initialized host ip-172-31-38-178 as rank 0
single-machine distributed training is initialized.
2024-11-01 18:18:00 - distributed_c10d.py[line:354] - INFO: Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-01 18:18:00 - utils.py[line:274] - INFO: initialized host ip-172-31-38-178 as rank 7
single-machine distributed training is initialized.
2024-11-01 18:18:00 - distributed_c10d.py[line:354] - INFO: Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-01 18:18:00 - utils.py[line:274] - INFO: initialized host ip-172-31-38-178 as rank 2
single-machine distributed training is initialized.
2024-11-01 18:18:00 - distributed_c10d.py[line:354] - INFO: Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-01 18:18:00 - utils.py[line:274] - INFO: initialized host ip-172-31-38-178 as rank 6
single-machine distributed training is initialized.
2024-11-01 18:18:00 - distributed_c10d.py[line:354] - INFO: Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-01 18:18:00 - utils.py[line:274] - INFO: initialized host ip-172-31-38-178 as rank 3
single-machine distributed training is initialized.
2024-11-01 18:18:00 - distributed_c10d.py[line:354] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-01 18:18:00 - utils.py[line:274] - INFO: initialized host ip-172-31-38-178 as rank 1
single-machine distributed training is initialized.
2024-11-01 18:18:06 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../polyformer_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 1000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 20, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 20, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512', 'restore_file': '../pretrain/polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_16_5000.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 1000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'score', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='polyformer_b', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='polyformer_b', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid=20, best_checkpoint_metric='score', bf16=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, cls_weight=0.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../datasets/pretrain/train_aihub_indoor_80.tsv,../../datasets/pretrain/val_aihub_indoor_80.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, det_weight=1.0, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_acc=True, eval_args='{"beam":5,"min_len":2,"max_len_a":0,"max_len_b":2}', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=20, max_image_size=512, max_source_positions=1024, max_src_length=80, max_target_positions=1024, max_tgt_length=420, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=8, num_bins=64, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', out_index=3, pad=1, patch_image_size=512, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, restore_file='../pretrain/polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_16_5000.pt', sample_patch_num=196, save_dir='./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512', save_interval=1, save_interval_updates=1000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', scst=False, scst_args='{}', seed=1, selected_cols='0,3,1,2', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='refcoco_pretrain', tensorboard_logdir=None, threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[8], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../polyformer_module', uses_ema=False, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=1000, vis_encoder_type='swin-base', wandb_project=None, warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'refcoco_pretrain', 'data': '../../datasets/pretrain/train_aihub_indoor_80.tsv,../../datasets/pretrain/val_aihub_indoor_80.tsv', 'selected_cols': '0,3,1,2', 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 80, 'max_tgt_length': 420, 'code_dict_size': 8192, 'patch_image_size': 512, 'num_bins': 64, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': True, 'eval_args': '{"beam":5,"min_len":2,"max_len_a":0,"max_len_b":2}', 'uses_ema': False, 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'det_weight': 1.0, 'cls_weight': 0.0, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2024-11-01 18:18:06 - base_task.py[line:187] - INFO: source dictionary: 4100 types
2024-11-01 18:18:06 - base_task.py[line:188] - INFO: target dictionary: 4100 types
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Downloading config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]Downloading config.json: 100%|██████████| 615/615 [00:00<00:00, 368kB/s]
Downloading model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]Downloading model.safetensors:   1%|          | 10.5M/1.12G [00:00<00:11, 100MB/s]Downloading model.safetensors:   3%|▎         | 31.5M/1.12G [00:00<00:07, 137MB/s]Downloading model.safetensors:   5%|▍         | 52.4M/1.12G [00:00<00:06, 152MB/s]Downloading model.safetensors:   7%|▋         | 73.4M/1.12G [00:00<00:06, 159MB/s]Downloading model.safetensors:   8%|▊         | 94.4M/1.12G [00:00<00:06, 163MB/s]Downloading model.safetensors:  10%|█         | 115M/1.12G [00:00<00:06, 166MB/s] Downloading model.safetensors:  12%|█▏        | 136M/1.12G [00:00<00:05, 168MB/s]Downloading model.safetensors:  14%|█▍        | 157M/1.12G [00:00<00:05, 168MB/s]Downloading model.safetensors:  16%|█▌        | 178M/1.12G [00:01<00:05, 169MB/s]Downloading model.safetensors:  18%|█▊        | 199M/1.12G [00:01<00:05, 170MB/s]Downloading model.safetensors:  20%|█▉        | 220M/1.12G [00:01<00:05, 159MB/s]Downloading model.safetensors:  22%|██▏       | 241M/1.12G [00:01<00:05, 166MB/s]Downloading model.safetensors:  23%|██▎       | 262M/1.12G [00:01<00:05, 170MB/s]Downloading model.safetensors:  25%|██▌       | 283M/1.12G [00:01<00:04, 172MB/s]Downloading model.safetensors:  27%|██▋       | 304M/1.12G [00:01<00:04, 174MB/s]Downloading model.safetensors:  29%|██▉       | 325M/1.12G [00:01<00:04, 175MB/s]Downloading model.safetensors:  31%|███       | 346M/1.12G [00:02<00:04, 175MB/s]Downloading model.safetensors:  33%|███▎      | 367M/1.12G [00:02<00:04, 175MB/s]Downloading model.safetensors:  35%|███▍      | 388M/1.12G [00:02<00:04, 176MB/s]Downloading model.safetensors:  37%|███▋      | 409M/1.12G [00:02<00:03, 177MB/s]Downloading model.safetensors:  39%|███▊      | 430M/1.12G [00:02<00:03, 178MB/s]Downloading model.safetensors:  40%|████      | 451M/1.12G [00:02<00:03, 177MB/s]Downloading model.safetensors:  42%|████▏     | 472M/1.12G [00:02<00:03, 178MB/s]Downloading model.safetensors:  44%|████▍     | 493M/1.12G [00:02<00:03, 177MB/s]Downloading model.safetensors:  46%|████▌     | 514M/1.12G [00:03<00:03, 177MB/s]Downloading model.safetensors:  48%|████▊     | 535M/1.12G [00:03<00:03, 176MB/s]Downloading model.safetensors:  50%|████▉     | 556M/1.12G [00:03<00:03, 177MB/s]Downloading model.safetensors:  52%|█████▏    | 577M/1.12G [00:03<00:03, 177MB/s]Downloading model.safetensors:  54%|█████▎    | 598M/1.12G [00:03<00:02, 176MB/s]Downloading model.safetensors:  55%|█████▌    | 619M/1.12G [00:03<00:02, 176MB/s]Downloading model.safetensors:  57%|█████▋    | 640M/1.12G [00:03<00:02, 175MB/s]Downloading model.safetensors:  59%|█████▉    | 661M/1.12G [00:03<00:02, 175MB/s]Downloading model.safetensors:  61%|██████    | 682M/1.12G [00:03<00:02, 176MB/s]Downloading model.safetensors:  63%|██████▎   | 703M/1.12G [00:04<00:02, 176MB/s]Downloading model.safetensors:  65%|██████▍   | 724M/1.12G [00:04<00:02, 175MB/s]Downloading model.safetensors:  67%|██████▋   | 744M/1.12G [00:04<00:02, 175MB/s]Downloading model.safetensors:  69%|██████▊   | 765M/1.12G [00:04<00:01, 175MB/s]Downloading model.safetensors:  70%|███████   | 786M/1.12G [00:04<00:01, 176MB/s]Downloading model.safetensors:  72%|███████▏  | 807M/1.12G [00:04<00:01, 178MB/s]Downloading model.safetensors:  74%|███████▍  | 828M/1.12G [00:04<00:01, 178MB/s]Downloading model.safetensors:  76%|███████▌  | 849M/1.12G [00:04<00:01, 177MB/s]Downloading model.safetensors:  78%|███████▊  | 870M/1.12G [00:05<00:01, 177MB/s]Downloading model.safetensors:  80%|███████▉  | 891M/1.12G [00:05<00:01, 177MB/s]Downloading model.safetensors:  82%|████████▏ | 912M/1.12G [00:05<00:01, 176MB/s]Downloading model.safetensors:  84%|████████▎ | 933M/1.12G [00:05<00:01, 176MB/s]Downloading model.safetensors:  86%|████████▌ | 954M/1.12G [00:05<00:00, 173MB/s]Downloading model.safetensors:  87%|████████▋ | 975M/1.12G [00:05<00:00, 174MB/s]Downloading model.safetensors:  89%|████████▉ | 996M/1.12G [00:05<00:00, 175MB/s]Downloading model.safetensors:  91%|█████████ | 1.02G/1.12G [00:05<00:00, 175MB/s]Downloading model.safetensors:  93%|█████████▎| 1.04G/1.12G [00:06<00:00, 175MB/s]Downloading model.safetensors:  95%|█████████▍| 1.06G/1.12G [00:06<00:00, 175MB/s]Downloading model.safetensors:  97%|█████████▋| 1.08G/1.12G [00:06<00:00, 176MB/s]Downloading model.safetensors:  99%|█████████▊| 1.10G/1.12G [00:06<00:00, 176MB/s]Downloading model.safetensors: 100%|██████████| 1.12G/1.12G [00:06<00:00, 173MB/s]
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 3 row count 6839 total row count 54715
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
Downloading tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]Downloading tokenizer_config.json: 100%|██████████| 25.0/25.0 [00:00<00:00, 4.99kB/s]
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 4 row count 6839 total row count 54715
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 7 row count 6839 total row count 54715
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 5 row count 6839 total row count 54715
2024-11-01 18:18:25 - train.py[line:101] - INFO: PolyFormerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(4100, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): SwinTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (pos_drop): Dropout(p=0.0, inplace=False)
      (layers): ModuleList(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): Identity()
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.009)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=512, out_features=256, bias=False)
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=256, out_features=256, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.017)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=256, out_features=1024, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1024, out_features=256, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=256, out_features=256, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.026)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=256, out_features=1024, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1024, out_features=256, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=1024, out_features=512, bias=False)
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.035)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.043)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (2): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.052)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (3): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.061)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (4): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.070)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (5): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.078)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (6): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.087)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (7): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.096)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (8): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.104)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (9): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.113)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (10): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.122)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (11): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.130)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (12): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.139)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (13): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.148)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (14): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.157)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (15): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.165)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (16): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.174)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (17): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.183)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=2048, out_features=1024, bias=False)
            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.191)
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.200)
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
      )
      (norm3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
    (bert): XLMRobertaForMaskedLM(
      (roberta): XLMRobertaModel(
        (embeddings): XLMRobertaEmbeddings(
          (word_embeddings): Embedding(250002, 768, padding_idx=1)
          (position_embeddings): Embedding(514, 768, padding_idx=1)
          (token_type_embeddings): Embedding(1, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): XLMRobertaEncoder(
          (layer): ModuleList(
            (0): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
      )
      (lm_head): XLMRobertaLMHead(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (decoder): Linear(in_features=768, out_features=250002, bias=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(4100, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (reg_head): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): Linear(in_features=768, out_features=768, bias=True)
        (2): Linear(in_features=768, out_features=2, bias=True)
      )
    )
    (cls_head): Linear(in_features=768, out_features=3, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2024-11-01 18:18:25 - train.py[line:102] - INFO: task: RefcocoPretrainTask
2024-11-01 18:18:25 - train.py[line:103] - INFO: model: PolyFormerModel
2024-11-01 18:18:25 - train.py[line:104] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2024-11-01 18:18:25 - train.py[line:108] - INFO: num. shared model params: 478,547,732 (num. trained: 478,547,732)
2024-11-01 18:18:25 - train.py[line:115] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 6 row count 6839 total row count 54715
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 1 row count 6840 total row count 54715
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 2 row count 6840 total row count 54715
local datafile ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/val_aihub_indoor_80.tsv slice_id 0 row count 6840 total row count 54715
Downloading (…)tencepiece.bpe.model: 100%|██████████| 5.07M/5.07M [00:00<00:00, 19.6MB/s]Downloading (…)tencepiece.bpe.model: 100%|██████████| 5.07M/5.07M [00:00<00:00, 19.4MB/s]
Downloading tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]Downloading tokenizer.json: 100%|██████████| 9.10M/9.10M [00:00<00:00, 18.1MB/s]Downloading tokenizer.json: 100%|██████████| 9.10M/9.10M [00:00<00:00, 17.9MB/s]
2024-11-01 18:18:28 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2024-11-01 18:18:28 - distributed_c10d.py[line:354] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-11-01 18:18:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2024-11-01 18:18:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.layers.0.downsample.reduction.bias <- encoder.embed_images.layers.1.downsample.reduction.bias
2024-11-01 18:18:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.layers.0.downsample.reduction.bias <- encoder.embed_images.layers.2.downsample.reduction.bias
2024-11-01 18:18:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.layers.0.downsample.reduction.bias <- decoder.cls_head.bias
2024-11-01 18:18:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.bert.roberta.embeddings.word_embeddings.weight <- encoder.bert.lm_head.decoder.weight
2024-11-01 18:18:28 - trainer.py[line:124] - INFO: detected shared parameter: encoder.bert.lm_head.bias <- encoder.bert.lm_head.decoder.bias
2024-11-01 18:18:30 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 8 workers***********************
2024-11-01 18:18:30 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-01 18:18:30 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-01 18:18:30 - utils.py[line:765] - INFO: rank   2: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-01 18:18:30 - utils.py[line:765] - INFO: rank   3: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-01 18:18:30 - utils.py[line:765] - INFO: rank   4: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-01 18:18:30 - utils.py[line:765] - INFO: rank   5: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-01 18:18:30 - utils.py[line:765] - INFO: rank   6: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-01 18:18:30 - utils.py[line:765] - INFO: rank   7: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-01 18:18:30 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 8 workers***********************
2024-11-01 18:18:30 - train.py[line:145] - INFO: training on 8 devices (GPUs/TPUs)
2024-11-01 18:18:30 - train.py[line:151] - INFO: max tokens per device = None and max sentences per device = 20
2024-11-01 18:18:30 - trainer.py[line:458] - INFO: Preparing to load checkpoint ../pretrain/polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_16_5000.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
2024-11-01 18:18:42 - trainer.py[line:619] - INFO: Loaded checkpoint ../pretrain/polyformer_b_pretrain_aihub_indoor_80_checkpoints/20_5e-5_512/checkpoint_16_5000.pt (epoch 16 @ 0 updates)
2024-11-01 18:18:42 - trainer.py[line:639] - INFO: loading train data for epoch 1
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
slice_id 7 seek offset 350000
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
slice_id 2 seek offset 100000
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
slice_id 0 seek offset 0
slice_id 3 seek offset 150000
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
2024-11-01 18:18:44 - trainer.py[line:703] - INFO: begin training epoch 1
2024-11-01 18:18:44 - train.py[line:297] - INFO: Start iterating over samples
slice_id 1 seek offset 50000
slice_id 5 seek offset 250000
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
slice_id 6 seek offset 300000
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
slice_id 4 seek offset 200000
Total steps 6260, warmup steps 375, warmup_factor 0.0026666666666666666
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
loss_reg: 0.080322265625 loss_cls: 0.0
loss_reg: 0.1181640625 loss_cls: 0.0
loss_reg: 0.091796875 loss_cls: 0.0
loss_reg: 0.139892578125 loss_cls: 0.0
loss_reg: 0.09814453125 loss_cls: 0.0
loss_reg: 0.10455322265625 loss_cls: 0.0
loss_reg: 0.0689697265625 loss_cls: 0.0
loss_reg: 0.08880615234375 loss_cls: 0.0
loss_reg: 0.08380126953125 loss_cls: 0.0
loss_reg: 0.09844970703125 loss_cls: 0.0
loss_reg: 0.1036376953125 loss_cls: 0.0
loss_reg: 0.11065673828125 loss_cls: 0.0
loss_reg: 0.084716796875 loss_cls: 0.0
loss_reg: 0.0750732421875 loss_cls: 0.0
loss_reg: 0.08282470703125 loss_cls: 0.0
loss_reg: 0.09600830078125 loss_cls: 0.0
loss_reg: 0.087890625 loss_cls: 0.0
loss_reg: 0.0797119140625 loss_cls: 0.0
loss_reg: 0.081787109375 loss_cls: 0.0
loss_reg: 0.1136474609375 loss_cls: 0.0
loss_reg: 0.07684326171875 loss_cls: 0.0
loss_reg: 0.0955810546875 loss_cls: 0.0
loss_reg: 0.0859375 loss_cls: 0.0
loss_reg: 0.10052490234375 loss_cls: 0.0
loss_reg: 0.1146240234375 loss_cls: 0.0
loss_reg: 0.132568359375 loss_cls: 0.0
loss_reg: 0.10235595703125 loss_cls: 0.0
loss_reg: 0.0911865234375 loss_cls: 0.0
loss_reg: 0.07330322265625 loss_cls: 0.0
loss_reg: 0.0751953125 loss_cls: 0.0
loss_reg: 0.11492919921875 loss_cls: 0.0
loss_reg: 0.1143798828125 loss_cls: 0.0
loss_reg: 0.1021728515625 loss_cls: 0.0
loss_reg: 0.09564208984375 loss_cls: 0.0
loss_reg: 0.1156005859375 loss_cls: 0.0
loss_reg: 0.10205078125 loss_cls: 0.0
loss_reg: 0.118408203125 loss_cls: 0.0
loss_reg: 0.1243896484375 loss_cls: 0.0
loss_reg: 0.10308837890625 loss_cls: 0.0
loss_reg: 0.07757568359375 loss_cls: 0.0
loss_reg: 0.1094970703125 loss_cls: 0.0
loss_reg: 0.0892333984375 loss_cls: 0.0
loss_reg: 0.0960693359375 loss_cls: 0.0
loss_reg: 0.0784912109375 loss_cls: 0.0
loss_reg: 0.10430908203125 loss_cls: 0.0
loss_reg: 0.07293701171875 loss_cls: 0.0
loss_reg: 0.0880126953125 loss_cls: 0.0
loss_reg: 0.087890625 loss_cls: 0.0
loss_reg: 0.10833740234375 loss_cls: 0.0
loss_reg: 0.06756591796875 loss_cls: 0.0
loss_reg: 0.102783203125 loss_cls: 0.0
loss_reg: 0.10198974609375 loss_cls: 0.0
loss_reg: 0.0755615234375 loss_cls: 0.0
loss_reg: 0.125732421875 loss_cls: 0.0
loss_reg: 0.10028076171875 loss_cls: 0.0
loss_reg: 0.090576171875 loss_cls: 0.0
loss_reg: 0.10845947265625 loss_cls: 0.0
loss_reg: 0.1087646484375 loss_cls: 0.0
loss_reg: 0.1243896484375 loss_cls: 0.0
loss_reg: 0.10430908203125 loss_cls: 0.0
loss_reg: 0.1160888671875 loss_cls: 0.0
loss_reg: 0.06689453125 loss_cls: 0.0
loss_reg: 0.104248046875 loss_cls: 0.0
loss_reg: 0.07952880859375 loss_cls: 0.0
2024-11-01 18:21:01 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.622, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.31, wps=562.9, ups=0.11, wpb=5117.9, bsz=1280, num_updates=10, lr=1.33333e-06, gnorm=0.01, clip=0, loss_scale=128, train_wall=82, gb_free=9.7, wall=152
2024-11-01 18:22:43 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.623, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.32, wps=504, ups=0.1, wpb=5118.4, bsz=1280, num_updates=20, lr=2.66667e-06, gnorm=0.007, clip=0, loss_scale=128, train_wall=46, gb_free=9.7, wall=253
2024-11-01 18:24:25 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.623, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.32, wps=500.9, ups=0.1, wpb=5117.7, bsz=1280, num_updates=30, lr=4e-06, gnorm=0.008, clip=0, loss_scale=128, train_wall=42, gb_free=9.7, wall=355
2024-11-01 18:26:06 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.638, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.45, wps=504.7, ups=0.1, wpb=5117.7, bsz=1280, num_updates=40, lr=5.33333e-06, gnorm=0.007, clip=0, loss_scale=128, train_wall=45, gb_free=9.7, wall=457
2024-11-01 18:27:48 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.633, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.41, wps=502.7, ups=0.1, wpb=5118.3, bsz=1280, num_updates=50, lr=6.66667e-06, gnorm=0.006, clip=0, loss_scale=128, train_wall=46, gb_free=9.7, wall=559
2024-11-01 18:29:30 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.624, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.33, wps=501.8, ups=0.1, wpb=5118.4, bsz=1280, num_updates=60, lr=8e-06, gnorm=0.007, clip=0, loss_scale=128, train_wall=50, gb_free=9.7, wall=661
2024-11-01 18:31:13 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.62, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.3, wps=499.1, ups=0.1, wpb=5118.4, bsz=1280, num_updates=70, lr=9.33333e-06, gnorm=0.008, clip=0, loss_scale=128, train_wall=64, gb_free=9.7, wall=763
2024-11-01 18:32:56 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.614, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.24, wps=497.6, ups=0.1, wpb=5117.3, bsz=1280, num_updates=80, lr=1.06667e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=74, gb_free=9.7, wall=866
2024-11-01 18:34:38 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.606, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.18, wps=498.2, ups=0.1, wpb=5118.6, bsz=1280, num_updates=90, lr=1.2e-05, gnorm=0.011, clip=0, loss_scale=128, train_wall=89, gb_free=9.8, wall=969
2024-11-01 18:36:21 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.622, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.31, wps=500.9, ups=0.1, wpb=5118.3, bsz=1280, num_updates=100, lr=1.33333e-05, gnorm=0.009, clip=0, loss_scale=128, train_wall=99, gb_free=9.7, wall=1071
2024-11-01 18:38:04 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.62, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.29, wps=497.1, ups=0.1, wpb=5118.6, bsz=1280, num_updates=110, lr=1.46667e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=103, gb_free=9.7, wall=1174
2024-11-01 18:39:46 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.618, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.28, wps=500.8, ups=0.1, wpb=5117.7, bsz=1280, num_updates=120, lr=1.6e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=102, gb_free=9.7, wall=1276
2024-11-01 18:41:28 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.653, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.58, wps=500.5, ups=0.1, wpb=5118.7, bsz=1280, num_updates=130, lr=1.73333e-05, gnorm=0.006, clip=0, loss_scale=128, train_wall=102, gb_free=9.6, wall=1378
2024-11-01 18:43:10 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.637, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.44, wps=501.5, ups=0.1, wpb=5117.9, bsz=1280, num_updates=140, lr=1.86667e-05, gnorm=0.012, clip=0, loss_scale=128, train_wall=102, gb_free=9.8, wall=1480
2024-11-01 18:44:52 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.637, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.44, wps=500, ups=0.1, wpb=5117.6, bsz=1280, num_updates=150, lr=2e-05, gnorm=0.009, clip=0, loss_scale=128, train_wall=102, gb_free=9.8, wall=1583
2024-11-01 18:46:36 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.602, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.15, wps=496.4, ups=0.1, wpb=5117.6, bsz=1280, num_updates=160, lr=2.13333e-05, gnorm=0.008, clip=0, loss_scale=128, train_wall=103, gb_free=9.6, wall=1686
2024-11-01 18:48:18 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.608, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.2, wps=498.1, ups=0.1, wpb=5117.7, bsz=1280, num_updates=170, lr=2.26667e-05, gnorm=0.009, clip=0, loss_scale=128, train_wall=103, gb_free=9.7, wall=1789
2024-11-01 18:50:00 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.608, ntokens=5117.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.2, wps=501.6, ups=0.1, wpb=5117.5, bsz=1280, num_updates=180, lr=2.4e-05, gnorm=0.009, clip=0, loss_scale=128, train_wall=102, gb_free=9.7, wall=1891
2024-11-01 18:51:43 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.599, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.11, wps=500.9, ups=0.1, wpb=5117.7, bsz=1280, num_updates=190, lr=2.53333e-05, gnorm=0.009, clip=0, loss_scale=128, train_wall=102, gb_free=9.7, wall=1993
2024-11-01 18:53:25 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.63, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.38, wps=501.1, ups=0.1, wpb=5118, bsz=1280, num_updates=200, lr=2.66667e-05, gnorm=0.011, clip=0, loss_scale=128, train_wall=102, gb_free=9.7, wall=2095
2024-11-01 18:55:07 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.641, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.48, wps=500.5, ups=0.1, wpb=5118.2, bsz=1280, num_updates=210, lr=2.8e-05, gnorm=0.011, clip=0, loss_scale=128, train_wall=102, gb_free=9.7, wall=2197
2024-11-01 18:56:48 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.614, ntokens=5118.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.24, wps=504.4, ups=0.1, wpb=5118.8, bsz=1280, num_updates=220, lr=2.93333e-05, gnorm=0.015, clip=0, loss_scale=128, train_wall=101, gb_free=9.7, wall=2299
2024-11-01 18:58:31 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.671, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.73, wps=500.7, ups=0.1, wpb=5117.4, bsz=1280, num_updates=230, lr=3.06667e-05, gnorm=0.01, clip=0, loss_scale=128, train_wall=102, gb_free=9.7, wall=2401
2024-11-01 19:00:14 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.641, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.47, wps=495.9, ups=0.1, wpb=5117.9, bsz=1280, num_updates=240, lr=3.2e-05, gnorm=0.01, clip=0, loss_scale=128, train_wall=103, gb_free=9.7, wall=2504
2024-11-01 19:01:56 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.67, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.73, wps=502.8, ups=0.1, wpb=5118.2, bsz=1280, num_updates=250, lr=3.33333e-05, gnorm=0.012, clip=0, loss_scale=128, train_wall=102, gb_free=9.7, wall=2606
2024-11-01 19:03:38 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.636, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.43, wps=498.4, ups=0.1, wpb=5118.1, bsz=1280, num_updates=260, lr=3.46667e-05, gnorm=0.015, clip=0, loss_scale=128, train_wall=103, gb_free=9.7, wall=2709
2024-11-01 19:05:20 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.672, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.74, wps=500.9, ups=0.1, wpb=5118.1, bsz=1280, num_updates=270, lr=3.6e-05, gnorm=0.011, clip=0, loss_scale=128, train_wall=102, gb_free=9.7, wall=2811
2024-11-01 19:07:03 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.63, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.38, wps=500.6, ups=0.1, wpb=5118.6, bsz=1280, num_updates=280, lr=3.73333e-05, gnorm=0.013, clip=0, loss_scale=128, train_wall=102, gb_free=9.7, wall=2913
2024-11-01 19:08:45 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.63, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.38, wps=498, ups=0.1, wpb=5117.6, bsz=1280, num_updates=290, lr=3.86667e-05, gnorm=0.013, clip=0, loss_scale=128, train_wall=103, gb_free=9.7, wall=3016
2024-11-01 19:10:29 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.649, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.54, wps=495.9, ups=0.1, wpb=5118.7, bsz=1280, num_updates=300, lr=4e-05, gnorm=0.012, clip=0, loss_scale=128, train_wall=103, gb_free=9.6, wall=3119
2024-11-01 19:12:13 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.656, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.6, wps=491.2, ups=0.1, wpb=5118.2, bsz=1280, num_updates=310, lr=4.13333e-05, gnorm=0.015, clip=0, loss_scale=128, train_wall=104, gb_free=9.7, wall=3223
slice_id 2 seek offset 13680
slice_id 6 seek offset 41037
slice_id 3 seek offset 20520
slice_id 1 seek offset 6840
slice_id 4 seek offset 27359
slice_id 5 seek offset 34198
slice_id 7 seek offset 47876
2024-11-01 19:12:37 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 2 seek offset 13680
slice_id 4 seek offset 27359
slice_id 1 seek offset 6840
slice_id 3 seek offset 20520
slice_id 6 seek offset 41037
slice_id 7 seek offset 47876
slice_id 5 seek offset 34198
slice_id 0 seek offset 0
2024-11-01 19:19:57 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.668 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.71 | score 0.4919 | wps 498.7 | wpb 639.7 | bsz 160 | num_updates 313
2024-11-01 19:19:57 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 313 updates
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2024-11-01 19:19:58 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000

slice_id 3 seek offset 150000
slice_id 4 seek offset 200000
slice_id 2 seek offset 100000
slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
slice_id 5 seek offset 250000
slice_id 6 seek offset 300000
2024-11-01 19:20:08 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_best.pt
2024-11-01 19:20:20 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_best.pt (epoch 1 @ 313 updates, score 0.4919) (writing took 22.316229579999344 seconds)
2024-11-01 19:20:20 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 313 updates
2024-11-01 19:20:20 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-01 19:21:54 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-01 19:21:54 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt (epoch 1 @ 313 updates, score 0) (writing took 94.11981945200023 seconds)
2024-11-01 19:21:54 - train.py[line:336] - INFO: end of epoch 1 (average epoch stats below)
2024-11-01 19:21:54 - progress_bar.py[line:282] - INFO: epoch 001 | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.631 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.39 | wps 426.9 | ups 0.08 | wpb 5109.9 | bsz 1278 | num_updates 313 | lr 4.17333e-05 | gnorm 0.01 | clip 0 | loss_scale 128 | train_wall 2811 | gb_free 9.7 | wall 3804
2024-11-01 19:21:54 - trainer.py[line:639] - INFO: loading train data for epoch 2
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-01 19:21:57 - trainer.py[line:703] - INFO: begin training epoch 2
2024-11-01 19:21:57 - train.py[line:297] - INFO: Start iterating over samples
2024-11-01 19:23:11 - progress_bar.py[line:274] - INFO: epoch 002:      7 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.654, ntokens=4862, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=12.59, wps=73.9, ups=0.02, wpb=4862, bsz=1216, num_updates=320, lr=4.26667e-05, gnorm=0.014, clip=0, loss_scale=128, train_wall=49, gb_free=9.7, wall=3881
2024-11-01 19:24:53 - progress_bar.py[line:274] - INFO: epoch 002:     17 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.682, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.83, wps=500.7, ups=0.1, wpb=5118.1, bsz=1280, num_updates=330, lr=4.4e-05, gnorm=0.011, clip=0, loss_scale=128, train_wall=35, gb_free=9.7, wall=3984
2024-11-01 19:26:35 - progress_bar.py[line:274] - INFO: epoch 002:     27 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.668, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.71, wps=504.3, ups=0.1, wpb=5117.6, bsz=1280, num_updates=340, lr=4.53333e-05, gnorm=0.012, clip=0, loss_scale=128, train_wall=35, gb_free=9.7, wall=4085
2024-11-01 19:28:16 - progress_bar.py[line:274] - INFO: epoch 002:     37 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.693, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.93, wps=504.1, ups=0.1, wpb=5117.6, bsz=1280, num_updates=350, lr=4.66667e-05, gnorm=0.015, clip=0, loss_scale=128, train_wall=35, gb_free=9.7, wall=4187
2024-11-01 19:29:58 - progress_bar.py[line:274] - INFO: epoch 002:     47 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.634, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.42, wps=503.7, ups=0.1, wpb=5118.2, bsz=1280, num_updates=360, lr=4.8e-05, gnorm=0.019, clip=0, loss_scale=128, train_wall=35, gb_free=9.7, wall=4288
2024-11-01 19:31:39 - progress_bar.py[line:274] - INFO: epoch 002:     57 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.66, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.64, wps=506.3, ups=0.1, wpb=5118.4, bsz=1280, num_updates=370, lr=4.93333e-05, gnorm=0.018, clip=0, loss_scale=128, train_wall=35, gb_free=9.7, wall=4389
2024-11-01 19:33:21 - progress_bar.py[line:274] - INFO: epoch 002:     67 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.616, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.26, wps=502.3, ups=0.1, wpb=5118.4, bsz=1280, num_updates=380, lr=4.99575e-05, gnorm=0.012, clip=0, loss_scale=128, train_wall=35, gb_free=9.7, wall=4491
2024-11-01 19:35:03 - progress_bar.py[line:274] - INFO: epoch 002:     77 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.617, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.27, wps=503.3, ups=0.1, wpb=5117.7, bsz=1280, num_updates=390, lr=4.98726e-05, gnorm=0.017, clip=0, loss_scale=128, train_wall=35, gb_free=9.7, wall=4593
2024-11-01 19:36:44 - progress_bar.py[line:274] - INFO: epoch 002:     87 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.599, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.12, wps=504.9, ups=0.1, wpb=5118.1, bsz=1280, num_updates=400, lr=4.97876e-05, gnorm=0.01, clip=0, loss_scale=128, train_wall=35, gb_free=9.7, wall=4694
2024-11-01 19:38:26 - progress_bar.py[line:274] - INFO: epoch 002:     97 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.579, ntokens=5118.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.95, wps=503.4, ups=0.1, wpb=5118.9, bsz=1280, num_updates=410, lr=4.97026e-05, gnorm=0.011, clip=0, loss_scale=128, train_wall=35, gb_free=9.7, wall=4796
2024-11-01 19:40:08 - progress_bar.py[line:274] - INFO: epoch 002:    107 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.577, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.93, wps=501.8, ups=0.1, wpb=5118.3, bsz=1280, num_updates=420, lr=4.96177e-05, gnorm=0.011, clip=0, loss_scale=128, train_wall=35, gb_free=9.7, wall=4898
2024-11-01 19:41:51 - progress_bar.py[line:274] - INFO: epoch 002:    117 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.562, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.81, wps=493.9, ups=0.1, wpb=5117.8, bsz=1280, num_updates=430, lr=4.95327e-05, gnorm=0.015, clip=0, loss_scale=128, train_wall=35, gb_free=9.7, wall=5002
2024-11-01 19:43:35 - progress_bar.py[line:274] - INFO: epoch 002:    127 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.518, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.45, wps=493.9, ups=0.1, wpb=5118.3, bsz=1280, num_updates=440, lr=4.94477e-05, gnorm=0.011, clip=0, loss_scale=128, train_wall=35, gb_free=9.7, wall=5105
2024-11-01 19:45:18 - progress_bar.py[line:274] - INFO: epoch 002:    137 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.491, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.24, wps=495.7, ups=0.1, wpb=5118.4, bsz=1280, num_updates=450, lr=4.93628e-05, gnorm=0.009, clip=0, loss_scale=128, train_wall=35, gb_free=9.7, wall=5208
2024-11-01 19:47:00 - progress_bar.py[line:274] - INFO: epoch 002:    147 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.521, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.48, wps=502.6, ups=0.1, wpb=5117.4, bsz=1280, num_updates=460, lr=4.92778e-05, gnorm=0.012, clip=0, loss_scale=128, train_wall=35, gb_free=9.7, wall=5310
2024-11-01 19:48:41 - progress_bar.py[line:274] - INFO: epoch 002:    157 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.517, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.45, wps=506.3, ups=0.1, wpb=5117.6, bsz=1280, num_updates=470, lr=4.91929e-05, gnorm=0.011, clip=0, loss_scale=128, train_wall=35, gb_free=9.7, wall=5411
2024-11-01 19:50:25 - progress_bar.py[line:274] - INFO: epoch 002:    167 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.54, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.63, wps=491.4, ups=0.1, wpb=5117.9, bsz=1280, num_updates=480, lr=4.91079e-05, gnorm=0.012, clip=0, loss_scale=128, train_wall=35, gb_free=9.7, wall=5516
2024-11-01 19:52:08 - progress_bar.py[line:274] - INFO: epoch 002:    177 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.577, ntokens=5117.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.94, wps=497.4, ups=0.1, wpb=5117.5, bsz=1280, num_updates=490, lr=4.90229e-05, gnorm=0.012, clip=0, loss_scale=128, train_wall=35, gb_free=9.7, wall=5618
2024-11-01 19:53:50 - progress_bar.py[line:274] - INFO: epoch 002:    187 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.584, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.99, wps=504.4, ups=0.1, wpb=5117.7, bsz=1280, num_updates=500, lr=4.8938e-05, gnorm=0.009, clip=0, loss_scale=128, train_wall=35, gb_free=9.7, wall=5720
2024-11-01 19:55:31 - progress_bar.py[line:274] - INFO: epoch 002:    197 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.599, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.12, wps=506.3, ups=0.1, wpb=5117.6, bsz=1280, num_updates=510, lr=4.8853e-05, gnorm=0.011, clip=0, loss_scale=128, train_wall=35, gb_free=9.7, wall=5821
2024-11-01 19:57:12 - progress_bar.py[line:274] - INFO: epoch 002:    207 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.622, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.31, wps=505.1, ups=0.1, wpb=5118.3, bsz=1280, num_updates=520, lr=4.87681e-05, gnorm=0.011, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=5922
2024-11-01 19:58:53 - progress_bar.py[line:274] - INFO: epoch 002:    217 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.631, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.39, wps=504.6, ups=0.1, wpb=5118.6, bsz=1280, num_updates=530, lr=4.86831e-05, gnorm=0.014, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=6024
2024-11-01 20:00:35 - progress_bar.py[line:274] - INFO: epoch 002:    227 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.641, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.48, wps=503.3, ups=0.1, wpb=5118.3, bsz=1280, num_updates=540, lr=4.85981e-05, gnorm=0.019, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=6125
2024-11-01 20:02:17 - progress_bar.py[line:274] - INFO: epoch 002:    237 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.594, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.07, wps=501.4, ups=0.1, wpb=5117.3, bsz=1280, num_updates=550, lr=4.85132e-05, gnorm=0.012, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=6227
2024-11-01 20:03:59 - progress_bar.py[line:274] - INFO: epoch 002:    247 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.602, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.14, wps=504.6, ups=0.1, wpb=5118.3, bsz=1280, num_updates=560, lr=4.84282e-05, gnorm=0.017, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=6329
2024-11-01 20:05:40 - progress_bar.py[line:274] - INFO: epoch 002:    257 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.607, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.19, wps=504, ups=0.1, wpb=5118, bsz=1280, num_updates=570, lr=4.83432e-05, gnorm=0.012, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=6430
2024-11-01 20:07:22 - progress_bar.py[line:274] - INFO: epoch 002:    267 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.615, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.25, wps=505, ups=0.1, wpb=5117.8, bsz=1280, num_updates=580, lr=4.82583e-05, gnorm=0.012, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=6532
2024-11-01 20:09:03 - progress_bar.py[line:274] - INFO: epoch 002:    277 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.561, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.8, wps=504.1, ups=0.1, wpb=5118.7, bsz=1280, num_updates=590, lr=4.81733e-05, gnorm=0.013, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=6633
2024-11-01 20:10:44 - progress_bar.py[line:274] - INFO: epoch 002:    287 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.517, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.45, wps=506.1, ups=0.1, wpb=5118.1, bsz=1280, num_updates=600, lr=4.80884e-05, gnorm=0.017, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=6734
2024-11-01 20:12:27 - progress_bar.py[line:274] - INFO: epoch 002:    297 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.545, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.67, wps=499.8, ups=0.1, wpb=5118.4, bsz=1280, num_updates=610, lr=4.80034e-05, gnorm=0.01, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=6837
2024-11-01 20:14:10 - progress_bar.py[line:274] - INFO: epoch 002:    307 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.5, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.31, wps=497.3, ups=0.1, wpb=5118, bsz=1280, num_updates=620, lr=4.79184e-05, gnorm=0.012, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=6940
slice_id 2 seek offset 13680
slice_id 6 seek offset 41037
slice_id 1 seek offset 6840
slice_id 3 seek offset 20520
slice_id 7 seek offset 47876
slice_id 5 seek offset 34198
slice_id 4 seek offset 27359
2024-11-01 20:15:04 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 2 seek offset 13680
slice_id 4 seek offset 27359
slice_id 3 seek offset 20520
slice_id 1 seek offset 6840
slice_id 6 seek offset 41037
slice_id 7 seek offset 47876
slice_id 5 seek offset 34198
slice_id 0 seek offset 0
2024-11-01 20:22:29 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.542 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.64 | score 0.4899 | wps 492.7 | wpb 639.7 | bsz 160 | num_updates 626 | best_score 0.4919
2024-11-01 20:22:29 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 626 updates
2024-11-01 20:22:29 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000
slice_id 2 seek offset 100000
slice_id 4 seek offset 200000
slice_id 3 seek offset 150000
slice_id 6 seek offset 300000
slice_id 5 seek offset 250000
slice_id 7 seek offset 350000
slice_id 1 seek offset 50000
2024-11-01 20:23:31 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-01 20:23:31 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt (epoch 2 @ 626 updates, score 0.4899) (writing took 61.76694686499832 seconds)
2024-11-01 20:23:31 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 626 updates
2024-11-01 20:23:31 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-01 20:24:32 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-01 20:24:32 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt (epoch 2 @ 626 updates, score 0) (writing took 61.31595024299895 seconds)
2024-11-01 20:24:32 - train.py[line:336] - INFO: end of epoch 2 (average epoch stats below)
2024-11-01 20:24:32 - progress_bar.py[line:282] - INFO: epoch 002 | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.589 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.03 | wps 425.5 | ups 0.08 | wpb 5109.9 | bsz 1278 | num_updates 626 | lr 4.78675e-05 | gnorm 0.013 | clip 0 | loss_scale 256 | train_wall 1092 | gb_free 9.7 | wall 7563
2024-11-01 20:24:32 - trainer.py[line:639] - INFO: loading train data for epoch 3
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-01 20:24:35 - trainer.py[line:703] - INFO: begin training epoch 3
2024-11-01 20:24:35 - train.py[line:297] - INFO: Start iterating over samples
2024-11-01 20:25:19 - progress_bar.py[line:274] - INFO: epoch 003:      4 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.523, ntokens=4862, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=11.5, wps=72.6, ups=0.01, wpb=4862, bsz=1216, num_updates=630, lr=4.78335e-05, gnorm=0.012, clip=0, loss_scale=256, train_wall=33, gb_free=9.7, wall=7609
2024-11-01 20:27:00 - progress_bar.py[line:274] - INFO: epoch 003:     14 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.505, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.35, wps=503.8, ups=0.1, wpb=5118.2, bsz=1280, num_updates=640, lr=4.77485e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=7711
2024-11-01 20:28:43 - progress_bar.py[line:274] - INFO: epoch 003:     24 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.541, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.64, wps=499.9, ups=0.1, wpb=5117.7, bsz=1280, num_updates=650, lr=4.76636e-05, gnorm=0.011, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=7813
2024-11-01 20:30:27 - progress_bar.py[line:274] - INFO: epoch 003:     34 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.506, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.36, wps=489.9, ups=0.1, wpb=5117.6, bsz=1280, num_updates=660, lr=4.75786e-05, gnorm=0.01, clip=0, loss_scale=256, train_wall=35, gb_free=9.8, wall=7917
2024-11-01 20:32:12 - progress_bar.py[line:274] - INFO: epoch 003:     44 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.556, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.76, wps=487.7, ups=0.1, wpb=5118, bsz=1280, num_updates=670, lr=4.74936e-05, gnorm=0.011, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=8022
2024-11-01 20:33:57 - progress_bar.py[line:274] - INFO: epoch 003:     54 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.555, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.75, wps=489.1, ups=0.1, wpb=5118.7, bsz=1280, num_updates=680, lr=4.74087e-05, gnorm=0.011, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=8127
2024-11-01 20:35:39 - progress_bar.py[line:274] - INFO: epoch 003:     64 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.575, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.92, wps=501.6, ups=0.1, wpb=5118.1, bsz=1280, num_updates=690, lr=4.73237e-05, gnorm=0.01, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=8229
2024-11-01 20:37:21 - progress_bar.py[line:274] - INFO: epoch 003:     74 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.562, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.81, wps=499.3, ups=0.1, wpb=5118, bsz=1280, num_updates=700, lr=4.72387e-05, gnorm=0.011, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=8332
2024-11-01 20:39:03 - progress_bar.py[line:274] - INFO: epoch 003:     84 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.597, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.1, wps=503.8, ups=0.1, wpb=5117.8, bsz=1280, num_updates=710, lr=4.71538e-05, gnorm=0.011, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=8433
2024-11-01 20:40:44 - progress_bar.py[line:274] - INFO: epoch 003:     94 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.62, ntokens=5118.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.29, wps=506.4, ups=0.1, wpb=5118.9, bsz=1280, num_updates=720, lr=4.70688e-05, gnorm=0.01, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=8534
2024-11-01 20:42:26 - progress_bar.py[line:274] - INFO: epoch 003:    104 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.613, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.24, wps=502.2, ups=0.1, wpb=5118.3, bsz=1280, num_updates=730, lr=4.69839e-05, gnorm=0.009, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=8636
2024-11-01 20:44:07 - progress_bar.py[line:274] - INFO: epoch 003:    114 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.589, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.03, wps=506, ups=0.1, wpb=5118, bsz=1280, num_updates=740, lr=4.68989e-05, gnorm=0.012, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=8737
2024-11-01 20:45:48 - progress_bar.py[line:274] - INFO: epoch 003:    124 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.635, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.42, wps=505, ups=0.1, wpb=5118.4, bsz=1280, num_updates=750, lr=4.68139e-05, gnorm=0.014, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=8839
2024-11-01 20:47:29 - progress_bar.py[line:274] - INFO: epoch 003:    134 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.593, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.06, wps=506.8, ups=0.1, wpb=5118.4, bsz=1280, num_updates=760, lr=4.6729e-05, gnorm=0.012, clip=0, loss_scale=256, train_wall=35, gb_free=9.8, wall=8940
2024-11-01 20:49:11 - progress_bar.py[line:274] - INFO: epoch 003:    144 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.605, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.17, wps=501.6, ups=0.1, wpb=5117.3, bsz=1280, num_updates=770, lr=4.6644e-05, gnorm=0.014, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=9042
2024-11-01 20:50:53 - progress_bar.py[line:274] - INFO: epoch 003:    154 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.569, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.87, wps=503.2, ups=0.1, wpb=5117.7, bsz=1280, num_updates=780, lr=4.6559e-05, gnorm=0.01, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=9143
2024-11-01 20:52:35 - progress_bar.py[line:274] - INFO: epoch 003:    164 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.59, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.04, wps=503.6, ups=0.1, wpb=5117.8, bsz=1280, num_updates=790, lr=4.64741e-05, gnorm=0.01, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=9245
2024-11-01 20:54:17 - progress_bar.py[line:274] - INFO: epoch 003:    174 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.576, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.92, wps=502.9, ups=0.1, wpb=5117.8, bsz=1280, num_updates=800, lr=4.63891e-05, gnorm=0.011, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=9347
2024-11-01 20:56:00 - progress_bar.py[line:274] - INFO: epoch 003:    184 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.599, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.12, wps=496.4, ups=0.1, wpb=5117.7, bsz=1280, num_updates=810, lr=4.63042e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=9450
2024-11-01 20:57:43 - progress_bar.py[line:274] - INFO: epoch 003:    194 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.611, ntokens=5117.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.22, wps=493.1, ups=0.1, wpb=5117.2, bsz=1280, num_updates=820, lr=4.62192e-05, gnorm=0.013, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=9554
2024-11-01 20:59:27 - progress_bar.py[line:274] - INFO: epoch 003:    204 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.617, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.27, wps=494.3, ups=0.1, wpb=5118.5, bsz=1280, num_updates=830, lr=4.61342e-05, gnorm=0.012, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=9657
2024-11-01 21:01:09 - progress_bar.py[line:274] - INFO: epoch 003:    214 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.612, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.22, wps=500.5, ups=0.1, wpb=5118.4, bsz=1280, num_updates=840, lr=4.60493e-05, gnorm=0.017, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=9759
2024-11-01 21:02:51 - progress_bar.py[line:274] - INFO: epoch 003:    224 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.614, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.24, wps=504, ups=0.1, wpb=5118.6, bsz=1280, num_updates=850, lr=4.59643e-05, gnorm=0.011, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=9861
2024-11-01 21:04:32 - progress_bar.py[line:274] - INFO: epoch 003:    234 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.646, ntokens=5117, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.52, wps=503.2, ups=0.1, wpb=5117, bsz=1280, num_updates=860, lr=4.58794e-05, gnorm=0.012, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=9963
2024-11-01 21:06:14 - progress_bar.py[line:274] - INFO: epoch 003:    244 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.622, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.31, wps=502.2, ups=0.1, wpb=5118.1, bsz=1280, num_updates=870, lr=4.57944e-05, gnorm=0.013, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=10065
2024-11-01 21:07:56 - progress_bar.py[line:274] - INFO: epoch 003:    254 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.638, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.45, wps=503.8, ups=0.1, wpb=5118.2, bsz=1280, num_updates=880, lr=4.57094e-05, gnorm=0.011, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=10166
2024-11-01 21:09:38 - progress_bar.py[line:274] - INFO: epoch 003:    264 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.669, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.72, wps=503.5, ups=0.1, wpb=5118.2, bsz=1280, num_updates=890, lr=4.56245e-05, gnorm=0.018, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=10268
2024-11-01 21:11:19 - progress_bar.py[line:274] - INFO: epoch 003:    274 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.647, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.53, wps=503.8, ups=0.1, wpb=5118.4, bsz=1280, num_updates=900, lr=4.55395e-05, gnorm=0.012, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=10369
2024-11-01 21:13:00 - progress_bar.py[line:274] - INFO: epoch 003:    284 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.655, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.6, wps=505.9, ups=0.1, wpb=5118.1, bsz=1280, num_updates=910, lr=4.54545e-05, gnorm=0.009, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=10471
2024-11-01 21:14:42 - progress_bar.py[line:274] - INFO: epoch 003:    294 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.667, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.7, wps=504, ups=0.1, wpb=5118.1, bsz=1280, num_updates=920, lr=4.53696e-05, gnorm=0.01, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=10572
2024-11-01 21:16:24 - progress_bar.py[line:274] - INFO: epoch 003:    304 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.644, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.5, wps=501, ups=0.1, wpb=5118, bsz=1280, num_updates=930, lr=4.52846e-05, gnorm=0.01, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=10674
slice_id 2 seek offset 13680
slice_id 6 seek offset 41037
slice_id 1 seek offset 6840
slice_id 3 seek offset 20520
slice_id 5 seek offset 34198slice_id 7 seek offset 47876slice_id 4 seek offset 27359


2024-11-01 21:17:48 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 2 seek offset 13680
slice_id 4 seek offset 27359
slice_id 1 seek offset 6840
slice_id 3 seek offset 20520
slice_id 5 seek offset 34198
slice_id 6 seek offset 41037
slice_id 7 seek offset 47876
slice_id 0 seek offset 0
2024-11-01 21:25:09 - progress_bar.py[line:282] - INFO: epoch 003 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.645 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.51 | score 0.4961 | wps 498.7 | wpb 639.7 | bsz 160 | num_updates 939 | best_score 0.4961
2024-11-01 21:25:09 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 939 updates
2024-11-01 21:25:09 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
slice_id 3 seek offset 150000
slice_id 2 seek offset 100000
slice_id 4 seek offset 200000
slice_id 1 seek offset 50000
slice_id 6 seek offset 300000
slice_id 5 seek offset 250000
slice_id 7 seek offset 350000
2024-11-01 21:26:10 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_best.pt
2024-11-01 21:27:25 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_best.pt (epoch 3 @ 939 updates, score 0.4961) (writing took 136.06418418300018 seconds)
2024-11-01 21:27:26 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 939 updates
2024-11-01 21:27:26 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-01 21:28:53 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-01 21:28:53 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt (epoch 3 @ 939 updates, score 0) (writing took 87.68273277499975 seconds)
2024-11-01 21:28:53 - train.py[line:336] - INFO: end of epoch 3 (average epoch stats below)
2024-11-01 21:28:53 - progress_bar.py[line:282] - INFO: epoch 003 | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.6 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.13 | wps 414.3 | ups 0.08 | wpb 5109.9 | bsz 1278 | num_updates 939 | lr 4.52082e-05 | gnorm 0.011 | clip 0 | loss_scale 256 | train_wall 1091 | gb_free 9.7 | wall 11423
2024-11-01 21:28:53 - trainer.py[line:639] - INFO: loading train data for epoch 4
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-01 21:28:56 - trainer.py[line:703] - INFO: begin training epoch 4
2024-11-01 21:28:56 - train.py[line:297] - INFO: Start iterating over samples
2024-11-01 21:29:09 - progress_bar.py[line:274] - INFO: epoch 004:      1 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.618, ntokens=4862.4, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=12.28, wps=63.6, ups=0.01, wpb=4862.4, bsz=1216, num_updates=940, lr=4.51997e-05, gnorm=0.012, clip=0, loss_scale=256, train_wall=33, gb_free=9.7, wall=11439
2024-11-01 21:30:51 - progress_bar.py[line:274] - INFO: epoch 004:     11 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.608, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.19, wps=501.5, ups=0.1, wpb=5117.8, bsz=1280, num_updates=950, lr=4.51147e-05, gnorm=0.011, clip=0, loss_scale=256, train_wall=35, gb_free=9.6, wall=11541
2024-11-01 21:32:33 - progress_bar.py[line:274] - INFO: epoch 004:     21 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.602, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.14, wps=502.4, ups=0.1, wpb=5118.3, bsz=1280, num_updates=960, lr=4.50297e-05, gnorm=0.011, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=11643
2024-11-01 21:34:16 - progress_bar.py[line:274] - INFO: epoch 004:     31 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.584, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.99, wps=499.3, ups=0.1, wpb=5117.8, bsz=1280, num_updates=970, lr=4.49448e-05, gnorm=0.009, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=11746
2024-11-01 21:35:57 - progress_bar.py[line:274] - INFO: epoch 004:     41 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.603, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.15, wps=503.2, ups=0.1, wpb=5117.8, bsz=1280, num_updates=980, lr=4.48598e-05, gnorm=0.01, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=11847
2024-11-01 21:37:40 - progress_bar.py[line:274] - INFO: epoch 004:     51 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.588, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.02, wps=500.4, ups=0.1, wpb=5118.2, bsz=1280, num_updates=990, lr=4.47749e-05, gnorm=0.012, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=11950
2024-11-01 21:39:21 - progress_bar.py[line:274] - INFO: epoch 004:     61 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.551, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.72, wps=502.6, ups=0.1, wpb=5118.5, bsz=1280, num_updates=1000, lr=4.46899e-05, gnorm=0.009, clip=0, loss_scale=256, train_wall=35, gb_free=9.7, wall=12052
slice_id 2 seek offset 13680
slice_id 6 seek offset 41037
slice_id 1 seek offset 6840
slice_id 3 seek offset 20520
slice_id 7 seek offset 47876
2024-11-01 21:39:21 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 4 seek offset 27359
slice_id 5 seek offset 34198
slice_id 2 seek offset 13680
slice_id 3 seek offset 20520
slice_id 4 seek offset 27359
slice_id 1 seek offset 6840
slice_id 6 seek offset 41037
slice_id 7 seek offset 47876
slice_id 5 seek offset 34198
slice_id 0 seek offset 0
2024-11-01 21:46:44 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.553 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.74 | score 0.4973 | wps 496.2 | wpb 639.7 | bsz 160 | num_updates 1000 | best_score 0.4973
2024-11-01 21:46:44 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 1000 updates
2024-11-01 21:46:44 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_4_1000.pt
2024-11-01 21:46:55 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_4_1000.pt
2024-11-01 21:49:43 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_4_1000.pt (epoch 4 @ 1000 updates, score 0.4973) (writing took 179.3582329339988 seconds)
2024-11-01 21:51:16 - progress_bar.py[line:274] - INFO: epoch 004:     71 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.515, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.43, wps=71.6, ups=0.01, wpb=5118.1, bsz=1280, num_updates=1010, lr=4.46049e-05, gnorm=0.012, clip=0, loss_scale=256, train_wall=35, gb_free=9.6, wall=12766
2024-11-01 21:52:59 - progress_bar.py[line:274] - INFO: epoch 004:     81 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.513, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.42, wps=494.6, ups=0.1, wpb=5117.3, bsz=1280, num_updates=1020, lr=4.452e-05, gnorm=0.016, clip=0, loss_scale=256, train_wall=35, gb_free=9.8, wall=12870
2024-11-01 21:54:43 - progress_bar.py[line:274] - INFO: epoch 004:     91 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.516, ntokens=5118.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.44, wps=492.1, ups=0.1, wpb=5118.8, bsz=1280, num_updates=1030, lr=4.4435e-05, gnorm=0.013, clip=0, loss_scale=512, train_wall=35, gb_free=9.6, wall=12974
2024-11-01 21:56:27 - progress_bar.py[line:274] - INFO: epoch 004:    101 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.507, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.37, wps=495.7, ups=0.1, wpb=5118.4, bsz=1280, num_updates=1040, lr=4.435e-05, gnorm=0.011, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=13077
2024-11-01 21:58:09 - progress_bar.py[line:274] - INFO: epoch 004:    111 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.498, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.3, wps=502.5, ups=0.1, wpb=5118.4, bsz=1280, num_updates=1050, lr=4.42651e-05, gnorm=0.011, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=13179
2024-11-01 21:59:50 - progress_bar.py[line:274] - INFO: epoch 004:    121 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.522, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.48, wps=502.7, ups=0.1, wpb=5117.9, bsz=1280, num_updates=1060, lr=4.41801e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=13281
2024-11-01 22:01:32 - progress_bar.py[line:274] - INFO: epoch 004:    131 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.556, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.76, wps=501.8, ups=0.1, wpb=5118.7, bsz=1280, num_updates=1070, lr=4.40952e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=13383
2024-11-01 22:03:15 - progress_bar.py[line:274] - INFO: epoch 004:    141 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.531, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.56, wps=499.3, ups=0.1, wpb=5117.4, bsz=1280, num_updates=1080, lr=4.40102e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=13485
2024-11-01 22:04:57 - progress_bar.py[line:274] - INFO: epoch 004:    151 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.542, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.65, wps=502.7, ups=0.1, wpb=5117.7, bsz=1280, num_updates=1090, lr=4.39252e-05, gnorm=0.01, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=13587
2024-11-01 22:06:38 - progress_bar.py[line:274] - INFO: epoch 004:    161 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.533, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.58, wps=505.3, ups=0.1, wpb=5117.8, bsz=1280, num_updates=1100, lr=4.38403e-05, gnorm=0.011, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=13688
2024-11-01 22:08:20 - progress_bar.py[line:274] - INFO: epoch 004:    171 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.519, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.46, wps=500.4, ups=0.1, wpb=5117.6, bsz=1280, num_updates=1110, lr=4.37553e-05, gnorm=0.011, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=13790
2024-11-01 22:10:02 - progress_bar.py[line:274] - INFO: epoch 004:    181 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.51, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.4, wps=503.2, ups=0.1, wpb=5117.7, bsz=1280, num_updates=1120, lr=4.36703e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=13892
2024-11-01 22:11:44 - progress_bar.py[line:274] - INFO: epoch 004:    191 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.52, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.47, wps=502.4, ups=0.1, wpb=5117.6, bsz=1280, num_updates=1130, lr=4.35854e-05, gnorm=0.011, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=13994
2024-11-01 22:13:26 - progress_bar.py[line:274] - INFO: epoch 004:    201 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.539, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.62, wps=502.2, ups=0.1, wpb=5118.1, bsz=1280, num_updates=1140, lr=4.35004e-05, gnorm=0.016, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=14096
2024-11-01 22:15:08 - progress_bar.py[line:274] - INFO: epoch 004:    211 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.542, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.65, wps=501.5, ups=0.1, wpb=5118.2, bsz=1280, num_updates=1150, lr=4.34155e-05, gnorm=0.015, clip=0, loss_scale=512, train_wall=35, gb_free=9.8, wall=14198
2024-11-01 22:16:50 - progress_bar.py[line:274] - INFO: epoch 004:    221 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.531, ntokens=5118.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.56, wps=501.4, ups=0.1, wpb=5118.9, bsz=1280, num_updates=1160, lr=4.33305e-05, gnorm=0.012, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=14300
2024-11-01 22:18:32 - progress_bar.py[line:274] - INFO: epoch 004:    231 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.554, ntokens=5117, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.74, wps=501.3, ups=0.1, wpb=5117, bsz=1280, num_updates=1170, lr=4.32455e-05, gnorm=0.01, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=14402
2024-11-01 22:20:15 - progress_bar.py[line:274] - INFO: epoch 004:    241 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.553, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.74, wps=496.8, ups=0.1, wpb=5118.3, bsz=1280, num_updates=1180, lr=4.31606e-05, gnorm=0.008, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=14505
2024-11-01 22:21:57 - progress_bar.py[line:274] - INFO: epoch 004:    251 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.524, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.51, wps=500, ups=0.1, wpb=5117.9, bsz=1280, num_updates=1190, lr=4.30756e-05, gnorm=0.011, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=14608
2024-11-01 22:23:40 - progress_bar.py[line:274] - INFO: epoch 004:    261 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.525, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.51, wps=500.3, ups=0.1, wpb=5118.3, bsz=1280, num_updates=1200, lr=4.29907e-05, gnorm=0.013, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=14710
2024-11-01 22:25:22 - progress_bar.py[line:274] - INFO: epoch 004:    271 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.513, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.42, wps=497.7, ups=0.1, wpb=5118.1, bsz=1280, num_updates=1210, lr=4.29057e-05, gnorm=0.013, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=14813
2024-11-01 22:27:05 - progress_bar.py[line:274] - INFO: epoch 004:    281 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.571, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.88, wps=498, ups=0.1, wpb=5118.6, bsz=1280, num_updates=1220, lr=4.28207e-05, gnorm=0.01, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=14915
2024-11-01 22:28:48 - progress_bar.py[line:274] - INFO: epoch 004:    291 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.543, ntokens=5117.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.65, wps=499.2, ups=0.1, wpb=5117.5, bsz=1280, num_updates=1230, lr=4.27358e-05, gnorm=0.013, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=15018
2024-11-01 22:30:31 - progress_bar.py[line:274] - INFO: epoch 004:    301 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.549, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.71, wps=496.4, ups=0.1, wpb=5118.7, bsz=1280, num_updates=1240, lr=4.26508e-05, gnorm=0.013, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=15121
2024-11-01 22:32:15 - progress_bar.py[line:274] - INFO: epoch 004:    311 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.533, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.58, wps=492.4, ups=0.1, wpb=5117.8, bsz=1280, num_updates=1250, lr=4.25658e-05, gnorm=0.01, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=15225
slice_id 6 seek offset 41037slice_id 1 seek offset 6840

slice_id 2 seek offset 13680
slice_id 3 seek offset 20520
slice_id 7 seek offset 47876
2024-11-01 22:32:28 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 4 seek offset 27359
slice_id 0 seek offset 0
slice_id 5 seek offset 34198
slice_id 2 seek offset 13680
slice_id 4 seek offset 27359
slice_id 3 seek offset 20520
slice_id 1 seek offset 6840
slice_id 5 seek offset 34198
slice_id 6 seek offset 41037
slice_id 7 seek offset 47876
slice_id 0 seek offset 0
2024-11-01 22:39:55 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.572 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.89 | score 0.4966 | wps 491.6 | wpb 639.7 | bsz 160 | num_updates 1252 | best_score 0.4973
2024-11-01 22:39:55 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 1252 updates
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
2024-11-01 22:39:55 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
slice_id 2 seek offset 100000
slice_id 6 seek offset 300000
slice_id 4 seek offset 200000
slice_id 1 seek offset 50000
slice_id 3 seek offset 150000
slice_id 7 seek offset 350000
slice_id 5 seek offset 250000
2024-11-01 22:40:56 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-01 22:40:56 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt (epoch 4 @ 1252 updates, score 0.4966) (writing took 61.07401941699936 seconds)
2024-11-01 22:40:56 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 1252 updates
2024-11-01 22:40:56 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-01 22:41:57 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-01 22:41:58 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt (epoch 4 @ 1252 updates, score 0) (writing took 61.813038370994036 seconds)
2024-11-01 22:41:58 - train.py[line:336] - INFO: end of epoch 4 (average epoch stats below)
2024-11-01 22:41:58 - progress_bar.py[line:282] - INFO: epoch 004 | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.542 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.65 | wps 364.8 | ups 0.07 | wpb 5109.9 | bsz 1278 | num_updates 1252 | lr 4.25489e-05 | gnorm 0.011 | clip 0 | loss_scale 512 | train_wall 1091 | gb_free 9.7 | wall 15808
2024-11-01 22:41:58 - trainer.py[line:639] - INFO: loading train data for epoch 5
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-01 22:42:00 - trainer.py[line:703] - INFO: begin training epoch 5
2024-11-01 22:42:00 - train.py[line:297] - INFO: Start iterating over samples
2024-11-01 22:43:25 - progress_bar.py[line:274] - INFO: epoch 005:      8 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.567, ntokens=4862.3, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=11.85, wps=72.6, ups=0.01, wpb=4862.3, bsz=1216, num_updates=1260, lr=4.24809e-05, gnorm=0.01, clip=0, loss_scale=512, train_wall=33, gb_free=9.7, wall=15895
2024-11-01 22:45:07 - progress_bar.py[line:274] - INFO: epoch 005:     18 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.569, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.87, wps=502.4, ups=0.1, wpb=5117.9, bsz=1280, num_updates=1270, lr=4.23959e-05, gnorm=0.012, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=15997
2024-11-01 22:46:50 - progress_bar.py[line:274] - INFO: epoch 005:     28 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.595, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.08, wps=498.3, ups=0.1, wpb=5117.7, bsz=1280, num_updates=1280, lr=4.2311e-05, gnorm=0.014, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=16100
2024-11-01 22:48:32 - progress_bar.py[line:274] - INFO: epoch 005:     38 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.561, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.8, wps=499.7, ups=0.1, wpb=5117.9, bsz=1280, num_updates=1290, lr=4.2226e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=16202
2024-11-01 22:50:14 - progress_bar.py[line:274] - INFO: epoch 005:     48 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.561, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.81, wps=501.3, ups=0.1, wpb=5118.2, bsz=1280, num_updates=1300, lr=4.2141e-05, gnorm=0.011, clip=0, loss_scale=512, train_wall=35, gb_free=9.8, wall=16304
2024-11-01 22:51:56 - progress_bar.py[line:274] - INFO: epoch 005:     58 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.537, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.6, wps=503.8, ups=0.1, wpb=5118.3, bsz=1280, num_updates=1310, lr=4.20561e-05, gnorm=0.01, clip=0, loss_scale=512, train_wall=35, gb_free=9.8, wall=16406
2024-11-01 22:53:38 - progress_bar.py[line:274] - INFO: epoch 005:     68 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.524, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.51, wps=498.9, ups=0.1, wpb=5118.5, bsz=1280, num_updates=1320, lr=4.19711e-05, gnorm=0.01, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=16508
2024-11-01 22:55:22 - progress_bar.py[line:274] - INFO: epoch 005:     78 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.501, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.32, wps=494.1, ups=0.1, wpb=5117.6, bsz=1280, num_updates=1330, lr=4.18862e-05, gnorm=0.008, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=16612
2024-11-01 22:57:04 - progress_bar.py[line:274] - INFO: epoch 005:     88 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.526, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.52, wps=501.9, ups=0.1, wpb=5118.1, bsz=1280, num_updates=1340, lr=4.18012e-05, gnorm=0.01, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=16714
2024-11-01 22:58:46 - progress_bar.py[line:274] - INFO: epoch 005:     98 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.514, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.42, wps=502.4, ups=0.1, wpb=5118.6, bsz=1280, num_updates=1350, lr=4.17162e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=16816
2024-11-01 23:00:28 - progress_bar.py[line:274] - INFO: epoch 005:    108 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.529, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.54, wps=500.8, ups=0.1, wpb=5118.5, bsz=1280, num_updates=1360, lr=4.16313e-05, gnorm=0.008, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=16918
2024-11-01 23:02:10 - progress_bar.py[line:274] - INFO: epoch 005:    118 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.541, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.64, wps=501.7, ups=0.1, wpb=5117.9, bsz=1280, num_updates=1370, lr=4.15463e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=17020
2024-11-01 23:03:52 - progress_bar.py[line:274] - INFO: epoch 005:    128 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.541, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.64, wps=503.3, ups=0.1, wpb=5118.5, bsz=1280, num_updates=1380, lr=4.14613e-05, gnorm=0.011, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=17122
2024-11-01 23:05:34 - progress_bar.py[line:274] - INFO: epoch 005:    138 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.585, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12, wps=499.7, ups=0.1, wpb=5118.1, bsz=1280, num_updates=1390, lr=4.13764e-05, gnorm=0.012, clip=0, loss_scale=512, train_wall=35, gb_free=9.8, wall=17224
2024-11-01 23:07:17 - progress_bar.py[line:274] - INFO: epoch 005:    148 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.571, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.89, wps=499.1, ups=0.1, wpb=5117.6, bsz=1280, num_updates=1400, lr=4.12914e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=17327
2024-11-01 23:08:59 - progress_bar.py[line:274] - INFO: epoch 005:    158 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.535, ntokens=5117.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.59, wps=499, ups=0.1, wpb=5117.5, bsz=1280, num_updates=1410, lr=4.12065e-05, gnorm=0.008, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=17429
2024-11-01 23:10:42 - progress_bar.py[line:274] - INFO: epoch 005:    168 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.525, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.51, wps=497.4, ups=0.1, wpb=5118.1, bsz=1280, num_updates=1420, lr=4.11215e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=17532
2024-11-01 23:12:25 - progress_bar.py[line:274] - INFO: epoch 005:    178 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.541, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.64, wps=496.3, ups=0.1, wpb=5117.3, bsz=1280, num_updates=1430, lr=4.10365e-05, gnorm=0.008, clip=0, loss_scale=512, train_wall=35, gb_free=9.6, wall=17635
2024-11-01 23:14:07 - progress_bar.py[line:274] - INFO: epoch 005:    188 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.538, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.61, wps=502.3, ups=0.1, wpb=5117.7, bsz=1280, num_updates=1440, lr=4.09516e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=17737
2024-11-01 23:15:49 - progress_bar.py[line:274] - INFO: epoch 005:    198 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.538, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.61, wps=502.8, ups=0.1, wpb=5117.7, bsz=1280, num_updates=1450, lr=4.08666e-05, gnorm=0.011, clip=0, loss_scale=512, train_wall=35, gb_free=9.6, wall=17839
2024-11-01 23:17:31 - progress_bar.py[line:274] - INFO: epoch 005:    208 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.527, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.53, wps=498.9, ups=0.1, wpb=5118.2, bsz=1280, num_updates=1460, lr=4.07816e-05, gnorm=0.01, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=17942
2024-11-01 23:19:14 - progress_bar.py[line:274] - INFO: epoch 005:    218 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.52, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.47, wps=497.3, ups=0.1, wpb=5118.6, bsz=1280, num_updates=1470, lr=4.06967e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=18044
2024-11-01 23:20:57 - progress_bar.py[line:274] - INFO: epoch 005:    228 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.53, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.55, wps=500, ups=0.1, wpb=5118.1, bsz=1280, num_updates=1480, lr=4.06117e-05, gnorm=0.01, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=18147
2024-11-01 23:22:39 - progress_bar.py[line:274] - INFO: epoch 005:    238 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.523, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.5, wps=499.5, ups=0.1, wpb=5117.4, bsz=1280, num_updates=1490, lr=4.05268e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=18249
2024-11-01 23:24:21 - progress_bar.py[line:274] - INFO: epoch 005:    248 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.502, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.33, wps=502.2, ups=0.1, wpb=5118.4, bsz=1280, num_updates=1500, lr=4.04418e-05, gnorm=0.01, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=18351
2024-11-01 23:26:03 - progress_bar.py[line:274] - INFO: epoch 005:    258 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.519, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.47, wps=502.8, ups=0.1, wpb=5118, bsz=1280, num_updates=1510, lr=4.03568e-05, gnorm=0.008, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=18453
2024-11-01 23:27:45 - progress_bar.py[line:274] - INFO: epoch 005:    268 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.511, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.4, wps=502, ups=0.1, wpb=5117.8, bsz=1280, num_updates=1520, lr=4.02719e-05, gnorm=0.011, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=18555
2024-11-01 23:29:26 - progress_bar.py[line:274] - INFO: epoch 005:    278 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.511, ntokens=5118.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.4, wps=504.4, ups=0.1, wpb=5118.8, bsz=1280, num_updates=1530, lr=4.01869e-05, gnorm=0.011, clip=0, loss_scale=512, train_wall=35, gb_free=9.7, wall=18656
2024-11-01 23:31:08 - progress_bar.py[line:274] - INFO: epoch 005:    288 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.533, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.58, wps=503.9, ups=0.1, wpb=5117.7, bsz=1280, num_updates=1540, lr=4.0102e-05, gnorm=0.012, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=18758
2024-11-01 23:32:49 - progress_bar.py[line:274] - INFO: epoch 005:    298 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.512, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.41, wps=503.9, ups=0.1, wpb=5118.7, bsz=1280, num_updates=1550, lr=4.0017e-05, gnorm=0.013, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=18860
2024-11-01 23:34:31 - progress_bar.py[line:274] - INFO: epoch 005:    308 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.535, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.59, wps=503, ups=0.1, wpb=5118, bsz=1280, num_updates=1560, lr=3.9932e-05, gnorm=0.011, clip=0, loss_scale=1024, train_wall=35, gb_free=9.6, wall=18961
slice_id 2 seek offset 13680
slice_id 6 seek offset 41037
slice_id 1 seek offset 6840
slice_id 3 seek offset 20520
slice_id 5 seek offset 34198slice_id 7 seek offset 47876

slice_id 4 seek offset 27359
2024-11-01 23:35:15 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 2 seek offset 13680
slice_id 1 seek offset 6840
slice_id 3 seek offset 20520
slice_id 5 seek offset 34198
slice_id 6 seek offset 41037
slice_id 4 seek offset 27359
slice_id 7 seek offset 47876
slice_id 0 seek offset 0
2024-11-01 23:42:37 - progress_bar.py[line:282] - INFO: epoch 005 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.501 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.32 | score 0.4988 | wps 497 | wpb 639.7 | bsz 160 | num_updates 1565 | best_score 0.4988
2024-11-01 23:42:37 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 1565 updates
2024-11-01 23:42:37 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
slice_id 3 seek offset 150000
slice_id 4 seek offset 200000
slice_id 2 seek offset 100000
slice_id 6 seek offset 300000
slice_id 5 seek offset 250000
slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
2024-11-01 23:43:38 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_best.pt
2024-11-01 23:44:53 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_best.pt (epoch 5 @ 1565 updates, score 0.4988) (writing took 135.6688820519994 seconds)
2024-11-01 23:44:54 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 1565 updates
2024-11-01 23:44:54 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-01 23:46:21 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-01 23:46:21 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt (epoch 5 @ 1565 updates, score 0) (writing took 87.73549868199916 seconds)
2024-11-01 23:46:21 - train.py[line:336] - INFO: end of epoch 5 (average epoch stats below)
2024-11-01 23:46:21 - progress_bar.py[line:282] - INFO: epoch 005 | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.536 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.6 | wps 413.9 | ups 0.08 | wpb 5109.9 | bsz 1278 | num_updates 1565 | lr 3.98895e-05 | gnorm 0.01 | clip 0 | loss_scale 1024 | train_wall 1091 | gb_free 9.7 | wall 19672
2024-11-01 23:46:21 - trainer.py[line:639] - INFO: loading train data for epoch 6
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-01 23:46:24 - trainer.py[line:703] - INFO: begin training epoch 6
2024-11-01 23:46:24 - train.py[line:297] - INFO: Start iterating over samples
2024-11-01 23:47:18 - progress_bar.py[line:274] - INFO: epoch 006:      5 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.503, ntokens=4862, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=11.34, wps=63.4, ups=0.01, wpb=4862, bsz=1216, num_updates=1570, lr=3.98471e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=33, gb_free=9.7, wall=19729
2024-11-01 23:49:00 - progress_bar.py[line:274] - INFO: epoch 006:     15 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.488, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.22, wps=503.3, ups=0.1, wpb=5118.3, bsz=1280, num_updates=1580, lr=3.97621e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=19830
2024-11-01 23:50:42 - progress_bar.py[line:274] - INFO: epoch 006:     25 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.505, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.36, wps=499.2, ups=0.1, wpb=5117.6, bsz=1280, num_updates=1590, lr=3.96771e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=19933
2024-11-01 23:52:27 - progress_bar.py[line:274] - INFO: epoch 006:     35 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.489, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.23, wps=490.4, ups=0.1, wpb=5117.6, bsz=1280, num_updates=1600, lr=3.95922e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=20037
2024-11-01 23:54:10 - progress_bar.py[line:274] - INFO: epoch 006:     45 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.523, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.5, wps=494.4, ups=0.1, wpb=5118, bsz=1280, num_updates=1610, lr=3.95072e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=20141
2024-11-01 23:55:53 - progress_bar.py[line:274] - INFO: epoch 006:     55 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.528, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.54, wps=496.9, ups=0.1, wpb=5118.7, bsz=1280, num_updates=1620, lr=3.94223e-05, gnorm=0.012, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=20244
2024-11-01 23:57:37 - progress_bar.py[line:274] - INFO: epoch 006:     65 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.518, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.46, wps=494.3, ups=0.1, wpb=5118.1, bsz=1280, num_updates=1630, lr=3.93373e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=35, gb_free=9.8, wall=20347
2024-11-01 23:59:21 - progress_bar.py[line:274] - INFO: epoch 006:     75 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.495, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.27, wps=492.1, ups=0.1, wpb=5117.8, bsz=1280, num_updates=1640, lr=3.92523e-05, gnorm=0.011, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=20451
2024-11-02 00:01:04 - progress_bar.py[line:274] - INFO: epoch 006:     85 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.515, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.43, wps=498.2, ups=0.1, wpb=5118.2, bsz=1280, num_updates=1650, lr=3.91674e-05, gnorm=0.012, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=20554
2024-11-02 00:02:48 - progress_bar.py[line:274] - INFO: epoch 006:     95 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.517, ntokens=5118.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.44, wps=491.8, ups=0.1, wpb=5118.9, bsz=1280, num_updates=1660, lr=3.90824e-05, gnorm=0.011, clip=0, loss_scale=1024, train_wall=35, gb_free=9.8, wall=20658
2024-11-02 00:04:31 - progress_bar.py[line:274] - INFO: epoch 006:    105 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.504, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.34, wps=493.8, ups=0.1, wpb=5118.2, bsz=1280, num_updates=1670, lr=3.89975e-05, gnorm=0.01, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=20762
2024-11-02 00:06:14 - progress_bar.py[line:274] - INFO: epoch 006:    115 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.502, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.33, wps=499.4, ups=0.1, wpb=5117.8, bsz=1280, num_updates=1680, lr=3.89125e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=20864
2024-11-02 00:07:56 - progress_bar.py[line:274] - INFO: epoch 006:    125 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.503, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.34, wps=499.6, ups=0.1, wpb=5118.5, bsz=1280, num_updates=1690, lr=3.88275e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=20967
2024-11-02 00:09:40 - progress_bar.py[line:274] - INFO: epoch 006:    135 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.496, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.29, wps=492.9, ups=0.1, wpb=5118.4, bsz=1280, num_updates=1700, lr=3.87426e-05, gnorm=0.011, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=21070
2024-11-02 00:11:22 - progress_bar.py[line:274] - INFO: epoch 006:    145 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.511, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.4, wps=501.3, ups=0.1, wpb=5117.4, bsz=1280, num_updates=1710, lr=3.86576e-05, gnorm=0.01, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=21173
2024-11-02 00:13:08 - progress_bar.py[line:274] - INFO: epoch 006:    155 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.515, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.43, wps=485.9, ups=0.09, wpb=5117.4, bsz=1280, num_updates=1720, lr=3.85726e-05, gnorm=0.01, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=21278
2024-11-02 00:14:53 - progress_bar.py[line:274] - INFO: epoch 006:    165 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.529, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.54, wps=485.4, ups=0.09, wpb=5117.7, bsz=1280, num_updates=1730, lr=3.84877e-05, gnorm=0.012, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=21383
2024-11-02 00:16:37 - progress_bar.py[line:274] - INFO: epoch 006:    175 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.508, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.38, wps=491.4, ups=0.1, wpb=5118.2, bsz=1280, num_updates=1740, lr=3.84027e-05, gnorm=0.01, clip=0, loss_scale=1024, train_wall=35, gb_free=9.6, wall=21487
2024-11-02 00:18:21 - progress_bar.py[line:274] - INFO: epoch 006:    185 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.507, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.37, wps=493.1, ups=0.1, wpb=5117.4, bsz=1280, num_updates=1750, lr=3.83178e-05, gnorm=0.01, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=21591
2024-11-02 00:20:03 - progress_bar.py[line:274] - INFO: epoch 006:    195 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.497, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.29, wps=499.4, ups=0.1, wpb=5117.4, bsz=1280, num_updates=1760, lr=3.82328e-05, gnorm=0.011, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=21694
2024-11-02 00:21:45 - progress_bar.py[line:274] - INFO: epoch 006:    205 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.503, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.34, wps=503, ups=0.1, wpb=5118.6, bsz=1280, num_updates=1770, lr=3.81478e-05, gnorm=0.011, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=21795
2024-11-02 00:23:28 - progress_bar.py[line:274] - INFO: epoch 006:    215 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.476, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.13, wps=500.1, ups=0.1, wpb=5118.5, bsz=1280, num_updates=1780, lr=3.80629e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=21898
2024-11-02 00:25:10 - progress_bar.py[line:274] - INFO: epoch 006:    225 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.478, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.14, wps=497.4, ups=0.1, wpb=5118.3, bsz=1280, num_updates=1790, lr=3.79779e-05, gnorm=0.01, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=22001
2024-11-02 00:26:53 - progress_bar.py[line:274] - INFO: epoch 006:    235 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.511, ntokens=5117.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.4, wps=499.6, ups=0.1, wpb=5117.1, bsz=1280, num_updates=1800, lr=3.78929e-05, gnorm=0.011, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=22103
2024-11-02 00:28:38 - progress_bar.py[line:274] - INFO: epoch 006:    245 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.504, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.34, wps=487.3, ups=0.1, wpb=5118.1, bsz=1280, num_updates=1810, lr=3.7808e-05, gnorm=0.012, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=22208
2024-11-02 00:30:22 - progress_bar.py[line:274] - INFO: epoch 006:    255 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.488, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.22, wps=492, ups=0.1, wpb=5118.2, bsz=1280, num_updates=1820, lr=3.7723e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=22312
2024-11-02 00:32:06 - progress_bar.py[line:274] - INFO: epoch 006:    265 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.49, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.24, wps=493.1, ups=0.1, wpb=5118, bsz=1280, num_updates=1830, lr=3.76381e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=22416
2024-11-02 00:33:50 - progress_bar.py[line:274] - INFO: epoch 006:    275 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.493, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.26, wps=489.2, ups=0.1, wpb=5118.7, bsz=1280, num_updates=1840, lr=3.75531e-05, gnorm=0.01, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=22521
2024-11-02 00:35:32 - progress_bar.py[line:274] - INFO: epoch 006:    285 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.535, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.59, wps=502.3, ups=0.1, wpb=5118, bsz=1280, num_updates=1850, lr=3.74681e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=22622
2024-11-02 00:37:14 - progress_bar.py[line:274] - INFO: epoch 006:    295 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.513, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.42, wps=501.9, ups=0.1, wpb=5118.3, bsz=1280, num_updates=1860, lr=3.73832e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=22724
2024-11-02 00:38:57 - progress_bar.py[line:274] - INFO: epoch 006:    305 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.5, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.31, wps=497.6, ups=0.1, wpb=5117.8, bsz=1280, num_updates=1870, lr=3.72982e-05, gnorm=0.01, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=22827
slice_id 2 seek offset 13680
slice_id 6 seek offset 41037
slice_id 1 seek offset 6840slice_id 3 seek offset 20520

slice_id 4 seek offset 27359slice_id 5 seek offset 34198

2024-11-02 00:40:12 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 7 seek offset 47876
slice_id 0 seek offset 0
slice_id 4 seek offset 27359
slice_id 2 seek offset 13680
slice_id 3 seek offset 20520
slice_id 1 seek offset 6840
slice_id 6 seek offset 41037
slice_id 5 seek offset 34198
slice_id 0 seek offset 0
slice_id 7 seek offset 47876
2024-11-02 00:47:35 - progress_bar.py[line:282] - INFO: epoch 006 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.515 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.43 | score 0.5062 | wps 494.7 | wpb 639.7 | bsz 160 | num_updates 1878 | best_score 0.5062
2024-11-02 00:47:35 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 1878 updates
2024-11-02 00:47:35 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
slice_id 2 seek offset 100000
slice_id 6 seek offset 300000
slice_id 4 seek offset 200000
slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
slice_id 3 seek offset 150000
slice_id 5 seek offset 250000
2024-11-02 00:48:36 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_best.pt
2024-11-02 00:49:51 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_best.pt (epoch 6 @ 1878 updates, score 0.5062) (writing took 135.1246982360026 seconds)
2024-11-02 00:49:51 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 1878 updates
2024-11-02 00:49:51 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-02 00:51:18 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-02 00:51:19 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt (epoch 6 @ 1878 updates, score 0) (writing took 87.49134762099857 seconds)
2024-11-02 00:51:19 - train.py[line:336] - INFO: end of epoch 6 (average epoch stats below)
2024-11-02 00:51:19 - progress_bar.py[line:282] - INFO: epoch 006 | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.505 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.35 | wps 410.4 | ups 0.08 | wpb 5109.9 | bsz 1278 | num_updates 1878 | lr 3.72302e-05 | gnorm 0.01 | clip 0 | loss_scale 1024 | train_wall 1093 | gb_free 9.7 | wall 23569
2024-11-02 00:51:19 - trainer.py[line:639] - INFO: loading train data for epoch 7
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-02 00:51:21 - trainer.py[line:703] - INFO: begin training epoch 7
2024-11-02 00:51:21 - train.py[line:297] - INFO: Start iterating over samples
2024-11-02 00:51:45 - progress_bar.py[line:274] - INFO: epoch 007:      2 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.51, ntokens=4862.4, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=11.4, wps=63.3, ups=0.01, wpb=4862.4, bsz=1216, num_updates=1880, lr=3.72133e-05, gnorm=0.012, clip=0, loss_scale=1024, train_wall=33, gb_free=9.7, wall=23595
2024-11-02 00:53:27 - progress_bar.py[line:274] - INFO: epoch 007:     12 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.482, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.18, wps=500.6, ups=0.1, wpb=5118, bsz=1280, num_updates=1890, lr=3.71283e-05, gnorm=0.012, clip=0, loss_scale=1024, train_wall=35, gb_free=9.6, wall=23697
2024-11-02 00:55:09 - progress_bar.py[line:274] - INFO: epoch 007:     22 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.489, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.22, wps=503, ups=0.1, wpb=5118, bsz=1280, num_updates=1900, lr=3.70433e-05, gnorm=0.018, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=23799
2024-11-02 00:56:51 - progress_bar.py[line:274] - INFO: epoch 007:     32 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.521, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.48, wps=499.9, ups=0.1, wpb=5117.9, bsz=1280, num_updates=1910, lr=3.69584e-05, gnorm=0.011, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=23901
2024-11-02 00:58:33 - progress_bar.py[line:274] - INFO: epoch 007:     42 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.517, ntokens=5117.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.45, wps=501.8, ups=0.1, wpb=5117.5, bsz=1280, num_updates=1920, lr=3.68734e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=24003
2024-11-02 01:00:15 - progress_bar.py[line:274] - INFO: epoch 007:     52 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.567, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.85, wps=500.1, ups=0.1, wpb=5118.4, bsz=1280, num_updates=1930, lr=3.67884e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=24106
2024-11-02 01:01:58 - progress_bar.py[line:274] - INFO: epoch 007:     62 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.562, ntokens=5118.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.81, wps=501.2, ups=0.1, wpb=5118.8, bsz=1280, num_updates=1940, lr=3.67035e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=24208
2024-11-02 01:03:40 - progress_bar.py[line:274] - INFO: epoch 007:     72 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.565, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.83, wps=501, ups=0.1, wpb=5117.7, bsz=1280, num_updates=1950, lr=3.66185e-05, gnorm=0.01, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=24310
2024-11-02 01:05:25 - progress_bar.py[line:274] - INFO: epoch 007:     82 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.568, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.86, wps=488.4, ups=0.1, wpb=5117.6, bsz=1280, num_updates=1960, lr=3.65336e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=24415
2024-11-02 01:07:06 - progress_bar.py[line:274] - INFO: epoch 007:     92 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.566, ntokens=5118.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.84, wps=504.3, ups=0.1, wpb=5118.8, bsz=1280, num_updates=1970, lr=3.64486e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=24516
2024-11-02 01:08:49 - progress_bar.py[line:274] - INFO: epoch 007:    102 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.558, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.78, wps=496.8, ups=0.1, wpb=5118.3, bsz=1280, num_updates=1980, lr=3.63636e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=35, gb_free=9.8, wall=24619
2024-11-02 01:10:31 - progress_bar.py[line:274] - INFO: epoch 007:    112 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.591, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.05, wps=501.4, ups=0.1, wpb=5118.4, bsz=1280, num_updates=1990, lr=3.62787e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=24721
slice_id 6 seek offset 41037
slice_id 1 seek offset 6840
slice_id 4 seek offset 27359
slice_id 3 seek offset 20520
slice_id 2 seek offset 13680
slice_id 5 seek offset 34198
slice_id 7 seek offset 47876
2024-11-02 01:12:13 - progress_bar.py[line:274] - INFO: epoch 007:    122 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.612, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.23, wps=504, ups=0.1, wpb=5118, bsz=1280, num_updates=2000, lr=3.61937e-05, gnorm=0.01, clip=0, loss_scale=1024, train_wall=35, gb_free=9.6, wall=24823
2024-11-02 01:12:13 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 4 seek offset 27359
slice_id 2 seek offset 13680
slice_id 1 seek offset 6840
slice_id 3 seek offset 20520
slice_id 6 seek offset 41037
slice_id 7 seek offset 47876
slice_id 5 seek offset 34198
slice_id 0 seek offset 0
2024-11-02 01:19:36 - progress_bar.py[line:282] - INFO: epoch 007 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.636 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.43 | score 0.5077 | wps 495.4 | wpb 639.7 | bsz 160 | num_updates 2000 | best_score 0.5077
2024-11-02 01:19:36 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 2000 updates
2024-11-02 01:19:36 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_7_2000.pt
2024-11-02 01:19:47 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_7_2000.pt
2024-11-02 01:22:29 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_7_2000.pt (epoch 7 @ 2000 updates, score 0.5077) (writing took 172.5432088480011 seconds)
2024-11-02 01:24:00 - progress_bar.py[line:274] - INFO: epoch 007:    132 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.641, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.47, wps=72.4, ups=0.01, wpb=5118.6, bsz=1280, num_updates=2010, lr=3.61088e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=25530
2024-11-02 01:25:42 - progress_bar.py[line:274] - INFO: epoch 007:    142 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.622, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.31, wps=500, ups=0.1, wpb=5117.3, bsz=1280, num_updates=2020, lr=3.60238e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=25633
2024-11-02 01:27:25 - progress_bar.py[line:274] - INFO: epoch 007:    152 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.578, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.95, wps=500.3, ups=0.1, wpb=5117.7, bsz=1280, num_updates=2030, lr=3.59388e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=35, gb_free=9.6, wall=25735
2024-11-02 01:29:06 - progress_bar.py[line:274] - INFO: epoch 007:    162 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.547, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.69, wps=504.7, ups=0.1, wpb=5118.1, bsz=1280, num_updates=2040, lr=3.58539e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=35, gb_free=9.7, wall=25836
2024-11-02 01:30:49 - progress_bar.py[line:274] - INFO: epoch 007:    172 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.549, ntokens=5117.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.71, wps=499.2, ups=0.1, wpb=5117.5, bsz=1280, num_updates=2050, lr=3.57689e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=25939
2024-11-02 01:32:31 - progress_bar.py[line:274] - INFO: epoch 007:    182 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.56, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.8, wps=500, ups=0.1, wpb=5117.7, bsz=1280, num_updates=2060, lr=3.56839e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.8, wall=26041
2024-11-02 01:34:13 - progress_bar.py[line:274] - INFO: epoch 007:    192 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.539, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.62, wps=499.5, ups=0.1, wpb=5117.4, bsz=1280, num_updates=2070, lr=3.5599e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=26144
2024-11-02 01:35:56 - progress_bar.py[line:274] - INFO: epoch 007:    202 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.565, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.84, wps=499.9, ups=0.1, wpb=5118.3, bsz=1280, num_updates=2080, lr=3.5514e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=26246
2024-11-02 01:37:39 - progress_bar.py[line:274] - INFO: epoch 007:    212 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.559, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.79, wps=497.6, ups=0.1, wpb=5118.1, bsz=1280, num_updates=2090, lr=3.54291e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=26349
2024-11-02 01:39:22 - progress_bar.py[line:274] - INFO: epoch 007:    222 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.539, ntokens=5118.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.62, wps=497.8, ups=0.1, wpb=5118.9, bsz=1280, num_updates=2100, lr=3.53441e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=26452
2024-11-02 01:41:05 - progress_bar.py[line:274] - INFO: epoch 007:    232 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.565, ntokens=5117, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.84, wps=493.4, ups=0.1, wpb=5117, bsz=1280, num_updates=2110, lr=3.52591e-05, gnorm=0.011, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=26555
2024-11-02 01:42:50 - progress_bar.py[line:274] - INFO: epoch 007:    242 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.565, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.83, wps=489.8, ups=0.1, wpb=5118.4, bsz=1280, num_updates=2120, lr=3.51742e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=26660
2024-11-02 01:44:35 - progress_bar.py[line:274] - INFO: epoch 007:    252 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.567, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.85, wps=486, ups=0.09, wpb=5117.9, bsz=1280, num_updates=2130, lr=3.50892e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.8, wall=26765
2024-11-02 01:46:20 - progress_bar.py[line:274] - INFO: epoch 007:    262 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.581, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.97, wps=490, ups=0.1, wpb=5118.2, bsz=1280, num_updates=2140, lr=3.50042e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=26870
2024-11-02 01:48:02 - progress_bar.py[line:274] - INFO: epoch 007:    272 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.575, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.92, wps=497.1, ups=0.1, wpb=5118.2, bsz=1280, num_updates=2150, lr=3.49193e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.8, wall=26973
2024-11-02 01:49:45 - progress_bar.py[line:274] - INFO: epoch 007:    282 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.569, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.87, wps=500, ups=0.1, wpb=5118.4, bsz=1280, num_updates=2160, lr=3.48343e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=27075
2024-11-02 01:51:29 - progress_bar.py[line:274] - INFO: epoch 007:    292 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.559, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.78, wps=490.3, ups=0.1, wpb=5117.8, bsz=1280, num_updates=2170, lr=3.47494e-05, gnorm=0.011, clip=0, loss_scale=2048, train_wall=35, gb_free=9.8, wall=27179
2024-11-02 01:53:11 - progress_bar.py[line:274] - INFO: epoch 007:    302 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.549, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.7, wps=501.9, ups=0.1, wpb=5118.6, bsz=1280, num_updates=2180, lr=3.46644e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=35, gb_free=9.6, wall=27281
2024-11-02 01:54:54 - progress_bar.py[line:274] - INFO: epoch 007:    312 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.534, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.59, wps=498.3, ups=0.1, wpb=5117.9, bsz=1280, num_updates=2190, lr=3.45794e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=27384
slice_id 2 seek offset 13680
slice_id 6 seek offset 41037
slice_id 1 seek offset 6840
slice_id 3 seek offset 20520
slice_id 7 seek offset 47876slice_id 4 seek offset 27359

slice_id 5 seek offset 34198
2024-11-02 01:54:57 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 4 seek offset 27359
slice_id 2 seek offset 13680
slice_id 1 seek offset 6840
slice_id 3 seek offset 20520
slice_id 6 seek offset 41037
slice_id 5 seek offset 34198
slice_id 7 seek offset 47876
slice_id 0 seek offset 0
2024-11-02 02:02:19 - progress_bar.py[line:282] - INFO: epoch 007 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.53 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.55 | score 0.5066 | wps 496.9 | wpb 639.7 | bsz 160 | num_updates 2191 | best_score 0.5077
2024-11-02 02:02:19 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 2191 updates
2024-11-02 02:02:19 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
slice_id 3 seek offset 150000
slice_id 1 seek offset 50000
slice_id 4 seek offset 200000
slice_id 2 seek offset 100000
slice_id 7 seek offset 350000
slice_id 5 seek offset 250000
slice_id 6 seek offset 300000
2024-11-02 02:03:21 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-02 02:03:21 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt (epoch 7 @ 2191 updates, score 0.5066) (writing took 61.7519318620034 seconds)
2024-11-02 02:03:21 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 2191 updates
2024-11-02 02:03:21 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-02 02:04:21 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-02 02:04:21 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt (epoch 7 @ 2191 updates, score 0) (writing took 60.65002335600002 seconds)
2024-11-02 02:04:21 - train.py[line:336] - INFO: end of epoch 7 (average epoch stats below)
2024-11-02 02:04:21 - progress_bar.py[line:282] - INFO: epoch 007 | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.56 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.79 | wps 364.9 | ups 0.07 | wpb 5109.9 | bsz 1278 | num_updates 2191 | lr 3.45709e-05 | gnorm 0.009 | clip 0 | loss_scale 2048 | train_wall 1092 | gb_free 9.7 | wall 27952
2024-11-02 02:04:21 - trainer.py[line:639] - INFO: loading train data for epoch 8
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-02 02:04:24 - trainer.py[line:703] - INFO: begin training epoch 8
2024-11-02 02:04:24 - train.py[line:297] - INFO: Start iterating over samples
2024-11-02 02:05:58 - progress_bar.py[line:274] - INFO: epoch 008:      9 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.537, ntokens=4862, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=11.61, wps=73.2, ups=0.02, wpb=4862, bsz=1216, num_updates=2200, lr=3.44945e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=33, gb_free=9.6, wall=28049
2024-11-02 02:07:39 - progress_bar.py[line:274] - INFO: epoch 008:     19 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.549, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.7, wps=506.9, ups=0.1, wpb=5118.1, bsz=1280, num_updates=2210, lr=3.44095e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=35, gb_free=9.6, wall=28150
2024-11-02 02:09:20 - progress_bar.py[line:274] - INFO: epoch 008:     29 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.548, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.7, wps=506.5, ups=0.1, wpb=5117.7, bsz=1280, num_updates=2220, lr=3.43246e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=28251
2024-11-02 02:11:02 - progress_bar.py[line:274] - INFO: epoch 008:     39 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.563, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.82, wps=505.1, ups=0.1, wpb=5118, bsz=1280, num_updates=2230, lr=3.42396e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=28352
2024-11-02 02:12:43 - progress_bar.py[line:274] - INFO: epoch 008:     49 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.597, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.1, wps=505.8, ups=0.1, wpb=5118, bsz=1280, num_updates=2240, lr=3.41546e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=28453
2024-11-02 02:14:23 - progress_bar.py[line:274] - INFO: epoch 008:     59 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.591, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=12.05, wps=509.1, ups=0.1, wpb=5118.4, bsz=1280, num_updates=2250, lr=3.40697e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=28554
2024-11-02 02:16:07 - progress_bar.py[line:274] - INFO: epoch 008:     69 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.572, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.89, wps=492.1, ups=0.1, wpb=5118.4, bsz=1280, num_updates=2260, lr=3.39847e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=28658
2024-11-02 02:17:49 - progress_bar.py[line:274] - INFO: epoch 008:     79 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.567, ntokens=5117.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.85, wps=504.4, ups=0.1, wpb=5117.5, bsz=1280, num_updates=2270, lr=3.38997e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.8, wall=28759
2024-11-02 02:19:31 - progress_bar.py[line:274] - INFO: epoch 008:     89 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.56, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.8, wps=503.5, ups=0.1, wpb=5118.4, bsz=1280, num_updates=2280, lr=3.38148e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.6, wall=28861
2024-11-02 02:21:12 - progress_bar.py[line:274] - INFO: epoch 008:     99 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.548, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.7, wps=505.7, ups=0.1, wpb=5118.4, bsz=1280, num_updates=2290, lr=3.37298e-05, gnorm=0.012, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=28962
2024-11-02 02:22:53 - progress_bar.py[line:274] - INFO: epoch 008:    109 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.537, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.61, wps=504.6, ups=0.1, wpb=5118.4, bsz=1280, num_updates=2300, lr=3.36449e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=29063
2024-11-02 02:24:36 - progress_bar.py[line:274] - INFO: epoch 008:    119 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.549, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.7, wps=497.4, ups=0.1, wpb=5117.9, bsz=1280, num_updates=2310, lr=3.35599e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=29166
2024-11-02 02:26:19 - progress_bar.py[line:274] - INFO: epoch 008:    129 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.555, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.75, wps=497.6, ups=0.1, wpb=5118.7, bsz=1280, num_updates=2320, lr=3.34749e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=29269
2024-11-02 02:28:02 - progress_bar.py[line:274] - INFO: epoch 008:    139 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.572, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.89, wps=498.3, ups=0.1, wpb=5117.9, bsz=1280, num_updates=2330, lr=3.339e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=29372
2024-11-02 02:29:43 - progress_bar.py[line:274] - INFO: epoch 008:    149 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.564, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.83, wps=506.5, ups=0.1, wpb=5117.6, bsz=1280, num_updates=2340, lr=3.3305e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=29473
2024-11-02 02:31:24 - progress_bar.py[line:274] - INFO: epoch 008:    159 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.556, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.76, wps=503.1, ups=0.1, wpb=5117.6, bsz=1280, num_updates=2350, lr=3.32201e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=29575
2024-11-02 02:33:06 - progress_bar.py[line:274] - INFO: epoch 008:    169 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.547, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.69, wps=505.2, ups=0.1, wpb=5118.1, bsz=1280, num_updates=2360, lr=3.31351e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=29676
2024-11-02 02:34:47 - progress_bar.py[line:274] - INFO: epoch 008:    179 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.545, ntokens=5116.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.68, wps=505.6, ups=0.1, wpb=5116.9, bsz=1280, num_updates=2370, lr=3.30501e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=29777
2024-11-02 02:36:28 - progress_bar.py[line:274] - INFO: epoch 008:    189 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.541, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.64, wps=508, ups=0.1, wpb=5117.9, bsz=1280, num_updates=2380, lr=3.29652e-05, gnorm=0.012, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=29878
2024-11-02 02:38:10 - progress_bar.py[line:274] - INFO: epoch 008:    199 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.535, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.59, wps=502.5, ups=0.1, wpb=5117.9, bsz=1280, num_updates=2390, lr=3.28802e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=35, gb_free=9.8, wall=29980
2024-11-02 02:39:51 - progress_bar.py[line:274] - INFO: epoch 008:    209 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.526, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.52, wps=504.8, ups=0.1, wpb=5118.4, bsz=1280, num_updates=2400, lr=3.27952e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=30081
2024-11-02 02:41:32 - progress_bar.py[line:274] - INFO: epoch 008:    219 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.5, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.32, wps=506, ups=0.1, wpb=5118.5, bsz=1280, num_updates=2410, lr=3.27103e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=30182
2024-11-02 02:43:14 - progress_bar.py[line:274] - INFO: epoch 008:    229 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.512, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.41, wps=502.5, ups=0.1, wpb=5117.9, bsz=1280, num_updates=2420, lr=3.26253e-05, gnorm=0.011, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=30284
2024-11-02 02:44:58 - progress_bar.py[line:274] - INFO: epoch 008:    239 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.514, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.42, wps=493, ups=0.1, wpb=5117.6, bsz=1280, num_updates=2430, lr=3.25404e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=30388
2024-11-02 02:46:40 - progress_bar.py[line:274] - INFO: epoch 008:    249 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.534, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.58, wps=500.5, ups=0.1, wpb=5118.2, bsz=1280, num_updates=2440, lr=3.24554e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.6, wall=30490
2024-11-02 02:48:23 - progress_bar.py[line:274] - INFO: epoch 008:    259 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.545, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.67, wps=497.6, ups=0.1, wpb=5118, bsz=1280, num_updates=2450, lr=3.23704e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=30593
2024-11-02 02:50:05 - progress_bar.py[line:274] - INFO: epoch 008:    269 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.533, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.58, wps=500.1, ups=0.1, wpb=5118, bsz=1280, num_updates=2460, lr=3.22855e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=30695
2024-11-02 02:51:47 - progress_bar.py[line:274] - INFO: epoch 008:    279 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.546, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.68, wps=504.6, ups=0.1, wpb=5118.6, bsz=1280, num_updates=2470, lr=3.22005e-05, gnorm=0.013, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=30797
2024-11-02 02:53:27 - progress_bar.py[line:274] - INFO: epoch 008:    289 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.545, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.67, wps=508.2, ups=0.1, wpb=5117.6, bsz=1280, num_updates=2480, lr=3.21155e-05, gnorm=0.013, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=30898
2024-11-02 02:55:08 - progress_bar.py[line:274] - INFO: epoch 008:    299 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.528, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.54, wps=507, ups=0.1, wpb=5118.7, bsz=1280, num_updates=2490, lr=3.20306e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=30999
2024-11-02 02:56:49 - progress_bar.py[line:274] - INFO: epoch 008:    309 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.501, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.33, wps=509.2, ups=0.1, wpb=5118.3, bsz=1280, num_updates=2500, lr=3.19456e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=31099
slice_id 2 seek offset 13680
slice_id 6 seek offset 41037
slice_id 1 seek offset 6840
slice_id 3 seek offset 20520
slice_id 5 seek offset 34198slice_id 4 seek offset 27359

slice_id 7 seek offset 47876
2024-11-02 02:57:22 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 4 seek offset 27359
slice_id 2 seek offset 13680
slice_id 3 seek offset 20520
slice_id 1 seek offset 6840
slice_id 5 seek offset 34198
slice_id 6 seek offset 41037
slice_id 0 seek offset 0
slice_id 7 seek offset 47876
2024-11-02 03:04:44 - progress_bar.py[line:282] - INFO: epoch 008 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.494 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.26 | score 0.5052 | wps 496.6 | wpb 639.7 | bsz 160 | num_updates 2504 | best_score 0.5077
2024-11-02 03:04:44 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 8 @ 2504 updates
2024-11-02 03:04:44 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
slice_id 2 seek offset 100000
slice_id 6 seek offset 300000
slice_id 3 seek offset 150000
slice_id 7 seek offset 350000
slice_id 5 seek offset 250000
slice_id 1 seek offset 50000
slice_id 4 seek offset 200000
2024-11-02 03:05:45 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-02 03:05:46 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt (epoch 8 @ 2504 updates, score 0.5052) (writing took 61.175828480001655 seconds)
2024-11-02 03:05:46 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 8 @ 2504 updates
2024-11-02 03:05:46 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-02 03:06:47 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-02 03:06:47 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt (epoch 8 @ 2504 updates, score 0) (writing took 61.335994897999626 seconds)
2024-11-02 03:06:47 - train.py[line:336] - INFO: end of epoch 8 (average epoch stats below)
2024-11-02 03:06:47 - progress_bar.py[line:282] - INFO: epoch 008 | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.545 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.67 | wps 427 | ups 0.08 | wpb 5109.9 | bsz 1278 | num_updates 2504 | lr 3.19116e-05 | gnorm 0.009 | clip 0 | loss_scale 2048 | train_wall 1092 | gb_free 9.7 | wall 31697
2024-11-02 03:06:47 - trainer.py[line:639] - INFO: loading train data for epoch 9
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-02 03:06:50 - trainer.py[line:703] - INFO: begin training epoch 9
2024-11-02 03:06:50 - train.py[line:297] - INFO: Start iterating over samples
2024-11-02 03:07:54 - progress_bar.py[line:274] - INFO: epoch 009:      6 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.48, ntokens=4862.1, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=11.16, wps=73.1, ups=0.02, wpb=4862.1, bsz=1216, num_updates=2510, lr=3.18607e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=33, gb_free=9.7, wall=31764
2024-11-02 03:09:36 - progress_bar.py[line:274] - INFO: epoch 009:     16 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.467, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.06, wps=503.5, ups=0.1, wpb=5118, bsz=1280, num_updates=2520, lr=3.17757e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=31866
2024-11-02 03:11:18 - progress_bar.py[line:274] - INFO: epoch 009:     26 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.498, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.3, wps=500.9, ups=0.1, wpb=5117.6, bsz=1280, num_updates=2530, lr=3.16907e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=31968
2024-11-02 03:13:00 - progress_bar.py[line:274] - INFO: epoch 009:     36 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.508, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.38, wps=501.5, ups=0.1, wpb=5117.8, bsz=1280, num_updates=2540, lr=3.16058e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=32070
2024-11-02 03:14:43 - progress_bar.py[line:274] - INFO: epoch 009:     46 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.526, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.52, wps=496.2, ups=0.1, wpb=5118, bsz=1280, num_updates=2550, lr=3.15208e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=35, gb_free=9.7, wall=32173
2024-11-02 03:16:25 - progress_bar.py[line:274] - INFO: epoch 009:     56 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.515, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.43, wps=502.5, ups=0.1, wpb=5118.7, bsz=1280, num_updates=2560, lr=3.14359e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=32275
2024-11-02 03:18:06 - progress_bar.py[line:274] - INFO: epoch 009:     66 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.514, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.42, wps=502.9, ups=0.1, wpb=5118.2, bsz=1280, num_updates=2570, lr=3.13509e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=32377
2024-11-02 03:19:49 - progress_bar.py[line:274] - INFO: epoch 009:     76 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.518, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.45, wps=501.5, ups=0.1, wpb=5117.8, bsz=1280, num_updates=2580, lr=3.12659e-05, gnorm=0.012, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=32479
2024-11-02 03:21:30 - progress_bar.py[line:274] - INFO: epoch 009:     86 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.521, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.48, wps=503.2, ups=0.1, wpb=5117.9, bsz=1280, num_updates=2590, lr=3.1181e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=32580
2024-11-02 03:23:12 - progress_bar.py[line:274] - INFO: epoch 009:     96 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.52, ntokens=5119.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.47, wps=503.9, ups=0.1, wpb=5119.1, bsz=1280, num_updates=2600, lr=3.1096e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=32682
2024-11-02 03:24:53 - progress_bar.py[line:274] - INFO: epoch 009:    106 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.557, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.77, wps=505.3, ups=0.1, wpb=5118.1, bsz=1280, num_updates=2610, lr=3.1011e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=32783
2024-11-02 03:26:35 - progress_bar.py[line:274] - INFO: epoch 009:    116 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.544, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.66, wps=502.9, ups=0.1, wpb=5117.9, bsz=1280, num_updates=2620, lr=3.09261e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=32885
2024-11-02 03:28:17 - progress_bar.py[line:274] - INFO: epoch 009:    126 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.521, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.48, wps=502.9, ups=0.1, wpb=5118.2, bsz=1280, num_updates=2630, lr=3.08411e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=32987
2024-11-02 03:29:58 - progress_bar.py[line:274] - INFO: epoch 009:    136 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.538, ntokens=5118.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.61, wps=503.6, ups=0.1, wpb=5118.8, bsz=1280, num_updates=2640, lr=3.07562e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=33089
2024-11-02 03:31:40 - progress_bar.py[line:274] - INFO: epoch 009:    146 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.536, ntokens=5117.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.6, wps=501.6, ups=0.1, wpb=5117.2, bsz=1280, num_updates=2650, lr=3.06712e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=33191
2024-11-02 03:33:22 - progress_bar.py[line:274] - INFO: epoch 009:    156 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.527, ntokens=5117.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.53, wps=501.1, ups=0.1, wpb=5117.5, bsz=1280, num_updates=2660, lr=3.05862e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=33293
2024-11-02 03:35:04 - progress_bar.py[line:274] - INFO: epoch 009:    166 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.514, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.42, wps=504.3, ups=0.1, wpb=5117.7, bsz=1280, num_updates=2670, lr=3.05013e-05, gnorm=0.006, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=33394
2024-11-02 03:36:46 - progress_bar.py[line:274] - INFO: epoch 009:    176 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.547, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.69, wps=500.2, ups=0.1, wpb=5117.9, bsz=1280, num_updates=2680, lr=3.04163e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=33496
2024-11-02 03:38:28 - progress_bar.py[line:274] - INFO: epoch 009:    186 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.54, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.63, wps=502.8, ups=0.1, wpb=5117.8, bsz=1280, num_updates=2690, lr=3.03314e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=33598
2024-11-02 03:40:10 - progress_bar.py[line:274] - INFO: epoch 009:    196 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.548, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.69, wps=503.7, ups=0.1, wpb=5117.3, bsz=1280, num_updates=2700, lr=3.02464e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=33700
2024-11-02 03:41:51 - progress_bar.py[line:274] - INFO: epoch 009:    206 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.538, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.62, wps=505.9, ups=0.1, wpb=5118.4, bsz=1280, num_updates=2710, lr=3.01614e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=33801
2024-11-02 03:43:33 - progress_bar.py[line:274] - INFO: epoch 009:    216 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.534, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.59, wps=501.9, ups=0.1, wpb=5118.5, bsz=1280, num_updates=2720, lr=3.00765e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=33903
2024-11-02 03:45:14 - progress_bar.py[line:274] - INFO: epoch 009:    226 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.533, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.57, wps=504.9, ups=0.1, wpb=5118.2, bsz=1280, num_updates=2730, lr=2.99915e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=34004
2024-11-02 03:46:56 - progress_bar.py[line:274] - INFO: epoch 009:    236 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.526, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.52, wps=501.4, ups=0.1, wpb=5117.3, bsz=1280, num_updates=2740, lr=2.99065e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=34106
2024-11-02 03:48:38 - progress_bar.py[line:274] - INFO: epoch 009:    246 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.518, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.46, wps=504.2, ups=0.1, wpb=5118.3, bsz=1280, num_updates=2750, lr=2.98216e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=34208
2024-11-02 03:50:19 - progress_bar.py[line:274] - INFO: epoch 009:    256 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.537, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.61, wps=504.3, ups=0.1, wpb=5118.1, bsz=1280, num_updates=2760, lr=2.97366e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=34309
2024-11-02 03:52:01 - progress_bar.py[line:274] - INFO: epoch 009:    266 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.529, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.54, wps=504.8, ups=0.1, wpb=5117.6, bsz=1280, num_updates=2770, lr=2.96517e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=34411
2024-11-02 03:53:43 - progress_bar.py[line:274] - INFO: epoch 009:    276 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.533, ntokens=5119, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.57, wps=502.2, ups=0.1, wpb=5119, bsz=1280, num_updates=2780, lr=2.95667e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=34513
2024-11-02 03:55:24 - progress_bar.py[line:274] - INFO: epoch 009:    286 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.543, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.66, wps=503.8, ups=0.1, wpb=5118.1, bsz=1280, num_updates=2790, lr=2.94817e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=34614
2024-11-02 03:57:06 - progress_bar.py[line:274] - INFO: epoch 009:    296 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.515, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.43, wps=502.2, ups=0.1, wpb=5118.3, bsz=1280, num_updates=2800, lr=2.93968e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=34716
2024-11-02 03:58:49 - progress_bar.py[line:274] - INFO: epoch 009:    306 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.509, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.39, wps=495.7, ups=0.1, wpb=5117.8, bsz=1280, num_updates=2810, lr=2.93118e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=34820
slice_id 6 seek offset 41037slice_id 1 seek offset 6840

slice_id 4 seek offset 27359slice_id 3 seek offset 20520slice_id 7 seek offset 47876


slice_id 5 seek offset 34198
2024-11-02 03:59:56 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 2 seek offset 13680
slice_id 4 seek offset 27359
slice_id 1 seek offset 6840
slice_id 2 seek offset 13680
slice_id 3 seek offset 20520
slice_id 6 seek offset 41037
slice_id 5 seek offset 34198
slice_id 7 seek offset 47876
slice_id 0 seek offset 0
2024-11-02 04:07:25 - progress_bar.py[line:282] - INFO: epoch 009 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.512 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.41 | score 0.5088 | wps 488.9 | wpb 639.7 | bsz 160 | num_updates 2817 | best_score 0.5088
2024-11-02 04:07:25 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 9 @ 2817 updates
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2024-11-02 04:07:25 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
slice_id 2 seek offset 100000
slice_id 4 seek offset 200000
slice_id 1 seek offset 50000
slice_id 6 seek offset 300000
slice_id 7 seek offset 350000
slice_id 3 seek offset 150000
slice_id 5 seek offset 250000
2024-11-02 04:08:26 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_best.pt
2024-11-02 04:09:40 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_best.pt (epoch 9 @ 2817 updates, score 0.5088) (writing took 135.35888826300652 seconds)
2024-11-02 04:09:41 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 9 @ 2817 updates
2024-11-02 04:09:41 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-02 04:11:08 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-02 04:11:08 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt (epoch 9 @ 2817 updates, score 0) (writing took 87.40448407999793 seconds)
2024-11-02 04:11:08 - train.py[line:336] - INFO: end of epoch 9 (average epoch stats below)
2024-11-02 04:11:08 - progress_bar.py[line:282] - INFO: epoch 009 | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.524 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.51 | wps 414.2 | ups 0.08 | wpb 5109.9 | bsz 1278 | num_updates 2817 | lr 2.92523e-05 | gnorm 0.009 | clip 0 | loss_scale 4096 | train_wall 1092 | gb_free 9.7 | wall 35558
2024-11-02 04:11:08 - trainer.py[line:639] - INFO: loading train data for epoch 10
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-02 04:11:11 - trainer.py[line:703] - INFO: begin training epoch 10
2024-11-02 04:11:11 - train.py[line:297] - INFO: Start iterating over samples
2024-11-02 04:11:44 - progress_bar.py[line:274] - INFO: epoch 010:      3 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.503, ntokens=4862.4, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=11.34, wps=62.7, ups=0.01, wpb=4862.4, bsz=1216, num_updates=2820, lr=2.92268e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=33, gb_free=9.7, wall=35595
2024-11-02 04:13:27 - progress_bar.py[line:274] - INFO: epoch 010:     13 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.513, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.42, wps=499.7, ups=0.1, wpb=5117.9, bsz=1280, num_updates=2830, lr=2.91419e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.8, wall=35697
2024-11-02 04:15:09 - progress_bar.py[line:274] - INFO: epoch 010:     23 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.498, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.29, wps=501, ups=0.1, wpb=5117.9, bsz=1280, num_updates=2840, lr=2.90569e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.8, wall=35799
2024-11-02 04:16:52 - progress_bar.py[line:274] - INFO: epoch 010:     33 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.467, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.06, wps=497.4, ups=0.1, wpb=5117.8, bsz=1280, num_updates=2850, lr=2.8972e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=35902
2024-11-02 04:18:34 - progress_bar.py[line:274] - INFO: epoch 010:     43 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.497, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.29, wps=502.4, ups=0.1, wpb=5117.6, bsz=1280, num_updates=2860, lr=2.8887e-05, gnorm=0.006, clip=0, loss_scale=4096, train_wall=35, gb_free=9.8, wall=36004
2024-11-02 04:20:16 - progress_bar.py[line:274] - INFO: epoch 010:     53 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.491, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.24, wps=502.5, ups=0.1, wpb=5118.6, bsz=1280, num_updates=2870, lr=2.8802e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=36106
2024-11-02 04:21:58 - progress_bar.py[line:274] - INFO: epoch 010:     63 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.489, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.23, wps=500.3, ups=0.1, wpb=5118.4, bsz=1280, num_updates=2880, lr=2.87171e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.8, wall=36208
2024-11-02 04:23:40 - progress_bar.py[line:274] - INFO: epoch 010:     73 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.495, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.28, wps=501.5, ups=0.1, wpb=5117.9, bsz=1280, num_updates=2890, lr=2.86321e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=36310
2024-11-02 04:25:22 - progress_bar.py[line:274] - INFO: epoch 010:     83 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.5, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.31, wps=500.2, ups=0.1, wpb=5117.8, bsz=1280, num_updates=2900, lr=2.85472e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=36413
2024-11-02 04:27:04 - progress_bar.py[line:274] - INFO: epoch 010:     93 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.508, ntokens=5118.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.38, wps=502.5, ups=0.1, wpb=5118.9, bsz=1280, num_updates=2910, lr=2.84622e-05, gnorm=0.006, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=36514
2024-11-02 04:28:47 - progress_bar.py[line:274] - INFO: epoch 010:    103 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.524, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.5, wps=497.3, ups=0.1, wpb=5118.2, bsz=1280, num_updates=2920, lr=2.83772e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=36617
2024-11-02 04:30:33 - progress_bar.py[line:274] - INFO: epoch 010:    113 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.524, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.51, wps=484.8, ups=0.09, wpb=5118.4, bsz=1280, num_updates=2930, lr=2.82923e-05, gnorm=0.006, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=36723
2024-11-02 04:32:17 - progress_bar.py[line:274] - INFO: epoch 010:    123 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.508, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.38, wps=488.8, ups=0.1, wpb=5118, bsz=1280, num_updates=2940, lr=2.82073e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=36828
2024-11-02 04:33:59 - progress_bar.py[line:274] - INFO: epoch 010:    133 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.503, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.34, wps=502, ups=0.1, wpb=5118.6, bsz=1280, num_updates=2950, lr=2.81223e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=36930
2024-11-02 04:35:41 - progress_bar.py[line:274] - INFO: epoch 010:    143 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.519, ntokens=5117.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.46, wps=501.6, ups=0.1, wpb=5117.2, bsz=1280, num_updates=2960, lr=2.80374e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=37032
2024-11-02 04:37:24 - progress_bar.py[line:274] - INFO: epoch 010:    153 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.504, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.35, wps=499.1, ups=0.1, wpb=5117.6, bsz=1280, num_updates=2970, lr=2.79524e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=37134
2024-11-02 04:39:06 - progress_bar.py[line:274] - INFO: epoch 010:    163 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.494, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.27, wps=502.7, ups=0.1, wpb=5118.2, bsz=1280, num_updates=2980, lr=2.78675e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=37236
2024-11-02 04:40:48 - progress_bar.py[line:274] - INFO: epoch 010:    173 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.506, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.36, wps=501.3, ups=0.1, wpb=5117.3, bsz=1280, num_updates=2990, lr=2.77825e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=37338
2024-11-02 04:42:30 - progress_bar.py[line:274] - INFO: epoch 010:    183 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.49, ntokens=5118, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.24, wps=502.9, ups=0.1, wpb=5118, bsz=1280, num_updates=3000, lr=2.76975e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=37440
slice_id 4 seek offset 27359
slice_id 2 seek offset 13680
slice_id 7 seek offset 47876
slice_id 3 seek offset 20520
slice_id 6 seek offset 41037
2024-11-02 04:42:30 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 1 seek offset 6840
slice_id 5 seek offset 34198
slice_id 3 seek offset 20520
slice_id 4 seek offset 27359
slice_id 2 seek offset 13680
slice_id 1 seek offset 6840
slice_id 6 seek offset 41037
slice_id 7 seek offset 47876
slice_id 5 seek offset 34198
slice_id 0 seek offset 0
2024-11-02 04:49:49 - progress_bar.py[line:282] - INFO: epoch 010 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.512 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.41 | score 0.5115 | wps 499.5 | wpb 639.7 | bsz 160 | num_updates 3000 | best_score 0.5115
2024-11-02 04:49:49 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 10 @ 3000 updates
2024-11-02 04:49:49 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_10_3000.pt
2024-11-02 04:50:00 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_10_3000.pt
2024-11-02 04:52:44 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_10_3000.pt (epoch 10 @ 3000 updates, score 0.5115) (writing took 174.8937126899982 seconds)
2024-11-02 04:54:16 - progress_bar.py[line:274] - INFO: epoch 010:    193 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.506, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.36, wps=72.5, ups=0.01, wpb=5117.3, bsz=1280, num_updates=3010, lr=2.76126e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=38146
2024-11-02 04:55:57 - progress_bar.py[line:274] - INFO: epoch 010:    203 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.521, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.48, wps=506.1, ups=0.1, wpb=5118.1, bsz=1280, num_updates=3020, lr=2.75276e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=38247
2024-11-02 04:57:38 - progress_bar.py[line:274] - INFO: epoch 010:    213 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.529, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.54, wps=505.5, ups=0.1, wpb=5118.5, bsz=1280, num_updates=3030, lr=2.74427e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=38348
2024-11-02 04:59:19 - progress_bar.py[line:274] - INFO: epoch 010:    223 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.506, ntokens=5118.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.36, wps=507.8, ups=0.1, wpb=5118.8, bsz=1280, num_updates=3040, lr=2.73577e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=38449
2024-11-02 05:01:00 - progress_bar.py[line:274] - INFO: epoch 010:    233 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.519, ntokens=5116.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.46, wps=504.7, ups=0.1, wpb=5116.9, bsz=1280, num_updates=3050, lr=2.72727e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=38550
2024-11-02 05:02:42 - progress_bar.py[line:274] - INFO: epoch 010:    243 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.5, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.32, wps=505.3, ups=0.1, wpb=5118.2, bsz=1280, num_updates=3060, lr=2.71878e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=38652
2024-11-02 05:04:23 - progress_bar.py[line:274] - INFO: epoch 010:    253 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.495, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.28, wps=505.6, ups=0.1, wpb=5118.2, bsz=1280, num_updates=3070, lr=2.71028e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=38753
2024-11-02 05:06:05 - progress_bar.py[line:274] - INFO: epoch 010:    263 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.512, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.41, wps=502.9, ups=0.1, wpb=5118.2, bsz=1280, num_updates=3080, lr=2.70178e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=38855
2024-11-02 05:07:46 - progress_bar.py[line:274] - INFO: epoch 010:    273 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.511, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.4, wps=504.2, ups=0.1, wpb=5118.2, bsz=1280, num_updates=3090, lr=2.69329e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=38956
2024-11-02 05:09:28 - progress_bar.py[line:274] - INFO: epoch 010:    283 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.524, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.5, wps=504.3, ups=0.1, wpb=5118.5, bsz=1280, num_updates=3100, lr=2.68479e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=39058
2024-11-02 05:11:09 - progress_bar.py[line:274] - INFO: epoch 010:    293 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.52, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.47, wps=505.2, ups=0.1, wpb=5117.7, bsz=1280, num_updates=3110, lr=2.6763e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=35, gb_free=9.7, wall=39159
2024-11-02 05:12:20 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4096.0
2024-11-02 05:13:01 - progress_bar.py[line:274] - INFO: epoch 010:    304 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.498, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.3, wps=457.5, ups=0.09, wpb=5117.9, bsz=1280, num_updates=3120, lr=2.6678e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=38, gb_free=9.7, wall=39271
slice_id 2 seek offset 13680
slice_id 6 seek offset 41037
slice_id 7 seek offset 47876slice_id 1 seek offset 6840

slice_id 4 seek offset 27359
slice_id 3 seek offset 20520slice_id 5 seek offset 34198

2024-11-02 05:14:25 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 4 seek offset 27359
slice_id 2 seek offset 13680
slice_id 3 seek offset 20520
slice_id 1 seek offset 6840
slice_id 6 seek offset 41037
slice_id 5 seek offset 34198
slice_id 7 seek offset 47876
slice_id 0 seek offset 0
2024-11-02 05:21:44 - progress_bar.py[line:282] - INFO: epoch 010 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.512 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.41 | score 0.5101 | wps 500.3 | wpb 639.7 | bsz 160 | num_updates 3129 | best_score 0.5115
2024-11-02 05:21:44 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 10 @ 3129 updates
2024-11-02 05:21:44 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
slice_id 4 seek offset 200000
slice_id 3 seek offset 150000
slice_id 2 seek offset 100000
slice_id 5 seek offset 250000
slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
slice_id 6 seek offset 300000
2024-11-02 05:22:44 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-02 05:22:44 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt (epoch 10 @ 3129 updates, score 0.5101) (writing took 60.60222977399826 seconds)
2024-11-02 05:22:44 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 10 @ 3129 updates
2024-11-02 05:22:44 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-02 05:23:45 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-02 05:23:45 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt (epoch 10 @ 3129 updates, score 0) (writing took 60.418115934000525 seconds)
2024-11-02 05:23:45 - train.py[line:336] - INFO: end of epoch 10 (average epoch stats below)
2024-11-02 05:23:45 - progress_bar.py[line:282] - INFO: epoch 010 | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.506 | ntokens 5109.84 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.36 | wps 365.9 | ups 0.07 | wpb 5109.8 | bsz 1277.9 | num_updates 3129 | lr 2.66015e-05 | gnorm 0.008 | clip 0 | loss_scale 4096 | train_wall 1092 | gb_free 9.7 | wall 39915
2024-11-02 05:23:45 - trainer.py[line:639] - INFO: loading train data for epoch 11
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-02 05:23:47 - trainer.py[line:703] - INFO: begin training epoch 11
2024-11-02 05:23:47 - train.py[line:297] - INFO: Start iterating over samples
2024-11-02 05:24:00 - progress_bar.py[line:274] - INFO: epoch 011:      1 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.503, ntokens=4862.4, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=11.34, wps=73.7, ups=0.02, wpb=4862.4, bsz=1216, num_updates=3130, lr=2.6593e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=33, gb_free=9.7, wall=39931
2024-11-02 05:25:42 - progress_bar.py[line:274] - INFO: epoch 011:     11 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.511, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.4, wps=505, ups=0.1, wpb=5117.8, bsz=1280, num_updates=3140, lr=2.65081e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=40032
2024-11-02 05:27:23 - progress_bar.py[line:274] - INFO: epoch 011:     21 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.516, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.44, wps=504.5, ups=0.1, wpb=5118.3, bsz=1280, num_updates=3150, lr=2.64231e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=40133
2024-11-02 05:29:04 - progress_bar.py[line:274] - INFO: epoch 011:     31 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.522, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.49, wps=505.1, ups=0.1, wpb=5117.8, bsz=1280, num_updates=3160, lr=2.63381e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=40235
2024-11-02 05:30:46 - progress_bar.py[line:274] - INFO: epoch 011:     41 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.529, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.54, wps=502.5, ups=0.1, wpb=5117.8, bsz=1280, num_updates=3170, lr=2.62532e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=40337
2024-11-02 05:32:28 - progress_bar.py[line:274] - INFO: epoch 011:     51 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.538, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.62, wps=502.6, ups=0.1, wpb=5118.2, bsz=1280, num_updates=3180, lr=2.61682e-05, gnorm=0.014, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=40438
2024-11-02 05:34:09 - progress_bar.py[line:274] - INFO: epoch 011:     61 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.558, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.77, wps=507.3, ups=0.1, wpb=5118.5, bsz=1280, num_updates=3190, lr=2.60833e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=40539
2024-11-02 05:35:50 - progress_bar.py[line:274] - INFO: epoch 011:     71 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.531, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.56, wps=506.2, ups=0.1, wpb=5118.1, bsz=1280, num_updates=3200, lr=2.59983e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=40640
2024-11-02 05:37:32 - progress_bar.py[line:274] - INFO: epoch 011:     81 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.53, ntokens=5117.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.55, wps=501.5, ups=0.1, wpb=5117.3, bsz=1280, num_updates=3210, lr=2.59133e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.8, wall=40742
2024-11-02 05:39:13 - progress_bar.py[line:274] - INFO: epoch 011:     91 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.523, ntokens=5118.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.49, wps=505.6, ups=0.1, wpb=5118.8, bsz=1280, num_updates=3220, lr=2.58284e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.6, wall=40844
2024-11-02 05:40:55 - progress_bar.py[line:274] - INFO: epoch 011:    101 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.522, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.49, wps=502.1, ups=0.1, wpb=5118.4, bsz=1280, num_updates=3230, lr=2.57434e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=40946
2024-11-02 05:42:37 - progress_bar.py[line:274] - INFO: epoch 011:    111 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.516, ntokens=5118.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.44, wps=506.1, ups=0.1, wpb=5118.4, bsz=1280, num_updates=3240, lr=2.56585e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=41047
2024-11-02 05:44:17 - progress_bar.py[line:274] - INFO: epoch 011:    121 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.516, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.44, wps=508.3, ups=0.1, wpb=5117.9, bsz=1280, num_updates=3250, lr=2.55735e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=41147
2024-11-02 05:45:58 - progress_bar.py[line:274] - INFO: epoch 011:    131 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.527, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.52, wps=508.7, ups=0.1, wpb=5118.7, bsz=1280, num_updates=3260, lr=2.54885e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=41248
2024-11-02 05:47:39 - progress_bar.py[line:274] - INFO: epoch 011:    141 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.53, ntokens=5117.4, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.55, wps=503.7, ups=0.1, wpb=5117.4, bsz=1280, num_updates=3270, lr=2.54036e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=41350
2024-11-02 05:49:21 - progress_bar.py[line:274] - INFO: epoch 011:    151 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.518, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.46, wps=504.6, ups=0.1, wpb=5117.7, bsz=1280, num_updates=3280, lr=2.53186e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=41451
2024-11-02 05:51:02 - progress_bar.py[line:274] - INFO: epoch 011:    161 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.51, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.39, wps=505.7, ups=0.1, wpb=5117.8, bsz=1280, num_updates=3290, lr=2.52336e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=41552
2024-11-02 05:52:43 - progress_bar.py[line:274] - INFO: epoch 011:    171 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.528, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.54, wps=504.7, ups=0.1, wpb=5117.6, bsz=1280, num_updates=3300, lr=2.51487e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=41654
2024-11-02 05:54:26 - progress_bar.py[line:274] - INFO: epoch 011:    181 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.521, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.48, wps=501.5, ups=0.1, wpb=5117.7, bsz=1280, num_updates=3310, lr=2.50637e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=41756
2024-11-02 05:56:07 - progress_bar.py[line:274] - INFO: epoch 011:    191 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.503, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.34, wps=505, ups=0.1, wpb=5117.6, bsz=1280, num_updates=3320, lr=2.49788e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=41857
2024-11-02 05:57:48 - progress_bar.py[line:274] - INFO: epoch 011:    201 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.511, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.4, wps=505, ups=0.1, wpb=5118.1, bsz=1280, num_updates=3330, lr=2.48938e-05, gnorm=0.006, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=41958
2024-11-02 05:59:29 - progress_bar.py[line:274] - INFO: epoch 011:    211 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.542, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.64, wps=506.8, ups=0.1, wpb=5118.2, bsz=1280, num_updates=3340, lr=2.48088e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.8, wall=42059
2024-11-02 06:01:10 - progress_bar.py[line:274] - INFO: epoch 011:    221 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.508, ntokens=5118.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.37, wps=506.9, ups=0.1, wpb=5118.9, bsz=1280, num_updates=3350, lr=2.47239e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=42160
2024-11-02 06:02:51 - progress_bar.py[line:274] - INFO: epoch 011:    231 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.496, ntokens=5117, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.28, wps=509, ups=0.1, wpb=5117, bsz=1280, num_updates=3360, lr=2.46389e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=42261
2024-11-02 06:04:32 - progress_bar.py[line:274] - INFO: epoch 011:    241 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.474, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.11, wps=503.8, ups=0.1, wpb=5118.3, bsz=1280, num_updates=3370, lr=2.4554e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=42363
2024-11-02 06:06:14 - progress_bar.py[line:274] - INFO: epoch 011:    251 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.493, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.26, wps=504.2, ups=0.1, wpb=5117.9, bsz=1280, num_updates=3380, lr=2.4469e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=42464
2024-11-02 06:07:55 - progress_bar.py[line:274] - INFO: epoch 011:    261 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.5, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.32, wps=505.4, ups=0.1, wpb=5118.3, bsz=1280, num_updates=3390, lr=2.4384e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=42565
2024-11-02 06:09:36 - progress_bar.py[line:274] - INFO: epoch 011:    271 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.505, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.36, wps=505.4, ups=0.1, wpb=5118.1, bsz=1280, num_updates=3400, lr=2.42991e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=42667
2024-11-02 06:11:18 - progress_bar.py[line:274] - INFO: epoch 011:    281 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.497, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.29, wps=502.3, ups=0.1, wpb=5118.6, bsz=1280, num_updates=3410, lr=2.42141e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=42768
2024-11-02 06:13:00 - progress_bar.py[line:274] - INFO: epoch 011:    291 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.498, ntokens=5117.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.3, wps=503, ups=0.1, wpb=5117.5, bsz=1280, num_updates=3420, lr=2.41291e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=42870
2024-11-02 06:14:42 - progress_bar.py[line:274] - INFO: epoch 011:    301 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.468, ntokens=5118.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.07, wps=502.6, ups=0.1, wpb=5118.7, bsz=1280, num_updates=3430, lr=2.40442e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=42972
2024-11-02 06:16:25 - progress_bar.py[line:274] - INFO: epoch 011:    311 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.471, ntokens=5117.8, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.09, wps=498.4, ups=0.1, wpb=5117.8, bsz=1280, num_updates=3440, lr=2.39592e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=43075
slice_id 2 seek offset 13680
slice_id 6 seek offset 41037
slice_id 1 seek offset 6840
slice_id 4 seek offset 27359slice_id 7 seek offset 47876

2024-11-02 06:16:38 - train.py[line:449] - INFO: begin validation on "valid" subset
slice_id 3 seek offset 20520slice_id 5 seek offset 34198

slice_id 0 seek offset 0
slice_id 4 seek offset 27359
slice_id 2 seek offset 13680
slice_id 3 seek offset 20520
slice_id 1 seek offset 6840
slice_id 5 seek offset 34198
slice_id 6 seek offset 41037
slice_id 7 seek offset 47876
slice_id 0 seek offset 0
2024-11-02 06:23:57 - progress_bar.py[line:282] - INFO: epoch 011 | valid on 'valid' subset | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.505 | ntokens 639.67 | nsentences 159.985 | sample_size 159.985 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.35 | score 0.5115 | wps 499.5 | wpb 639.7 | bsz 160 | num_updates 3442 | best_score 0.5115
2024-11-02 06:23:57 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 11 @ 3442 updates
2024-11-02 06:23:57 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 5 row count 50000 total row count 400000
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 7 row count 50000 total row count 400000
slice_id 4 seek offset 200000
slice_id 3 seek offset 150000
slice_id 2 seek offset 100000
slice_id 6 seek offset 300000
slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
slice_id 5 seek offset 250000
2024-11-02 06:24:58 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_best.pt
2024-11-02 06:26:49 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_best.pt (epoch 11 @ 3442 updates, score 0.5115) (writing took 172.29934750899702 seconds)
2024-11-02 06:26:49 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 11 @ 3442 updates
2024-11-02 06:26:49 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-02 06:27:49 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt
2024-11-02 06:27:50 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_pretrain_aihub_indoor_80_checkpoints_resume/20_5e-5_512/checkpoint_last.pt (epoch 11 @ 3442 updates, score 0) (writing took 60.095097183999314 seconds)
2024-11-02 06:27:50 - train.py[line:336] - INFO: end of epoch 11 (average epoch stats below)
2024-11-02 06:27:50 - progress_bar.py[line:282] - INFO: epoch 011 | loss 0.005 | loss_v1 0 | loss_v2 0 | nll_loss 3.513 | ntokens 5109.87 | nsentences 1277.95 | sample_size 1277.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.42 | wps 416 | ups 0.08 | wpb 5109.9 | bsz 1278 | num_updates 3442 | lr 2.39422e-05 | gnorm 0.009 | clip 0 | loss_scale 4096 | train_wall 1089 | gb_free 9.7 | wall 43760
2024-11-02 06:27:50 - trainer.py[line:639] - INFO: loading train data for epoch 12
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/pretrain/train_aihub_indoor_80.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-02 06:27:52 - trainer.py[line:703] - INFO: begin training epoch 12
2024-11-02 06:27:52 - train.py[line:297] - INFO: Start iterating over samples
2024-11-02 06:29:16 - progress_bar.py[line:274] - INFO: epoch 012:      8 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.491, ntokens=4862.3, nsentences=1216, sample_size=1216, sample_size_v1=0, sample_size_v2=0, ppl=11.25, wps=63, ups=0.01, wpb=4862.3, bsz=1216, num_updates=3450, lr=2.38743e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=33, gb_free=9.7, wall=43846
2024-11-02 06:30:57 - progress_bar.py[line:274] - INFO: epoch 012:     18 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.464, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.04, wps=506.4, ups=0.1, wpb=5117.9, bsz=1280, num_updates=3460, lr=2.37893e-05, gnorm=0.013, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=43947
2024-11-02 06:32:39 - progress_bar.py[line:274] - INFO: epoch 012:     28 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.477, ntokens=5117.7, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.13, wps=502.2, ups=0.1, wpb=5117.7, bsz=1280, num_updates=3470, lr=2.37043e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=44049
2024-11-02 06:34:20 - progress_bar.py[line:274] - INFO: epoch 012:     38 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.483, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.18, wps=504.2, ups=0.1, wpb=5117.9, bsz=1280, num_updates=3480, lr=2.36194e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=44151
2024-11-02 06:36:02 - progress_bar.py[line:274] - INFO: epoch 012:     48 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.5, ntokens=5118.2, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.31, wps=502.4, ups=0.1, wpb=5118.2, bsz=1280, num_updates=3490, lr=2.35344e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.8, wall=44252
2024-11-02 06:37:43 - progress_bar.py[line:274] - INFO: epoch 012:     58 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.498, ntokens=5118.3, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.3, wps=506.4, ups=0.1, wpb=5118.3, bsz=1280, num_updates=3500, lr=2.34494e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.8, wall=44353
2024-11-02 06:39:25 - progress_bar.py[line:274] - INFO: epoch 012:     68 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.509, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.38, wps=503.4, ups=0.1, wpb=5118.5, bsz=1280, num_updates=3510, lr=2.33645e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=44455
2024-11-02 06:41:07 - progress_bar.py[line:274] - INFO: epoch 012:     78 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.498, ntokens=5117.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.3, wps=501.9, ups=0.1, wpb=5117.6, bsz=1280, num_updates=3520, lr=2.32795e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=44557
2024-11-02 06:42:49 - progress_bar.py[line:274] - INFO: epoch 012:     88 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.501, ntokens=5118.1, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.33, wps=502.9, ups=0.1, wpb=5118.1, bsz=1280, num_updates=3530, lr=2.31946e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=44659
2024-11-02 06:44:30 - progress_bar.py[line:274] - INFO: epoch 012:     98 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.502, ntokens=5118.6, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.33, wps=502.9, ups=0.1, wpb=5118.6, bsz=1280, num_updates=3540, lr=2.31096e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=44761
2024-11-02 06:46:12 - progress_bar.py[line:274] - INFO: epoch 012:    108 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.484, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.19, wps=505.7, ups=0.1, wpb=5118.5, bsz=1280, num_updates=3550, lr=2.30246e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=44862
2024-11-02 06:47:53 - progress_bar.py[line:274] - INFO: epoch 012:    118 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.479, ntokens=5117.9, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.15, wps=506.8, ups=0.1, wpb=5117.9, bsz=1280, num_updates=3560, lr=2.29397e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=44963
2024-11-02 06:49:33 - progress_bar.py[line:274] - INFO: epoch 012:    128 / 313 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=3.472, ntokens=5118.5, nsentences=1280, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=11.1, wps=507.8, ups=0.1, wpb=5118.5, bsz=1280, num_updates=3570, lr=2.28547e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=35, gb_free=9.7, wall=45064
Traceback (most recent call last):
  File "../../train.py", line 543, in <module>
    cli_main()
  File "../../train.py", line 536, in cli_main
WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers
    distributed_utils.call_main(cfg, main)
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/distributed/utils.py", line 374, in call_main
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 20675 closing signal SIGINT
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/distributed/utils.py", line 348, in distributed_main
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 20676 closing signal SIGINT
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 20677 closing signal SIGINT
    main(cfg, **kwargs)
  File "../../train.py", line 190, in main
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 20678 closing signal SIGINT
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 20679 closing signal SIGINT
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/contextlib.py", line 74, in inner
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 20680 closing signal SIGINT
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 20681 closing signal SIGINT
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 20682 closing signal SIGINT
    return func(*args, **kwds)
  File "../../train.py", line 298, in train
    for i, samples in enumerate(progress):
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/logging/progress_bar.py", line 261, in __iter__
    for i, obj in enumerate(self.iterable, start=self.n):
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 56, in __next__
    x = next(self._itr)
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 509, in _chunk_iterator
    for x in itr:
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 56, in __next__
    x = next(self._itr)
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 635, in __next__
    item = self._queue.get(True)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/queue.py", line 170, in get
    self.not_empty.wait()
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/threading.py", line 296, in wait
    waiter.acquire()
KeyboardInterrupt
terminate called without an active exception
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 20675 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 20676 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 20677 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 20678 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 20679 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 20680 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 20681 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 20682 closing signal SIGTERM
Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 850, in _invoke_run
    time.sleep(monitor_interval)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 20567 got signal: 2

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 716, in run
    self._shutdown(e.sigval)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py", line 289, in _shutdown
    self._pcontext.close(death_sig)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 332, in close
    self._close(death_sig=death_sig, timeout=timeout)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 709, in _close
    handler.proc.wait(time_to_wait)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/subprocess.py", line 1019, in wait
    return self._wait(timeout=timeout)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/subprocess.py", line 1647, in _wait
    time.sleep(delay)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 20567 got signal: 2

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    result = agent.run()
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 721, in run
    self._shutdown()
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py", line 289, in _shutdown
    self._pcontext.close(death_sig)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 332, in close
    self._close(death_sig=death_sig, timeout=timeout)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 709, in _close
    handler.proc.wait(time_to_wait)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/subprocess.py", line 1019, in wait
    return self._wait(timeout=timeout)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/subprocess.py", line 1647, in _wait
    time.sleep(delay)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 20567 got signal: 2
