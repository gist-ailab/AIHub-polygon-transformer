/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launch.py:188: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  FutureWarning,
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2024-11-08 03:29:46 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 03:29:46 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 03:29:46 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 03:29:46 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 03:29:46 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 03:29:46 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 03:29:46 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 03:29:46 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 03:29:49 - utils.py[line:258] - INFO: distributed init (rank 2): env://
2024-11-08 03:29:49 - utils.py[line:261] - INFO: Start init
2024-11-08 03:29:49 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 2
2024-11-08 03:29:49 - utils.py[line:258] - INFO: distributed init (rank 5): env://
2024-11-08 03:29:49 - utils.py[line:261] - INFO: Start init
2024-11-08 03:29:49 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 5
2024-11-08 03:29:49 - utils.py[line:258] - INFO: distributed init (rank 4): env://
2024-11-08 03:29:49 - utils.py[line:261] - INFO: Start init
2024-11-08 03:29:49 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 4
2024-11-08 03:29:49 - utils.py[line:258] - INFO: distributed init (rank 3): env://
2024-11-08 03:29:49 - utils.py[line:261] - INFO: Start init
2024-11-08 03:29:49 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 3
2024-11-08 03:29:49 - utils.py[line:258] - INFO: distributed init (rank 6): env://
2024-11-08 03:29:49 - utils.py[line:261] - INFO: Start init
2024-11-08 03:29:49 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 6
2024-11-08 03:29:49 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2024-11-08 03:29:49 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2024-11-08 03:29:49 - utils.py[line:261] - INFO: Start init
2024-11-08 03:29:49 - utils.py[line:261] - INFO: Start init
2024-11-08 03:29:49 - utils.py[line:258] - INFO: distributed init (rank 7): env://
2024-11-08 03:29:49 - utils.py[line:261] - INFO: Start init
2024-11-08 03:29:49 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2024-11-08 03:29:49 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 7
2024-11-08 03:29:49 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2024-11-08 03:29:49 - distributed_c10d.py[line:354] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 03:29:49 - utils.py[line:274] - INFO: initialized host ip-172-31-9-178 as rank 1
single-machine distributed training is initialized.
2024-11-08 03:29:49 - distributed_c10d.py[line:354] - INFO: Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 03:29:49 - utils.py[line:274] - INFO: initialized host ip-172-31-9-178 as rank 4
single-machine distributed training is initialized.
2024-11-08 03:29:49 - distributed_c10d.py[line:354] - INFO: Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 03:29:49 - utils.py[line:274] - INFO: initialized host ip-172-31-9-178 as rank 3
single-machine distributed training is initialized.
2024-11-08 03:29:49 - distributed_c10d.py[line:354] - INFO: Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 03:29:49 - distributed_c10d.py[line:354] - INFO: Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 03:29:49 - utils.py[line:274] - INFO: initialized host ip-172-31-9-178 as rank 6
single-machine distributed training is initialized.
2024-11-08 03:29:49 - utils.py[line:274] - INFO: initialized host ip-172-31-9-178 as rank 5
single-machine distributed training is initialized.
2024-11-08 03:29:49 - distributed_c10d.py[line:354] - INFO: Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 03:29:49 - distributed_c10d.py[line:354] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 03:29:49 - distributed_c10d.py[line:354] - INFO: Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 03:29:49 - utils.py[line:274] - INFO: initialized host ip-172-31-9-178 as rank 2
single-machine distributed training is initialized.
2024-11-08 03:29:49 - utils.py[line:274] - INFO: initialized host ip-172-31-9-178 as rank 0
single-machine distributed training is initialized.
2024-11-08 03:29:49 - utils.py[line:274] - INFO: initialized host ip-172-31-9-178 as rank 7
single-machine distributed training is initialized.
2024-11-08 03:29:53 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../polyformer_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 500, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512', 'restore_file': '../finetune/polyformer_b_aihub_indoor_80_checkpoints/100_5e-5_512/checkpoint_epoch_53.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 500, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'score', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='polyformer_b', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='polyformer_b', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=16, batch_size_valid=16, best_checkpoint_metric='score', bf16=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, cls_weight=0.0005, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv,../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, det_weight=0.1, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_acc=True, eval_args='{"beam":5,"min_len":2,"max_len_a":0,"max_len_b":2}', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=100, max_image_size=512, max_source_positions=1024, max_src_length=80, max_target_positions=1024, max_tgt_length=420, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=8, num_bins=64, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', out_index=3, pad=1, patch_image_size=512, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, restore_file='../finetune/polyformer_b_aihub_indoor_80_checkpoints/100_5e-5_512/checkpoint_epoch_53.pt', sample_patch_num=196, save_dir='./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512', save_interval=1, save_interval_updates=500, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', scst=False, scst_args='{}', seed=1, selected_cols='0,5,6,2,4,3,7', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='refcoco', tensorboard_logdir=None, threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[8], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../polyformer_module', uses_ema=False, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=500, vis_encoder_type='swin-base', wandb_project=None, warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'refcoco', 'data': '../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv,../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv', 'selected_cols': '0,5,6,2,4,3,7', 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 80, 'max_tgt_length': 420, 'code_dict_size': 8192, 'patch_image_size': 512, 'num_bins': 64, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': True, 'eval_args': '{"beam":5,"min_len":2,"max_len_a":0,"max_len_b":2}', 'uses_ema': False, 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'det_weight': 0.1, 'cls_weight': 0.0005, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2024-11-08 03:29:53 - base_task.py[line:187] - INFO: source dictionary: 4100 types
2024-11-08 03:29:53 - base_task.py[line:188] - INFO: target dictionary: 4100 types
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2024-11-08 03:30:04 - train.py[line:101] - INFO: PolyFormerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(4100, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): SwinTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (pos_drop): Dropout(p=0.0, inplace=False)
      (layers): ModuleList(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): Identity()
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.009)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=512, out_features=256, bias=False)
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=256, out_features=256, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.017)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=256, out_features=1024, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1024, out_features=256, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=256, out_features=256, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.026)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=256, out_features=1024, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1024, out_features=256, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=1024, out_features=512, bias=False)
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.035)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.043)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (2): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.052)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (3): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.061)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (4): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.070)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (5): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.078)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (6): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.087)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (7): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.096)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (8): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.104)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (9): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.113)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (10): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.122)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (11): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.130)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (12): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.139)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (13): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.148)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (14): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.157)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (15): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.165)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (16): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.174)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (17): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.183)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=2048, out_features=1024, bias=False)
            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.191)
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.200)
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
      )
      (norm3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
    (bert): XLMRobertaForMaskedLM(
      (roberta): XLMRobertaModel(
        (embeddings): XLMRobertaEmbeddings(
          (word_embeddings): Embedding(250002, 768, padding_idx=1)
          (position_embeddings): Embedding(514, 768, padding_idx=1)
          (token_type_embeddings): Embedding(1, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): XLMRobertaEncoder(
          (layer): ModuleList(
            (0): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
      )
      (lm_head): XLMRobertaLMHead(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (decoder): Linear(in_features=768, out_features=250002, bias=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(4100, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (reg_head): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): Linear(in_features=768, out_features=768, bias=True)
        (2): Linear(in_features=768, out_features=2, bias=True)
      )
    )
    (cls_head): Linear(in_features=768, out_features=3, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2024-11-08 03:30:04 - train.py[line:102] - INFO: task: RefcocoTask
2024-11-08 03:30:04 - train.py[line:103] - INFO: model: PolyFormerModel
2024-11-08 03:30:04 - train.py[line:104] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2024-11-08 03:30:04 - train.py[line:108] - INFO: num. shared model params: 478,547,732 (num. trained: 478,547,732)
2024-11-08 03:30:04 - train.py[line:115] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 0 row count 6840 total row count 54715
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping




file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 6 row count 6839 total row count 54715file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 7 row count 6839 total row count 54715file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 4 row count 6839 total row count 54715file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 3 row count 6839 total row count 54715
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 2 row count 6840 total row count 54715



local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 5 row count 6839 total row count 54715
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_val.tsv slice_id 1 row count 6840 total row count 54715
2024-11-08 03:30:27 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2024-11-08 03:30:29 - distributed_c10d.py[line:354] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-11-08 03:30:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2024-11-08 03:30:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.layers.0.downsample.reduction.bias <- encoder.embed_images.layers.1.downsample.reduction.bias
2024-11-08 03:30:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.layers.0.downsample.reduction.bias <- encoder.embed_images.layers.2.downsample.reduction.bias
2024-11-08 03:30:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.layers.0.downsample.reduction.bias <- decoder.cls_head.bias
2024-11-08 03:30:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.bert.roberta.embeddings.word_embeddings.weight <- encoder.bert.lm_head.decoder.weight
2024-11-08 03:30:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.bert.lm_head.bias <- encoder.bert.lm_head.decoder.bias
2024-11-08 03:30:30 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 8 workers***********************
2024-11-08 03:30:30 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 03:30:30 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 03:30:30 - utils.py[line:765] - INFO: rank   2: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 03:30:30 - utils.py[line:765] - INFO: rank   3: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 03:30:30 - utils.py[line:765] - INFO: rank   4: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 03:30:30 - utils.py[line:765] - INFO: rank   5: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 03:30:30 - utils.py[line:765] - INFO: rank   6: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 03:30:30 - utils.py[line:765] - INFO: rank   7: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 03:30:30 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 8 workers***********************
2024-11-08 03:30:30 - train.py[line:145] - INFO: training on 8 devices (GPUs/TPUs)
2024-11-08 03:30:30 - train.py[line:151] - INFO: max tokens per device = None and max sentences per device = 16
2024-11-08 03:30:30 - trainer.py[line:458] - INFO: Preparing to load checkpoint ../finetune/polyformer_b_aihub_indoor_80_checkpoints/100_5e-5_512/checkpoint_epoch_53.pt
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
2024-11-08 03:30:42 - trainer.py[line:619] - INFO: Loaded checkpoint ../finetune/polyformer_b_aihub_indoor_80_checkpoints/100_5e-5_512/checkpoint_epoch_53.pt (epoch 54 @ 0 updates)
2024-11-08 03:30:42 - trainer.py[line:639] - INFO: loading train data for epoch 1
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 row count 50000 total row count 400000
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
slice_id 7 seek offset 350000
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping



file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 row count 50000 total row count 400000file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 row count 50000 total row count 400000

local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 row count 50000 total row count 400000
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
slice_id 0 seek offset 0
slice_id 4 seek offset 200000
slice_id 3 seek offset 150000
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
2024-11-08 03:33:25 - trainer.py[line:703] - INFO: begin training epoch 1
2024-11-08 03:33:25 - train.py[line:297] - INFO: Start iterating over samples
slice_id 2 seek offset 100000
slice_id 6 seek offset 300000
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 row count 50000 total row count 400000
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
slice_id 5 seek offset 250000
slice_id 1 seek offset 50000
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
loss_reg: 0.02260975600080856 loss_cls: 0.0029151414055377245
loss_reg: 0.023421138579062327 loss_cls: 0.002919314429163933
loss_reg: 0.01713970880890448 loss_cls: 0.0034312282223254442
loss_reg: 0.021332630771555516 loss_cls: 0.004411744419485331
loss_reg: 0.02097268734065616 loss_cls: 0.00293748383410275
loss_reg: 0.01660040497001266 loss_cls: 0.0030813380144536495
loss_reg: 0.01786980469556349 loss_cls: 0.003563228063285351
loss_reg: 0.004543109072685348 loss_cls: 0.0027485834434628487
loss_reg: 0.0206801952029622 loss_cls: 0.0031034809071570635
loss_reg: 0.017991478171550706 loss_cls: 0.0030012072529643774
loss_reg: 0.019546231506009763 loss_cls: 0.0031315304804593325
loss_reg: 0.021742205903741596 loss_cls: 0.002798374742269516
loss_reg: 0.018917265085260905 loss_cls: 0.0033075748942792416
loss_reg: 0.01651578951513973 loss_cls: 0.0035696655977517366
loss_reg: 0.02421151812609244 loss_cls: 0.0037521515041589737
loss_reg: 0.018287360313656967 loss_cls: 0.0044374167919158936
loss_reg: 0.004271196253159945 loss_cls: 0.002737878356128931
loss_reg: 0.01658026071218285 loss_cls: 0.004148784093558788
loss_reg: 0.022620518512528134 loss_cls: 0.0034201086964458227
loss_reg: 0.019514924070241593 loss_cls: 0.004241808317601681
loss_reg: 0.021864395008602305 loss_cls: 0.002702851314097643
loss_reg: 0.015669427452529118 loss_cls: 0.0035500056110322475
loss_reg: 0.021107301732814984 loss_cls: 0.0024486787151545286
loss_reg: 0.01909859915320129 loss_cls: 0.004127210006117821
loss_reg: 0.019690568802679633 loss_cls: 0.0027131615206599236
loss_reg: 0.021766842851307856 loss_cls: 0.003790924558416009
loss_reg: 0.0038221662755091902 loss_cls: 0.0027127705980092287
loss_reg: 0.01701720697900698 loss_cls: 0.004470893181860447
loss_reg: 0.01531058062345093 loss_cls: 0.003748447634279728
loss_reg: 0.024376967162616305 loss_cls: 0.0026995802763849497
loss_reg: 0.021293249376829172 loss_cls: 0.0037828872445970774
loss_reg: 0.01832402161178491 loss_cls: 0.0030696443282067776
loss_reg: 0.01768649292841327 loss_cls: 0.003421241883188486
loss_reg: 0.02022292130999605 loss_cls: 0.0036333256866782904
loss_reg: 0.0037489044415718806 loss_cls: 0.0035483343526721
loss_reg: 0.021375434636981487 loss_cls: 0.003368196776136756
loss_reg: 0.018530839203478144 loss_cls: 0.0061694043688476086
loss_reg: 0.017734334092517703 loss_cls: 0.004112239461392164
loss_reg: 0.018411886607942334 loss_cls: 0.0052265687845647335
loss_reg: 0.020958652195113874 loss_cls: 0.00381821789778769
loss_reg: 0.02058628586465066 loss_cls: 0.004670480731874704
loss_reg: 0.019966471633695575 loss_cls: 0.0035493087489157915
loss_reg: 0.005180647246255722 loss_cls: 0.0024195476435124874
loss_reg: 0.018039839993370527 loss_cls: 0.005129538010805845
loss_reg: 0.020410472827466646 loss_cls: 0.00290597858838737
loss_reg: 0.016974329792555296 loss_cls: 0.003145715454593301
loss_reg: 0.019559591252080497 loss_cls: 0.003087102435529232
loss_reg: 0.02083287440740407 loss_cls: 0.0033115516416728497
loss_reg: 0.019852339960089387 loss_cls: 0.0029089548625051975
loss_reg: 0.020175322842360777 loss_cls: 0.003176040481775999
loss_reg: 0.006323373983850418 loss_cls: 0.0024889379274100065
loss_reg: 0.020220211987360414 loss_cls: 0.003973618149757385
loss_reg: 0.02471294826594849 loss_cls: 0.0037168990820646286
loss_reg: 0.019927464617173714 loss_cls: 0.0029865645337849855
loss_reg: 0.019976679778756463 loss_cls: 0.00352631532587111
loss_reg: 0.0181806210721539 loss_cls: 0.0035693752579391003
loss_reg: 0.018637922892327578 loss_cls: 0.0029925976414233446
loss_reg: 0.005991966275792128 loss_cls: 0.0026464068796485662
loss_reg: 0.024638350634098204 loss_cls: 0.0036282697692513466
loss_reg: 0.023811998408248235 loss_cls: 0.002381842350587249
loss_reg: 0.019037072238646216 loss_cls: 0.004033675417304039
loss_reg: 0.02161161682093443 loss_cls: 0.0024849488399922848
loss_reg: 0.016904162869288367 loss_cls: 0.00453637819737196
loss_reg: 0.0037037771004264568 loss_cls: 0.003276130883023143
2024-11-08 03:34:28 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.281, ntokens=17535.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.86, wps=3227.6, ups=0.19, wpb=17535.3, bsz=1024, num_updates=10, lr=2.13129e-07, gnorm=0.01, clip=0, loss_scale=128, train_wall=46, gb_free=13.5, wall=238
2024-11-08 03:35:22 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.288, ntokens=17733.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.89, wps=3312.9, ups=0.19, wpb=17733.4, bsz=1024, num_updates=20, lr=4.26257e-07, gnorm=0.01, clip=0, loss_scale=128, train_wall=42, gb_free=13.5, wall=292
2024-11-08 03:36:14 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.232, ntokens=17420.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.7, wps=3317.1, ups=0.19, wpb=17420.7, bsz=1024, num_updates=30, lr=6.39386e-07, gnorm=0.005, clip=0, loss_scale=128, train_wall=33, gb_free=13.5, wall=344
2024-11-08 03:37:08 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.301, ntokens=17831.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.93, wps=3348.2, ups=0.19, wpb=17831.8, bsz=1024, num_updates=40, lr=8.52515e-07, gnorm=0.005, clip=0, loss_scale=128, train_wall=31, gb_free=13.6, wall=397
2024-11-08 03:38:01 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.293, ntokens=17628.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.9, wps=3320.7, ups=0.19, wpb=17628.1, bsz=1024, num_updates=50, lr=1.06564e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=451
2024-11-08 03:38:54 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.318, ntokens=17924.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.99, wps=3384.8, ups=0.19, wpb=17924.3, bsz=1024, num_updates=60, lr=1.27877e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=31, gb_free=13.5, wall=504
2024-11-08 03:39:47 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.301, ntokens=17717.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.93, wps=3355.5, ups=0.19, wpb=17717.1, bsz=1024, num_updates=70, lr=1.4919e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=556
2024-11-08 03:40:40 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.264, ntokens=17601.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.8, wps=3302.7, ups=0.19, wpb=17601.8, bsz=1024, num_updates=80, lr=1.70503e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=610
2024-11-08 03:41:34 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.291, ntokens=17624.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.89, wps=3266, ups=0.19, wpb=17624.4, bsz=1024, num_updates=90, lr=1.91816e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=31, gb_free=13.5, wall=664
2024-11-08 03:42:27 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.27, ntokens=17657, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.82, wps=3336.9, ups=0.19, wpb=17657, bsz=1024, num_updates=100, lr=2.13129e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=31, gb_free=13.5, wall=716
2024-11-08 03:43:20 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.271, ntokens=17488, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.83, wps=3277.3, ups=0.19, wpb=17488, bsz=1024, num_updates=110, lr=2.34442e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=770
2024-11-08 03:44:14 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.293, ntokens=17657, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.9, wps=3300.2, ups=0.19, wpb=17657, bsz=1024, num_updates=120, lr=2.55754e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=823
2024-11-08 03:45:06 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.291, ntokens=17663.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.89, wps=3350, ups=0.19, wpb=17663.1, bsz=1024, num_updates=130, lr=2.77067e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=876
2024-11-08 03:45:59 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.272, ntokens=17542.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.83, wps=3311.9, ups=0.19, wpb=17542.9, bsz=1024, num_updates=140, lr=2.9838e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=929
2024-11-08 03:46:53 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.241, ntokens=17394.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.73, wps=3241.6, ups=0.19, wpb=17394.6, bsz=1024, num_updates=150, lr=3.19693e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.4, wall=983
2024-11-08 03:47:46 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.253, ntokens=17608.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.77, wps=3299.1, ups=0.19, wpb=17608.3, bsz=1024, num_updates=160, lr=3.41006e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=1036
2024-11-08 03:48:39 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.309, ntokens=18153.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.96, wps=3413.8, ups=0.19, wpb=18153.7, bsz=1024, num_updates=170, lr=3.62319e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=1089
2024-11-08 03:49:33 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.254, ntokens=17369.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.77, wps=3254.2, ups=0.19, wpb=17369.1, bsz=1024, num_updates=180, lr=3.83632e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=1143
2024-11-08 03:50:26 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.351, ntokens=17980.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.1, wps=3391.5, ups=0.19, wpb=17980.9, bsz=1024, num_updates=190, lr=4.04945e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.4, wall=1196
2024-11-08 03:51:19 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.369, ntokens=17957.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.17, wps=3397.8, ups=0.19, wpb=17957.7, bsz=1024, num_updates=200, lr=4.26257e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=1249
2024-11-08 03:52:12 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.331, ntokens=17907.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.03, wps=3339.3, ups=0.19, wpb=17907.3, bsz=1024, num_updates=210, lr=4.4757e-06, gnorm=0.002, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=1302
2024-11-08 03:53:05 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.33, ntokens=17882.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.03, wps=3386.2, ups=0.19, wpb=17882.3, bsz=1024, num_updates=220, lr=4.68883e-06, gnorm=0.002, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=1355
2024-11-08 03:53:58 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.323, ntokens=17841, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5, wps=3356.7, ups=0.19, wpb=17841, bsz=1024, num_updates=230, lr=4.90196e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=1408
2024-11-08 03:54:52 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.347, ntokens=18014.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.09, wps=3368.5, ups=0.19, wpb=18014.1, bsz=1024, num_updates=240, lr=5.11509e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.4, wall=1462
2024-11-08 03:55:45 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.28, ntokens=17552.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.86, wps=3287.7, ups=0.19, wpb=17552.9, bsz=1024, num_updates=250, lr=5.32822e-06, gnorm=0.002, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=1515
2024-11-08 03:56:38 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.294, ntokens=17776.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.91, wps=3367.8, ups=0.19, wpb=17776.1, bsz=1024, num_updates=260, lr=5.54135e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=1568
2024-11-08 03:57:31 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.283, ntokens=17647.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.87, wps=3338.9, ups=0.19, wpb=17647.3, bsz=1024, num_updates=270, lr=5.75448e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=1621
2024-11-08 03:58:24 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.292, ntokens=17675.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.9, wps=3317.1, ups=0.19, wpb=17675.8, bsz=1024, num_updates=280, lr=5.9676e-06, gnorm=0.005, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=1674
2024-11-08 03:59:17 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.287, ntokens=17688.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.88, wps=3327.3, ups=0.19, wpb=17688.6, bsz=1024, num_updates=290, lr=6.18073e-06, gnorm=0.006, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=1727
2024-11-08 04:00:09 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.292, ntokens=17589.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.9, wps=3368, ups=0.19, wpb=17589.2, bsz=1024, num_updates=300, lr=6.39386e-06, gnorm=0.005, clip=0, loss_scale=128, train_wall=30, gb_free=13.4, wall=1779
2024-11-08 04:01:03 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.451, ntokens=18811.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.47, wps=3539.6, ups=0.19, wpb=18811.6, bsz=1024, num_updates=310, lr=6.60699e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=31, gb_free=13.4, wall=1832
2024-11-08 04:01:55 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.416, ntokens=18484.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.34, wps=3529.9, ups=0.19, wpb=18484.5, bsz=1024, num_updates=320, lr=6.82012e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.4, wall=1885
2024-11-08 04:02:47 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.375, ntokens=18256.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.19, wps=3502.7, ups=0.19, wpb=18256.4, bsz=1024, num_updates=330, lr=7.03325e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.4, wall=1937
2024-11-08 04:03:40 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.369, ntokens=18254.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.16, wps=3470.7, ups=0.19, wpb=18254.4, bsz=1024, num_updates=340, lr=7.24638e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=1990
2024-11-08 04:04:32 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.404, ntokens=18619.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.29, wps=3566, ups=0.19, wpb=18619.8, bsz=1024, num_updates=350, lr=7.45951e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=2042
2024-11-08 04:05:24 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.438, ntokens=18682, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.42, wps=3568.3, ups=0.19, wpb=18682, bsz=1024, num_updates=360, lr=7.67263e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=2094
2024-11-08 04:06:16 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.378, ntokens=18394.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.2, wps=3527.2, ups=0.19, wpb=18394.6, bsz=1024, num_updates=370, lr=7.88576e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.2, wall=2146
2024-11-08 04:07:10 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.33, ntokens=17954.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.03, wps=3375.3, ups=0.19, wpb=17954.2, bsz=1024, num_updates=380, lr=8.09889e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=33, gb_free=13.4, wall=2199
reach the end of datafile, start a new reader
reach the end of datafile, start a new reader
2024-11-08 04:08:03 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.333, ntokens=17998.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.04, wps=3383.5, ups=0.19, wpb=17998.3, bsz=1024, num_updates=390, lr=8.31202e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=36, gb_free=13.5, wall=2253
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt2024-11-08 04:08:05 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 391 updates
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_1.ptcp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_1.ptcp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt



cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
2024-11-08 04:08:05 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cp: cp: cp: cannot stat './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt'cannot stat './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt'cannot stat './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt'cannot stat './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt': No such file or directory
: No such file or directory: No such file or directory: No such file or directory


cp: cp: cp: cannot stat './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt'cannot stat './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt'cannot stat './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt': No such file or directory
: No such file or directory: No such file or directory

local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping


local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2024-11-08 04:08:19 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
2024-11-08 04:08:33 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 1 @ 391 updates, score 0) (writing took 27.942258747993037 seconds)
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
2024-11-08 04:08:38 - train.py[line:336] - INFO: end of epoch 1 (average epoch stats below)
2024-11-08 04:08:38 - progress_bar.py[line:282] - INFO: epoch 001 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.316 | ntokens 17842.9 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 4.98 | wps 3315.9 | ups 0.19 | wpb 17842.9 | bsz 1023 | num_updates 391 | lr 8.33333e-06 | gnorm 0.004 | clip 0 | loss_scale 128 | train_wall 1223 | gb_free 13.4 | wall 2288
2024-11-08 04:08:38 - trainer.py[line:639] - INFO: loading train data for epoch 2
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 row count 50000 total row count 400000file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 row count 50000 total row count 400000

slice_id 1 seek offset 50000
slice_id 5 seek offset 250000
slice_id 2 seek offset 100000
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping



file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 row count 50000 total row count 400000file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 row count 50000 total row count 400000file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 row count 50000 total row count 400000

file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 row count 50000 total row count 400000

slice_id 6 seek offset 300000
slice_id 4 seek offset 200000
slice_id 7 seek offset 350000
slice_id 3 seek offset 150000
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 04:11:21 - trainer.py[line:703] - INFO: begin training epoch 2
2024-11-08 04:11:21 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 04:12:10 - progress_bar.py[line:274] - INFO: epoch 002:      9 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.281, ntokens=16920.7, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=4.86, wps=684, ups=0.04, wpb=16920.7, bsz=985.6, num_updates=400, lr=8.52515e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=29, gb_free=13.5, wall=2500
2024-11-08 04:13:03 - progress_bar.py[line:274] - INFO: epoch 002:     19 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.286, ntokens=17781.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.88, wps=3366, ups=0.19, wpb=17781.7, bsz=1024, num_updates=410, lr=8.73828e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=2553
2024-11-08 04:13:56 - progress_bar.py[line:274] - INFO: epoch 002:     29 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.273, ntokens=17664.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.83, wps=3326.8, ups=0.19, wpb=17664.5, bsz=1024, num_updates=420, lr=8.95141e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=2606
2024-11-08 04:14:49 - progress_bar.py[line:274] - INFO: epoch 002:     39 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.281, ntokens=17781.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.86, wps=3364.3, ups=0.19, wpb=17781.4, bsz=1024, num_updates=430, lr=9.16454e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=31, gb_free=13.3, wall=2659
2024-11-08 04:15:42 - progress_bar.py[line:274] - INFO: epoch 002:     49 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.295, ntokens=17766.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.91, wps=3339.9, ups=0.19, wpb=17766.1, bsz=1024, num_updates=440, lr=9.37766e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=33, gb_free=13.6, wall=2712
2024-11-08 04:16:36 - progress_bar.py[line:274] - INFO: epoch 002:     59 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.276, ntokens=17745.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.84, wps=3292.6, ups=0.19, wpb=17745.1, bsz=1024, num_updates=450, lr=9.59079e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=45, gb_free=13.6, wall=2766
2024-11-08 04:17:30 - progress_bar.py[line:274] - INFO: epoch 002:     69 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.325, ntokens=17994.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.01, wps=3322.7, ups=0.18, wpb=17994.6, bsz=1024, num_updates=460, lr=9.80392e-06, gnorm=0.005, clip=0, loss_scale=128, train_wall=54, gb_free=13.5, wall=2820
2024-11-08 04:18:24 - progress_bar.py[line:274] - INFO: epoch 002:     79 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.269, ntokens=17623, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.82, wps=3248.7, ups=0.18, wpb=17623, bsz=1024, num_updates=470, lr=1.00171e-05, gnorm=0.006, clip=0, loss_scale=128, train_wall=54, gb_free=13.5, wall=2874
2024-11-08 04:19:19 - progress_bar.py[line:274] - INFO: epoch 002:     89 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.294, ntokens=17736, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.9, wps=3265.3, ups=0.18, wpb=17736, bsz=1024, num_updates=480, lr=1.02302e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=54, gb_free=13.5, wall=2929
2024-11-08 04:20:13 - progress_bar.py[line:274] - INFO: epoch 002:     99 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.285, ntokens=17772.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.87, wps=3289.2, ups=0.19, wpb=17772.9, bsz=1024, num_updates=490, lr=1.04433e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=54, gb_free=13.4, wall=2983
2024-11-08 04:21:07 - progress_bar.py[line:274] - INFO: epoch 002:    109 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.295, ntokens=17619.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.91, wps=3232.5, ups=0.18, wpb=17619.3, bsz=1024, num_updates=500, lr=1.06564e-05, gnorm=0.004, clip=0, loss_scale=128, train_wall=54, gb_free=13.3, wall=3037
2024-11-08 04:22:02 - progress_bar.py[line:274] - INFO: epoch 002:    119 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.332, ntokens=17921.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.03, wps=3259.8, ups=0.18, wpb=17921.9, bsz=1024, num_updates=510, lr=1.08696e-05, gnorm=0.004, clip=0, loss_scale=128, train_wall=55, gb_free=13.4, wall=3092
2024-11-08 04:22:57 - progress_bar.py[line:274] - INFO: epoch 002:    129 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.274, ntokens=17451.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.84, wps=3205.9, ups=0.18, wpb=17451.5, bsz=1024, num_updates=520, lr=1.10827e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=54, gb_free=13.5, wall=3147
2024-11-08 04:23:51 - progress_bar.py[line:274] - INFO: epoch 002:    139 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.281, ntokens=17567.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.86, wps=3249.3, ups=0.18, wpb=17567.8, bsz=1024, num_updates=530, lr=1.12958e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=54, gb_free=13.5, wall=3201
2024-11-08 04:24:45 - progress_bar.py[line:274] - INFO: epoch 002:    149 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.274, ntokens=17618.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.84, wps=3266.5, ups=0.19, wpb=17618.6, bsz=1024, num_updates=540, lr=1.1509e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=54, gb_free=13.5, wall=3255
2024-11-08 04:25:39 - progress_bar.py[line:274] - INFO: epoch 002:    159 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.283, ntokens=17768.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.87, wps=3263.1, ups=0.18, wpb=17768.3, bsz=1024, num_updates=550, lr=1.17221e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=54, gb_free=13.5, wall=3309
2024-11-08 04:26:34 - progress_bar.py[line:274] - INFO: epoch 002:    169 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.286, ntokens=17867.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.88, wps=3283.3, ups=0.18, wpb=17867.5, bsz=1024, num_updates=560, lr=1.19352e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=54, gb_free=13.5, wall=3363
2024-11-08 04:27:28 - progress_bar.py[line:274] - INFO: epoch 002:    179 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.269, ntokens=17460.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.82, wps=3216.6, ups=0.18, wpb=17460.5, bsz=1024, num_updates=570, lr=1.21483e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=54, gb_free=13.6, wall=3418
2024-11-08 04:28:22 - progress_bar.py[line:274] - INFO: epoch 002:    189 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.265, ntokens=17606.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.81, wps=3237.3, ups=0.18, wpb=17606.1, bsz=1024, num_updates=580, lr=1.23615e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=54, gb_free=13.6, wall=3472
2024-11-08 04:29:17 - progress_bar.py[line:274] - INFO: epoch 002:    199 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.354, ntokens=18257.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.11, wps=3364.8, ups=0.18, wpb=18257.9, bsz=1024, num_updates=590, lr=1.25746e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=54, gb_free=13.5, wall=3526
2024-11-08 04:30:11 - progress_bar.py[line:274] - INFO: epoch 002:    209 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.295, ntokens=17891.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.91, wps=3285.2, ups=0.18, wpb=17891.7, bsz=1024, num_updates=600, lr=1.27877e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=54, gb_free=13.4, wall=3581
2024-11-08 04:31:06 - progress_bar.py[line:274] - INFO: epoch 002:    219 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.34, ntokens=17928.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.06, wps=3264.6, ups=0.18, wpb=17928.4, bsz=1024, num_updates=610, lr=1.30009e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=55, gb_free=13.5, wall=3636
2024-11-08 04:32:00 - progress_bar.py[line:274] - INFO: epoch 002:    229 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.26, ntokens=17493.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.79, wps=3233.6, ups=0.18, wpb=17493.7, bsz=1024, num_updates=620, lr=1.3214e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=54, gb_free=13.5, wall=3690
2024-11-08 04:32:54 - progress_bar.py[line:274] - INFO: epoch 002:    239 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.269, ntokens=17502.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.82, wps=3230.5, ups=0.18, wpb=17502.6, bsz=1024, num_updates=630, lr=1.34271e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=54, gb_free=13.4, wall=3744
2024-11-08 04:33:49 - progress_bar.py[line:274] - INFO: epoch 002:    249 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.27, ntokens=17517.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.82, wps=3191.9, ups=0.18, wpb=17517.1, bsz=1024, num_updates=640, lr=1.36402e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=55, gb_free=13.5, wall=3799
2024-11-08 04:34:44 - progress_bar.py[line:274] - INFO: epoch 002:    259 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.245, ntokens=17444, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.74, wps=3180.1, ups=0.18, wpb=17444, bsz=1024, num_updates=650, lr=1.38534e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=55, gb_free=13.5, wall=3854
2024-11-08 04:35:39 - progress_bar.py[line:274] - INFO: epoch 002:    269 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.284, ntokens=17774.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.87, wps=3256.1, ups=0.18, wpb=17774.7, bsz=1024, num_updates=660, lr=1.40665e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=54, gb_free=13.2, wall=3908
2024-11-08 04:36:33 - progress_bar.py[line:274] - INFO: epoch 002:    279 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.268, ntokens=17653.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.82, wps=3270.1, ups=0.19, wpb=17653.5, bsz=1024, num_updates=670, lr=1.42796e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=54, gb_free=13.4, wall=3962
2024-11-08 04:37:27 - progress_bar.py[line:274] - INFO: epoch 002:    289 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.245, ntokens=17454.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.74, wps=3212.9, ups=0.18, wpb=17454.1, bsz=1024, num_updates=680, lr=1.44928e-05, gnorm=0.01, clip=0, loss_scale=256, train_wall=54, gb_free=13.5, wall=4017
2024-11-08 04:38:22 - progress_bar.py[line:274] - INFO: epoch 002:    299 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.298, ntokens=17843.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.92, wps=3249.8, ups=0.18, wpb=17843.2, bsz=1024, num_updates=690, lr=1.47059e-05, gnorm=0.01, clip=0, loss_scale=256, train_wall=55, gb_free=13.5, wall=4072
2024-11-08 04:39:17 - progress_bar.py[line:274] - INFO: epoch 002:    309 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.414, ntokens=18559.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.33, wps=3366, ups=0.18, wpb=18559.6, bsz=1024, num_updates=700, lr=1.4919e-05, gnorm=0.01, clip=0, loss_scale=256, train_wall=55, gb_free=13.2, wall=4127
2024-11-08 04:40:11 - progress_bar.py[line:274] - INFO: epoch 002:    319 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.414, ntokens=18438.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.33, wps=3385.8, ups=0.18, wpb=18438.7, bsz=1024, num_updates=710, lr=1.51321e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=54, gb_free=13.5, wall=4181
2024-11-08 04:41:06 - progress_bar.py[line:274] - INFO: epoch 002:    329 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.339, ntokens=18044.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.06, wps=3287.1, ups=0.18, wpb=18044.4, bsz=1024, num_updates=720, lr=1.53453e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=55, gb_free=13.4, wall=4236
2024-11-08 04:42:01 - progress_bar.py[line:274] - INFO: epoch 002:    339 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.351, ntokens=18149.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.1, wps=3303.4, ups=0.18, wpb=18149.8, bsz=1024, num_updates=730, lr=1.55584e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=55, gb_free=13.4, wall=4291
2024-11-08 04:42:56 - progress_bar.py[line:274] - INFO: epoch 002:    349 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.38, ntokens=18508.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.2, wps=3359.6, ups=0.18, wpb=18508.1, bsz=1024, num_updates=740, lr=1.57715e-05, gnorm=0.009, clip=0, loss_scale=256, train_wall=55, gb_free=13.3, wall=4346
2024-11-08 04:43:52 - progress_bar.py[line:274] - INFO: epoch 002:    359 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.376, ntokens=18280.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.19, wps=3283.3, ups=0.18, wpb=18280.9, bsz=1024, num_updates=750, lr=1.59847e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=56, gb_free=13.4, wall=4402
2024-11-08 04:44:50 - progress_bar.py[line:274] - INFO: epoch 002:    369 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.352, ntokens=18018.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.11, wps=3091.2, ups=0.17, wpb=18018.9, bsz=1024, num_updates=760, lr=1.61978e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=58, gb_free=13.5, wall=4460
2024-11-08 04:45:49 - progress_bar.py[line:274] - INFO: epoch 002:    379 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.323, ntokens=17930.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5, wps=3074.2, ups=0.17, wpb=17930.3, bsz=1024, num_updates=770, lr=1.64109e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=58, gb_free=13.5, wall=4518
2024-11-08 04:46:49 - progress_bar.py[line:274] - INFO: epoch 002:    389 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.322, ntokens=17700.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5, wps=2937.2, ups=0.17, wpb=17700.9, bsz=1024, num_updates=780, lr=1.6624e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=60, gb_free=13.5, wall=4579
reach the end of datafile, start a new reader
reach the end of datafile, start a new reader
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
2024-11-08 04:46:57 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 782 updates
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
2024-11-08 04:46:57 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
2024-11-08 04:49:06 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 row count 50000 total row count 400000
slice_id 1 seek offset 50000
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 row count 50000 total row count 400000
slice_id 5 seek offset 250000
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 row count 50000 total row count 400000
slice_id 2 seek offset 100000
slice_id 7 seek offset 350000
slice_id 4 seek offset 200000
slice_id 6 seek offset 300000
slice_id 3 seek offset 150000
2024-11-08 04:51:17 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 2 @ 782 updates, score 0) (writing took 260.3607551830064 seconds)
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
2024-11-08 04:52:22 - train.py[line:336] - INFO: end of epoch 2 (average epoch stats below)
2024-11-08 04:52:22 - progress_bar.py[line:282] - INFO: epoch 002 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.304 | ntokens 17795.9 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 4.94 | wps 2652.2 | ups 0.15 | wpb 17795.9 | bsz 1023 | num_updates 782 | lr 1.66667e-05 | gnorm 0.006 | clip 0 | loss_scale 256 | train_wall 2014 | gb_free 13.4 | wall 4912
2024-11-08 04:52:22 - trainer.py[line:639] - INFO: loading train data for epoch 3
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 04:55:06 - trainer.py[line:703] - INFO: begin training epoch 3
2024-11-08 04:55:06 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 04:55:52 - progress_bar.py[line:274] - INFO: epoch 003:      8 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.235, ntokens=16694.7, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=4.71, wps=307.1, ups=0.02, wpb=16694.7, bsz=985.6, num_updates=790, lr=1.68372e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=35, gb_free=13.4, wall=5122
2024-11-08 04:56:48 - progress_bar.py[line:274] - INFO: epoch 003:     18 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.293, ntokens=17901.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.9, wps=3225.6, ups=0.18, wpb=17901.5, bsz=1024, num_updates=800, lr=1.70503e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=45, gb_free=13.5, wall=5178
2024-11-08 04:57:41 - progress_bar.py[line:274] - INFO: epoch 003:     28 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.312, ntokens=17881.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.97, wps=3373.2, ups=0.19, wpb=17881.7, bsz=1024, num_updates=810, lr=1.72634e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=37, gb_free=13.4, wall=5231
2024-11-08 04:58:34 - progress_bar.py[line:274] - INFO: epoch 003:     38 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.311, ntokens=17912.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.96, wps=3385.1, ups=0.19, wpb=17912.9, bsz=1024, num_updates=820, lr=1.74766e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=5284
2024-11-08 04:59:28 - progress_bar.py[line:274] - INFO: epoch 003:     48 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.305, ntokens=17721, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.94, wps=3289.9, ups=0.19, wpb=17721, bsz=1024, num_updates=830, lr=1.76897e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=5338
2024-11-08 05:00:22 - progress_bar.py[line:274] - INFO: epoch 003:     58 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.297, ntokens=17823.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.91, wps=3294.5, ups=0.18, wpb=17823.4, bsz=1024, num_updates=840, lr=1.79028e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=5392
2024-11-08 05:01:16 - progress_bar.py[line:274] - INFO: epoch 003:     68 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.276, ntokens=17643.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.84, wps=3268.2, ups=0.19, wpb=17643.4, bsz=1024, num_updates=850, lr=1.81159e-05, gnorm=0.009, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=5446
2024-11-08 05:02:10 - progress_bar.py[line:274] - INFO: epoch 003:     78 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.294, ntokens=17884.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.9, wps=3327.9, ups=0.19, wpb=17884.5, bsz=1024, num_updates=860, lr=1.83291e-05, gnorm=0.01, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=5499
2024-11-08 05:03:04 - progress_bar.py[line:274] - INFO: epoch 003:     88 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.219, ntokens=17202.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.65, wps=3183.1, ups=0.19, wpb=17202.1, bsz=1024, num_updates=870, lr=1.85422e-05, gnorm=0.01, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=5553
2024-11-08 05:03:58 - progress_bar.py[line:274] - INFO: epoch 003:     98 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.282, ntokens=17716, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.86, wps=3282.8, ups=0.19, wpb=17716, bsz=1024, num_updates=880, lr=1.87553e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=5607
2024-11-08 05:04:52 - progress_bar.py[line:274] - INFO: epoch 003:    108 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.282, ntokens=17544.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.86, wps=3233.8, ups=0.18, wpb=17544.8, bsz=1024, num_updates=890, lr=1.89685e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=5662
2024-11-08 05:05:45 - progress_bar.py[line:274] - INFO: epoch 003:    118 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.314, ntokens=17929.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.97, wps=3355.6, ups=0.19, wpb=17929.2, bsz=1024, num_updates=900, lr=1.91816e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=5715
2024-11-08 05:06:39 - progress_bar.py[line:274] - INFO: epoch 003:    128 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.26, ntokens=17466, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.79, wps=3231.9, ups=0.19, wpb=17466, bsz=1024, num_updates=910, lr=1.93947e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=5769
2024-11-08 05:07:33 - progress_bar.py[line:274] - INFO: epoch 003:    138 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.248, ntokens=17273.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.75, wps=3225.1, ups=0.19, wpb=17273.5, bsz=1024, num_updates=920, lr=1.96078e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=5823
2024-11-08 05:08:28 - progress_bar.py[line:274] - INFO: epoch 003:    148 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.284, ntokens=17656.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.87, wps=3230.3, ups=0.18, wpb=17656.9, bsz=1024, num_updates=930, lr=1.9821e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=5877
2024-11-08 05:09:23 - progress_bar.py[line:274] - INFO: epoch 003:    158 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.292, ntokens=17831.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.9, wps=3231.3, ups=0.18, wpb=17831.6, bsz=1024, num_updates=940, lr=2.00341e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=5933
2024-11-08 05:10:17 - progress_bar.py[line:274] - INFO: epoch 003:    168 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.304, ntokens=17982.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.94, wps=3294.7, ups=0.18, wpb=17982.9, bsz=1024, num_updates=950, lr=2.02472e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=31, gb_free=13.4, wall=5987
2024-11-08 05:11:11 - progress_bar.py[line:274] - INFO: epoch 003:    178 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.232, ntokens=17181.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.7, wps=3189.3, ups=0.19, wpb=17181.7, bsz=1024, num_updates=960, lr=2.04604e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=6041
2024-11-08 05:12:05 - progress_bar.py[line:274] - INFO: epoch 003:    188 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.286, ntokens=17835.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.88, wps=3303, ups=0.19, wpb=17835.7, bsz=1024, num_updates=970, lr=2.06735e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=6095
2024-11-08 05:12:59 - progress_bar.py[line:274] - INFO: epoch 003:    198 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.282, ntokens=17554.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.86, wps=3271.6, ups=0.19, wpb=17554.7, bsz=1024, num_updates=980, lr=2.08866e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=6149
2024-11-08 05:13:53 - progress_bar.py[line:274] - INFO: epoch 003:    208 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.295, ntokens=17918.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.91, wps=3324.6, ups=0.19, wpb=17918.2, bsz=1024, num_updates=990, lr=2.10997e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=6203
2024-11-08 05:14:47 - progress_bar.py[line:274] - INFO: epoch 003:    218 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.296, ntokens=17536.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.91, wps=3262.8, ups=0.19, wpb=17536.7, bsz=1024, num_updates=1000, lr=2.13129e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=6256
2024-11-08 05:15:41 - progress_bar.py[line:274] - INFO: epoch 003:    228 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.282, ntokens=17771.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.86, wps=3256.5, ups=0.18, wpb=17771.9, bsz=1024, num_updates=1010, lr=2.1526e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=6311
2024-11-08 05:16:35 - progress_bar.py[line:274] - INFO: epoch 003:    238 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.246, ntokens=17462.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.74, wps=3213.5, ups=0.18, wpb=17462.8, bsz=1024, num_updates=1020, lr=2.17391e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=31, gb_free=13.5, wall=6365
2024-11-08 05:17:29 - progress_bar.py[line:274] - INFO: epoch 003:    248 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.304, ntokens=17702.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.94, wps=3332.3, ups=0.19, wpb=17702.6, bsz=1024, num_updates=1030, lr=2.19523e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=30, gb_free=13.5, wall=6418
2024-11-08 05:18:22 - progress_bar.py[line:274] - INFO: epoch 003:    258 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.235, ntokens=17357.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.71, wps=3235.3, ups=0.19, wpb=17357.6, bsz=1024, num_updates=1040, lr=2.21654e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=31, gb_free=13.5, wall=6472
2024-11-08 05:19:16 - progress_bar.py[line:274] - INFO: epoch 003:    268 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.345, ntokens=18249.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.08, wps=3398.5, ups=0.19, wpb=18249.6, bsz=1024, num_updates=1050, lr=2.23785e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=30, gb_free=13.5, wall=6526
2024-11-08 05:20:10 - progress_bar.py[line:274] - INFO: epoch 003:    278 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.294, ntokens=17764.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.9, wps=3292.1, ups=0.19, wpb=17764.1, bsz=1024, num_updates=1060, lr=2.25916e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=30, gb_free=13.4, wall=6580
2024-11-08 05:21:04 - progress_bar.py[line:274] - INFO: epoch 003:    288 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.217, ntokens=17227.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.65, wps=3167.5, ups=0.18, wpb=17227.8, bsz=1024, num_updates=1070, lr=2.28048e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=30, gb_free=13.6, wall=6634
2024-11-08 05:21:58 - progress_bar.py[line:274] - INFO: epoch 003:    298 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.328, ntokens=17898.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.02, wps=3341.2, ups=0.19, wpb=17898.3, bsz=1024, num_updates=1080, lr=2.30179e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=30, gb_free=13.4, wall=6688
2024-11-08 05:22:51 - progress_bar.py[line:274] - INFO: epoch 003:    308 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.409, ntokens=18402.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.31, wps=3432.9, ups=0.19, wpb=18402.7, bsz=1024, num_updates=1090, lr=2.3231e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=6741
2024-11-08 05:23:44 - progress_bar.py[line:274] - INFO: epoch 003:    318 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.389, ntokens=18312.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.24, wps=3453.5, ups=0.19, wpb=18312.9, bsz=1024, num_updates=1100, lr=2.34442e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=31, gb_free=13.4, wall=6794
2024-11-08 05:24:38 - progress_bar.py[line:274] - INFO: epoch 003:    328 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.357, ntokens=18118.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.12, wps=3414.9, ups=0.19, wpb=18118.6, bsz=1024, num_updates=1110, lr=2.36573e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=34, gb_free=13.4, wall=6847
2024-11-08 05:25:31 - progress_bar.py[line:274] - INFO: epoch 003:    338 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.399, ntokens=18372.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.27, wps=3461.6, ups=0.19, wpb=18372.7, bsz=1024, num_updates=1120, lr=2.38704e-05, gnorm=0.003, clip=0, loss_scale=512, train_wall=39, gb_free=13.4, wall=6900
2024-11-08 05:26:25 - progress_bar.py[line:274] - INFO: epoch 003:    348 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.393, ntokens=18510.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.25, wps=3403.2, ups=0.18, wpb=18510.1, bsz=1024, num_updates=1130, lr=2.40835e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=47, gb_free=13.2, wall=6955
2024-11-08 05:27:19 - progress_bar.py[line:274] - INFO: epoch 003:    358 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.376, ntokens=18306.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.19, wps=3397.6, ups=0.19, wpb=18306.6, bsz=1024, num_updates=1140, lr=2.42967e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=54, gb_free=13.2, wall=7009
2024-11-08 05:28:12 - progress_bar.py[line:274] - INFO: epoch 003:    368 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.347, ntokens=18037.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.09, wps=3371.4, ups=0.19, wpb=18037.1, bsz=1024, num_updates=1150, lr=2.45098e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=53, gb_free=13.4, wall=7062
2024-11-08 05:29:07 - progress_bar.py[line:274] - INFO: epoch 003:    378 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.334, ntokens=17982.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.04, wps=3316.9, ups=0.18, wpb=17982.3, bsz=1024, num_updates=1160, lr=2.47229e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=54, gb_free=13.3, wall=7116
2024-11-08 05:30:02 - progress_bar.py[line:274] - INFO: epoch 003:    388 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.349, ntokens=17965.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.1, wps=3268, ups=0.18, wpb=17965.8, bsz=1024, num_updates=1170, lr=2.49361e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=55, gb_free=13.4, wall=7171
reach the end of datafile, start a new reader
reach the end of datafile, start a new reader
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt2024-11-08 05:30:15 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 1173 updates

cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_3.ptcp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt

cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
2024-11-08 05:30:15 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
cp: cannot create regular file './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt': File exists
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
2024-11-08 05:32:05 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 row count 50000 total row count 400000
slice_id 2 seek offset 100000
2024-11-08 05:34:00 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 3 @ 1173 updates, score 0) (writing took 224.55026989002363 seconds)
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 row count 50000 total row count 400000
slice_id 1 seek offset 50000
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 row count 50000 total row count 400000file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 row count 50000 total row count 400000

local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 row count 50000 total row count 400000
slice_id 5 seek offset 250000
slice_id 7 seek offset 350000
slice_id 4 seek offset 200000
slice_id 6 seek offset 300000
slice_id 3 seek offset 150000
2024-11-08 05:34:55 - train.py[line:336] - INFO: end of epoch 3 (average epoch stats below)
2024-11-08 05:34:55 - progress_bar.py[line:282] - INFO: epoch 003 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.304 | ntokens 17784.7 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 4.94 | wps 2723.1 | ups 0.15 | wpb 17784.7 | bsz 1023 | num_updates 1173 | lr 2.5e-05 | gnorm 0.006 | clip 0 | loss_scale 512 | train_wall 1339 | gb_free 13.4 | wall 7465
2024-11-08 05:34:55 - trainer.py[line:639] - INFO: loading train data for epoch 4
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 05:37:43 - trainer.py[line:703] - INFO: begin training epoch 4
2024-11-08 05:37:43 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 05:38:34 - progress_bar.py[line:274] - INFO: epoch 004:      7 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.276, ntokens=16998.2, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=4.84, wps=331.7, ups=0.02, wpb=16998.2, bsz=985.6, num_updates=1180, lr=2.51492e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=59, gb_free=13.6, wall=7684
2024-11-08 05:39:40 - progress_bar.py[line:274] - INFO: epoch 004:     17 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.32, ntokens=17917.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.99, wps=2726.6, ups=0.15, wpb=17917.9, bsz=1024, num_updates=1190, lr=2.53623e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=66, gb_free=13.6, wall=7750
2024-11-08 05:40:46 - progress_bar.py[line:274] - INFO: epoch 004:     27 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.287, ntokens=17656.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.88, wps=2664.7, ups=0.15, wpb=17656.8, bsz=1024, num_updates=1200, lr=2.55754e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=66, gb_free=13.6, wall=7816
2024-11-08 05:41:53 - progress_bar.py[line:274] - INFO: epoch 004:     37 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.324, ntokens=18080.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.01, wps=2719, ups=0.15, wpb=18080.6, bsz=1024, num_updates=1210, lr=2.57886e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=66, gb_free=13.5, wall=7882
2024-11-08 05:42:44 - progress_bar.py[line:274] - INFO: epoch 004:     47 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.271, ntokens=17609.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.83, wps=3420.2, ups=0.19, wpb=17609.3, bsz=1024, num_updates=1220, lr=2.60017e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=40, gb_free=13.5, wall=7934
2024-11-08 05:43:39 - progress_bar.py[line:274] - INFO: epoch 004:     57 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.28, ntokens=17636.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.86, wps=3204, ups=0.18, wpb=17636.2, bsz=1024, num_updates=1230, lr=2.62148e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=45, gb_free=13.4, wall=7989
2024-11-08 05:44:34 - progress_bar.py[line:274] - INFO: epoch 004:     67 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.312, ntokens=17847.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.97, wps=3226.8, ups=0.18, wpb=17847.3, bsz=1024, num_updates=1240, lr=2.6428e-05, gnorm=0.003, clip=0, loss_scale=512, train_wall=54, gb_free=13.4, wall=8044
2024-11-08 05:45:30 - progress_bar.py[line:274] - INFO: epoch 004:     77 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.232, ntokens=17303.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.7, wps=3138.9, ups=0.18, wpb=17303.2, bsz=1024, num_updates=1250, lr=2.66411e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=55, gb_free=13.5, wall=8099
2024-11-08 05:46:24 - progress_bar.py[line:274] - INFO: epoch 004:     87 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.272, ntokens=17653.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.83, wps=3245.1, ups=0.18, wpb=17653.4, bsz=1024, num_updates=1260, lr=2.68542e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=54, gb_free=13.6, wall=8154
2024-11-08 05:47:19 - progress_bar.py[line:274] - INFO: epoch 004:     97 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.291, ntokens=17707, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.89, wps=3213.3, ups=0.18, wpb=17707, bsz=1024, num_updates=1270, lr=2.70673e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=55, gb_free=13.4, wall=8209
2024-11-08 05:48:14 - progress_bar.py[line:274] - INFO: epoch 004:    107 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.276, ntokens=17543.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.84, wps=3192.3, ups=0.18, wpb=17543.2, bsz=1024, num_updates=1280, lr=2.72805e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=55, gb_free=13.5, wall=8264
2024-11-08 05:49:09 - progress_bar.py[line:274] - INFO: epoch 004:    117 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.323, ntokens=17831.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5, wps=3218.2, ups=0.18, wpb=17831.1, bsz=1024, num_updates=1290, lr=2.74936e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=55, gb_free=13.5, wall=8319
2024-11-08 05:50:04 - progress_bar.py[line:274] - INFO: epoch 004:    127 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.283, ntokens=17544.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.87, wps=3201.4, ups=0.18, wpb=17544.4, bsz=1024, num_updates=1300, lr=2.77067e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=55, gb_free=13.5, wall=8374
2024-11-08 05:51:00 - progress_bar.py[line:274] - INFO: epoch 004:    137 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.3, ntokens=17554.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.92, wps=3162.9, ups=0.18, wpb=17554.4, bsz=1024, num_updates=1310, lr=2.79199e-05, gnorm=0.003, clip=0, loss_scale=512, train_wall=55, gb_free=13.3, wall=8430
2024-11-08 05:51:55 - progress_bar.py[line:274] - INFO: epoch 004:    147 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.338, ntokens=17976, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.06, wps=3240.5, ups=0.18, wpb=17976, bsz=1024, num_updates=1320, lr=2.8133e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=55, gb_free=13.5, wall=8485
2024-11-08 05:52:50 - progress_bar.py[line:274] - INFO: epoch 004:    157 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.295, ntokens=17645.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.91, wps=3245.8, ups=0.18, wpb=17645.7, bsz=1024, num_updates=1330, lr=2.83461e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=54, gb_free=13.6, wall=8539
2024-11-08 05:53:44 - progress_bar.py[line:274] - INFO: epoch 004:    167 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.343, ntokens=18192.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.07, wps=3317.8, ups=0.18, wpb=18192.6, bsz=1024, num_updates=1340, lr=2.85592e-05, gnorm=0.008, clip=0, loss_scale=512, train_wall=55, gb_free=13.5, wall=8594
2024-11-08 05:54:39 - progress_bar.py[line:274] - INFO: epoch 004:    177 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.255, ntokens=17242.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.77, wps=3144.1, ups=0.18, wpb=17242.9, bsz=1024, num_updates=1350, lr=2.87724e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=55, gb_free=13.3, wall=8649
2024-11-08 05:55:34 - progress_bar.py[line:274] - INFO: epoch 004:    187 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.338, ntokens=18062.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.06, wps=3322.6, ups=0.18, wpb=18062.6, bsz=1024, num_updates=1360, lr=2.89855e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=54, gb_free=13.5, wall=8703
2024-11-08 05:56:27 - progress_bar.py[line:274] - INFO: epoch 004:    197 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.33, ntokens=17833.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.03, wps=3320, ups=0.19, wpb=17833.4, bsz=1024, num_updates=1370, lr=2.91986e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=54, gb_free=13.4, wall=8757
2024-11-08 05:57:21 - progress_bar.py[line:274] - INFO: epoch 004:    207 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.322, ntokens=17976.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5, wps=3332.9, ups=0.19, wpb=17976.4, bsz=1024, num_updates=1380, lr=2.94118e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=54, gb_free=13.5, wall=8811
2024-11-08 05:58:16 - progress_bar.py[line:274] - INFO: epoch 004:    217 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.318, ntokens=17835.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.99, wps=3277.5, ups=0.18, wpb=17835.3, bsz=1024, num_updates=1390, lr=2.96249e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=54, gb_free=13.6, wall=8865
2024-11-08 05:59:10 - progress_bar.py[line:274] - INFO: epoch 004:    227 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.266, ntokens=17476.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.81, wps=3220.6, ups=0.18, wpb=17476.3, bsz=1024, num_updates=1400, lr=2.9838e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=54, gb_free=13.6, wall=8920
2024-11-08 06:00:04 - progress_bar.py[line:274] - INFO: epoch 004:    237 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.267, ntokens=17513.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.81, wps=3213.3, ups=0.18, wpb=17513.1, bsz=1024, num_updates=1410, lr=3.00512e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=54, gb_free=13.6, wall=8974
2024-11-08 06:01:00 - progress_bar.py[line:274] - INFO: epoch 004:    247 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.278, ntokens=17357.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.85, wps=3144.3, ups=0.18, wpb=17357.9, bsz=1024, num_updates=1420, lr=3.02643e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=55, gb_free=13.5, wall=9029
2024-11-08 06:01:54 - progress_bar.py[line:274] - INFO: epoch 004:    257 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.252, ntokens=17406.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.76, wps=3197.6, ups=0.18, wpb=17406.1, bsz=1024, num_updates=1430, lr=3.04774e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=54, gb_free=13.4, wall=9084
2024-11-08 06:02:49 - progress_bar.py[line:274] - INFO: epoch 004:    267 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.266, ntokens=17638.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.81, wps=3213.7, ups=0.18, wpb=17638.7, bsz=1024, num_updates=1440, lr=3.06905e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=55, gb_free=13.4, wall=9139
2024-11-08 06:03:44 - progress_bar.py[line:274] - INFO: epoch 004:    277 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.295, ntokens=17655, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.91, wps=3229.4, ups=0.18, wpb=17655, bsz=1024, num_updates=1450, lr=3.09037e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=55, gb_free=13.5, wall=9193
2024-11-08 06:04:39 - progress_bar.py[line:274] - INFO: epoch 004:    287 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.283, ntokens=17540.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.87, wps=3195.8, ups=0.18, wpb=17540.6, bsz=1024, num_updates=1460, lr=3.11168e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=55, gb_free=13.6, wall=9248
2024-11-08 06:05:33 - progress_bar.py[line:274] - INFO: epoch 004:    297 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.307, ntokens=17814.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.95, wps=3248.7, ups=0.18, wpb=17814.3, bsz=1024, num_updates=1470, lr=3.13299e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=55, gb_free=13.4, wall=9303
2024-11-08 06:06:30 - progress_bar.py[line:274] - INFO: epoch 004:    307 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.427, ntokens=18544.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.38, wps=3304.2, ups=0.18, wpb=18544.4, bsz=1024, num_updates=1480, lr=3.15431e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=56, gb_free=13.4, wall=9359
2024-11-08 06:07:25 - progress_bar.py[line:274] - INFO: epoch 004:    317 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.387, ntokens=18211.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.23, wps=3307.7, ups=0.18, wpb=18211.8, bsz=1024, num_updates=1490, lr=3.17562e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=55, gb_free=13.4, wall=9414
2024-11-08 06:08:20 - progress_bar.py[line:274] - INFO: epoch 004:    327 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.369, ntokens=18072.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.17, wps=3256.6, ups=0.18, wpb=18072.1, bsz=1024, num_updates=1500, lr=3.19693e-05, gnorm=0.003, clip=0, loss_scale=512, train_wall=55, gb_free=13.4, wall=9470
2024-11-08 06:09:16 - progress_bar.py[line:274] - INFO: epoch 004:    337 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.391, ntokens=18249.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.25, wps=3276.5, ups=0.18, wpb=18249.8, bsz=1024, num_updates=1510, lr=3.21824e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=56, gb_free=13.5, wall=9526
2024-11-08 06:10:12 - progress_bar.py[line:274] - INFO: epoch 004:    347 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.394, ntokens=18504.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.26, wps=3307.7, ups=0.18, wpb=18504.8, bsz=1024, num_updates=1520, lr=3.23956e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=56, gb_free=13.4, wall=9582
2024-11-08 06:11:07 - progress_bar.py[line:274] - INFO: epoch 004:    357 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.404, ntokens=18409.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.29, wps=3347.1, ups=0.18, wpb=18409.7, bsz=1024, num_updates=1530, lr=3.26087e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=55, gb_free=13.4, wall=9637
2024-11-08 06:12:02 - progress_bar.py[line:274] - INFO: epoch 004:    367 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.339, ntokens=18013.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.06, wps=3264.3, ups=0.18, wpb=18013.3, bsz=1024, num_updates=1540, lr=3.28218e-05, gnorm=0.004, clip=0, loss_scale=1024, train_wall=55, gb_free=13.3, wall=9692
2024-11-08 06:12:58 - progress_bar.py[line:274] - INFO: epoch 004:    377 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.4, ntokens=18417.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.28, wps=3306.4, ups=0.18, wpb=18417.8, bsz=1024, num_updates=1550, lr=3.3035e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=56, gb_free=13.3, wall=9747
2024-11-08 06:13:53 - progress_bar.py[line:274] - INFO: epoch 004:    387 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.348, ntokens=17982.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.09, wps=3219.6, ups=0.18, wpb=17982.8, bsz=1024, num_updates=1560, lr=3.32481e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=56, gb_free=13.4, wall=9803
reach the end of datafile, start a new reader
reach the end of datafile, start a new reader
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_4.ptcp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt

cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt2024-11-08 06:14:12 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 1564 updates

cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt
2024-11-08 06:14:12 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cp: cp: cannot create regular file './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt'cannot create regular file './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt'cannot create regular file './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt': File exists
: File exists: File exists

local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2024-11-08 06:15:58 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 row count 50000 total row count 400000file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 row count 50000 total row count 400000

file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 row count 50000 total row count 400000
slice_id 4 seek offset 200000
slice_id 3 seek offset 150000
slice_id 6 seek offset 300000
2024-11-08 06:17:53 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 4 @ 1564 updates, score 0) (writing took 220.80295308399945 seconds)
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 row count 50000 total row count 400000
slice_id 7 seek offset 350000
slice_id 5 seek offset 250000
slice_id 1 seek offset 50000
slice_id 2 seek offset 100000
2024-11-08 06:18:49 - train.py[line:336] - INFO: end of epoch 4 (average epoch stats below)
2024-11-08 06:18:49 - progress_bar.py[line:282] - INFO: epoch 004 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.315 | ntokens 17804.6 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 4.98 | wps 2643.5 | ups 0.15 | wpb 17804.6 | bsz 1023 | num_updates 1564 | lr 3.33333e-05 | gnorm 0.005 | clip 0 | loss_scale 1024 | train_wall 2157 | gb_free 13.4 | wall 10099
2024-11-08 06:18:49 - trainer.py[line:639] - INFO: loading train data for epoch 5
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 06:21:32 - trainer.py[line:703] - INFO: begin training epoch 5
2024-11-08 06:21:32 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 06:22:08 - progress_bar.py[line:274] - INFO: epoch 005:      6 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.288, ntokens=16950.1, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=4.88, wps=343, ups=0.02, wpb=16950.1, bsz=985.6, num_updates=1570, lr=3.34612e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=37, gb_free=13.5, wall=10297
2024-11-08 06:23:02 - progress_bar.py[line:274] - INFO: epoch 005:     16 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.324, ntokens=18019.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.01, wps=3300.4, ups=0.18, wpb=18019.7, bsz=1024, num_updates=1580, lr=3.36743e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=10352
2024-11-08 06:23:57 - progress_bar.py[line:274] - INFO: epoch 005:     26 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.292, ntokens=17669.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.9, wps=3212.9, ups=0.18, wpb=17669.1, bsz=1024, num_updates=1590, lr=3.38875e-05, gnorm=0.004, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=10407
2024-11-08 06:24:52 - progress_bar.py[line:274] - INFO: epoch 005:     36 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.326, ntokens=18047.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.01, wps=3290.3, ups=0.18, wpb=18047.6, bsz=1024, num_updates=1600, lr=3.41006e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=10462
2024-11-08 06:25:47 - progress_bar.py[line:274] - INFO: epoch 005:     46 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.284, ntokens=17636.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.87, wps=3228.1, ups=0.18, wpb=17636.6, bsz=1024, num_updates=1610, lr=3.43137e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=10517
2024-11-08 06:26:42 - progress_bar.py[line:274] - INFO: epoch 005:     56 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.243, ntokens=17429.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.73, wps=3136.3, ups=0.18, wpb=17429.8, bsz=1024, num_updates=1620, lr=3.45269e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=31, gb_free=13.4, wall=10572
2024-11-08 06:27:38 - progress_bar.py[line:274] - INFO: epoch 005:     66 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.303, ntokens=17821, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.93, wps=3212.6, ups=0.18, wpb=17821, bsz=1024, num_updates=1630, lr=3.474e-05, gnorm=0.004, clip=0, loss_scale=1024, train_wall=31, gb_free=13.3, wall=10628
2024-11-08 06:28:34 - progress_bar.py[line:274] - INFO: epoch 005:     76 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.268, ntokens=17513, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.82, wps=3138.3, ups=0.18, wpb=17513, bsz=1024, num_updates=1640, lr=3.49531e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=10683
2024-11-08 06:29:29 - progress_bar.py[line:274] - INFO: epoch 005:     86 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.259, ntokens=17536.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.79, wps=3159.7, ups=0.18, wpb=17536.2, bsz=1024, num_updates=1650, lr=3.51662e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=31, gb_free=13.5, wall=10739
2024-11-08 06:30:24 - progress_bar.py[line:274] - INFO: epoch 005:     96 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.299, ntokens=17748.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.92, wps=3231.9, ups=0.18, wpb=17748.1, bsz=1024, num_updates=1660, lr=3.53794e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=31, gb_free=13.6, wall=10794
2024-11-08 06:31:22 - progress_bar.py[line:274] - INFO: epoch 005:    106 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.25, ntokens=17450.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.76, wps=2983.4, ups=0.17, wpb=17450.6, bsz=1024, num_updates=1670, lr=3.55925e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=33, gb_free=13.4, wall=10852
2024-11-08 06:32:22 - progress_bar.py[line:274] - INFO: epoch 005:    116 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.319, ntokens=17766.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.99, wps=2979.4, ups=0.17, wpb=17766.7, bsz=1024, num_updates=1680, lr=3.58056e-05, gnorm=0.004, clip=0, loss_scale=1024, train_wall=41, gb_free=13.5, wall=10912
2024-11-08 06:33:22 - progress_bar.py[line:274] - INFO: epoch 005:    126 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.269, ntokens=17573.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.82, wps=2931.5, ups=0.17, wpb=17573.9, bsz=1024, num_updates=1690, lr=3.60188e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=47, gb_free=13.6, wall=10972
2024-11-08 06:34:20 - progress_bar.py[line:274] - INFO: epoch 005:    136 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.309, ntokens=17717.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.95, wps=3046, ups=0.17, wpb=17717.7, bsz=1024, num_updates=1700, lr=3.62319e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=44, gb_free=13.5, wall=11030
2024-11-08 06:35:21 - progress_bar.py[line:274] - INFO: epoch 005:    146 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.264, ntokens=17535.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.8, wps=2883.4, ups=0.16, wpb=17535.7, bsz=1024, num_updates=1710, lr=3.6445e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=45, gb_free=13.5, wall=11091
2024-11-08 06:36:22 - progress_bar.py[line:274] - INFO: epoch 005:    156 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.274, ntokens=17543.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.84, wps=2892.7, ups=0.16, wpb=17543.9, bsz=1024, num_updates=1720, lr=3.66581e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=50, gb_free=13.5, wall=11151
2024-11-08 06:37:22 - progress_bar.py[line:274] - INFO: epoch 005:    166 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.296, ntokens=17868.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.91, wps=2985.8, ups=0.17, wpb=17868.5, bsz=1024, num_updates=1730, lr=3.68713e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=60, gb_free=13.4, wall=11211
2024-11-08 06:38:23 - progress_bar.py[line:274] - INFO: epoch 005:    176 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.29, ntokens=17478.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.89, wps=2860.7, ups=0.16, wpb=17478.3, bsz=1024, num_updates=1740, lr=3.70844e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=61, gb_free=13.6, wall=11272
2024-11-08 06:39:30 - progress_bar.py[line:274] - INFO: epoch 005:    186 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.32, ntokens=17764.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.99, wps=2645.8, ups=0.15, wpb=17764.2, bsz=1024, num_updates=1750, lr=3.72975e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=67, gb_free=13.4, wall=11340
2024-11-08 06:40:37 - progress_bar.py[line:274] - INFO: epoch 005:    196 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.348, ntokens=17853.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.09, wps=2662.3, ups=0.15, wpb=17853.7, bsz=1024, num_updates=1760, lr=3.75107e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=67, gb_free=13.4, wall=11407
2024-11-08 06:41:32 - progress_bar.py[line:274] - INFO: epoch 005:    206 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.34, ntokens=18052.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.06, wps=3261.6, ups=0.18, wpb=18052.6, bsz=1024, num_updates=1770, lr=3.77238e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=45, gb_free=13.5, wall=11462
2024-11-08 06:42:27 - progress_bar.py[line:274] - INFO: epoch 005:    216 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.306, ntokens=17732.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.95, wps=3212.6, ups=0.18, wpb=17732.1, bsz=1024, num_updates=1780, lr=3.79369e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=31, gb_free=13.6, wall=11517
2024-11-08 06:43:23 - progress_bar.py[line:274] - INFO: epoch 005:    226 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.331, ntokens=17857.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.03, wps=3240, ups=0.18, wpb=17857.3, bsz=1024, num_updates=1790, lr=3.815e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=11572
2024-11-08 06:44:18 - progress_bar.py[line:274] - INFO: epoch 005:    236 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.267, ntokens=17412.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.81, wps=3166.9, ups=0.18, wpb=17412.3, bsz=1024, num_updates=1800, lr=3.83632e-05, gnorm=0.004, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=11627
2024-11-08 06:45:13 - progress_bar.py[line:274] - INFO: epoch 005:    246 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.312, ntokens=17639, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.96, wps=3156.4, ups=0.18, wpb=17639, bsz=1024, num_updates=1810, lr=3.85763e-05, gnorm=0.004, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=11683
2024-11-08 06:46:08 - progress_bar.py[line:274] - INFO: epoch 005:    256 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.32, ntokens=17767.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.99, wps=3230.1, ups=0.18, wpb=17767.7, bsz=1024, num_updates=1820, lr=3.87894e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=31, gb_free=13.4, wall=11738
2024-11-08 06:47:03 - progress_bar.py[line:274] - INFO: epoch 005:    266 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.316, ntokens=17693.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.98, wps=3222.8, ups=0.18, wpb=17693.7, bsz=1024, num_updates=1830, lr=3.90026e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=31, gb_free=13.5, wall=11793
2024-11-08 06:47:58 - progress_bar.py[line:274] - INFO: epoch 005:    276 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.286, ntokens=17650.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.88, wps=3219.3, ups=0.18, wpb=17650.6, bsz=1024, num_updates=1840, lr=3.92157e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=11848
2024-11-08 06:48:53 - progress_bar.py[line:274] - INFO: epoch 005:    286 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.304, ntokens=17649.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.94, wps=3200.6, ups=0.18, wpb=17649.4, bsz=1024, num_updates=1850, lr=3.94288e-05, gnorm=0.012, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=11903
2024-11-08 06:49:48 - progress_bar.py[line:274] - INFO: epoch 005:    296 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.286, ntokens=17541.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.88, wps=3229.5, ups=0.18, wpb=17541.8, bsz=1024, num_updates=1860, lr=3.96419e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=11957
2024-11-08 06:50:41 - progress_bar.py[line:274] - INFO: epoch 005:    306 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.419, ntokens=18415.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.35, wps=3418.6, ups=0.19, wpb=18415.1, bsz=1024, num_updates=1870, lr=3.98551e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=31, gb_free=13.4, wall=12011
2024-11-08 06:51:36 - progress_bar.py[line:274] - INFO: epoch 005:    316 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.377, ntokens=18160, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.19, wps=3331.7, ups=0.18, wpb=18160, bsz=1024, num_updates=1880, lr=4.00682e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=31, gb_free=13.5, wall=12066
2024-11-08 06:52:31 - progress_bar.py[line:274] - INFO: epoch 005:    326 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.35, ntokens=17951.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.1, wps=3272.1, ups=0.18, wpb=17951.5, bsz=1024, num_updates=1890, lr=4.02813e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=36, gb_free=13.4, wall=12121
2024-11-08 06:53:26 - progress_bar.py[line:274] - INFO: epoch 005:    336 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.381, ntokens=18088.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.21, wps=3302.5, ups=0.18, wpb=18088.2, bsz=1024, num_updates=1900, lr=4.04945e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=48, gb_free=13.5, wall=12175
2024-11-08 06:54:21 - progress_bar.py[line:274] - INFO: epoch 005:    346 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.354, ntokens=18104.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.11, wps=3276.4, ups=0.18, wpb=18104.2, bsz=1024, num_updates=1910, lr=4.07076e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=55, gb_free=13.5, wall=12231
2024-11-08 06:55:16 - progress_bar.py[line:274] - INFO: epoch 005:    356 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.365, ntokens=18218.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.15, wps=3313.7, ups=0.18, wpb=18218.3, bsz=1024, num_updates=1920, lr=4.09207e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=55, gb_free=13.3, wall=12286
2024-11-08 06:56:11 - progress_bar.py[line:274] - INFO: epoch 005:    366 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.352, ntokens=17962.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.11, wps=3258.9, ups=0.18, wpb=17962.1, bsz=1024, num_updates=1930, lr=4.11338e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=55, gb_free=13.4, wall=12341
2024-11-08 06:57:06 - progress_bar.py[line:274] - INFO: epoch 005:    376 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.39, ntokens=18236.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.24, wps=3302.8, ups=0.18, wpb=18236.2, bsz=1024, num_updates=1940, lr=4.1347e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=55, gb_free=13.4, wall=12396
2024-11-08 06:58:01 - progress_bar.py[line:274] - INFO: epoch 005:    386 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.346, ntokens=17753.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.08, wps=3242.7, ups=0.18, wpb=17753.8, bsz=1024, num_updates=1950, lr=4.15601e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=55, gb_free=13.3, wall=12451
reach the end of datafile, start a new reader
reach the end of datafile, start a new reader
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt
2024-11-08 06:58:25 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 1955 updates
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.ptcp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt

cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt
2024-11-08 06:58:25 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cp: cp: cp: cp: cp: cannot create regular file './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt'cannot create regular file './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt'cannot create regular file './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt'cannot create regular file './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt'cannot create regular file './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt'cannot create regular file './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt': File exists: File exists
: File exists
: File exists: File exists
: File exists


local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
2024-11-08 06:59:53 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping

local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 row count 50000 total row count 400000file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 row count 50000 total row count 400000

file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 row count 50000 total row count 400000
slice_id 1 seek offset 50000
slice_id 5 seek offset 250000
slice_id 2 seek offset 100000
slice_id 7 seek offset 350000
slice_id 6 seek offset 300000
slice_id 3 seek offset 150000
slice_id 4 seek offset 200000
2024-11-08 07:01:58 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 5 @ 1955 updates, score 0) (writing took 213.075667453988 seconds)
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt
2024-11-08 07:02:53 - train.py[line:336] - INFO: end of epoch 5 (average epoch stats below)
2024-11-08 07:02:53 - progress_bar.py[line:282] - INFO: epoch 005 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.314 | ntokens 17766 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 4.97 | wps 2627 | ups 0.15 | wpb 17766 | bsz 1023 | num_updates 1955 | lr 4.16667e-05 | gnorm 0.006 | clip 0 | loss_scale 1024 | train_wall 1570 | gb_free 13.3 | wall 12743
2024-11-08 07:02:53 - trainer.py[line:639] - INFO: loading train data for epoch 6
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 07:05:36 - trainer.py[line:703] - INFO: begin training epoch 6
2024-11-08 07:05:36 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 07:06:05 - progress_bar.py[line:274] - INFO: epoch 006:      5 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.299, ntokens=16956.5, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=4.92, wps=350.2, ups=0.02, wpb=16956.5, bsz=985.6, num_updates=1960, lr=4.17732e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=39, gb_free=13.6, wall=12935
2024-11-08 07:07:01 - progress_bar.py[line:274] - INFO: epoch 006:     15 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.275, ntokens=17600.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.84, wps=3172.8, ups=0.18, wpb=17600.6, bsz=1024, num_updates=1970, lr=4.19864e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=12990
2024-11-08 07:07:57 - progress_bar.py[line:274] - INFO: epoch 006:     25 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.33, ntokens=17796.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.03, wps=3176.6, ups=0.18, wpb=17796.8, bsz=1024, num_updates=1980, lr=4.21995e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=13046
2024-11-08 07:08:53 - progress_bar.py[line:274] - INFO: epoch 006:     35 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.291, ntokens=17729.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.89, wps=3170.6, ups=0.18, wpb=17729.1, bsz=1024, num_updates=1990, lr=4.24126e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=13102
2024-11-08 07:09:48 - progress_bar.py[line:274] - INFO: epoch 006:     45 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.274, ntokens=17528.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.84, wps=3159.7, ups=0.18, wpb=17528.1, bsz=1024, num_updates=2000, lr=4.26257e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=31, gb_free=13.6, wall=13158
2024-11-08 07:10:44 - progress_bar.py[line:274] - INFO: epoch 006:     55 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.3, ntokens=17694, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.93, wps=3180.1, ups=0.18, wpb=17694, bsz=1024, num_updates=2010, lr=4.28389e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.3, wall=13213
2024-11-08 07:11:39 - progress_bar.py[line:274] - INFO: epoch 006:     65 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.277, ntokens=17532.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.85, wps=3153.6, ups=0.18, wpb=17532.2, bsz=1024, num_updates=2020, lr=4.3052e-05, gnorm=0.004, clip=0, loss_scale=1024, train_wall=31, gb_free=13.6, wall=13269
2024-11-08 07:12:35 - progress_bar.py[line:274] - INFO: epoch 006:     75 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.349, ntokens=18014.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.1, wps=3254.2, ups=0.18, wpb=18014.1, bsz=1024, num_updates=2030, lr=4.32651e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=31, gb_free=13.5, wall=13324
2024-11-08 07:13:30 - progress_bar.py[line:274] - INFO: epoch 006:     85 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.278, ntokens=17453, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.85, wps=3127.4, ups=0.18, wpb=17453, bsz=1024, num_updates=2040, lr=4.34783e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=33, gb_free=13.5, wall=13380
2024-11-08 07:14:27 - progress_bar.py[line:274] - INFO: epoch 006:     95 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.365, ntokens=17828, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.15, wps=3130.4, ups=0.18, wpb=17828, bsz=1024, num_updates=2050, lr=4.36914e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=43, gb_free=13.6, wall=13437
2024-11-08 07:15:23 - progress_bar.py[line:274] - INFO: epoch 006:    105 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.298, ntokens=17386.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.92, wps=3114.7, ups=0.18, wpb=17386.2, bsz=1024, num_updates=2060, lr=4.39045e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=51, gb_free=13.6, wall=13493
2024-11-08 07:16:20 - progress_bar.py[line:274] - INFO: epoch 006:    115 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.309, ntokens=17505, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.96, wps=3102.4, ups=0.18, wpb=17505, bsz=1024, num_updates=2070, lr=4.41176e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=55, gb_free=13.5, wall=13549
2024-11-08 07:17:16 - progress_bar.py[line:274] - INFO: epoch 006:    125 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.322, ntokens=17815.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5, wps=3146, ups=0.18, wpb=17815.9, bsz=1024, num_updates=2080, lr=4.43308e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=57, gb_free=13.5, wall=13606
2024-11-08 07:18:12 - progress_bar.py[line:274] - INFO: epoch 006:    135 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.351, ntokens=17692.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.1, wps=3165.1, ups=0.18, wpb=17692.8, bsz=1024, num_updates=2090, lr=4.45439e-05, gnorm=0.006, clip=0, loss_scale=2048, train_wall=56, gb_free=13.5, wall=13662
2024-11-08 07:19:09 - progress_bar.py[line:274] - INFO: epoch 006:    145 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.286, ntokens=17534.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.88, wps=3098.9, ups=0.18, wpb=17534.2, bsz=1024, num_updates=2100, lr=4.4757e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=56, gb_free=13.5, wall=13719
2024-11-08 07:20:04 - progress_bar.py[line:274] - INFO: epoch 006:    155 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.317, ntokens=17791.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.98, wps=3208.2, ups=0.18, wpb=17791.4, bsz=1024, num_updates=2110, lr=4.49702e-05, gnorm=0.011, clip=0, loss_scale=2048, train_wall=55, gb_free=13.4, wall=13774
2024-11-08 07:20:59 - progress_bar.py[line:274] - INFO: epoch 006:    165 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.318, ntokens=17780.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.99, wps=3250.4, ups=0.18, wpb=17780.2, bsz=1024, num_updates=2120, lr=4.51833e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=55, gb_free=13.6, wall=13829
2024-11-08 07:21:54 - progress_bar.py[line:274] - INFO: epoch 006:    175 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.309, ntokens=17622.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.95, wps=3174.9, ups=0.18, wpb=17622.4, bsz=1024, num_updates=2130, lr=4.53964e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=55, gb_free=13.5, wall=13884
2024-11-08 07:22:50 - progress_bar.py[line:274] - INFO: epoch 006:    185 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.309, ntokens=17660.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.96, wps=3201.1, ups=0.18, wpb=17660.9, bsz=1024, num_updates=2140, lr=4.56095e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=55, gb_free=13.5, wall=13939
2024-11-08 07:23:44 - progress_bar.py[line:274] - INFO: epoch 006:    195 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.334, ntokens=17894.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.04, wps=3257.4, ups=0.18, wpb=17894.8, bsz=1024, num_updates=2150, lr=4.58227e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=55, gb_free=13.6, wall=13994
2024-11-08 07:24:40 - progress_bar.py[line:274] - INFO: epoch 006:    205 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.334, ntokens=17892.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.04, wps=3237.2, ups=0.18, wpb=17892.5, bsz=1024, num_updates=2160, lr=4.60358e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=55, gb_free=13.5, wall=14050
2024-11-08 07:25:35 - progress_bar.py[line:274] - INFO: epoch 006:    215 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.306, ntokens=17744.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.94, wps=3210.3, ups=0.18, wpb=17744.5, bsz=1024, num_updates=2170, lr=4.62489e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=55, gb_free=13.6, wall=14105
2024-11-08 07:26:31 - progress_bar.py[line:274] - INFO: epoch 006:    225 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.324, ntokens=17851.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.01, wps=3191, ups=0.18, wpb=17851.1, bsz=1024, num_updates=2180, lr=4.64621e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=56, gb_free=13.6, wall=14161
2024-11-08 07:27:27 - progress_bar.py[line:274] - INFO: epoch 006:    235 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.296, ntokens=17608.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.91, wps=3144.8, ups=0.18, wpb=17608.7, bsz=1024, num_updates=2190, lr=4.66752e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=56, gb_free=13.4, wall=14217
2024-11-08 07:28:23 - progress_bar.py[line:274] - INFO: epoch 006:    245 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.3, ntokens=17412.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.92, wps=3097.4, ups=0.18, wpb=17412.8, bsz=1024, num_updates=2200, lr=4.68883e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=56, gb_free=13.6, wall=14273
2024-11-08 07:29:19 - progress_bar.py[line:274] - INFO: epoch 006:    255 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.302, ntokens=17651.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.93, wps=3157.4, ups=0.18, wpb=17651.2, bsz=1024, num_updates=2210, lr=4.71014e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=56, gb_free=13.4, wall=14329
2024-11-08 07:30:15 - progress_bar.py[line:274] - INFO: epoch 006:    265 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.335, ntokens=17978.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.05, wps=3196.2, ups=0.18, wpb=17978.2, bsz=1024, num_updates=2220, lr=4.73146e-05, gnorm=0.005, clip=0, loss_scale=2048, train_wall=56, gb_free=13.6, wall=14385
2024-11-08 07:31:11 - progress_bar.py[line:274] - INFO: epoch 006:    275 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.307, ntokens=17633.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.95, wps=3153.3, ups=0.18, wpb=17633.2, bsz=1024, num_updates=2230, lr=4.75277e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=56, gb_free=13.4, wall=14441
2024-11-08 07:32:07 - progress_bar.py[line:274] - INFO: epoch 006:    285 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.292, ntokens=17538.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.9, wps=3144.6, ups=0.18, wpb=17538.6, bsz=1024, num_updates=2240, lr=4.77408e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=56, gb_free=13.4, wall=14497
2024-11-08 07:33:03 - progress_bar.py[line:274] - INFO: epoch 006:    295 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.317, ntokens=17736.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.98, wps=3151.1, ups=0.18, wpb=17736.7, bsz=1024, num_updates=2250, lr=4.7954e-05, gnorm=0.006, clip=0, loss_scale=2048, train_wall=56, gb_free=13.5, wall=14553
2024-11-08 07:33:59 - progress_bar.py[line:274] - INFO: epoch 006:    305 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.369, ntokens=18116.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.17, wps=3242.1, ups=0.18, wpb=18116.1, bsz=1024, num_updates=2260, lr=4.81671e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=56, gb_free=13.5, wall=14609
2024-11-08 07:34:56 - progress_bar.py[line:274] - INFO: epoch 006:    315 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.441, ntokens=18532.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.43, wps=3282.3, ups=0.18, wpb=18532.7, bsz=1024, num_updates=2270, lr=4.83802e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=56, gb_free=13.4, wall=14665
2024-11-08 07:35:51 - progress_bar.py[line:274] - INFO: epoch 006:    325 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.36, ntokens=18034.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.14, wps=3235.9, ups=0.18, wpb=18034.4, bsz=1024, num_updates=2280, lr=4.85934e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=56, gb_free=13.4, wall=14721
2024-11-08 07:36:48 - progress_bar.py[line:274] - INFO: epoch 006:    335 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.4, ntokens=18357.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.28, wps=3265.3, ups=0.18, wpb=18357.4, bsz=1024, num_updates=2290, lr=4.88065e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=56, gb_free=13.4, wall=14777
2024-11-08 07:37:43 - progress_bar.py[line:274] - INFO: epoch 006:    345 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.367, ntokens=18123.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.16, wps=3252.1, ups=0.18, wpb=18123.6, bsz=1024, num_updates=2300, lr=4.90196e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=56, gb_free=13.5, wall=14833
2024-11-08 07:38:40 - progress_bar.py[line:274] - INFO: epoch 006:    355 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.409, ntokens=18383.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.31, wps=3264.8, ups=0.18, wpb=18383.4, bsz=1024, num_updates=2310, lr=4.92327e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=56, gb_free=13.4, wall=14889
2024-11-08 07:39:36 - progress_bar.py[line:274] - INFO: epoch 006:    365 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.381, ntokens=18150.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.21, wps=3232.1, ups=0.18, wpb=18150.1, bsz=1024, num_updates=2320, lr=4.94459e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=56, gb_free=13.3, wall=14946
2024-11-08 07:40:31 - progress_bar.py[line:274] - INFO: epoch 006:    375 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.378, ntokens=18110.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.2, wps=3264.6, ups=0.18, wpb=18110.2, bsz=1024, num_updates=2330, lr=4.9659e-05, gnorm=0.006, clip=0, loss_scale=2048, train_wall=55, gb_free=13.5, wall=15001
2024-11-08 07:41:27 - progress_bar.py[line:274] - INFO: epoch 006:    385 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.331, ntokens=17669.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.03, wps=3146.2, ups=0.18, wpb=17669.9, bsz=1024, num_updates=2340, lr=4.98721e-05, gnorm=0.012, clip=0, loss_scale=2048, train_wall=56, gb_free=13.4, wall=15057
reach the end of datafile, start a new reader
reach the end of datafile, start a new reader
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt2024-11-08 07:41:57 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 2346 updates
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt

cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt
2024-11-08 07:41:57 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cp: cannot create regular file './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt'cannot create regular file './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt': File exists: File exists

local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
2024-11-08 07:43:50 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 row count 50000 total row count 400000file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 row count 50000 total row count 400000

slice_id 7 seek offset 350000
slice_id 3 seek offset 150000
2024-11-08 07:45:44 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 6 @ 2346 updates, score 0) (writing took 227.16138558698003 seconds)
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 row count 50000 total row count 400000
slice_id 1 seek offset 50000
slice_id 5 seek offset 250000
slice_id 2 seek offset 100000
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 row count 50000 total row count 400000file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 row count 50000 total row count 400000

slice_id 4 seek offset 200000
slice_id 6 seek offset 300000
2024-11-08 07:46:40 - train.py[line:336] - INFO: end of epoch 6 (average epoch stats below)
2024-11-08 07:46:40 - progress_bar.py[line:282] - INFO: epoch 006 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.328 | ntokens 17784.1 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 5.02 | wps 2647.5 | ups 0.15 | wpb 17784.1 | bsz 1023 | num_updates 2346 | lr 5e-05 | gnorm 0.008 | clip 0 | loss_scale 2048 | train_wall 1946 | gb_free 13.3 | wall 15369
2024-11-08 07:46:40 - trainer.py[line:639] - INFO: loading train data for epoch 7
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 07:49:22 - trainer.py[line:703] - INFO: begin training epoch 7
2024-11-08 07:49:22 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 07:49:47 - progress_bar.py[line:274] - INFO: epoch 007:      4 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.339, ntokens=17194.7, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=5.06, wps=344.2, ups=0.02, wpb=17194.7, bsz=985.6, num_updates=2350, lr=4.99946e-05, gnorm=0.015, clip=0, loss_scale=2048, train_wall=42, gb_free=13.6, wall=15557
2024-11-08 07:50:43 - progress_bar.py[line:274] - INFO: epoch 007:     14 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.325, ntokens=17776.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.01, wps=3179.5, ups=0.18, wpb=17776.3, bsz=1024, num_updates=2360, lr=4.9981e-05, gnorm=0.012, clip=0, loss_scale=2048, train_wall=30, gb_free=13.4, wall=15613
2024-11-08 07:51:39 - progress_bar.py[line:274] - INFO: epoch 007:     24 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.293, ntokens=17561.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.9, wps=3146.6, ups=0.18, wpb=17561.7, bsz=1024, num_updates=2370, lr=4.99674e-05, gnorm=0.013, clip=0, loss_scale=2048, train_wall=31, gb_free=13.5, wall=15669
2024-11-08 07:52:36 - progress_bar.py[line:274] - INFO: epoch 007:     34 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.34, ntokens=18089.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.06, wps=3190.4, ups=0.18, wpb=18089.7, bsz=1024, num_updates=2380, lr=4.99537e-05, gnorm=0.011, clip=0, loss_scale=2048, train_wall=31, gb_free=13.4, wall=15725
2024-11-08 07:53:32 - progress_bar.py[line:274] - INFO: epoch 007:     44 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.297, ntokens=17575, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.91, wps=3137.7, ups=0.18, wpb=17575, bsz=1024, num_updates=2390, lr=4.99401e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=15781
2024-11-08 07:54:28 - progress_bar.py[line:274] - INFO: epoch 007:     54 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.326, ntokens=17857.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.01, wps=3169.9, ups=0.18, wpb=17857.9, bsz=1024, num_updates=2400, lr=4.99265e-05, gnorm=0.011, clip=0, loss_scale=2048, train_wall=31, gb_free=13.4, wall=15838
2024-11-08 07:55:23 - progress_bar.py[line:274] - INFO: epoch 007:     64 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.35, ntokens=17915.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.1, wps=3224.2, ups=0.18, wpb=17915.1, bsz=1024, num_updates=2410, lr=4.99129e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=31, gb_free=13.5, wall=15893
2024-11-08 07:56:19 - progress_bar.py[line:274] - INFO: epoch 007:     74 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.325, ntokens=17736.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.01, wps=3204.1, ups=0.18, wpb=17736.8, bsz=1024, num_updates=2420, lr=4.98993e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=31, gb_free=13.4, wall=15949
2024-11-08 07:57:15 - progress_bar.py[line:274] - INFO: epoch 007:     84 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.267, ntokens=17626.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.81, wps=3151.9, ups=0.18, wpb=17626.6, bsz=1024, num_updates=2430, lr=4.98857e-05, gnorm=0.006, clip=0, loss_scale=2048, train_wall=31, gb_free=13.5, wall=16004
2024-11-08 07:58:12 - progress_bar.py[line:274] - INFO: epoch 007:     94 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.354, ntokens=17901.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.11, wps=3145.8, ups=0.18, wpb=17901.8, bsz=1024, num_updates=2440, lr=4.98721e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=32, gb_free=13.5, wall=16061
2024-11-08 07:59:08 - progress_bar.py[line:274] - INFO: epoch 007:    104 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.321, ntokens=17759.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5, wps=3123.3, ups=0.18, wpb=17759.9, bsz=1024, num_updates=2450, lr=4.98585e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=41, gb_free=13.5, wall=16118
2024-11-08 08:00:05 - progress_bar.py[line:274] - INFO: epoch 007:    114 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.349, ntokens=17760.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.1, wps=3132.1, ups=0.18, wpb=17760.6, bsz=1024, num_updates=2460, lr=4.98449e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=49, gb_free=13.4, wall=16175
2024-11-08 08:01:02 - progress_bar.py[line:274] - INFO: epoch 007:    124 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.274, ntokens=17529.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.84, wps=3079.9, ups=0.18, wpb=17529.9, bsz=1024, num_updates=2470, lr=4.98313e-05, gnorm=0.011, clip=0, loss_scale=2048, train_wall=54, gb_free=13.5, wall=16232
2024-11-08 08:01:58 - progress_bar.py[line:274] - INFO: epoch 007:    134 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.269, ntokens=17282.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.82, wps=3095.9, ups=0.18, wpb=17282.4, bsz=1024, num_updates=2480, lr=4.98177e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=55, gb_free=13.5, wall=16288
2024-11-08 08:02:54 - progress_bar.py[line:274] - INFO: epoch 007:    144 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.334, ntokens=17853.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.04, wps=3159.8, ups=0.18, wpb=17853.9, bsz=1024, num_updates=2490, lr=4.98041e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=56, gb_free=13.5, wall=16344
2024-11-08 08:03:51 - progress_bar.py[line:274] - INFO: epoch 007:    154 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.305, ntokens=17790.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.94, wps=3139.2, ups=0.18, wpb=17790.8, bsz=1024, num_updates=2500, lr=4.97905e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=57, gb_free=13.3, wall=16401
2024-11-08 08:04:48 - progress_bar.py[line:274] - INFO: epoch 007:    164 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.318, ntokens=17768.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.99, wps=3143.4, ups=0.18, wpb=17768.3, bsz=1024, num_updates=2510, lr=4.97769e-05, gnorm=0.011, clip=0, loss_scale=2048, train_wall=56, gb_free=13.4, wall=16457
2024-11-08 08:05:44 - progress_bar.py[line:274] - INFO: epoch 007:    174 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.317, ntokens=17920.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.98, wps=3167.2, ups=0.18, wpb=17920.7, bsz=1024, num_updates=2520, lr=4.97633e-05, gnorm=0.011, clip=0, loss_scale=2048, train_wall=57, gb_free=13.4, wall=16514
2024-11-08 08:06:39 - progress_bar.py[line:274] - INFO: epoch 007:    184 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.254, ntokens=17346.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.77, wps=3143.5, ups=0.18, wpb=17346.3, bsz=1024, num_updates=2530, lr=4.97497e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=55, gb_free=13.4, wall=16569
2024-11-08 08:07:36 - progress_bar.py[line:274] - INFO: epoch 007:    194 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.324, ntokens=17869.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.01, wps=3178.3, ups=0.18, wpb=17869.5, bsz=1024, num_updates=2540, lr=4.97361e-05, gnorm=0.006, clip=0, loss_scale=2048, train_wall=56, gb_free=13.5, wall=16625
2024-11-08 08:08:32 - progress_bar.py[line:274] - INFO: epoch 007:    204 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.316, ntokens=17821.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.98, wps=3132.8, ups=0.18, wpb=17821.4, bsz=1024, num_updates=2550, lr=4.97225e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=57, gb_free=13.6, wall=16682
2024-11-08 08:09:29 - progress_bar.py[line:274] - INFO: epoch 007:    214 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.356, ntokens=18120.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.12, wps=3188.7, ups=0.18, wpb=18120.2, bsz=1024, num_updates=2560, lr=4.97089e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=57, gb_free=13.4, wall=16739
2024-11-08 08:10:26 - progress_bar.py[line:274] - INFO: epoch 007:    224 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.312, ntokens=17745.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.97, wps=3129.6, ups=0.18, wpb=17745.7, bsz=1024, num_updates=2570, lr=4.96953e-05, gnorm=0.012, clip=0, loss_scale=4096, train_wall=57, gb_free=13.5, wall=16796
2024-11-08 08:11:23 - progress_bar.py[line:274] - INFO: epoch 007:    234 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.28, ntokens=17390.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.86, wps=3058.8, ups=0.18, wpb=17390.6, bsz=1024, num_updates=2580, lr=4.96817e-05, gnorm=0.012, clip=0, loss_scale=4096, train_wall=57, gb_free=13.4, wall=16853
2024-11-08 08:12:19 - progress_bar.py[line:274] - INFO: epoch 007:    244 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.311, ntokens=17671.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.96, wps=3128.7, ups=0.18, wpb=17671.1, bsz=1024, num_updates=2590, lr=4.96681e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=56, gb_free=13.4, wall=16909
2024-11-08 08:13:16 - progress_bar.py[line:274] - INFO: epoch 007:    254 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.356, ntokens=17862, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.12, wps=3160.6, ups=0.18, wpb=17862, bsz=1024, num_updates=2600, lr=4.96545e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=56, gb_free=13.3, wall=16966
2024-11-08 08:14:12 - progress_bar.py[line:274] - INFO: epoch 007:    264 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.298, ntokens=17673.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.92, wps=3139.2, ups=0.18, wpb=17673.5, bsz=1024, num_updates=2610, lr=4.96409e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=56, gb_free=13.5, wall=17022
2024-11-08 08:15:09 - progress_bar.py[line:274] - INFO: epoch 007:    274 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.336, ntokens=17901.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.05, wps=3158.9, ups=0.18, wpb=17901.4, bsz=1024, num_updates=2620, lr=4.96273e-05, gnorm=0.005, clip=0, loss_scale=4096, train_wall=57, gb_free=13.5, wall=17079
2024-11-08 08:16:06 - progress_bar.py[line:274] - INFO: epoch 007:    284 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.294, ntokens=17429.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.9, wps=3066.4, ups=0.18, wpb=17429.2, bsz=1024, num_updates=2630, lr=4.96136e-05, gnorm=0.006, clip=0, loss_scale=4096, train_wall=57, gb_free=13.6, wall=17135
2024-11-08 08:17:03 - progress_bar.py[line:274] - INFO: epoch 007:    294 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.339, ntokens=17591.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.06, wps=3089, ups=0.18, wpb=17591.7, bsz=1024, num_updates=2640, lr=4.96e-05, gnorm=0.006, clip=0, loss_scale=4096, train_wall=57, gb_free=13.4, wall=17192
2024-11-08 08:18:00 - progress_bar.py[line:274] - INFO: epoch 007:    304 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.409, ntokens=18256.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.31, wps=3191.7, ups=0.17, wpb=18256.5, bsz=1024, num_updates=2650, lr=4.95864e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=57, gb_free=13.2, wall=17250
2024-11-08 08:18:57 - progress_bar.py[line:274] - INFO: epoch 007:    314 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.486, ntokens=18767.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.6, wps=3311.9, ups=0.18, wpb=18767.4, bsz=1024, num_updates=2660, lr=4.95728e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=57, gb_free=13.2, wall=17306
2024-11-08 08:19:53 - progress_bar.py[line:274] - INFO: epoch 007:    324 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.416, ntokens=18130.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.34, wps=3212.3, ups=0.18, wpb=18130.8, bsz=1024, num_updates=2670, lr=4.95592e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=56, gb_free=13.4, wall=17363
2024-11-08 08:20:49 - progress_bar.py[line:274] - INFO: epoch 007:    334 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.409, ntokens=18209.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.31, wps=3227.4, ups=0.18, wpb=18209.3, bsz=1024, num_updates=2680, lr=4.95456e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=56, gb_free=13.5, wall=17419
2024-11-08 08:21:46 - progress_bar.py[line:274] - INFO: epoch 007:    344 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.355, ntokens=17916.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.12, wps=3160.2, ups=0.18, wpb=17916.4, bsz=1024, num_updates=2690, lr=4.9532e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=57, gb_free=13.4, wall=17476
2024-11-08 08:22:43 - progress_bar.py[line:274] - INFO: epoch 007:    354 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.461, ntokens=18730.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.51, wps=3311.8, ups=0.18, wpb=18730.4, bsz=1024, num_updates=2700, lr=4.95184e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=56, gb_free=13.1, wall=17532
2024-11-08 08:23:40 - progress_bar.py[line:274] - INFO: epoch 007:    364 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.435, ntokens=18436.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.41, wps=3225.9, ups=0.17, wpb=18436.4, bsz=1024, num_updates=2710, lr=4.95048e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=57, gb_free=13.5, wall=17590
2024-11-08 08:24:36 - progress_bar.py[line:274] - INFO: epoch 007:    374 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.371, ntokens=17946, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.17, wps=3171.4, ups=0.18, wpb=17946, bsz=1024, num_updates=2720, lr=4.94912e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=56, gb_free=13.3, wall=17646
2024-11-08 08:25:34 - progress_bar.py[line:274] - INFO: epoch 007:    384 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.411, ntokens=18220.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.32, wps=3187.7, ups=0.17, wpb=18220.8, bsz=1024, num_updates=2730, lr=4.94776e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=57, gb_free=13.4, wall=17703
reach the end of datafile, start a new reader
reach the end of datafile, start a new reader
2024-11-08 08:26:10 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 2737 updates
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt
2024-11-08 08:26:10 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cp: cannot create regular file './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt'cannot create regular file './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt': File exists: File exists

local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
2024-11-08 08:28:05 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 row count 50000 total row count 400000file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 row count 50000 total row count 400000

slice_id 4 seek offset 200000
slice_id 7 seek offset 350000
2024-11-08 08:30:02 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 7 @ 2737 updates, score 0) (writing took 232.1783337990055 seconds)
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 row count 50000 total row count 400000
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 row count 50000 total row count 400000
slice_id 3 seek offset 150000
slice_id 6 seek offset 300000
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 row count 50000 total row count 400000
slice_id 1 seek offset 50000
slice_id 2 seek offset 100000
slice_id 5 seek offset 250000
2024-11-08 08:30:58 - train.py[line:336] - INFO: end of epoch 7 (average epoch stats below)
2024-11-08 08:30:58 - progress_bar.py[line:282] - INFO: epoch 007 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.34 | ntokens 17839.9 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 5.06 | wps 2623.6 | ups 0.15 | wpb 17839.9 | bsz 1023 | num_updates 2737 | lr 4.94681e-05 | gnorm 0.009 | clip 0 | loss_scale 4096 | train_wall 1937 | gb_free 13.4 | wall 18028
2024-11-08 08:30:58 - trainer.py[line:639] - INFO: loading train data for epoch 8
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 08:33:41 - trainer.py[line:703] - INFO: begin training epoch 8
2024-11-08 08:33:41 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 08:33:59 - progress_bar.py[line:274] - INFO: epoch 008:      3 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.344, ntokens=17100.5, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=5.08, wps=338, ups=0.02, wpb=17100.5, bsz=985.6, num_updates=2740, lr=4.9464e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=45, gb_free=13.5, wall=18209
2024-11-08 08:34:55 - progress_bar.py[line:274] - INFO: epoch 008:     13 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.268, ntokens=17414.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.82, wps=3135.7, ups=0.18, wpb=17414.2, bsz=1024, num_updates=2750, lr=4.94504e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=31, gb_free=13.4, wall=18265
2024-11-08 08:35:52 - progress_bar.py[line:274] - INFO: epoch 008:     23 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.348, ntokens=17912, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.09, wps=3153.7, ups=0.18, wpb=17912, bsz=1024, num_updates=2760, lr=4.94368e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=31, gb_free=13.6, wall=18322
2024-11-08 08:36:49 - progress_bar.py[line:274] - INFO: epoch 008:     33 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.311, ntokens=17865.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.96, wps=3147.6, ups=0.18, wpb=17865.8, bsz=1024, num_updates=2770, lr=4.94232e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=31, gb_free=13.5, wall=18378
2024-11-08 08:37:45 - progress_bar.py[line:274] - INFO: epoch 008:     43 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.279, ntokens=17511.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.85, wps=3106.8, ups=0.18, wpb=17511.3, bsz=1024, num_updates=2780, lr=4.94096e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=31, gb_free=13.4, wall=18435
2024-11-08 08:38:41 - progress_bar.py[line:274] - INFO: epoch 008:     53 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.271, ntokens=17472.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.83, wps=3087.3, ups=0.18, wpb=17472.5, bsz=1024, num_updates=2790, lr=4.9396e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=31, gb_free=13.5, wall=18491
2024-11-08 08:39:38 - progress_bar.py[line:274] - INFO: epoch 008:     63 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.357, ntokens=18033.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.12, wps=3173.2, ups=0.18, wpb=18033.8, bsz=1024, num_updates=2800, lr=4.93824e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=33, gb_free=13.4, wall=18548
2024-11-08 08:40:36 - progress_bar.py[line:274] - INFO: epoch 008:     73 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.335, ntokens=17705.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.04, wps=3064.2, ups=0.17, wpb=17705.5, bsz=1024, num_updates=2810, lr=4.93688e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=48, gb_free=13.5, wall=18606
2024-11-08 08:41:33 - progress_bar.py[line:274] - INFO: epoch 008:     83 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.248, ntokens=17328.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.75, wps=3032.6, ups=0.18, wpb=17328.2, bsz=1024, num_updates=2820, lr=4.93552e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=57, gb_free=13.5, wall=18663
2024-11-08 08:42:30 - progress_bar.py[line:274] - INFO: epoch 008:     93 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.322, ntokens=17708, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5, wps=3124.9, ups=0.18, wpb=17708, bsz=1024, num_updates=2830, lr=4.93416e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=57, gb_free=13.4, wall=18720
2024-11-08 08:43:27 - progress_bar.py[line:274] - INFO: epoch 008:    103 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.279, ntokens=17518.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.85, wps=3046.5, ups=0.17, wpb=17518.6, bsz=1024, num_updates=2840, lr=4.9328e-05, gnorm=0.012, clip=0, loss_scale=4096, train_wall=57, gb_free=13.6, wall=18777
2024-11-08 08:44:25 - progress_bar.py[line:274] - INFO: epoch 008:    113 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.337, ntokens=17769.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.05, wps=3090.4, ups=0.17, wpb=17769.1, bsz=1024, num_updates=2850, lr=4.93144e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=57, gb_free=13.6, wall=18835
2024-11-08 08:45:22 - progress_bar.py[line:274] - INFO: epoch 008:    123 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.33, ntokens=17828, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.03, wps=3141.7, ups=0.18, wpb=17828, bsz=1024, num_updates=2860, lr=4.93008e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=57, gb_free=13.6, wall=18891
2024-11-08 08:46:19 - progress_bar.py[line:274] - INFO: epoch 008:    133 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.31, ntokens=17679.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.96, wps=3061.5, ups=0.17, wpb=17679.5, bsz=1024, num_updates=2870, lr=4.92872e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=58, gb_free=13.5, wall=18949
2024-11-08 08:47:18 - progress_bar.py[line:274] - INFO: epoch 008:    143 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.336, ntokens=17740.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.05, wps=3024.2, ups=0.17, wpb=17740.8, bsz=1024, num_updates=2880, lr=4.92735e-05, gnorm=0.006, clip=0, loss_scale=4096, train_wall=59, gb_free=13.3, wall=19008
2024-11-08 08:48:16 - progress_bar.py[line:274] - INFO: epoch 008:    153 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.3, ntokens=17721.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.92, wps=3045.9, ups=0.17, wpb=17721.6, bsz=1024, num_updates=2890, lr=4.92599e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=58, gb_free=13.6, wall=19066
2024-11-08 08:49:15 - progress_bar.py[line:274] - INFO: epoch 008:    163 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.309, ntokens=17699.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.95, wps=3012.6, ups=0.17, wpb=17699.2, bsz=1024, num_updates=2900, lr=4.92463e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=59, gb_free=13.5, wall=19125
2024-11-08 08:50:13 - progress_bar.py[line:274] - INFO: epoch 008:    173 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.293, ntokens=17743.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.9, wps=3067.7, ups=0.17, wpb=17743.7, bsz=1024, num_updates=2910, lr=4.92327e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=58, gb_free=13.5, wall=19183
2024-11-08 08:51:11 - progress_bar.py[line:274] - INFO: epoch 008:    183 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.277, ntokens=17318.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.85, wps=2980.6, ups=0.17, wpb=17318.7, bsz=1024, num_updates=2920, lr=4.92191e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=58, gb_free=13.5, wall=19241
2024-11-08 08:52:09 - progress_bar.py[line:274] - INFO: epoch 008:    193 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.356, ntokens=17854, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.12, wps=3100.4, ups=0.17, wpb=17854, bsz=1024, num_updates=2930, lr=4.92055e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=57, gb_free=13.3, wall=19298
2024-11-08 08:53:06 - progress_bar.py[line:274] - INFO: epoch 008:    203 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.344, ntokens=18015.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.08, wps=3120.5, ups=0.17, wpb=18015.2, bsz=1024, num_updates=2940, lr=4.91919e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=58, gb_free=13.4, wall=19356
2024-11-08 08:54:05 - progress_bar.py[line:274] - INFO: epoch 008:    213 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.351, ntokens=18036.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.1, wps=3090.8, ups=0.17, wpb=18036.2, bsz=1024, num_updates=2950, lr=4.91783e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=58, gb_free=13.5, wall=19414
2024-11-08 08:55:03 - progress_bar.py[line:274] - INFO: epoch 008:    223 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.339, ntokens=17810.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.06, wps=3054.8, ups=0.17, wpb=17810.8, bsz=1024, num_updates=2960, lr=4.91647e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=58, gb_free=13.6, wall=19473
2024-11-08 08:56:01 - progress_bar.py[line:274] - INFO: epoch 008:    233 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.368, ntokens=17937.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.16, wps=3110.7, ups=0.17, wpb=17937.7, bsz=1024, num_updates=2970, lr=4.91511e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=58, gb_free=13.5, wall=19530
2024-11-08 08:56:59 - progress_bar.py[line:274] - INFO: epoch 008:    243 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.335, ntokens=17626.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.05, wps=3042.9, ups=0.17, wpb=17626.8, bsz=1024, num_updates=2980, lr=4.91375e-05, gnorm=0.006, clip=0, loss_scale=4096, train_wall=58, gb_free=13.6, wall=19588
2024-11-08 08:57:56 - progress_bar.py[line:274] - INFO: epoch 008:    253 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.277, ntokens=17410.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.85, wps=3027.6, ups=0.17, wpb=17410.1, bsz=1024, num_updates=2990, lr=4.91239e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=57, gb_free=13.5, wall=19646
2024-11-08 08:58:54 - progress_bar.py[line:274] - INFO: epoch 008:    263 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.315, ntokens=17756.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.98, wps=3054.1, ups=0.17, wpb=17756.9, bsz=1024, num_updates=3000, lr=4.91103e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=58, gb_free=13.5, wall=19704
2024-11-08 08:59:52 - progress_bar.py[line:274] - INFO: epoch 008:    273 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.328, ntokens=17970.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.02, wps=3123.2, ups=0.17, wpb=17970.2, bsz=1024, num_updates=3010, lr=4.90967e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=57, gb_free=13.5, wall=19762
2024-11-08 09:00:50 - progress_bar.py[line:274] - INFO: epoch 008:    283 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.32, ntokens=17699.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.99, wps=3057.6, ups=0.17, wpb=17699.8, bsz=1024, num_updates=3020, lr=4.90831e-05, gnorm=0.006, clip=0, loss_scale=4096, train_wall=58, gb_free=13.6, wall=19819
2024-11-08 09:01:47 - progress_bar.py[line:274] - INFO: epoch 008:    293 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.315, ntokens=17659.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.98, wps=3072.6, ups=0.17, wpb=17659.2, bsz=1024, num_updates=3030, lr=4.90695e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=57, gb_free=13.5, wall=19877
2024-11-08 09:02:45 - progress_bar.py[line:274] - INFO: epoch 008:    303 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.381, ntokens=18053, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.21, wps=3120.5, ups=0.17, wpb=18053, bsz=1024, num_updates=3040, lr=4.90559e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=58, gb_free=13.5, wall=19935
2024-11-08 09:03:43 - progress_bar.py[line:274] - INFO: epoch 008:    313 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.437, ntokens=18369.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.41, wps=3169.3, ups=0.17, wpb=18369.3, bsz=1024, num_updates=3050, lr=4.90423e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=58, gb_free=13.4, wall=19993
2024-11-08 09:04:41 - progress_bar.py[line:274] - INFO: epoch 008:    323 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.384, ntokens=17966.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.22, wps=3091.4, ups=0.17, wpb=17966.4, bsz=1024, num_updates=3060, lr=4.90287e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=58, gb_free=13.4, wall=20051
2024-11-08 09:05:39 - progress_bar.py[line:274] - INFO: epoch 008:    333 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.455, ntokens=18654.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.48, wps=3202.7, ups=0.17, wpb=18654.4, bsz=1024, num_updates=3070, lr=4.90151e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=58, gb_free=13.1, wall=20109
2024-11-08 09:06:37 - progress_bar.py[line:274] - INFO: epoch 008:    343 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.391, ntokens=18152.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.25, wps=3127.9, ups=0.17, wpb=18152.6, bsz=1024, num_updates=3080, lr=4.90015e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=58, gb_free=13.5, wall=20167
2024-11-08 09:07:36 - progress_bar.py[line:274] - INFO: epoch 008:    353 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.418, ntokens=18466.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.34, wps=3169.8, ups=0.17, wpb=18466.4, bsz=1024, num_updates=3090, lr=4.89879e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=58, gb_free=13.4, wall=20225
2024-11-08 09:08:33 - progress_bar.py[line:274] - INFO: epoch 008:    363 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.405, ntokens=18319.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.3, wps=3189.9, ups=0.17, wpb=18319.5, bsz=1024, num_updates=3100, lr=4.89743e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=57, gb_free=13.3, wall=20283
2024-11-08 09:09:31 - progress_bar.py[line:274] - INFO: epoch 008:    373 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.379, ntokens=18187.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.2, wps=3153, ups=0.17, wpb=18187.8, bsz=1024, num_updates=3110, lr=4.89607e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=58, gb_free=13.3, wall=20340
2024-11-08 09:10:29 - progress_bar.py[line:274] - INFO: epoch 008:    383 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.377, ntokens=17865.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.19, wps=3079.8, ups=0.17, wpb=17865.5, bsz=1024, num_updates=3120, lr=4.89471e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=58, gb_free=13.5, wall=20398
reach the end of datafile, start a new reader
reach the end of datafile, start a new reader
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt2024-11-08 09:11:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 8 @ 3128 updates
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_8.ptcp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt


cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt
2024-11-08 09:11:11 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cp: cp: cp: cannot create regular file './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt'cannot create regular file './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt'cannot create regular file './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt'cannot create regular file './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt': File exists
: File exists: File exists
: File exists

local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2024-11-08 09:12:58 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 row count 50000 total row count 400000
slice_id 2 seek offset 100000
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 row count 50000 total row count 400000
slice_id 7 seek offset 350000
slice_id 3 seek offset 150000
slice_id 4 seek offset 200000
2024-11-08 09:14:53 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 8 @ 3128 updates, score 0) (writing took 221.58973757800413 seconds)
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 row count 50000 total row count 400000
slice_id 5 seek offset 250000
slice_id 1 seek offset 50000
slice_id 6 seek offset 300000
2024-11-08 09:15:48 - train.py[line:336] - INFO: end of epoch 8 (average epoch stats below)
2024-11-08 09:15:48 - progress_bar.py[line:282] - INFO: epoch 008 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.338 | ntokens 17819.1 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 5.06 | wps 2590.4 | ups 0.15 | wpb 17819.1 | bsz 1023 | num_updates 3128 | lr 4.89362e-05 | gnorm 0.008 | clip 0 | loss_scale 8192 | train_wall 2075 | gb_free 13.3 | wall 20718
2024-11-08 09:15:48 - trainer.py[line:639] - INFO: loading train data for epoch 9
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 09:18:30 - trainer.py[line:703] - INFO: begin training epoch 9
2024-11-08 09:18:30 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 09:18:43 - progress_bar.py[line:274] - INFO: epoch 009:      2 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.358, ntokens=17141.2, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=5.13, wps=346.5, ups=0.02, wpb=17141.2, bsz=985.6, num_updates=3130, lr=4.89334e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=48, gb_free=13.6, wall=20893
2024-11-08 09:19:39 - progress_bar.py[line:274] - INFO: epoch 009:     12 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.321, ntokens=17444.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5, wps=3114.7, ups=0.18, wpb=17444.1, bsz=1024, num_updates=3140, lr=4.89198e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=31, gb_free=13.3, wall=20949
2024-11-08 09:20:35 - progress_bar.py[line:274] - INFO: epoch 009:     22 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.342, ntokens=17755.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.07, wps=3182.1, ups=0.18, wpb=17755.6, bsz=1024, num_updates=3150, lr=4.89062e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=31, gb_free=13.5, wall=21005
2024-11-08 09:21:31 - progress_bar.py[line:274] - INFO: epoch 009:     32 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.333, ntokens=17875.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.04, wps=3176.2, ups=0.18, wpb=17875.9, bsz=1024, num_updates=3160, lr=4.88926e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=33, gb_free=13.5, wall=21061
2024-11-08 09:22:29 - progress_bar.py[line:274] - INFO: epoch 009:     42 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.349, ntokens=17766.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.1, wps=3089.8, ups=0.17, wpb=17766.8, bsz=1024, num_updates=3170, lr=4.8879e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=51, gb_free=13.6, wall=21119
2024-11-08 09:23:26 - progress_bar.py[line:274] - INFO: epoch 009:     52 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.269, ntokens=17315.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.82, wps=3019.1, ups=0.17, wpb=17315.9, bsz=1024, num_updates=3180, lr=4.88654e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=57, gb_free=13.3, wall=21176
2024-11-08 09:24:24 - progress_bar.py[line:274] - INFO: epoch 009:     62 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.381, ntokens=18011.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.21, wps=3119.6, ups=0.17, wpb=18011.3, bsz=1024, num_updates=3190, lr=4.88518e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=58, gb_free=13.5, wall=21234
2024-11-08 09:25:22 - progress_bar.py[line:274] - INFO: epoch 009:     72 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.308, ntokens=17506.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.95, wps=3004.4, ups=0.17, wpb=17506.1, bsz=1024, num_updates=3200, lr=4.88382e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=58, gb_free=13.4, wall=21292
2024-11-08 09:26:20 - progress_bar.py[line:274] - INFO: epoch 009:     82 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.342, ntokens=17833.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.07, wps=3078.2, ups=0.17, wpb=17833.5, bsz=1024, num_updates=3210, lr=4.88246e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=58, gb_free=13.4, wall=21350
2024-11-08 09:27:17 - progress_bar.py[line:274] - INFO: epoch 009:     92 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.337, ntokens=17695.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.05, wps=3107.5, ups=0.18, wpb=17695.7, bsz=1024, num_updates=3220, lr=4.8811e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=57, gb_free=13.5, wall=21407
2024-11-08 09:28:11 - progress_bar.py[line:274] - INFO: epoch 009:    102 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.318, ntokens=17789.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.99, wps=3318.3, ups=0.19, wpb=17789.9, bsz=1024, num_updates=3230, lr=4.87974e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=51, gb_free=13.5, wall=21461
2024-11-08 09:29:06 - progress_bar.py[line:274] - INFO: epoch 009:    112 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.279, ntokens=17357.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.85, wps=3135.9, ups=0.18, wpb=17357.9, bsz=1024, num_updates=3240, lr=4.87838e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=42, gb_free=13.6, wall=21516
2024-11-08 09:30:04 - progress_bar.py[line:274] - INFO: epoch 009:    122 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.316, ntokens=17711.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.98, wps=3044.8, ups=0.17, wpb=17711.1, bsz=1024, num_updates=3250, lr=4.87702e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=56, gb_free=13.5, wall=21574
2024-11-08 09:31:01 - progress_bar.py[line:274] - INFO: epoch 009:    132 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.315, ntokens=17570, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.98, wps=3073.8, ups=0.17, wpb=17570, bsz=1024, num_updates=3260, lr=4.87566e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=57, gb_free=13.5, wall=21631
2024-11-08 09:31:56 - progress_bar.py[line:274] - INFO: epoch 009:    142 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.32, ntokens=17685.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.99, wps=3254.3, ups=0.18, wpb=17685.9, bsz=1024, num_updates=3270, lr=4.8743e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=52, gb_free=13.4, wall=21686
2024-11-08 09:32:52 - progress_bar.py[line:274] - INFO: epoch 009:    152 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.322, ntokens=17679.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5, wps=3128.7, ups=0.18, wpb=17679.9, bsz=1024, num_updates=3280, lr=4.87294e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=53, gb_free=13.5, wall=21742
2024-11-08 09:33:51 - progress_bar.py[line:274] - INFO: epoch 009:    162 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.313, ntokens=17683.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.97, wps=3027.3, ups=0.17, wpb=17683.1, bsz=1024, num_updates=3290, lr=4.87158e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=58, gb_free=13.5, wall=21801
2024-11-08 09:34:49 - progress_bar.py[line:274] - INFO: epoch 009:    172 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.346, ntokens=17846, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.09, wps=3076.9, ups=0.17, wpb=17846, bsz=1024, num_updates=3300, lr=4.87022e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=58, gb_free=13.6, wall=21859
2024-11-08 09:35:47 - progress_bar.py[line:274] - INFO: epoch 009:    182 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.313, ntokens=17672.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.97, wps=3047.6, ups=0.17, wpb=17672.3, bsz=1024, num_updates=3310, lr=4.86886e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=58, gb_free=13.6, wall=21916
2024-11-08 09:36:45 - progress_bar.py[line:274] - INFO: epoch 009:    192 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.357, ntokens=17843.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.12, wps=3074.3, ups=0.17, wpb=17843.8, bsz=1024, num_updates=3320, lr=4.8675e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=58, gb_free=13.6, wall=21975
2024-11-08 09:37:42 - progress_bar.py[line:274] - INFO: epoch 009:    202 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.36, ntokens=17942.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.13, wps=3134.9, ups=0.17, wpb=17942.9, bsz=1024, num_updates=3330, lr=4.86614e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=57, gb_free=13.5, wall=22032
2024-11-08 09:38:39 - progress_bar.py[line:274] - INFO: epoch 009:    212 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.328, ntokens=17887.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.02, wps=3124.2, ups=0.17, wpb=17887.5, bsz=1024, num_updates=3340, lr=4.86478e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=57, gb_free=13.4, wall=22089
2024-11-08 09:39:37 - progress_bar.py[line:274] - INFO: epoch 009:    222 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.342, ntokens=17811.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.07, wps=3084.7, ups=0.17, wpb=17811.8, bsz=1024, num_updates=3350, lr=4.86342e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=58, gb_free=13.5, wall=22147
2024-11-08 09:40:35 - progress_bar.py[line:274] - INFO: epoch 009:    232 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.366, ntokens=17888.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.16, wps=3106.6, ups=0.17, wpb=17888.1, bsz=1024, num_updates=3360, lr=4.86206e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=57, gb_free=13.5, wall=22204
2024-11-08 09:41:32 - progress_bar.py[line:274] - INFO: epoch 009:    242 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.296, ntokens=17238.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.91, wps=3001.4, ups=0.17, wpb=17238.4, bsz=1024, num_updates=3370, lr=4.8607e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=57, gb_free=13.5, wall=22262
2024-11-08 09:42:29 - progress_bar.py[line:274] - INFO: epoch 009:    252 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.316, ntokens=17685.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.98, wps=3104.2, ups=0.18, wpb=17685.6, bsz=1024, num_updates=3380, lr=4.85934e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=57, gb_free=13.5, wall=22319
2024-11-08 09:43:26 - progress_bar.py[line:274] - INFO: epoch 009:    262 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.348, ntokens=17868.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.09, wps=3132.2, ups=0.18, wpb=17868.6, bsz=1024, num_updates=3390, lr=4.85797e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=57, gb_free=13.5, wall=22376
2024-11-08 09:44:23 - progress_bar.py[line:274] - INFO: epoch 009:    272 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.299, ntokens=17859.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.92, wps=3121, ups=0.17, wpb=17859.5, bsz=1024, num_updates=3400, lr=4.85661e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=57, gb_free=13.5, wall=22433
2024-11-08 09:45:21 - progress_bar.py[line:274] - INFO: epoch 009:    282 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.29, ntokens=17557, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.89, wps=3050.9, ups=0.17, wpb=17557, bsz=1024, num_updates=3410, lr=4.85525e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=57, gb_free=13.6, wall=22491
2024-11-08 09:46:18 - progress_bar.py[line:274] - INFO: epoch 009:    292 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.305, ntokens=17677.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.94, wps=3069.9, ups=0.17, wpb=17677.9, bsz=1024, num_updates=3420, lr=4.85389e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=58, gb_free=13.4, wall=22548
2024-11-08 09:47:15 - progress_bar.py[line:274] - INFO: epoch 009:    302 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.348, ntokens=17791.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.09, wps=3117.8, ups=0.18, wpb=17791.6, bsz=1024, num_updates=3430, lr=4.85253e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=57, gb_free=13.4, wall=22605
2024-11-08 09:48:12 - progress_bar.py[line:274] - INFO: epoch 009:    312 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.422, ntokens=18392.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.36, wps=3244.5, ups=0.18, wpb=18392.2, bsz=1024, num_updates=3440, lr=4.85117e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=57, gb_free=13.4, wall=22662
2024-11-08 09:49:09 - progress_bar.py[line:274] - INFO: epoch 009:    322 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.417, ntokens=18254.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.34, wps=3220.2, ups=0.18, wpb=18254.3, bsz=1024, num_updates=3450, lr=4.84981e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=57, gb_free=13.3, wall=22719
2024-11-08 09:50:05 - progress_bar.py[line:274] - INFO: epoch 009:    332 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.383, ntokens=18282.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.22, wps=3233.5, ups=0.18, wpb=18282.3, bsz=1024, num_updates=3460, lr=4.84845e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=56, gb_free=13.5, wall=22775
2024-11-08 09:51:02 - progress_bar.py[line:274] - INFO: epoch 009:    342 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.367, ntokens=17979.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.16, wps=3177.6, ups=0.18, wpb=17979.4, bsz=1024, num_updates=3470, lr=4.84709e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=56, gb_free=13.4, wall=22832
2024-11-08 09:51:59 - progress_bar.py[line:274] - INFO: epoch 009:    352 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.431, ntokens=18383.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.39, wps=3210.2, ups=0.17, wpb=18383.8, bsz=1024, num_updates=3480, lr=4.84573e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=57, gb_free=13.4, wall=22889
2024-11-08 09:52:55 - progress_bar.py[line:274] - INFO: epoch 009:    362 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.354, ntokens=18115.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.11, wps=3266.1, ups=0.18, wpb=18115.8, bsz=1024, num_updates=3490, lr=4.84437e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=55, gb_free=13.3, wall=22944
2024-11-08 09:53:52 - progress_bar.py[line:274] - INFO: epoch 009:    372 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.443, ntokens=18733.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.44, wps=3259, ups=0.17, wpb=18733.8, bsz=1024, num_updates=3500, lr=4.84301e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=57, gb_free=13.3, wall=23002
2024-11-08 09:54:49 - progress_bar.py[line:274] - INFO: epoch 009:    382 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.336, ntokens=17772.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.05, wps=3130.1, ups=0.18, wpb=17772.4, bsz=1024, num_updates=3510, lr=4.84165e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=57, gb_free=13.5, wall=23059
reach the end of datafile, start a new reader
reach the end of datafile, start a new reader
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.ptcp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt

cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.ptcp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.ptcp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt
2024-11-08 09:55:36 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 9 @ 3519 updates


2024-11-08 09:55:36 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cp: cp: cp: cannot create regular file './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt'cannot create regular file './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt'cannot create regular file './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt'cannot create regular file './polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt': File exists
: File exists: File exists
: File exists

local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2024-11-08 09:57:25 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping


local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 2 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 6 row count 50000 total row count 400000file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 3 row count 50000 total row count 400000

file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 7 row count 50000 total row count 400000
slice_id 7 seek offset 350000
slice_id 2 seek offset 100000
slice_id 3 seek offset 150000
slice_id 6 seek offset 300000
2024-11-08 09:59:19 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 9 @ 3519 updates, score 0) (writing took 222.90675143897533 seconds)
cp ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 5 row count 50000 total row count 400000file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 1 row count 50000 total row count 400000

local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 4 row count 50000 total row count 400000
slice_id 1 seek offset 50000
slice_id 5 seek offset 250000
slice_id 4 seek offset 200000
2024-11-08 10:00:15 - train.py[line:336] - INFO: end of epoch 9 (average epoch stats below)
2024-11-08 10:00:15 - progress_bar.py[line:282] - INFO: epoch 009 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.341 | ntokens 17807.6 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 5.07 | wps 2611 | ups 0.15 | wpb 17807.6 | bsz 1023 | num_updates 3519 | lr 4.84043e-05 | gnorm 0.008 | clip 0 | loss_scale 8192 | train_wall 2113 | gb_free 13.3 | wall 23384
2024-11-08 10:00:15 - trainer.py[line:639] - INFO: loading train data for epoch 10
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_bbox_fix/aihub_indoor_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 10:02:58 - trainer.py[line:703] - INFO: begin training epoch 10
2024-11-08 10:02:58 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 10:03:05 - progress_bar.py[line:274] - INFO: epoch 010:      1 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.371, ntokens=17453.4, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=5.17, wps=351.5, ups=0.02, wpb=17453.4, bsz=985.6, num_updates=3520, lr=4.84029e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=50, gb_free=13.4, wall=23555
2024-11-08 10:04:01 - progress_bar.py[line:274] - INFO: epoch 010:     11 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.28, ntokens=17511.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.86, wps=3130.2, ups=0.18, wpb=17511.6, bsz=1024, num_updates=3530, lr=4.83893e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=31, gb_free=13.4, wall=23611
2024-11-08 10:04:58 - progress_bar.py[line:274] - INFO: epoch 010:     21 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.314, ntokens=17794.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.97, wps=3138.2, ups=0.18, wpb=17794.2, bsz=1024, num_updates=3540, lr=4.83757e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=30, gb_free=13.4, wall=23668
2024-11-08 10:05:54 - progress_bar.py[line:274] - INFO: epoch 010:     31 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.286, ntokens=17737.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.88, wps=3188.5, ups=0.18, wpb=17737.9, bsz=1024, num_updates=3550, lr=4.83621e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=31, gb_free=13.3, wall=23724
2024-11-08 10:06:52 - progress_bar.py[line:274] - INFO: epoch 010:     41 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.303, ntokens=17723.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.94, wps=3024.7, ups=0.17, wpb=17723.7, bsz=1024, num_updates=3560, lr=4.83485e-05, gnorm=0.005, clip=0, loss_scale=8192, train_wall=40, gb_free=13.4, wall=23782
2024-11-08 10:07:50 - progress_bar.py[line:274] - INFO: epoch 010:     51 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.291, ntokens=17516.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.89, wps=3013.4, ups=0.17, wpb=17516.5, bsz=1024, num_updates=3570, lr=4.83349e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=54, gb_free=13.5, wall=23840
2024-11-08 10:08:44 - progress_bar.py[line:274] - INFO: epoch 010:     61 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.31, ntokens=17826.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.96, wps=3304.9, ups=0.19, wpb=17826.6, bsz=1024, num_updates=3580, lr=4.83213e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=38, gb_free=13.5, wall=23894
2024-11-08 10:09:42 - progress_bar.py[line:274] - INFO: epoch 010:     71 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.298, ntokens=17606.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.92, wps=3048.4, ups=0.17, wpb=17606.6, bsz=1024, num_updates=3590, lr=4.83077e-05, gnorm=0.005, clip=0, loss_scale=16384, train_wall=31, gb_free=13.6, wall=23952
2024-11-08 10:10:41 - progress_bar.py[line:274] - INFO: epoch 010:     81 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.31, ntokens=17723.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.96, wps=3034.4, ups=0.17, wpb=17723.1, bsz=1024, num_updates=3600, lr=4.82941e-05, gnorm=0.005, clip=0, loss_scale=16384, train_wall=36, gb_free=13.6, wall=24010
2024-11-08 10:11:39 - progress_bar.py[line:274] - INFO: epoch 010:     91 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.337, ntokens=17804.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5.05, wps=3042.7, ups=0.17, wpb=17804.9, bsz=1024, num_updates=3610, lr=4.82805e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=48, gb_free=13.5, wall=24069
2024-11-08 10:12:38 - progress_bar.py[line:274] - INFO: epoch 010:    101 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.283, ntokens=17542.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.87, wps=2992.9, ups=0.17, wpb=17542.5, bsz=1024, num_updates=3620, lr=4.82669e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=58, gb_free=13.5, wall=24128
Traceback (most recent call last):
Traceback (most recent call last):
  File "../../train.py", line 543, in <module>
  File "../../train.py", line 543, in <module>
Traceback (most recent call last):
  File "../../train.py", line 543, in <module>
    cli_main()
  File "../../train.py", line 536, in cli_main
    cli_main()
  File "../../train.py", line 536, in cli_main
    cli_main()    
distributed_utils.call_main(cfg, main)  File "../../train.py", line 536, in cli_main

  File "/home/ubuntu/src/fairseq/fairseq/fairseq/distributed/utils.py", line 374, in call_main
    distributed_utils.call_main(cfg, main)
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/distributed/utils.py", line 348, in distributed_main
        distributed_utils.call_main(cfg, main)distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)

  File "/home/ubuntu/src/fairseq/fairseq/fairseq/distributed/utils.py", line 374, in call_main
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 190, in main
    main(cfg, **kwargs)
      File "../../train.py", line 190, in main
distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)    
valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)  File "/home/ubuntu/src/fairseq/fairseq/fairseq/distributed/utils.py", line 348, in distributed_main

  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/contextlib.py", line 74, in inner
        valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)return func(*args, **kwds)

  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/contextlib.py", line 74, in inner
  File "../../train.py", line 298, in train
    main(cfg, **kwargs)
  File "../../train.py", line 190, in main
    return func(*args, **kwds)
  File "../../train.py", line 298, in train
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)    
for i, samples in enumerate(progress):  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/contextlib.py", line 74, in inner

  File "/home/ubuntu/src/fairseq/fairseq/fairseq/logging/progress_bar.py", line 261, in __iter__
        return func(*args, **kwds)for i, samples in enumerate(progress):

  File "../../train.py", line 298, in train
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/logging/progress_bar.py", line 261, in __iter__
    for i, obj in enumerate(self.iterable, start=self.n):
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 56, in __next__
    x = next(self._itr)
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 509, in _chunk_iterator
        for i, obj in enumerate(self.iterable, start=self.n):for i, samples in enumerate(progress):

  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 56, in __next__
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/logging/progress_bar.py", line 261, in __iter__
    x = next(self._itr)
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 509, in _chunk_iterator
        for i, obj in enumerate(self.iterable, start=self.n):for x in itr:

  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 56, in __next__
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 56, in __next__
        x = next(self._itr)x = next(self._itr)

  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 509, in _chunk_iterator
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 637, in __next__
    for x in itr:
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 56, in __next__
    x = next(self._itr)
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 637, in __next__
    for x in itr:
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 56, in __next__
    raise item
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 567, in run
    x = next(self._itr)
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 637, in __next__
    raise item
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 567, in run
    for item in self._source:
      File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
raise item
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 567, in run
    for item in self._source:
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    for item in self._source:
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._next_data()
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._next_data()
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]    
data = [self.dataset[idx] for idx in possibly_batched_index]  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>

  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
        data = [self.dataset[idx] for idx in possibly_batched_index]data = [self.dataset[idx] for idx in possibly_batched_index]

      File "/home/ubuntu/workspaces/AIHub-polygon-transformer/data/refcoco_dataset.py", line 82, in __getitem__
  File "/home/ubuntu/workspaces/AIHub-polygon-transformer/data/refcoco_dataset.py", line 82, in __getitem__
data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
        data = [self.dataset[idx] for idx in possibly_batched_index]    data = self.dataset[index]
data = self.dataset[index]
  File "/home/ubuntu/workspaces/AIHub-polygon-transformer/data/refcoco_dataset.py", line 82, in __getitem__

  File "/home/ubuntu/workspaces/AIHub-polygon-transformer/data/file_dataset.py", line 111, in __getitem__
  File "/home/ubuntu/workspaces/AIHub-polygon-transformer/data/file_dataset.py", line 111, in __getitem__
    data = self.dataset[index]
  File "/home/ubuntu/workspaces/AIHub-polygon-transformer/data/file_dataset.py", line 111, in __getitem__
    column_l = [dtype(column_l[col_id]) for col_id, dtype in zip(self.selected_col_ids, self.dtypes)]    
column_l = [dtype(column_l[col_id]) for col_id, dtype in zip(self.selected_col_ids, self.dtypes)]  File "/home/ubuntu/workspaces/AIHub-polygon-transformer/data/file_dataset.py", line 111, in <listcomp>

  File "/home/ubuntu/workspaces/AIHub-polygon-transformer/data/file_dataset.py", line 111, in <listcomp>
    column_l = [dtype(column_l[col_id]) for col_id, dtype in zip(self.selected_col_ids, self.dtypes)]
  File "/home/ubuntu/workspaces/AIHub-polygon-transformer/data/file_dataset.py", line 111, in <listcomp>
    column_l = [dtype(column_l[col_id]) for col_id, dtype in zip(self.selected_col_ids, self.dtypes)]    
    column_l = [dtype(column_l[col_id]) for col_id, dtype in zip(self.selected_col_ids, self.dtypes)]column_l = [dtype(column_l[col_id]) for col_id, dtype in zip(self.selected_col_ids, self.dtypes)]

IndexError: list index out of rangeIndexError
IndexError: : list index out of rangelist index out of range

Traceback (most recent call last):
  File "../../train.py", line 543, in <module>
    cli_main()
  File "../../train.py", line 536, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 190, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "../../train.py", line 298, in train
    for i, samples in enumerate(progress):
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/logging/progress_bar.py", line 261, in __iter__
    for i, obj in enumerate(self.iterable, start=self.n):
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 56, in __next__
    x = next(self._itr)
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 509, in _chunk_iterator
    for x in itr:
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 56, in __next__
    x = next(self._itr)
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 637, in __next__
    raise item
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 567, in run
    for item in self._source:
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ubuntu/workspaces/AIHub-polygon-transformer/data/refcoco_dataset.py", line 82, in __getitem__
    data = self.dataset[index]
  File "/home/ubuntu/workspaces/AIHub-polygon-transformer/data/file_dataset.py", line 111, in __getitem__
    column_l = [dtype(column_l[col_id]) for col_id, dtype in zip(self.selected_col_ids, self.dtypes)]
  File "/home/ubuntu/workspaces/AIHub-polygon-transformer/data/file_dataset.py", line 111, in <listcomp>
    column_l = [dtype(column_l[col_id]) for col_id, dtype in zip(self.selected_col_ids, self.dtypes)]
IndexError: list index out of range
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1686434 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1686435 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1686437 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1686439 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 1686433) of binary: /home/ubuntu/anaconda3/envs/polyformer/bin/python3
Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 248, in launch_agent
    failures=result.failures,
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
../../train.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-11-08_10:12:41
  host      : ip-172-31-9-178.us-west-2.compute.internal
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 1686436)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-11-08_10:12:41
  host      : ip-172-31-9-178.us-west-2.compute.internal
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 1686438)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-11-08_10:12:41
  host      : ip-172-31-9-178.us-west-2.compute.internal
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 1686440)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-11-08_10:12:41
  host      : ip-172-31-9-178.us-west-2.compute.internal
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1686433)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
