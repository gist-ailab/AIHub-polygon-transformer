/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launch.py:188: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  FutureWarning,
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2024-11-08 03:32:23 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 03:32:23 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 03:32:23 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 03:32:23 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 03:32:23 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 03:32:23 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 03:32:23 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 03:32:23 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-08 03:32:25 - utils.py[line:258] - INFO: distributed init (rank 4): env://
2024-11-08 03:32:25 - utils.py[line:261] - INFO: Start init
2024-11-08 03:32:25 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 4
2024-11-08 03:32:25 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2024-11-08 03:32:25 - utils.py[line:261] - INFO: Start init
2024-11-08 03:32:25 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2024-11-08 03:32:25 - utils.py[line:258] - INFO: distributed init (rank 7): env://
2024-11-08 03:32:25 - utils.py[line:261] - INFO: Start init
2024-11-08 03:32:25 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 7
2024-11-08 03:32:25 - utils.py[line:258] - INFO: distributed init (rank 2): env://
2024-11-08 03:32:25 - utils.py[line:261] - INFO: Start init
2024-11-08 03:32:25 - utils.py[line:258] - INFO: distributed init (rank 6): env://
2024-11-08 03:32:25 - utils.py[line:261] - INFO: Start init
2024-11-08 03:32:25 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 2
2024-11-08 03:32:25 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 6
2024-11-08 03:32:25 - utils.py[line:258] - INFO: distributed init (rank 5): env://
2024-11-08 03:32:25 - utils.py[line:261] - INFO: Start init
2024-11-08 03:32:25 - utils.py[line:258] - INFO: distributed init (rank 3): env://
2024-11-08 03:32:25 - utils.py[line:261] - INFO: Start init
2024-11-08 03:32:25 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 5
2024-11-08 03:32:25 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2024-11-08 03:32:25 - utils.py[line:261] - INFO: Start init
2024-11-08 03:32:25 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2024-11-08 03:32:25 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 3
2024-11-08 03:32:25 - distributed_c10d.py[line:354] - INFO: Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 03:32:25 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 3
single-machine distributed training is initialized.
2024-11-08 03:32:25 - distributed_c10d.py[line:354] - INFO: Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 03:32:25 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 7
single-machine distributed training is initialized.
2024-11-08 03:32:25 - distributed_c10d.py[line:354] - INFO: Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 03:32:25 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 4
single-machine distributed training is initialized.
2024-11-08 03:32:25 - distributed_c10d.py[line:354] - INFO: Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 03:32:25 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 2
single-machine distributed training is initialized.
2024-11-08 03:32:25 - distributed_c10d.py[line:354] - INFO: Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 03:32:25 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 6
single-machine distributed training is initialized.
2024-11-08 03:32:25 - distributed_c10d.py[line:354] - INFO: Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 03:32:25 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 5
single-machine distributed training is initialized.
2024-11-08 03:32:25 - distributed_c10d.py[line:354] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 03:32:25 - distributed_c10d.py[line:354] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-08 03:32:25 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 1
single-machine distributed training is initialized.
2024-11-08 03:32:25 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 0
single-machine distributed training is initialized.
2024-11-08 03:32:29 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../polyformer_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 500, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512', 'restore_file': '../finetune/polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_33.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 500, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'score', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='polyformer_b', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='polyformer_b', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=16, batch_size_valid=16, best_checkpoint_metric='score', bf16=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, cls_weight=0.0005, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv,../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, det_weight=0.1, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_acc=True, eval_args='{"beam":5,"min_len":2,"max_len_a":0,"max_len_b":2}', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=100, max_image_size=512, max_source_positions=1024, max_src_length=80, max_target_positions=1024, max_tgt_length=420, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=8, num_bins=64, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', out_index=3, pad=1, patch_image_size=512, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, restore_file='../finetune/polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_33.pt', sample_patch_num=196, save_dir='./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512', save_interval=1, save_interval_updates=500, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', scst=False, scst_args='{}', seed=1, selected_cols='0,5,6,2,4,3,7', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='refcoco', tensorboard_logdir=None, threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[8], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../polyformer_module', uses_ema=False, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=500, vis_encoder_type='swin-base', wandb_project=None, warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'refcoco', 'data': '../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv,../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv', 'selected_cols': '0,5,6,2,4,3,7', 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 80, 'max_tgt_length': 420, 'code_dict_size': 8192, 'patch_image_size': 512, 'num_bins': 64, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': True, 'eval_args': '{"beam":5,"min_len":2,"max_len_a":0,"max_len_b":2}', 'uses_ema': False, 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'det_weight': 0.1, 'cls_weight': 0.0005, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2024-11-08 03:32:29 - base_task.py[line:187] - INFO: source dictionary: 4100 types
2024-11-08 03:32:29 - base_task.py[line:188] - INFO: target dictionary: 4100 types
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
The model and loaded state dict do not match exactly

unexpected key in source state_dict: norm.weight, norm.bias, head.weight, head.bias, layers.0.blocks.1.attn_mask, layers.1.blocks.1.attn_mask, layers.2.blocks.1.attn_mask, layers.2.blocks.3.attn_mask, layers.2.blocks.5.attn_mask, layers.2.blocks.7.attn_mask, layers.2.blocks.9.attn_mask, layers.2.blocks.11.attn_mask, layers.2.blocks.13.attn_mask, layers.2.blocks.15.attn_mask, layers.2.blocks.17.attn_mask

missing keys in source state_dict: norm3.weight, norm3.bias

Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
The model and loaded state dict do not match exactly

unexpected key in source state_dict: norm.weight, norm.bias, head.weight, head.bias, layers.0.blocks.1.attn_mask, layers.1.blocks.1.attn_mask, layers.2.blocks.1.attn_mask, layers.2.blocks.3.attn_mask, layers.2.blocks.5.attn_mask, layers.2.blocks.7.attn_mask, layers.2.blocks.9.attn_mask, layers.2.blocks.11.attn_mask, layers.2.blocks.13.attn_mask, layers.2.blocks.15.attn_mask, layers.2.blocks.17.attn_mask

missing keys in source state_dict: norm3.weight, norm3.bias

2024-11-08 03:32:43 - train.py[line:101] - INFO: PolyFormerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(4100, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): SwinTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (pos_drop): Dropout(p=0.0, inplace=False)
      (layers): ModuleList(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): Identity()
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.009)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=512, out_features=256, bias=False)
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=256, out_features=256, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.017)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=256, out_features=1024, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1024, out_features=256, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=256, out_features=256, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.026)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=256, out_features=1024, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1024, out_features=256, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=1024, out_features=512, bias=False)
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.035)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.043)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (2): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.052)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (3): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.061)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (4): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.070)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (5): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.078)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (6): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.087)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (7): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.096)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (8): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.104)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (9): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.113)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (10): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.122)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (11): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.130)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (12): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.139)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (13): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.148)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (14): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.157)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (15): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.165)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (16): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.174)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (17): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.183)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=2048, out_features=1024, bias=False)
            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.191)
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.200)
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
      )
      (norm3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
    (bert): XLMRobertaForMaskedLM(
      (roberta): XLMRobertaModel(
        (embeddings): XLMRobertaEmbeddings(
          (word_embeddings): Embedding(250002, 768, padding_idx=1)
          (position_embeddings): Embedding(514, 768, padding_idx=1)
          (token_type_embeddings): Embedding(1, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): XLMRobertaEncoder(
          (layer): ModuleList(
            (0): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
      )
      (lm_head): XLMRobertaLMHead(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (decoder): Linear(in_features=768, out_features=250002, bias=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(4100, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (reg_head): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): Linear(in_features=768, out_features=768, bias=True)
        (2): Linear(in_features=768, out_features=2, bias=True)
      )
    )
    (cls_head): Linear(in_features=768, out_features=3, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2024-11-08 03:32:43 - train.py[line:102] - INFO: task: RefcocoTask
2024-11-08 03:32:43 - train.py[line:103] - INFO: model: PolyFormerModel
2024-11-08 03:32:43 - train.py[line:104] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2024-11-08 03:32:43 - train.py[line:108] - INFO: num. shared model params: 478,547,732 (num. trained: 478,547,732)
2024-11-08 03:32:43 - train.py[line:115] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 4 row count 6955 total row count 55640
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 7 row count 6955 total row count 55640
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping





file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 2 row count 6955 total row count 55640file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 1 row count 6955 total row count 55640file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 5 row count 6955 total row count 55640file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 0 row count 6955 total row count 55640file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 6 row count 6955 total row count 55640
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_val.tsv slice_id 3 row count 6955 total row count 55640




2024-11-08 03:33:06 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2024-11-08 03:33:06 - distributed_c10d.py[line:354] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-11-08 03:33:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2024-11-08 03:33:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.layers.0.downsample.reduction.bias <- encoder.embed_images.layers.1.downsample.reduction.bias
2024-11-08 03:33:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.layers.0.downsample.reduction.bias <- encoder.embed_images.layers.2.downsample.reduction.bias
2024-11-08 03:33:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.layers.0.downsample.reduction.bias <- decoder.cls_head.bias
2024-11-08 03:33:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.bert.roberta.embeddings.word_embeddings.weight <- encoder.bert.lm_head.decoder.weight
2024-11-08 03:33:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.bert.lm_head.bias <- encoder.bert.lm_head.decoder.bias
2024-11-08 03:33:08 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 8 workers***********************
2024-11-08 03:33:08 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 03:33:08 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 03:33:08 - utils.py[line:765] - INFO: rank   2: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 03:33:08 - utils.py[line:765] - INFO: rank   3: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 03:33:08 - utils.py[line:765] - INFO: rank   4: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 03:33:08 - utils.py[line:765] - INFO: rank   5: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 03:33:08 - utils.py[line:765] - INFO: rank   6: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 03:33:08 - utils.py[line:765] - INFO: rank   7: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-08 03:33:08 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 8 workers***********************
2024-11-08 03:33:08 - train.py[line:145] - INFO: training on 8 devices (GPUs/TPUs)
2024-11-08 03:33:08 - train.py[line:151] - INFO: max tokens per device = None and max sentences per device = 16
2024-11-08 03:33:08 - trainer.py[line:458] - INFO: Preparing to load checkpoint ../finetune/polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_33.pt
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2024-11-08 03:33:20 - trainer.py[line:619] - INFO: Loaded checkpoint ../finetune/polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_33.pt (epoch 34 @ 0 updates)
2024-11-08 03:33:20 - trainer.py[line:639] - INFO: loading train data for epoch 1
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
slice_id 0 seek offset 0
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
2024-11-08 03:36:01 - trainer.py[line:703] - INFO: begin training epoch 1
2024-11-08 03:36:01 - train.py[line:297] - INFO: Start iterating over samples
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping



file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000


/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
slice_id 4 seek offset 200000
slice_id 7 seek offset 350000
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
slice_id 2 seek offset 100000slice_id 6 seek offset 300000

slice_id 1 seek offset 50000
slice_id 3 seek offset 150000
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
slice_id 5 seek offset 250000
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
loss_reg: 0.025881012051335427 loss_cls: 0.003364748787134886
loss_reg: 0.019065276692866614 loss_cls: 0.004622735548764467
loss_reg: 0.026148009677203342 loss_cls: 0.0037194702308624983
loss_reg: 0.02271651980351433 loss_cls: 0.004307171795517206
loss_reg: 0.028788540743953022 loss_cls: 0.0035580755211412907
loss_reg: 0.02610434310445587 loss_cls: 0.003026638412848115
loss_reg: 0.026176631299653422 loss_cls: 0.003729606745764613
loss_reg: 0.023435666343907695 loss_cls: 0.002764699049293995
loss_reg: 0.023628802587365053 loss_cls: 0.0038817119784653187
loss_reg: 0.0216828911366551 loss_cls: 0.004348513670265675
loss_reg: 0.023517197671742707 loss_cls: 0.0038495271001011133
loss_reg: 0.02313473003328881 loss_cls: 0.004110242240130901
loss_reg: 0.018713434757616894 loss_cls: 0.004774353466928005
loss_reg: 0.020150838164088962 loss_cls: 0.004631582647562027
loss_reg: 0.026296692503781784 loss_cls: 0.003754003206267953
loss_reg: 0.02375625695977645 loss_cls: 0.0025048081297427416
loss_reg: 0.02353497419122229 loss_cls: 0.004153951071202755
loss_reg: 0.0224461440071285 loss_cls: 0.003709561424329877
loss_reg: 0.0049196143574981 loss_cls: 0.0032956544309854507
loss_reg: 0.01751476667633419 loss_cls: 0.0031210232991725206
loss_reg: 0.025822046299746684 loss_cls: 0.0038594536017626524
loss_reg: 0.02530660496690899 loss_cls: 0.0038768602535128593
loss_reg: 0.017336999247323622 loss_cls: 0.003912998829036951
loss_reg: 0.019811864414543977 loss_cls: 0.003880799515172839
loss_reg: 0.021820550477021347 loss_cls: 0.003084636991843581
loss_reg: 0.025147860067765197 loss_cls: 0.0033630330581218004
loss_reg: 0.022828398475466388 loss_cls: 0.003575533628463745
loss_reg: 0.003306940497431692 loss_cls: 0.003179880091920495
loss_reg: 0.021797934700414794 loss_cls: 0.0034121491480618715
loss_reg: 0.024003475884421477 loss_cls: 0.004176664631813765
loss_reg: 0.027432928587878696 loss_cls: 0.0028487788513302803
loss_reg: 0.02614840163433267 loss_cls: 0.00446829991415143
loss_reg: 0.021579505611310137 loss_cls: 0.0034276486840099096
loss_reg: 0.021128074264958607 loss_cls: 0.005427186377346516
loss_reg: 0.01596428420048108 loss_cls: 0.004968704655766487
loss_reg: 0.018566518245510866 loss_cls: 0.0037831650115549564
loss_reg: 0.0028962993692752746 loss_cls: 0.0031750614289194345
loss_reg: 0.019571279431838576 loss_cls: 0.004725170321762562
loss_reg: 0.0223891582183356 loss_cls: 0.00531828822568059
loss_reg: 0.021006416598006842 loss_cls: 0.004009992815554142
loss_reg: 0.02489620508727732 loss_cls: 0.003672458231449127
loss_reg: 0.02669380140720994 loss_cls: 0.0038100681267678738
loss_reg: 0.020603621156033133 loss_cls: 0.003804936073720455
loss_reg: 0.0231661960042734 loss_cls: 0.0032934744376689196
loss_reg: 0.004621882227776611 loss_cls: 0.0031565180979669094
loss_reg: 0.031237953736498313 loss_cls: 0.0036132223904132843
loss_reg: 0.029875517147749938 loss_cls: 0.002626516157761216
loss_reg: 0.021954591693707764 loss_cls: 0.003706062911078334
loss_reg: 0.022692006311337734 loss_cls: 0.003199092112481594
loss_reg: 0.025795589084486793 loss_cls: 0.00505402497947216
loss_reg: 0.022801359148420804 loss_cls: 0.003700927132740617
loss_reg: 0.022387078727320025 loss_cls: 0.0030141244642436504
loss_reg: 0.0056099711004074255 loss_cls: 0.003694806480780244
loss_reg: 0.02090726219718814 loss_cls: 0.0033501789439469576
loss_reg: 0.02135847861276942 loss_cls: 0.0037125530652701855
loss_reg: 0.0210782524934172 loss_cls: 0.002808176213875413
loss_reg: 0.024519203948912046 loss_cls: 0.0041078440845012665
loss_reg: 0.02421218982632264 loss_cls: 0.003538113785907626
loss_reg: 0.021192218678471812 loss_cls: 0.0033651224803179502
loss_reg: 0.006195106361743172 loss_cls: 0.00337230134755373
loss_reg: 0.023004859849595775 loss_cls: 0.003620557487010956
loss_reg: 0.026425226017773768 loss_cls: 0.0040245321579277515
loss_reg: 0.006703530979280037 loss_cls: 0.0034437342546880245
loss_reg: 0.0035646265997419276 loss_cls: 0.0033483949955552816
2024-11-08 03:37:06 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.009, ntokens=17540.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=8.05, wps=3267, ups=0.19, wpb=17540.3, bsz=1024, num_updates=10, lr=2.13129e-07, gnorm=0.015, clip=0, loss_scale=128, train_wall=39, gb_free=13.4, wall=238
2024-11-08 03:38:00 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=2.98, ntokens=17260.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.89, wps=3189.2, ups=0.18, wpb=17260.7, bsz=1024, num_updates=20, lr=4.26257e-07, gnorm=0.014, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=292
2024-11-08 03:38:53 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=2.978, ntokens=17251.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.88, wps=3228.4, ups=0.19, wpb=17251.5, bsz=1024, num_updates=30, lr=6.39386e-07, gnorm=0.009, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=346
2024-11-08 03:39:47 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=2.978, ntokens=17478.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.88, wps=3243.3, ups=0.19, wpb=17478.8, bsz=1024, num_updates=40, lr=8.52515e-07, gnorm=0.005, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=400
2024-11-08 03:40:40 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.971, ntokens=17533.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.84, wps=3284.1, ups=0.19, wpb=17533.4, bsz=1024, num_updates=50, lr=1.06564e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.4, wall=453
2024-11-08 03:41:34 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.91, ntokens=17189.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.51, wps=3187.7, ups=0.19, wpb=17189.2, bsz=1024, num_updates=60, lr=1.27877e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.2, wall=507
2024-11-08 03:42:29 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.902, ntokens=17125.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.47, wps=3127.5, ups=0.18, wpb=17125.8, bsz=1024, num_updates=70, lr=1.4919e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=562
2024-11-08 03:43:23 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.924, ntokens=17101.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.59, wps=3179.3, ups=0.19, wpb=17101.4, bsz=1024, num_updates=80, lr=1.70503e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=31, gb_free=13.2, wall=615
2024-11-08 03:44:17 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.927, ntokens=17305.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.6, wps=3220.9, ups=0.19, wpb=17305.5, bsz=1024, num_updates=90, lr=1.91816e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=669
2024-11-08 03:45:10 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.968, ntokens=17447.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.83, wps=3251.6, ups=0.19, wpb=17447.2, bsz=1024, num_updates=100, lr=2.13129e-06, gnorm=0.005, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=723
2024-11-08 03:46:04 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.948, ntokens=17243, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.72, wps=3207.8, ups=0.19, wpb=17243, bsz=1024, num_updates=110, lr=2.34442e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.4, wall=777
2024-11-08 03:46:58 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.933, ntokens=17360.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.64, wps=3205.8, ups=0.18, wpb=17360.4, bsz=1024, num_updates=120, lr=2.55754e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=831
2024-11-08 03:47:52 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.963, ntokens=17477.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.8, wps=3235.5, ups=0.19, wpb=17477.1, bsz=1024, num_updates=130, lr=2.77067e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.2, wall=885
2024-11-08 03:48:46 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.951, ntokens=17116.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.73, wps=3160, ups=0.18, wpb=17116.8, bsz=1024, num_updates=140, lr=2.9838e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=939
2024-11-08 03:49:40 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.862, ntokens=16833.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.27, wps=3126.4, ups=0.19, wpb=16833.8, bsz=1024, num_updates=150, lr=3.19693e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=993
2024-11-08 03:50:34 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.909, ntokens=17365.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.51, wps=3227.6, ups=0.19, wpb=17365.6, bsz=1024, num_updates=160, lr=3.41006e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=1046
2024-11-08 03:51:28 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.966, ntokens=17362, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.82, wps=3245.7, ups=0.19, wpb=17362, bsz=1024, num_updates=170, lr=3.62319e-06, gnorm=0.002, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=1100
2024-11-08 03:52:21 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.995, ntokens=17273, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.97, wps=3204.9, ups=0.19, wpb=17273, bsz=1024, num_updates=180, lr=3.83632e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=1154
2024-11-08 03:53:15 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.944, ntokens=17160.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.7, wps=3188.8, ups=0.19, wpb=17160.1, bsz=1024, num_updates=190, lr=4.04945e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.4, wall=1208
2024-11-08 03:54:09 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.926, ntokens=17197.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.6, wps=3202.1, ups=0.19, wpb=17197.6, bsz=1024, num_updates=200, lr=4.26257e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=1261
2024-11-08 03:55:03 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.972, ntokens=17104.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.84, wps=3170.3, ups=0.19, wpb=17104.6, bsz=1024, num_updates=210, lr=4.4757e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=1315
2024-11-08 03:55:57 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.944, ntokens=17212.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.7, wps=3204.8, ups=0.19, wpb=17212.7, bsz=1024, num_updates=220, lr=4.68883e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.1, wall=1369
2024-11-08 03:56:50 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.955, ntokens=17548.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.76, wps=3303.5, ups=0.19, wpb=17548.1, bsz=1024, num_updates=230, lr=4.90196e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=1422
2024-11-08 03:57:44 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.933, ntokens=17237.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.64, wps=3189.8, ups=0.19, wpb=17237.3, bsz=1024, num_updates=240, lr=5.11509e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=1476
2024-11-08 03:58:38 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.992, ntokens=17724.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.96, wps=3288.9, ups=0.19, wpb=17724.1, bsz=1024, num_updates=250, lr=5.32822e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=1530
2024-11-08 03:59:32 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.918, ntokens=17418.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.56, wps=3234.6, ups=0.19, wpb=17418.1, bsz=1024, num_updates=260, lr=5.54135e-06, gnorm=0.002, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=1584
2024-11-08 04:00:25 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.945, ntokens=17186.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.7, wps=3192.5, ups=0.19, wpb=17186.2, bsz=1024, num_updates=270, lr=5.75448e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=1638
2024-11-08 04:01:19 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.925, ntokens=17241.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.59, wps=3199, ups=0.19, wpb=17241.2, bsz=1024, num_updates=280, lr=5.9676e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=31, gb_free=13.5, wall=1692
2024-11-08 04:02:13 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.942, ntokens=17176.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.69, wps=3172.3, ups=0.18, wpb=17176.9, bsz=1024, num_updates=290, lr=6.18073e-06, gnorm=0.005, clip=0, loss_scale=128, train_wall=30, gb_free=12.8, wall=1746
2024-11-08 04:03:07 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.89, ntokens=17101.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.41, wps=3197.4, ups=0.19, wpb=17101.7, bsz=1024, num_updates=300, lr=6.39386e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=1799
2024-11-08 04:04:01 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.973, ntokens=17503, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.85, wps=3253.6, ups=0.19, wpb=17503, bsz=1024, num_updates=310, lr=6.60699e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=1853
2024-11-08 04:04:55 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.002, ntokens=17704.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=8.01, wps=3274.3, ups=0.18, wpb=17704.2, bsz=1024, num_updates=320, lr=6.82012e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=1907
2024-11-08 04:05:48 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.905, ntokens=17217.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.49, wps=3217.9, ups=0.19, wpb=17217.9, bsz=1024, num_updates=330, lr=7.03325e-06, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=1961
2024-11-08 04:06:42 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.961, ntokens=17513.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.79, wps=3258.4, ups=0.19, wpb=17513.1, bsz=1024, num_updates=340, lr=7.24638e-06, gnorm=0.005, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=2014
2024-11-08 04:07:36 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.918, ntokens=17225, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.56, wps=3206.5, ups=0.19, wpb=17225, bsz=1024, num_updates=350, lr=7.45951e-06, gnorm=0.006, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=2068
2024-11-08 04:08:29 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.983, ntokens=17669.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.9, wps=3303.1, ups=0.19, wpb=17669.3, bsz=1024, num_updates=360, lr=7.67263e-06, gnorm=0.007, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=2122
2024-11-08 04:09:23 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.004, ntokens=17888.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=8.02, wps=3321.5, ups=0.19, wpb=17888.1, bsz=1024, num_updates=370, lr=7.88576e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=2176
2024-11-08 04:10:15 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.074, ntokens=17546.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=8.42, wps=3375, ups=0.19, wpb=17546.2, bsz=1024, num_updates=380, lr=8.09889e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=2228
2024-11-08 04:11:08 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.069, ntokens=17471.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=8.39, wps=3327.3, ups=0.19, wpb=17471.4, bsz=1024, num_updates=390, lr=8.31202e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=2280
2024-11-08 04:11:09 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 391 updates
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_1.ptcp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt

cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
2024-11-08 04:11:09 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cp: cannot stat './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt'cp: cannot stat './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt'cannot stat './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt': No such file or directory
: No such file or directory: No such file or directory

cp: cp: cp: cp: cannot stat './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt'cannot stat './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt'cannot stat './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt'cannot stat './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt': No such file or directory: No such file or directory
: No such file or directory: No such file or directory


local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping

2024-11-08 04:11:20 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
2024-11-08 04:11:32 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 1 @ 391 updates, score 0) (writing took 22.11375618900638 seconds)
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
2024-11-08 04:11:36 - train.py[line:336] - INFO: end of epoch 1 (average epoch stats below)
2024-11-08 04:11:36 - progress_bar.py[line:282] - INFO: epoch 001 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.956 | ntokens 17325.8 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 7.76 | wps 3189 | ups 0.18 | wpb 17325.8 | bsz 1023 | num_updates 391 | lr 8.33333e-06 | gnorm 0.004 | clip 0 | loss_scale 128 | train_wall 1192 | gb_free 13.2 | wall 2309
2024-11-08 04:11:36 - trainer.py[line:639] - INFO: loading train data for epoch 2
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000


slice_id 6 seek offset 300000
slice_id 1 seek offset 50000
slice_id 3 seek offset 150000
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping



file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000


slice_id 7 seek offset 350000
slice_id 2 seek offset 100000
slice_id 4 seek offset 200000
slice_id 5 seek offset 250000
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 04:14:16 - trainer.py[line:703] - INFO: begin training epoch 2
2024-11-08 04:14:16 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 04:15:07 - progress_bar.py[line:274] - INFO: epoch 002:      9 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.979, ntokens=16820.5, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=7.88, wps=703.9, ups=0.04, wpb=16820.5, bsz=985.6, num_updates=400, lr=8.52515e-06, gnorm=0.006, clip=0, loss_scale=128, train_wall=29, gb_free=13.6, wall=2519
2024-11-08 04:16:00 - progress_bar.py[line:274] - INFO: epoch 002:     19 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.955, ntokens=17396.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.75, wps=3227.6, ups=0.19, wpb=17396.1, bsz=1024, num_updates=410, lr=8.73828e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=2573
2024-11-08 04:16:53 - progress_bar.py[line:274] - INFO: epoch 002:     29 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.945, ntokens=17345.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.7, wps=3279.3, ups=0.19, wpb=17345.7, bsz=1024, num_updates=420, lr=8.95141e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.4, wall=2626
2024-11-08 04:17:47 - progress_bar.py[line:274] - INFO: epoch 002:     39 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.939, ntokens=17270.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.67, wps=3238.3, ups=0.19, wpb=17270.9, bsz=1024, num_updates=430, lr=9.16454e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=2679
2024-11-08 04:18:40 - progress_bar.py[line:274] - INFO: epoch 002:     49 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.948, ntokens=17754.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.72, wps=3355.6, ups=0.19, wpb=17754.5, bsz=1024, num_updates=440, lr=9.37766e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=2732
2024-11-08 04:19:32 - progress_bar.py[line:274] - INFO: epoch 002:     59 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.941, ntokens=17258.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.68, wps=3267.8, ups=0.19, wpb=17258.4, bsz=1024, num_updates=450, lr=9.59079e-06, gnorm=0.005, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=2785
2024-11-08 04:20:26 - progress_bar.py[line:274] - INFO: epoch 002:     69 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.873, ntokens=17259.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.32, wps=3217.7, ups=0.19, wpb=17259.7, bsz=1024, num_updates=460, lr=9.80392e-06, gnorm=0.006, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=2838
2024-11-08 04:21:20 - progress_bar.py[line:274] - INFO: epoch 002:     79 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.956, ntokens=17348.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.76, wps=3224.9, ups=0.19, wpb=17348.2, bsz=1024, num_updates=470, lr=1.00171e-05, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.4, wall=2892
2024-11-08 04:22:14 - progress_bar.py[line:274] - INFO: epoch 002:     89 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.951, ntokens=17455.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.74, wps=3252.6, ups=0.19, wpb=17455.2, bsz=1024, num_updates=480, lr=1.02302e-05, gnorm=0.006, clip=0, loss_scale=128, train_wall=30, gb_free=12.8, wall=2946
2024-11-08 04:23:07 - progress_bar.py[line:274] - INFO: epoch 002:     99 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.984, ntokens=17548, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.91, wps=3285, ups=0.19, wpb=17548, bsz=1024, num_updates=490, lr=1.04433e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=2999
2024-11-08 04:24:01 - progress_bar.py[line:274] - INFO: epoch 002:    109 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.95, ntokens=17220.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.73, wps=3202.6, ups=0.19, wpb=17220.2, bsz=1024, num_updates=500, lr=1.06564e-05, gnorm=0.006, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=3053
2024-11-08 04:24:55 - progress_bar.py[line:274] - INFO: epoch 002:    119 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.96, ntokens=17522.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.78, wps=3255.8, ups=0.19, wpb=17522.6, bsz=1024, num_updates=510, lr=1.08696e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=3107
2024-11-08 04:25:48 - progress_bar.py[line:274] - INFO: epoch 002:    129 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.927, ntokens=17362.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.61, wps=3240.2, ups=0.19, wpb=17362.3, bsz=1024, num_updates=520, lr=1.10827e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=3161
2024-11-08 04:26:42 - progress_bar.py[line:274] - INFO: epoch 002:    139 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.935, ntokens=17226, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.64, wps=3188.7, ups=0.19, wpb=17226, bsz=1024, num_updates=530, lr=1.12958e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=3215
2024-11-08 04:27:35 - progress_bar.py[line:274] - INFO: epoch 002:    149 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.93, ntokens=17187.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.62, wps=3236.7, ups=0.19, wpb=17187.8, bsz=1024, num_updates=540, lr=1.1509e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=3268
2024-11-08 04:28:28 - progress_bar.py[line:274] - INFO: epoch 002:    159 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.912, ntokens=17475.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.53, wps=3289.3, ups=0.19, wpb=17475.4, bsz=1024, num_updates=550, lr=1.17221e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=3321
2024-11-08 04:29:22 - progress_bar.py[line:274] - INFO: epoch 002:    169 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.928, ntokens=17175.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.61, wps=3209.2, ups=0.19, wpb=17175.8, bsz=1024, num_updates=560, lr=1.19352e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=31, gb_free=13.2, wall=3374
2024-11-08 04:30:16 - progress_bar.py[line:274] - INFO: epoch 002:    179 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.915, ntokens=17451.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.54, wps=3238, ups=0.19, wpb=17451.7, bsz=1024, num_updates=570, lr=1.21483e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=3428
2024-11-08 04:31:10 - progress_bar.py[line:274] - INFO: epoch 002:    189 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.908, ntokens=17070.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.51, wps=3174.8, ups=0.19, wpb=17070.6, bsz=1024, num_updates=580, lr=1.23615e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=3482
2024-11-08 04:32:03 - progress_bar.py[line:274] - INFO: epoch 002:    199 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.956, ntokens=17445, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.76, wps=3264.5, ups=0.19, wpb=17445, bsz=1024, num_updates=590, lr=1.25746e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=3535
2024-11-08 04:32:56 - progress_bar.py[line:274] - INFO: epoch 002:    209 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.887, ntokens=17023.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.4, wps=3187.8, ups=0.19, wpb=17023.5, bsz=1024, num_updates=600, lr=1.27877e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=3589
2024-11-08 04:33:50 - progress_bar.py[line:274] - INFO: epoch 002:    219 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.936, ntokens=17181.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.65, wps=3183.8, ups=0.19, wpb=17181.5, bsz=1024, num_updates=610, lr=1.30009e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=3643
2024-11-08 04:34:44 - progress_bar.py[line:274] - INFO: epoch 002:    229 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.896, ntokens=17304.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.44, wps=3241, ups=0.19, wpb=17304.7, bsz=1024, num_updates=620, lr=1.3214e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=30, gb_free=13.2, wall=3696
2024-11-08 04:35:37 - progress_bar.py[line:274] - INFO: epoch 002:    239 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.905, ntokens=16997.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.49, wps=3180, ups=0.19, wpb=16997.3, bsz=1024, num_updates=630, lr=1.34271e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=3750
2024-11-08 04:36:30 - progress_bar.py[line:274] - INFO: epoch 002:    249 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.918, ntokens=17665.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.56, wps=3332.2, ups=0.19, wpb=17665.8, bsz=1024, num_updates=640, lr=1.36402e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=3803
2024-11-08 04:37:24 - progress_bar.py[line:274] - INFO: epoch 002:    259 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.903, ntokens=17233.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.48, wps=3225.2, ups=0.19, wpb=17233.4, bsz=1024, num_updates=650, lr=1.38534e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=3856
2024-11-08 04:38:18 - progress_bar.py[line:274] - INFO: epoch 002:    269 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.949, ntokens=17403.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.72, wps=3206.6, ups=0.18, wpb=17403.1, bsz=1024, num_updates=660, lr=1.40665e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=3910
2024-11-08 04:39:11 - progress_bar.py[line:274] - INFO: epoch 002:    279 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.875, ntokens=17183.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.34, wps=3209.9, ups=0.19, wpb=17183.8, bsz=1024, num_updates=670, lr=1.42796e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=3964
2024-11-08 04:40:05 - progress_bar.py[line:274] - INFO: epoch 002:    289 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.905, ntokens=17030.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.49, wps=3187.1, ups=0.19, wpb=17030.9, bsz=1024, num_updates=680, lr=1.44928e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=4017
2024-11-08 04:40:59 - progress_bar.py[line:274] - INFO: epoch 002:    299 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.919, ntokens=17398.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.56, wps=3223.4, ups=0.19, wpb=17398.1, bsz=1024, num_updates=690, lr=1.47059e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=4071
2024-11-08 04:41:52 - progress_bar.py[line:274] - INFO: epoch 002:    309 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.958, ntokens=17366.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.77, wps=3241.6, ups=0.19, wpb=17366.5, bsz=1024, num_updates=700, lr=1.4919e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=4125
2024-11-08 04:42:46 - progress_bar.py[line:274] - INFO: epoch 002:    319 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.934, ntokens=17491.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.64, wps=3275.7, ups=0.19, wpb=17491.4, bsz=1024, num_updates=710, lr=1.51321e-05, gnorm=0.003, clip=0, loss_scale=256, train_wall=30, gb_free=13.1, wall=4178
2024-11-08 04:43:40 - progress_bar.py[line:274] - INFO: epoch 002:    329 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.883, ntokens=17297.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.38, wps=3184.5, ups=0.18, wpb=17297.5, bsz=1024, num_updates=720, lr=1.53453e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=4233
2024-11-08 04:44:33 - progress_bar.py[line:274] - INFO: epoch 002:    339 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.956, ntokens=17357.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.76, wps=3259.2, ups=0.19, wpb=17357.7, bsz=1024, num_updates=730, lr=1.55584e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=4286
2024-11-08 04:45:28 - progress_bar.py[line:274] - INFO: epoch 002:    349 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.955, ntokens=17502.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.76, wps=3227.8, ups=0.18, wpb=17502.6, bsz=1024, num_updates=740, lr=1.57715e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.3, wall=4340
2024-11-08 04:46:21 - progress_bar.py[line:274] - INFO: epoch 002:    359 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.903, ntokens=17466.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.48, wps=3284, ups=0.19, wpb=17466.8, bsz=1024, num_updates=750, lr=1.59847e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=4393
2024-11-08 04:47:14 - progress_bar.py[line:274] - INFO: epoch 002:    369 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.985, ntokens=17610.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.92, wps=3338.1, ups=0.19, wpb=17610.1, bsz=1024, num_updates=760, lr=1.61978e-05, gnorm=0.009, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=4446
2024-11-08 04:48:05 - progress_bar.py[line:274] - INFO: epoch 002:    379 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.078, ntokens=17647.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=8.45, wps=3415.5, ups=0.19, wpb=17647.7, bsz=1024, num_updates=770, lr=1.64109e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.3, wall=4498
2024-11-08 04:48:57 - progress_bar.py[line:274] - INFO: epoch 002:    389 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.045, ntokens=17343.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=8.25, wps=3349.3, ups=0.19, wpb=17343.4, bsz=1024, num_updates=780, lr=1.6624e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=4549
2024-11-08 04:49:04 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 782 updates
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_2.ptcp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt

cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_2.ptcp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt

cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
2024-11-08 04:49:04 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cannot create regular file './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt'cp: cannot create regular file './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt': File exists
: File exists
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
2024-11-08 04:50:55 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000

slice_id 2 seek offset 100000
slice_id 4 seek offset 200000
2024-11-08 04:52:47 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 2 @ 782 updates, score 0) (writing took 222.6348020019941 seconds)
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000
slice_id 7 seek offset 350000
slice_id 5 seek offset 250000
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000

file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000
slice_id 6 seek offset 300000
slice_id 3 seek offset 150000
slice_id 1 seek offset 50000
2024-11-08 04:53:41 - train.py[line:336] - INFO: end of epoch 2 (average epoch stats below)
2024-11-08 04:53:41 - progress_bar.py[line:282] - INFO: epoch 002 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.938 | ntokens 17333.8 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 7.66 | wps 2684 | ups 0.15 | wpb 17333.8 | bsz 1023 | num_updates 782 | lr 1.66667e-05 | gnorm 0.005 | clip 0 | loss_scale 256 | train_wall 1184 | gb_free 13.2 | wall 4834
2024-11-08 04:53:41 - trainer.py[line:639] - INFO: loading train data for epoch 3
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 04:56:21 - trainer.py[line:703] - INFO: begin training epoch 3
2024-11-08 04:56:21 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 04:57:06 - progress_bar.py[line:274] - INFO: epoch 003:      8 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.893, ntokens=16499.1, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=7.43, wps=337.2, ups=0.02, wpb=16499.1, bsz=985.6, num_updates=790, lr=1.68372e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=29, gb_free=13.4, wall=5039
2024-11-08 04:57:59 - progress_bar.py[line:274] - INFO: epoch 003:     18 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.999, ntokens=17576.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.99, wps=3322.5, ups=0.19, wpb=17576.9, bsz=1024, num_updates=800, lr=1.70503e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=5092
2024-11-08 04:58:53 - progress_bar.py[line:274] - INFO: epoch 003:     28 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.911, ntokens=17397.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.52, wps=3267.1, ups=0.19, wpb=17397.9, bsz=1024, num_updates=810, lr=1.72634e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=30, gb_free=13.2, wall=5145
2024-11-08 04:59:46 - progress_bar.py[line:274] - INFO: epoch 003:     38 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.935, ntokens=17349.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.65, wps=3242.9, ups=0.19, wpb=17349.3, bsz=1024, num_updates=820, lr=1.74766e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.3, wall=5198
2024-11-08 05:00:39 - progress_bar.py[line:274] - INFO: epoch 003:     48 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.936, ntokens=17613.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.65, wps=3322.3, ups=0.19, wpb=17613.7, bsz=1024, num_updates=830, lr=1.76897e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=5252
2024-11-08 05:01:32 - progress_bar.py[line:274] - INFO: epoch 003:     58 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.939, ntokens=17375.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.67, wps=3265.6, ups=0.19, wpb=17375.5, bsz=1024, num_updates=840, lr=1.79028e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=5305
2024-11-08 05:02:26 - progress_bar.py[line:274] - INFO: epoch 003:     68 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.803, ntokens=16894.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=6.98, wps=3135.5, ups=0.19, wpb=16894.2, bsz=1024, num_updates=850, lr=1.81159e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=5359
2024-11-08 05:03:19 - progress_bar.py[line:274] - INFO: epoch 003:     78 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.97, ntokens=17353.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.84, wps=3261.4, ups=0.19, wpb=17353.2, bsz=1024, num_updates=860, lr=1.83291e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=5412
2024-11-08 05:04:13 - progress_bar.py[line:274] - INFO: epoch 003:     88 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.88, ntokens=17157, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.36, wps=3206.3, ups=0.19, wpb=17157, bsz=1024, num_updates=870, lr=1.85422e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=5465
2024-11-08 05:05:06 - progress_bar.py[line:274] - INFO: epoch 003:     98 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.949, ntokens=17454.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.72, wps=3311, ups=0.19, wpb=17454.4, bsz=1024, num_updates=880, lr=1.87553e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=5518
2024-11-08 05:05:59 - progress_bar.py[line:274] - INFO: epoch 003:    108 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.955, ntokens=17366.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.75, wps=3239.8, ups=0.19, wpb=17366.1, bsz=1024, num_updates=890, lr=1.89685e-05, gnorm=0.008, clip=0, loss_scale=256, train_wall=30, gb_free=13, wall=5572
2024-11-08 05:06:53 - progress_bar.py[line:274] - INFO: epoch 003:    118 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.974, ntokens=17555.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.85, wps=3273.2, ups=0.19, wpb=17555.4, bsz=1024, num_updates=900, lr=1.91816e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=5625
2024-11-08 05:07:46 - progress_bar.py[line:274] - INFO: epoch 003:    128 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.913, ntokens=17361.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.53, wps=3239.4, ups=0.19, wpb=17361.6, bsz=1024, num_updates=910, lr=1.93947e-05, gnorm=0.009, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=5679
2024-11-08 05:08:39 - progress_bar.py[line:274] - INFO: epoch 003:    138 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.914, ntokens=17126.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.54, wps=3243.1, ups=0.19, wpb=17126.4, bsz=1024, num_updates=920, lr=1.96078e-05, gnorm=0.009, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=5732
2024-11-08 05:09:33 - progress_bar.py[line:274] - INFO: epoch 003:    148 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.94, ntokens=17210, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.67, wps=3225.6, ups=0.19, wpb=17210, bsz=1024, num_updates=930, lr=1.9821e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=5785
2024-11-08 05:10:27 - progress_bar.py[line:274] - INFO: epoch 003:    158 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.905, ntokens=17360, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.49, wps=3217.3, ups=0.19, wpb=17360, bsz=1024, num_updates=940, lr=2.00341e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=5839
2024-11-08 05:11:20 - progress_bar.py[line:274] - INFO: epoch 003:    168 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.92, ntokens=17161.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.57, wps=3192.7, ups=0.19, wpb=17161.7, bsz=1024, num_updates=950, lr=2.02472e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=5893
2024-11-08 05:12:14 - progress_bar.py[line:274] - INFO: epoch 003:    178 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.904, ntokens=17341.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.49, wps=3228, ups=0.19, wpb=17341.8, bsz=1024, num_updates=960, lr=2.04604e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.3, wall=5946
2024-11-08 05:13:08 - progress_bar.py[line:274] - INFO: epoch 003:    188 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.939, ntokens=17261.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.67, wps=3216.5, ups=0.19, wpb=17261.1, bsz=1024, num_updates=970, lr=2.06735e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=6000
2024-11-08 05:14:02 - progress_bar.py[line:274] - INFO: epoch 003:    198 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.889, ntokens=17135.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.41, wps=3167.2, ups=0.18, wpb=17135.6, bsz=1024, num_updates=980, lr=2.08866e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=6054
2024-11-08 05:14:55 - progress_bar.py[line:274] - INFO: epoch 003:    208 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.908, ntokens=17048, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.51, wps=3193.5, ups=0.19, wpb=17048, bsz=1024, num_updates=990, lr=2.10997e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=6108
2024-11-08 05:15:48 - progress_bar.py[line:274] - INFO: epoch 003:    218 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.873, ntokens=16912.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.33, wps=3193.9, ups=0.19, wpb=16912.1, bsz=1024, num_updates=1000, lr=2.13129e-05, gnorm=0.009, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=6161
2024-11-08 05:16:41 - progress_bar.py[line:274] - INFO: epoch 003:    228 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.943, ntokens=17606.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.69, wps=3306.6, ups=0.19, wpb=17606.3, bsz=1024, num_updates=1010, lr=2.1526e-05, gnorm=0.01, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=6214
2024-11-08 05:17:35 - progress_bar.py[line:274] - INFO: epoch 003:    238 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.889, ntokens=17114.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.41, wps=3213.3, ups=0.19, wpb=17114.8, bsz=1024, num_updates=1020, lr=2.17391e-05, gnorm=0.01, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=6267
2024-11-08 05:18:28 - progress_bar.py[line:274] - INFO: epoch 003:    248 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.936, ntokens=17758.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.65, wps=3300.3, ups=0.19, wpb=17758.9, bsz=1024, num_updates=1030, lr=2.19523e-05, gnorm=0.011, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=6321
2024-11-08 05:19:23 - progress_bar.py[line:274] - INFO: epoch 003:    258 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.906, ntokens=17330.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.5, wps=3190.2, ups=0.18, wpb=17330.8, bsz=1024, num_updates=1040, lr=2.21654e-05, gnorm=0.008, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=6375
2024-11-08 05:20:17 - progress_bar.py[line:274] - INFO: epoch 003:    268 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.96, ntokens=17492.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.78, wps=3242.8, ups=0.19, wpb=17492.9, bsz=1024, num_updates=1050, lr=2.23785e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=30, gb_free=13.6, wall=6429
2024-11-08 05:21:10 - progress_bar.py[line:274] - INFO: epoch 003:    278 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.888, ntokens=17268.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.4, wps=3224.5, ups=0.19, wpb=17268.7, bsz=1024, num_updates=1060, lr=2.25916e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=30, gb_free=13.2, wall=6483
2024-11-08 05:22:04 - progress_bar.py[line:274] - INFO: epoch 003:    288 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.841, ntokens=16817.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.16, wps=3102.8, ups=0.18, wpb=16817.1, bsz=1024, num_updates=1070, lr=2.28048e-05, gnorm=0.01, clip=0, loss_scale=512, train_wall=30, gb_free=13.4, wall=6537
2024-11-08 05:22:59 - progress_bar.py[line:274] - INFO: epoch 003:    298 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.926, ntokens=17399.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.6, wps=3205.6, ups=0.18, wpb=17399.6, bsz=1024, num_updates=1080, lr=2.30179e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=30, gb_free=13.1, wall=6591
2024-11-08 05:23:52 - progress_bar.py[line:274] - INFO: epoch 003:    308 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.993, ntokens=17382.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.96, wps=3271.7, ups=0.19, wpb=17382.4, bsz=1024, num_updates=1090, lr=2.3231e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=30, gb_free=13.4, wall=6644
2024-11-08 05:24:45 - progress_bar.py[line:274] - INFO: epoch 003:    318 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.879, ntokens=17352.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.36, wps=3246.1, ups=0.19, wpb=17352.5, bsz=1024, num_updates=1100, lr=2.34442e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=30, gb_free=13.5, wall=6698
2024-11-08 05:25:39 - progress_bar.py[line:274] - INFO: epoch 003:    328 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.912, ntokens=17319.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.53, wps=3238.6, ups=0.19, wpb=17319.8, bsz=1024, num_updates=1110, lr=2.36573e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=30, gb_free=13.5, wall=6751
2024-11-08 05:26:32 - progress_bar.py[line:274] - INFO: epoch 003:    338 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.944, ntokens=17548, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.7, wps=3294.3, ups=0.19, wpb=17548, bsz=1024, num_updates=1120, lr=2.38704e-05, gnorm=0.01, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=6805
2024-11-08 05:27:26 - progress_bar.py[line:274] - INFO: epoch 003:    348 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.938, ntokens=17372.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.67, wps=3246.5, ups=0.19, wpb=17372.9, bsz=1024, num_updates=1130, lr=2.40835e-05, gnorm=0.011, clip=0, loss_scale=512, train_wall=31, gb_free=13.5, wall=6858
2024-11-08 05:28:19 - progress_bar.py[line:274] - INFO: epoch 003:    358 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.906, ntokens=17523.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.5, wps=3267.1, ups=0.19, wpb=17523.6, bsz=1024, num_updates=1140, lr=2.42967e-05, gnorm=0.011, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=6912
2024-11-08 05:29:12 - progress_bar.py[line:274] - INFO: epoch 003:    368 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.971, ntokens=17615.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.84, wps=3310.2, ups=0.19, wpb=17615.3, bsz=1024, num_updates=1150, lr=2.45098e-05, gnorm=0.012, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=6965
2024-11-08 05:30:04 - progress_bar.py[line:274] - INFO: epoch 003:    378 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.038, ntokens=17438.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=8.21, wps=3374.7, ups=0.19, wpb=17438.5, bsz=1024, num_updates=1160, lr=2.47229e-05, gnorm=0.01, clip=0, loss_scale=512, train_wall=30, gb_free=13.4, wall=7017
2024-11-08 05:30:56 - progress_bar.py[line:274] - INFO: epoch 003:    388 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.038, ntokens=17522, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=8.21, wps=3387.9, ups=0.19, wpb=17522, bsz=1024, num_updates=1170, lr=2.49361e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=30, gb_free=13.4, wall=7068
2024-11-08 05:31:08 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 1173 updates
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_3.ptcp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt

cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
2024-11-08 05:31:08 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cannot create regular file './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt': File exists
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
2024-11-08 05:32:59 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000
slice_id 4 seek offset 200000
2024-11-08 05:34:50 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 3 @ 1173 updates, score 0) (writing took 222.31013034499483 seconds)
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000

slice_id 6 seek offset 300000
slice_id 3 seek offset 150000
slice_id 1 seek offset 50000
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000


slice_id 2 seek offset 100000
slice_id 7 seek offset 350000
slice_id 5 seek offset 250000
2024-11-08 05:35:45 - train.py[line:336] - INFO: end of epoch 3 (average epoch stats below)
2024-11-08 05:35:45 - progress_bar.py[line:282] - INFO: epoch 003 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.928 | ntokens 17319.9 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 7.61 | wps 2683.4 | ups 0.15 | wpb 17319.9 | bsz 1023 | num_updates 1173 | lr 2.5e-05 | gnorm 0.008 | clip 0 | loss_scale 512 | train_wall 1182 | gb_free 13.3 | wall 7357
2024-11-08 05:35:45 - trainer.py[line:639] - INFO: loading train data for epoch 4
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 05:38:26 - trainer.py[line:703] - INFO: begin training epoch 4
2024-11-08 05:38:26 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 05:39:05 - progress_bar.py[line:274] - INFO: epoch 004:      7 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.994, ntokens=16893.2, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=7.97, wps=345.1, ups=0.02, wpb=16893.2, bsz=985.6, num_updates=1180, lr=2.51492e-05, gnorm=0.01, clip=0, loss_scale=512, train_wall=29, gb_free=13.5, wall=7558
2024-11-08 05:39:59 - progress_bar.py[line:274] - INFO: epoch 004:     17 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.965, ntokens=17563.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.81, wps=3283.7, ups=0.19, wpb=17563.2, bsz=1024, num_updates=1190, lr=2.53623e-05, gnorm=0.011, clip=0, loss_scale=512, train_wall=30, gb_free=13.5, wall=7611
2024-11-08 05:40:52 - progress_bar.py[line:274] - INFO: epoch 004:     27 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.945, ntokens=17519, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.7, wps=3311.4, ups=0.19, wpb=17519, bsz=1024, num_updates=1200, lr=2.55754e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=30, gb_free=13.5, wall=7664
2024-11-08 05:41:45 - progress_bar.py[line:274] - INFO: epoch 004:     37 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.91, ntokens=17448.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.52, wps=3243.7, ups=0.19, wpb=17448.6, bsz=1024, num_updates=1210, lr=2.57886e-05, gnorm=0.008, clip=0, loss_scale=512, train_wall=30, gb_free=13.4, wall=7718
2024-11-08 05:42:39 - progress_bar.py[line:274] - INFO: epoch 004:     47 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.941, ntokens=17472.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.68, wps=3271.8, ups=0.19, wpb=17472.3, bsz=1024, num_updates=1220, lr=2.60017e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=30, gb_free=13.6, wall=7771
2024-11-08 05:43:32 - progress_bar.py[line:274] - INFO: epoch 004:     57 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.911, ntokens=17335.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.52, wps=3248.6, ups=0.19, wpb=17335.9, bsz=1024, num_updates=1230, lr=2.62148e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=30, gb_free=13.6, wall=7825
2024-11-08 05:44:26 - progress_bar.py[line:274] - INFO: epoch 004:     67 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.832, ntokens=17100.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.12, wps=3191.9, ups=0.19, wpb=17100.3, bsz=1024, num_updates=1240, lr=2.6428e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=7878
2024-11-08 05:45:20 - progress_bar.py[line:274] - INFO: epoch 004:     77 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.927, ntokens=17068.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.61, wps=3176.8, ups=0.19, wpb=17068.5, bsz=1024, num_updates=1250, lr=2.66411e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=7932
2024-11-08 05:46:13 - progress_bar.py[line:274] - INFO: epoch 004:     87 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.945, ntokens=17510.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.7, wps=3286.1, ups=0.19, wpb=17510.1, bsz=1024, num_updates=1260, lr=2.68542e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=30, gb_free=13.5, wall=7985
2024-11-08 05:47:06 - progress_bar.py[line:274] - INFO: epoch 004:     97 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.916, ntokens=17323.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.55, wps=3257.7, ups=0.19, wpb=17323.8, bsz=1024, num_updates=1270, lr=2.70673e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=30, gb_free=13.5, wall=8038
2024-11-08 05:47:59 - progress_bar.py[line:274] - INFO: epoch 004:    107 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.927, ntokens=17291.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.61, wps=3247.9, ups=0.19, wpb=17291.4, bsz=1024, num_updates=1280, lr=2.72805e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=30, gb_free=13.4, wall=8092
2024-11-08 05:48:52 - progress_bar.py[line:274] - INFO: epoch 004:    117 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.947, ntokens=17383.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.71, wps=3270.6, ups=0.19, wpb=17383.6, bsz=1024, num_updates=1290, lr=2.74936e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=31, gb_free=13.6, wall=8145
2024-11-08 05:49:45 - progress_bar.py[line:274] - INFO: epoch 004:    127 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.907, ntokens=17377.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.5, wps=3286.8, ups=0.19, wpb=17377.6, bsz=1024, num_updates=1300, lr=2.77067e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=31, gb_free=13.5, wall=8198
2024-11-08 05:50:38 - progress_bar.py[line:274] - INFO: epoch 004:    137 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.913, ntokens=17259.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.53, wps=3263.2, ups=0.19, wpb=17259.7, bsz=1024, num_updates=1310, lr=2.79199e-05, gnorm=0.008, clip=0, loss_scale=512, train_wall=31, gb_free=13.4, wall=8251
2024-11-08 05:51:32 - progress_bar.py[line:274] - INFO: epoch 004:    147 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.937, ntokens=17374, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.66, wps=3239.2, ups=0.19, wpb=17374, bsz=1024, num_updates=1320, lr=2.8133e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=30, gb_free=13.6, wall=8304
2024-11-08 05:52:25 - progress_bar.py[line:274] - INFO: epoch 004:    157 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.916, ntokens=17327.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.55, wps=3232.9, ups=0.19, wpb=17327.2, bsz=1024, num_updates=1330, lr=2.83461e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=30, gb_free=13.6, wall=8358
2024-11-08 05:53:19 - progress_bar.py[line:274] - INFO: epoch 004:    167 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.905, ntokens=17212.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.49, wps=3211.7, ups=0.19, wpb=17212.6, bsz=1024, num_updates=1340, lr=2.85592e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=8411
2024-11-08 05:54:13 - progress_bar.py[line:274] - INFO: epoch 004:    177 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.894, ntokens=17400.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.43, wps=3247.3, ups=0.19, wpb=17400.1, bsz=1024, num_updates=1350, lr=2.87724e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=30, gb_free=13.5, wall=8465
2024-11-08 05:55:06 - progress_bar.py[line:274] - INFO: epoch 004:    187 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.934, ntokens=17256.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.64, wps=3237.9, ups=0.19, wpb=17256.7, bsz=1024, num_updates=1360, lr=2.89855e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=8518
2024-11-08 05:55:59 - progress_bar.py[line:274] - INFO: epoch 004:    197 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.904, ntokens=17263.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.48, wps=3227.7, ups=0.19, wpb=17263.8, bsz=1024, num_updates=1370, lr=2.91986e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=31, gb_free=13.4, wall=8572
2024-11-08 05:56:53 - progress_bar.py[line:274] - INFO: epoch 004:    207 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.904, ntokens=17146.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.49, wps=3203.2, ups=0.19, wpb=17146.1, bsz=1024, num_updates=1380, lr=2.94118e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=30, gb_free=13.6, wall=8625
2024-11-08 05:57:46 - progress_bar.py[line:274] - INFO: epoch 004:    217 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.89, ntokens=17203.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.41, wps=3246.9, ups=0.19, wpb=17203.2, bsz=1024, num_updates=1390, lr=2.96249e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=30, gb_free=13.6, wall=8678
2024-11-08 05:58:39 - progress_bar.py[line:274] - INFO: epoch 004:    227 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.908, ntokens=17291.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.51, wps=3237.5, ups=0.19, wpb=17291.5, bsz=1024, num_updates=1400, lr=2.9838e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=30, gb_free=13.5, wall=8732
2024-11-08 05:59:33 - progress_bar.py[line:274] - INFO: epoch 004:    237 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.875, ntokens=17126.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.34, wps=3217.7, ups=0.19, wpb=17126.1, bsz=1024, num_updates=1410, lr=3.00512e-05, gnorm=0.008, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=8785
2024-11-08 06:00:26 - progress_bar.py[line:274] - INFO: epoch 004:    247 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.909, ntokens=17483.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.51, wps=3268.3, ups=0.19, wpb=17483.5, bsz=1024, num_updates=1420, lr=3.02643e-05, gnorm=0.011, clip=0, loss_scale=512, train_wall=30, gb_free=13.6, wall=8838
2024-11-08 06:01:20 - progress_bar.py[line:274] - INFO: epoch 004:    257 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.902, ntokens=17358.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.48, wps=3241.8, ups=0.19, wpb=17358.3, bsz=1024, num_updates=1430, lr=3.04774e-05, gnorm=0.008, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=8892
2024-11-08 06:02:13 - progress_bar.py[line:274] - INFO: epoch 004:    267 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.887, ntokens=17119.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.4, wps=3219.2, ups=0.19, wpb=17119.7, bsz=1024, num_updates=1440, lr=3.06905e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=30, gb_free=13.5, wall=8945
2024-11-08 06:03:07 - progress_bar.py[line:274] - INFO: epoch 004:    277 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.899, ntokens=17177.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.46, wps=3182.8, ups=0.19, wpb=17177.4, bsz=1024, num_updates=1450, lr=3.09037e-05, gnorm=0.013, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=8999
2024-11-08 06:04:00 - progress_bar.py[line:274] - INFO: epoch 004:    287 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.883, ntokens=17219, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.38, wps=3230.1, ups=0.19, wpb=17219, bsz=1024, num_updates=1460, lr=3.11168e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=9052
2024-11-08 06:04:53 - progress_bar.py[line:274] - INFO: epoch 004:    297 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.915, ntokens=17232.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.54, wps=3232.2, ups=0.19, wpb=17232.4, bsz=1024, num_updates=1470, lr=3.13299e-05, gnorm=0.008, clip=0, loss_scale=512, train_wall=30, gb_free=13.6, wall=9106
2024-11-08 06:05:47 - progress_bar.py[line:274] - INFO: epoch 004:    307 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.945, ntokens=17260.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.7, wps=3226.8, ups=0.19, wpb=17260.7, bsz=1024, num_updates=1480, lr=3.15431e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=30, gb_free=13.5, wall=9159
2024-11-08 06:06:40 - progress_bar.py[line:274] - INFO: epoch 004:    317 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.901, ntokens=17428.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.47, wps=3284.6, ups=0.19, wpb=17428.5, bsz=1024, num_updates=1490, lr=3.17562e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=30, gb_free=13.4, wall=9212
2024-11-08 06:07:33 - progress_bar.py[line:274] - INFO: epoch 004:    327 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.895, ntokens=17114.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.44, wps=3219, ups=0.19, wpb=17114.3, bsz=1024, num_updates=1500, lr=3.19693e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=30, gb_free=13.5, wall=9266
2024-11-08 06:08:26 - progress_bar.py[line:274] - INFO: epoch 004:    337 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.919, ntokens=17536.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.57, wps=3292.6, ups=0.19, wpb=17536.7, bsz=1024, num_updates=1510, lr=3.21824e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=30, gb_free=13.5, wall=9319
2024-11-08 06:09:20 - progress_bar.py[line:274] - INFO: epoch 004:    347 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.932, ntokens=17380.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.63, wps=3266.9, ups=0.19, wpb=17380.8, bsz=1024, num_updates=1520, lr=3.23956e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=9372
2024-11-08 06:10:13 - progress_bar.py[line:274] - INFO: epoch 004:    357 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.907, ntokens=17588.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.5, wps=3274.9, ups=0.19, wpb=17588.3, bsz=1024, num_updates=1530, lr=3.26087e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=30, gb_free=13.4, wall=9426
2024-11-08 06:11:07 - progress_bar.py[line:274] - INFO: epoch 004:    367 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.965, ntokens=17641.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.81, wps=3310.9, ups=0.19, wpb=17641.5, bsz=1024, num_updates=1540, lr=3.28218e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=9479
2024-11-08 06:11:59 - progress_bar.py[line:274] - INFO: epoch 004:    377 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.093, ntokens=17916.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=8.53, wps=3442.7, ups=0.19, wpb=17916.3, bsz=1024, num_updates=1550, lr=3.3035e-05, gnorm=0.004, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=9531
2024-11-08 06:12:50 - progress_bar.py[line:274] - INFO: epoch 004:    387 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.057, ntokens=17563.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=8.32, wps=3424.1, ups=0.19, wpb=17563.5, bsz=1024, num_updates=1560, lr=3.32481e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=9582
2024-11-08 06:13:08 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 1564 updates
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_4.ptcp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt

cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_4.ptcp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_4.ptcp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt


cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt
2024-11-08 06:13:08 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cannot create regular file './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt': File exists
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
2024-11-08 06:14:59 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000
slice_id 1 seek offset 50000
2024-11-08 06:16:50 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 4 @ 1564 updates, score 0) (writing took 222.51915184798418 seconds)
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000

slice_id 3 seek offset 150000
slice_id 6 seek offset 300000
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000

local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000
slice_id 7 seek offset 350000
slice_id 2 seek offset 100000
slice_id 4 seek offset 200000
slice_id 5 seek offset 250000
2024-11-08 06:17:45 - train.py[line:336] - INFO: end of epoch 4 (average epoch stats below)
2024-11-08 06:17:45 - progress_bar.py[line:282] - INFO: epoch 004 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.925 | ntokens 17337.7 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 7.6 | wps 2690.6 | ups 0.16 | wpb 17337.7 | bsz 1023 | num_updates 1564 | lr 3.33333e-05 | gnorm 0.007 | clip 0 | loss_scale 1024 | train_wall 1183 | gb_free 13.2 | wall 9877
2024-11-08 06:17:45 - trainer.py[line:639] - INFO: loading train data for epoch 5
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 06:20:26 - trainer.py[line:703] - INFO: begin training epoch 5
2024-11-08 06:20:26 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 06:21:01 - progress_bar.py[line:274] - INFO: epoch 005:      6 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.985, ntokens=16895.2, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=7.92, wps=344.3, ups=0.02, wpb=16895.2, bsz=985.6, num_updates=1570, lr=3.34612e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=29, gb_free=13.5, wall=10073
2024-11-08 06:21:53 - progress_bar.py[line:274] - INFO: epoch 005:     16 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.922, ntokens=17492.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.58, wps=3336.1, ups=0.19, wpb=17492.1, bsz=1024, num_updates=1580, lr=3.36743e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=10125
2024-11-08 06:22:46 - progress_bar.py[line:274] - INFO: epoch 005:     26 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.925, ntokens=17361.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.6, wps=3266.3, ups=0.19, wpb=17361.8, bsz=1024, num_updates=1590, lr=3.38875e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=10179
2024-11-08 06:23:40 - progress_bar.py[line:274] - INFO: epoch 005:     36 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.919, ntokens=17373.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.56, wps=3236.3, ups=0.19, wpb=17373.8, bsz=1024, num_updates=1600, lr=3.41006e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=10232
2024-11-08 06:24:34 - progress_bar.py[line:274] - INFO: epoch 005:     46 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.926, ntokens=17521.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.6, wps=3249.9, ups=0.19, wpb=17521.6, bsz=1024, num_updates=1610, lr=3.43137e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=31, gb_free=13.5, wall=10286
2024-11-08 06:25:27 - progress_bar.py[line:274] - INFO: epoch 005:     56 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.918, ntokens=17239.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.56, wps=3223.2, ups=0.19, wpb=17239.9, bsz=1024, num_updates=1620, lr=3.45269e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=10340
2024-11-08 06:26:20 - progress_bar.py[line:274] - INFO: epoch 005:     66 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.823, ntokens=16966.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.08, wps=3198.3, ups=0.19, wpb=16966.2, bsz=1024, num_updates=1630, lr=3.474e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=10393
2024-11-08 06:27:13 - progress_bar.py[line:274] - INFO: epoch 005:     76 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.916, ntokens=17168.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.55, wps=3238.2, ups=0.19, wpb=17168.1, bsz=1024, num_updates=1640, lr=3.49531e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=10446
2024-11-08 06:28:07 - progress_bar.py[line:274] - INFO: epoch 005:     86 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.919, ntokens=17344.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.56, wps=3259.6, ups=0.19, wpb=17344.3, bsz=1024, num_updates=1650, lr=3.51662e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=10499
2024-11-08 06:28:59 - progress_bar.py[line:274] - INFO: epoch 005:     96 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.886, ntokens=17161.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.39, wps=3242.7, ups=0.19, wpb=17161.5, bsz=1024, num_updates=1660, lr=3.53794e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=10552
2024-11-08 06:29:53 - progress_bar.py[line:274] - INFO: epoch 005:    106 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.936, ntokens=17374.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.65, wps=3265.5, ups=0.19, wpb=17374.3, bsz=1024, num_updates=1670, lr=3.55925e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=30, gb_free=13.2, wall=10605
2024-11-08 06:30:46 - progress_bar.py[line:274] - INFO: epoch 005:    116 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.918, ntokens=17274.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.56, wps=3209.6, ups=0.19, wpb=17274.4, bsz=1024, num_updates=1680, lr=3.58056e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=10659
2024-11-08 06:31:40 - progress_bar.py[line:274] - INFO: epoch 005:    126 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.912, ntokens=17428.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.52, wps=3246.7, ups=0.19, wpb=17428.1, bsz=1024, num_updates=1690, lr=3.60188e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=10713
2024-11-08 06:32:33 - progress_bar.py[line:274] - INFO: epoch 005:    136 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.917, ntokens=17418.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.55, wps=3303.8, ups=0.19, wpb=17418.7, bsz=1024, num_updates=1700, lr=3.62319e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=10765
2024-11-08 06:33:26 - progress_bar.py[line:274] - INFO: epoch 005:    146 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.909, ntokens=17071.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.51, wps=3197.7, ups=0.19, wpb=17071.4, bsz=1024, num_updates=1710, lr=3.6445e-05, gnorm=0.01, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=10819
2024-11-08 06:34:20 - progress_bar.py[line:274] - INFO: epoch 005:    156 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.885, ntokens=17300.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.39, wps=3222.6, ups=0.19, wpb=17300.1, bsz=1024, num_updates=1720, lr=3.66581e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=10872
2024-11-08 06:35:14 - progress_bar.py[line:274] - INFO: epoch 005:    166 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.895, ntokens=17182.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.44, wps=3207.3, ups=0.19, wpb=17182.6, bsz=1024, num_updates=1730, lr=3.68713e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=10926
2024-11-08 06:36:07 - progress_bar.py[line:274] - INFO: epoch 005:    176 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.91, ntokens=17513.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.52, wps=3297.7, ups=0.19, wpb=17513.5, bsz=1024, num_updates=1740, lr=3.70844e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=10979
2024-11-08 06:37:00 - progress_bar.py[line:274] - INFO: epoch 005:    186 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.931, ntokens=17157.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.63, wps=3223, ups=0.19, wpb=17157.8, bsz=1024, num_updates=1750, lr=3.72975e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=11032
2024-11-08 06:37:53 - progress_bar.py[line:274] - INFO: epoch 005:    196 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.903, ntokens=17384.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.48, wps=3279.2, ups=0.19, wpb=17384.9, bsz=1024, num_updates=1760, lr=3.75107e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=11085
2024-11-08 06:38:49 - progress_bar.py[line:274] - INFO: epoch 005:    206 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.885, ntokens=17162.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.39, wps=3079.9, ups=0.18, wpb=17162.1, bsz=1024, num_updates=1770, lr=3.77238e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=31, gb_free=13.3, wall=11141
2024-11-08 06:39:42 - progress_bar.py[line:274] - INFO: epoch 005:    216 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.891, ntokens=17060.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.42, wps=3178.1, ups=0.19, wpb=17060.3, bsz=1024, num_updates=1780, lr=3.79369e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.3, wall=11195
2024-11-08 06:40:36 - progress_bar.py[line:274] - INFO: epoch 005:    226 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.91, ntokens=17412.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.52, wps=3219.5, ups=0.18, wpb=17412.6, bsz=1024, num_updates=1790, lr=3.815e-05, gnorm=0.005, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=11249
2024-11-08 06:41:32 - progress_bar.py[line:274] - INFO: epoch 005:    236 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.877, ntokens=17136.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.35, wps=3064.8, ups=0.18, wpb=17136.5, bsz=1024, num_updates=1800, lr=3.83632e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=31, gb_free=13.6, wall=11305
2024-11-08 06:42:31 - progress_bar.py[line:274] - INFO: epoch 005:    246 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.931, ntokens=17650.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.63, wps=3004.4, ups=0.17, wpb=17650.3, bsz=1024, num_updates=1810, lr=3.85763e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=31, gb_free=13.5, wall=11363
2024-11-08 06:43:29 - progress_bar.py[line:274] - INFO: epoch 005:    256 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.887, ntokens=17449, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.4, wps=3011.5, ups=0.17, wpb=17449, bsz=1024, num_updates=1820, lr=3.87894e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=11421
2024-11-08 06:44:27 - progress_bar.py[line:274] - INFO: epoch 005:    266 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.916, ntokens=17380.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.55, wps=3013.6, ups=0.17, wpb=17380.8, bsz=1024, num_updates=1830, lr=3.90026e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=31, gb_free=13.2, wall=11479
2024-11-08 06:45:22 - progress_bar.py[line:274] - INFO: epoch 005:    276 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.894, ntokens=17134.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.44, wps=3118.8, ups=0.18, wpb=17134.2, bsz=1024, num_updates=1840, lr=3.92157e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=11534
2024-11-08 06:46:15 - progress_bar.py[line:274] - INFO: epoch 005:    286 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.913, ntokens=17307.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.53, wps=3258, ups=0.19, wpb=17307.8, bsz=1024, num_updates=1850, lr=3.94288e-05, gnorm=0.01, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=11587
2024-11-08 06:47:08 - progress_bar.py[line:274] - INFO: epoch 005:    296 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.88, ntokens=17178.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.36, wps=3211.2, ups=0.19, wpb=17178.1, bsz=1024, num_updates=1860, lr=3.96419e-05, gnorm=0.01, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=11641
2024-11-08 06:48:02 - progress_bar.py[line:274] - INFO: epoch 005:    306 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.939, ntokens=17440.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.67, wps=3258.7, ups=0.19, wpb=17440.3, bsz=1024, num_updates=1870, lr=3.98551e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=11694
2024-11-08 06:48:55 - progress_bar.py[line:274] - INFO: epoch 005:    316 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.895, ntokens=17220.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.44, wps=3216.6, ups=0.19, wpb=17220.6, bsz=1024, num_updates=1880, lr=4.00682e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=11748
2024-11-08 06:49:48 - progress_bar.py[line:274] - INFO: epoch 005:    326 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.896, ntokens=17263.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.45, wps=3252.9, ups=0.19, wpb=17263.2, bsz=1024, num_updates=1890, lr=4.02813e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=30, gb_free=13.1, wall=11801
2024-11-08 06:50:42 - progress_bar.py[line:274] - INFO: epoch 005:    336 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.918, ntokens=17341.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.56, wps=3248.4, ups=0.19, wpb=17341.4, bsz=1024, num_updates=1900, lr=4.04945e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=11854
2024-11-08 06:51:35 - progress_bar.py[line:274] - INFO: epoch 005:    346 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.865, ntokens=17213.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.29, wps=3226.3, ups=0.19, wpb=17213.5, bsz=1024, num_updates=1910, lr=4.07076e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=11908
2024-11-08 06:52:28 - progress_bar.py[line:274] - INFO: epoch 005:    356 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.919, ntokens=17560.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.56, wps=3304.1, ups=0.19, wpb=17560.1, bsz=1024, num_updates=1920, lr=4.09207e-05, gnorm=0.01, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=11961
2024-11-08 06:53:22 - progress_bar.py[line:274] - INFO: epoch 005:    366 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.927, ntokens=17475.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.6, wps=3276.4, ups=0.19, wpb=17475.1, bsz=1024, num_updates=1930, lr=4.11338e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=12014
2024-11-08 06:54:14 - progress_bar.py[line:274] - INFO: epoch 005:    376 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.043, ntokens=17690.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=8.24, wps=3399.5, ups=0.19, wpb=17690.7, bsz=1024, num_updates=1940, lr=4.1347e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=12066
2024-11-08 06:55:05 - progress_bar.py[line:274] - INFO: epoch 005:    386 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.017, ntokens=17241, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=8.09, wps=3336.6, ups=0.19, wpb=17241, bsz=1024, num_updates=1950, lr=4.15601e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.2, wall=12118
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.ptcp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt2024-11-08 06:55:28 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 1955 updates

cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt

cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt
2024-11-08 06:55:28 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cp: cp: cp: cp: cannot create regular file './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt'cannot create regular file './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt'cannot create regular file './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt'cannot create regular file './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt'cannot create regular file './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt': File exists
: File exists
: File exists: File exists: File exists


local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
2024-11-08 06:57:14 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000

slice_id 6 seek offset 300000
slice_id 3 seek offset 150000
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000

slice_id 5 seek offset 250000
slice_id 4 seek offset 200000
slice_id 2 seek offset 100000
2024-11-08 06:59:05 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 5 @ 1955 updates, score 0) (writing took 217.35794265998993 seconds)
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000
slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
2024-11-08 07:00:00 - train.py[line:336] - INFO: end of epoch 5 (average epoch stats below)
2024-11-08 07:00:00 - progress_bar.py[line:282] - INFO: epoch 005 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.914 | ntokens 17303.9 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 7.54 | wps 2669 | ups 0.15 | wpb 17303.9 | bsz 1023 | num_updates 1955 | lr 4.16667e-05 | gnorm 0.007 | clip 0 | loss_scale 1024 | train_wall 1185 | gb_free 13.3 | wall 12412
2024-11-08 07:00:00 - trainer.py[line:639] - INFO: loading train data for epoch 6
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 07:02:41 - trainer.py[line:703] - INFO: begin training epoch 6
2024-11-08 07:02:41 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 07:03:10 - progress_bar.py[line:274] - INFO: epoch 006:      5 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.945, ntokens=16515.2, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=7.7, wps=340.5, ups=0.02, wpb=16515.2, bsz=985.6, num_updates=1960, lr=4.17732e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=29, gb_free=13, wall=12603
2024-11-08 07:04:04 - progress_bar.py[line:274] - INFO: epoch 006:     15 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.933, ntokens=17449.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.64, wps=3262.6, ups=0.19, wpb=17449.9, bsz=1024, num_updates=1970, lr=4.19864e-05, gnorm=0.01, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=12656
2024-11-08 07:04:57 - progress_bar.py[line:274] - INFO: epoch 006:     25 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.956, ntokens=17543.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.76, wps=3321, ups=0.19, wpb=17543.9, bsz=1024, num_updates=1980, lr=4.21995e-05, gnorm=0.01, clip=0, loss_scale=1024, train_wall=30, gb_free=13.3, wall=12709
2024-11-08 07:05:50 - progress_bar.py[line:274] - INFO: epoch 006:     35 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.902, ntokens=17221.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.48, wps=3218.1, ups=0.19, wpb=17221.5, bsz=1024, num_updates=1990, lr=4.24126e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=12763
2024-11-08 07:06:43 - progress_bar.py[line:274] - INFO: epoch 006:     45 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.923, ntokens=17422, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.58, wps=3283.1, ups=0.19, wpb=17422, bsz=1024, num_updates=2000, lr=4.26257e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=12816
2024-11-08 07:07:36 - progress_bar.py[line:274] - INFO: epoch 006:     55 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.925, ntokens=17520.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.6, wps=3316.9, ups=0.19, wpb=17520.4, bsz=1024, num_updates=2010, lr=4.28389e-05, gnorm=0.01, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=12868
2024-11-08 07:08:29 - progress_bar.py[line:274] - INFO: epoch 006:     65 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.791, ntokens=16837.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=6.92, wps=3162.4, ups=0.19, wpb=16837.9, bsz=1024, num_updates=2020, lr=4.3052e-05, gnorm=0.012, clip=0, loss_scale=1024, train_wall=30, gb_free=13.2, wall=12922
2024-11-08 07:09:23 - progress_bar.py[line:274] - INFO: epoch 006:     75 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.939, ntokens=17495.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.67, wps=3269, ups=0.19, wpb=17495.6, bsz=1024, num_updates=2030, lr=4.32651e-05, gnorm=0.011, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=12975
2024-11-08 07:10:16 - progress_bar.py[line:274] - INFO: epoch 006:     85 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.936, ntokens=17339.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.65, wps=3259.5, ups=0.19, wpb=17339.5, bsz=1024, num_updates=2040, lr=4.34783e-05, gnorm=0.01, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=13028
2024-11-08 07:11:09 - progress_bar.py[line:274] - INFO: epoch 006:     95 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.915, ntokens=17277.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.54, wps=3269.3, ups=0.19, wpb=17277.5, bsz=1024, num_updates=2050, lr=4.36914e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=13081
2024-11-08 07:12:02 - progress_bar.py[line:274] - INFO: epoch 006:    105 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.926, ntokens=17319.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.6, wps=3243.8, ups=0.19, wpb=17319.2, bsz=1024, num_updates=2060, lr=4.39045e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=13135
2024-11-08 07:12:56 - progress_bar.py[line:274] - INFO: epoch 006:    115 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.912, ntokens=17095.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.53, wps=3176.7, ups=0.19, wpb=17095.5, bsz=1024, num_updates=2070, lr=4.41176e-05, gnorm=0.006, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=13188
2024-11-08 07:13:49 - progress_bar.py[line:274] - INFO: epoch 006:    125 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.92, ntokens=17417.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.57, wps=3277.3, ups=0.19, wpb=17417.3, bsz=1024, num_updates=2080, lr=4.43308e-05, gnorm=0.006, clip=0, loss_scale=2048, train_wall=30, gb_free=13.4, wall=13242
2024-11-08 07:14:42 - progress_bar.py[line:274] - INFO: epoch 006:    135 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.917, ntokens=17330.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.55, wps=3255.5, ups=0.19, wpb=17330.5, bsz=1024, num_updates=2090, lr=4.45439e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=13295
2024-11-08 07:15:37 - progress_bar.py[line:274] - INFO: epoch 006:    145 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.924, ntokens=17032.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.59, wps=3148.6, ups=0.18, wpb=17032.2, bsz=1024, num_updates=2100, lr=4.4757e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=13349
2024-11-08 07:16:30 - progress_bar.py[line:274] - INFO: epoch 006:    155 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.895, ntokens=17341.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.44, wps=3225.7, ups=0.19, wpb=17341.1, bsz=1024, num_updates=2110, lr=4.49702e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=13403
2024-11-08 07:17:24 - progress_bar.py[line:274] - INFO: epoch 006:    165 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.916, ntokens=17147.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.55, wps=3200, ups=0.19, wpb=17147.3, bsz=1024, num_updates=2120, lr=4.51833e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=30, gb_free=13.3, wall=13456
2024-11-08 07:18:18 - progress_bar.py[line:274] - INFO: epoch 006:    175 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.877, ntokens=17402, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.35, wps=3241.9, ups=0.19, wpb=17402, bsz=1024, num_updates=2130, lr=4.53964e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=13510
2024-11-08 07:19:10 - progress_bar.py[line:274] - INFO: epoch 006:    185 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.94, ntokens=17337, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.67, wps=3285, ups=0.19, wpb=17337, bsz=1024, num_updates=2140, lr=4.56095e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=13563
2024-11-08 07:20:04 - progress_bar.py[line:274] - INFO: epoch 006:    195 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.899, ntokens=17261.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.46, wps=3230, ups=0.19, wpb=17261.1, bsz=1024, num_updates=2150, lr=4.58227e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=13616
2024-11-08 07:20:57 - progress_bar.py[line:274] - INFO: epoch 006:    205 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.892, ntokens=17031.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.42, wps=3193.4, ups=0.19, wpb=17031.2, bsz=1024, num_updates=2160, lr=4.60358e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=13670
2024-11-08 07:21:50 - progress_bar.py[line:274] - INFO: epoch 006:    215 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.876, ntokens=17026.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.34, wps=3210.8, ups=0.19, wpb=17026.9, bsz=1024, num_updates=2170, lr=4.62489e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=31, gb_free=13.5, wall=13723
2024-11-08 07:22:46 - progress_bar.py[line:274] - INFO: epoch 006:    225 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.88, ntokens=17359.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.36, wps=3100.4, ups=0.18, wpb=17359.2, bsz=1024, num_updates=2180, lr=4.64621e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=43, gb_free=13.5, wall=13779
2024-11-08 07:23:40 - progress_bar.py[line:274] - INFO: epoch 006:    235 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.877, ntokens=17134.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.35, wps=3161.8, ups=0.18, wpb=17134.2, bsz=1024, num_updates=2190, lr=4.66752e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=54, gb_free=13.1, wall=13833
2024-11-08 07:24:33 - progress_bar.py[line:274] - INFO: epoch 006:    245 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.882, ntokens=17255, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.37, wps=3262.2, ups=0.19, wpb=17255, bsz=1024, num_updates=2200, lr=4.68883e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=53, gb_free=13.3, wall=13886
2024-11-08 07:25:27 - progress_bar.py[line:274] - INFO: epoch 006:    255 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.885, ntokens=17535.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.39, wps=3255.7, ups=0.19, wpb=17535.8, bsz=1024, num_updates=2210, lr=4.71014e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=54, gb_free=13.4, wall=13939
2024-11-08 07:26:20 - progress_bar.py[line:274] - INFO: epoch 006:    265 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.911, ntokens=17365.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.52, wps=3270.1, ups=0.19, wpb=17365.1, bsz=1024, num_updates=2220, lr=4.73146e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=53, gb_free=13.3, wall=13993
2024-11-08 07:27:13 - progress_bar.py[line:274] - INFO: epoch 006:    275 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.884, ntokens=17119.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.38, wps=3243.2, ups=0.19, wpb=17119.5, bsz=1024, num_updates=2230, lr=4.75277e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=53, gb_free=13.6, wall=14045
2024-11-08 07:28:06 - progress_bar.py[line:274] - INFO: epoch 006:    285 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.879, ntokens=17182.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.35, wps=3249, ups=0.19, wpb=17182.4, bsz=1024, num_updates=2240, lr=4.77408e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=53, gb_free=13.5, wall=14098
2024-11-08 07:28:59 - progress_bar.py[line:274] - INFO: epoch 006:    295 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.903, ntokens=17370.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.48, wps=3295.9, ups=0.19, wpb=17370.6, bsz=1024, num_updates=2250, lr=4.7954e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=53, gb_free=13.6, wall=14151
2024-11-08 07:29:50 - progress_bar.py[line:274] - INFO: epoch 006:    305 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.893, ntokens=17177.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.43, wps=3361.4, ups=0.2, wpb=17177.8, bsz=1024, num_updates=2260, lr=4.81671e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=41, gb_free=13.5, wall=14202
2024-11-08 07:30:43 - progress_bar.py[line:274] - INFO: epoch 006:    315 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.904, ntokens=17383.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.48, wps=3247.7, ups=0.19, wpb=17383.8, bsz=1024, num_updates=2270, lr=4.83802e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=31, gb_free=13.1, wall=14256
2024-11-08 07:31:37 - progress_bar.py[line:274] - INFO: epoch 006:    325 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.925, ntokens=17343.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.59, wps=3222.1, ups=0.19, wpb=17343.9, bsz=1024, num_updates=2280, lr=4.85934e-05, gnorm=0.011, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=14309
2024-11-08 07:32:30 - progress_bar.py[line:274] - INFO: epoch 006:    335 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.907, ntokens=17256.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.5, wps=3232.8, ups=0.19, wpb=17256.9, bsz=1024, num_updates=2290, lr=4.88065e-05, gnorm=0.012, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=14363
2024-11-08 07:33:23 - progress_bar.py[line:274] - INFO: epoch 006:    345 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.894, ntokens=17219.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.43, wps=3243.6, ups=0.19, wpb=17219.7, bsz=1024, num_updates=2300, lr=4.90196e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=30, gb_free=13.4, wall=14416
2024-11-08 07:34:17 - progress_bar.py[line:274] - INFO: epoch 006:    355 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.93, ntokens=17660.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.62, wps=3322, ups=0.19, wpb=17660.4, bsz=1024, num_updates=2310, lr=4.92327e-05, gnorm=0.011, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=14469
2024-11-08 07:35:10 - progress_bar.py[line:274] - INFO: epoch 006:    365 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.937, ntokens=17557.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.66, wps=3287.9, ups=0.19, wpb=17557.2, bsz=1024, num_updates=2320, lr=4.94459e-05, gnorm=0.012, clip=0, loss_scale=2048, train_wall=30, gb_free=13, wall=14522
2024-11-08 07:36:02 - progress_bar.py[line:274] - INFO: epoch 006:    375 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.027, ntokens=17623.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=8.15, wps=3370, ups=0.19, wpb=17623.7, bsz=1024, num_updates=2330, lr=4.9659e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=30, gb_free=13.1, wall=14575
2024-11-08 07:36:55 - progress_bar.py[line:274] - INFO: epoch 006:    385 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.016, ntokens=17234.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=8.09, wps=3257.9, ups=0.19, wpb=17234.6, bsz=1024, num_updates=2340, lr=4.98721e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=14628
2024-11-08 07:37:22 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 2346 updates
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_6.ptcp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_6.ptcp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt

cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt

cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt
2024-11-08 07:37:22 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cp: cannot create regular file './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt'cannot create regular file './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt': File exists: File exists

local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2024-11-08 07:39:13 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000
slice_id 7 seek offset 350000
slice_id 4 seek offset 200000
2024-11-08 07:41:05 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 6 @ 2346 updates, score 0) (writing took 222.42986478901003 seconds)
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000
slice_id 2 seek offset 100000
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000


local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000
slice_id 6 seek offset 300000
slice_id 1 seek offset 50000
slice_id 3 seek offset 150000
slice_id 5 seek offset 250000
2024-11-08 07:41:59 - train.py[line:336] - INFO: end of epoch 6 (average epoch stats below)
2024-11-08 07:41:59 - progress_bar.py[line:282] - INFO: epoch 006 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.913 | ntokens 17288.1 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 7.53 | wps 2682.8 | ups 0.16 | wpb 17288.1 | bsz 1023 | num_updates 2346 | lr 5e-05 | gnorm 0.009 | clip 0 | loss_scale 2048 | train_wall 1367 | gb_free 13.3 | wall 14932
2024-11-08 07:41:59 - trainer.py[line:639] - INFO: loading train data for epoch 7
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 07:44:40 - trainer.py[line:703] - INFO: begin training epoch 7
2024-11-08 07:44:40 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 07:45:03 - progress_bar.py[line:274] - INFO: epoch 007:      4 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.965, ntokens=16697.9, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=7.81, wps=342.2, ups=0.02, wpb=16697.9, bsz=985.6, num_updates=2350, lr=4.99946e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=29, gb_free=13.5, wall=15116
2024-11-08 07:45:56 - progress_bar.py[line:274] - INFO: epoch 007:     14 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.936, ntokens=17597.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.65, wps=3301.8, ups=0.19, wpb=17597.9, bsz=1024, num_updates=2360, lr=4.9981e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=31, gb_free=12.7, wall=15169
2024-11-08 07:46:49 - progress_bar.py[line:274] - INFO: epoch 007:     24 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.953, ntokens=17490.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.74, wps=3298.5, ups=0.19, wpb=17490.6, bsz=1024, num_updates=2370, lr=4.99674e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=31, gb_free=13.5, wall=15222
2024-11-08 07:47:42 - progress_bar.py[line:274] - INFO: epoch 007:     34 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.902, ntokens=17387.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.48, wps=3285.9, ups=0.19, wpb=17387.8, bsz=1024, num_updates=2380, lr=4.99537e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=15275
2024-11-08 07:48:35 - progress_bar.py[line:274] - INFO: epoch 007:     44 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.916, ntokens=17497.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.55, wps=3316, ups=0.19, wpb=17497.9, bsz=1024, num_updates=2390, lr=4.99401e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=15328
2024-11-08 07:49:28 - progress_bar.py[line:274] - INFO: epoch 007:     54 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.922, ntokens=17732.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.58, wps=3349.6, ups=0.19, wpb=17732.9, bsz=1024, num_updates=2400, lr=4.99265e-05, gnorm=0.012, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=15381
2024-11-08 07:50:21 - progress_bar.py[line:274] - INFO: epoch 007:     64 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.839, ntokens=17132.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.15, wps=3223.3, ups=0.19, wpb=17132.8, bsz=1024, num_updates=2410, lr=4.99129e-05, gnorm=0.012, clip=0, loss_scale=2048, train_wall=30, gb_free=13.1, wall=15434
2024-11-08 07:51:15 - progress_bar.py[line:274] - INFO: epoch 007:     74 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.922, ntokens=17323.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.58, wps=3252, ups=0.19, wpb=17323.2, bsz=1024, num_updates=2420, lr=4.98993e-05, gnorm=0.012, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=15487
2024-11-08 07:52:07 - progress_bar.py[line:274] - INFO: epoch 007:     84 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.881, ntokens=17286.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.37, wps=3272, ups=0.19, wpb=17286.5, bsz=1024, num_updates=2430, lr=4.98857e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=30, gb_free=13.4, wall=15540
2024-11-08 07:53:00 - progress_bar.py[line:274] - INFO: epoch 007:     94 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.908, ntokens=17300.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.51, wps=3267, ups=0.19, wpb=17300.5, bsz=1024, num_updates=2440, lr=4.98721e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=15593
2024-11-08 07:53:54 - progress_bar.py[line:274] - INFO: epoch 007:    104 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.949, ntokens=17739.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.72, wps=3319.1, ups=0.19, wpb=17739.7, bsz=1024, num_updates=2450, lr=4.98585e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=30, gb_free=13.4, wall=15646
2024-11-08 07:54:47 - progress_bar.py[line:274] - INFO: epoch 007:    114 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.902, ntokens=17258.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.47, wps=3233.7, ups=0.19, wpb=17258.6, bsz=1024, num_updates=2460, lr=4.98449e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=31, gb_free=13.5, wall=15700
2024-11-08 07:55:40 - progress_bar.py[line:274] - INFO: epoch 007:    124 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.891, ntokens=17327.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.42, wps=3273.8, ups=0.19, wpb=17327.9, bsz=1024, num_updates=2470, lr=4.98313e-05, gnorm=0.011, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=15752
2024-11-08 07:56:33 - progress_bar.py[line:274] - INFO: epoch 007:    134 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.9, ntokens=17358.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.46, wps=3252.7, ups=0.19, wpb=17358.6, bsz=1024, num_updates=2480, lr=4.98177e-05, gnorm=0.013, clip=0, loss_scale=2048, train_wall=31, gb_free=13.6, wall=15806
2024-11-08 07:57:27 - progress_bar.py[line:274] - INFO: epoch 007:    144 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.914, ntokens=17150, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.54, wps=3189.6, ups=0.19, wpb=17150, bsz=1024, num_updates=2490, lr=4.98041e-05, gnorm=0.014, clip=0, loss_scale=2048, train_wall=30, gb_free=13.1, wall=15860
2024-11-08 07:58:20 - progress_bar.py[line:274] - INFO: epoch 007:    154 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.926, ntokens=17488.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.6, wps=3297, ups=0.19, wpb=17488.6, bsz=1024, num_updates=2500, lr=4.97905e-05, gnorm=0.012, clip=0, loss_scale=2048, train_wall=30, gb_free=12.8, wall=15913
2024-11-08 07:59:14 - progress_bar.py[line:274] - INFO: epoch 007:    164 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.884, ntokens=17129.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.38, wps=3203.1, ups=0.19, wpb=17129.6, bsz=1024, num_updates=2510, lr=4.97769e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=31, gb_free=13.6, wall=15966
2024-11-08 08:00:07 - progress_bar.py[line:274] - INFO: epoch 007:    174 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.866, ntokens=17370.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.29, wps=3280.2, ups=0.19, wpb=17370.5, bsz=1024, num_updates=2520, lr=4.97633e-05, gnorm=0.013, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=16019
2024-11-08 08:01:00 - progress_bar.py[line:274] - INFO: epoch 007:    184 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.904, ntokens=17259.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.49, wps=3233.4, ups=0.19, wpb=17259.4, bsz=1024, num_updates=2530, lr=4.97497e-05, gnorm=0.013, clip=0, loss_scale=2048, train_wall=30, gb_free=13.3, wall=16072
2024-11-08 08:01:53 - progress_bar.py[line:274] - INFO: epoch 007:    194 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.878, ntokens=17163, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.35, wps=3238.3, ups=0.19, wpb=17163, bsz=1024, num_updates=2540, lr=4.97361e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=30, gb_free=13.3, wall=16125
2024-11-08 08:02:47 - progress_bar.py[line:274] - INFO: epoch 007:    204 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.92, ntokens=17168.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.57, wps=3193.2, ups=0.19, wpb=17168.6, bsz=1024, num_updates=2550, lr=4.97225e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=16179
2024-11-08 08:03:40 - progress_bar.py[line:274] - INFO: epoch 007:    214 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.874, ntokens=17163.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.33, wps=3216.8, ups=0.19, wpb=17163.3, bsz=1024, num_updates=2560, lr=4.97089e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=30, gb_free=13.4, wall=16233
2024-11-08 08:04:34 - progress_bar.py[line:274] - INFO: epoch 007:    224 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.872, ntokens=17360.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.32, wps=3255.3, ups=0.19, wpb=17360.6, bsz=1024, num_updates=2570, lr=4.96953e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=31, gb_free=13.5, wall=16286
2024-11-08 08:05:27 - progress_bar.py[line:274] - INFO: epoch 007:    234 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.876, ntokens=17136.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.34, wps=3204.6, ups=0.19, wpb=17136.7, bsz=1024, num_updates=2580, lr=4.96817e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=35, gb_free=13.5, wall=16339
2024-11-08 08:06:20 - progress_bar.py[line:274] - INFO: epoch 007:    244 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.891, ntokens=17349.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.42, wps=3242.6, ups=0.19, wpb=17349.8, bsz=1024, num_updates=2590, lr=4.96681e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=41, gb_free=13.3, wall=16393
2024-11-08 08:07:15 - progress_bar.py[line:274] - INFO: epoch 007:    254 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.919, ntokens=17722.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.56, wps=3271.5, ups=0.18, wpb=17722.3, bsz=1024, num_updates=2600, lr=4.96545e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=51, gb_free=13.6, wall=16447
2024-11-08 08:08:08 - progress_bar.py[line:274] - INFO: epoch 007:    264 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.89, ntokens=17398.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.41, wps=3256.1, ups=0.19, wpb=17398.3, bsz=1024, num_updates=2610, lr=4.96409e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=53, gb_free=13.2, wall=16501
2024-11-08 08:09:00 - progress_bar.py[line:274] - INFO: epoch 007:    274 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.894, ntokens=17221.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.43, wps=3326.8, ups=0.19, wpb=17221.4, bsz=1024, num_updates=2620, lr=4.96273e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=51, gb_free=13.6, wall=16552
2024-11-08 08:09:52 - progress_bar.py[line:274] - INFO: epoch 007:    284 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.878, ntokens=17171.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.35, wps=3302, ups=0.19, wpb=17171.3, bsz=1024, num_updates=2630, lr=4.96136e-05, gnorm=0.006, clip=0, loss_scale=4096, train_wall=35, gb_free=13.6, wall=16604
2024-11-08 08:10:45 - progress_bar.py[line:274] - INFO: epoch 007:    294 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.883, ntokens=17258.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.38, wps=3243.9, ups=0.19, wpb=17258.2, bsz=1024, num_updates=2640, lr=4.96e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=16658
2024-11-08 08:11:38 - progress_bar.py[line:274] - INFO: epoch 007:    304 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.893, ntokens=17431.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.43, wps=3281.2, ups=0.19, wpb=17431.3, bsz=1024, num_updates=2650, lr=4.95864e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=30, gb_free=13.4, wall=16711
2024-11-08 08:12:32 - progress_bar.py[line:274] - INFO: epoch 007:    314 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.934, ntokens=17414.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.64, wps=3254.4, ups=0.19, wpb=17414.6, bsz=1024, num_updates=2660, lr=4.95728e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=16764
2024-11-08 08:13:26 - progress_bar.py[line:274] - INFO: epoch 007:    324 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.876, ntokens=17356, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.34, wps=3201.1, ups=0.18, wpb=17356, bsz=1024, num_updates=2670, lr=4.95592e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=30, gb_free=13, wall=16818
2024-11-08 08:14:19 - progress_bar.py[line:274] - INFO: epoch 007:    334 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.903, ntokens=17306.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.48, wps=3255.2, ups=0.19, wpb=17306.2, bsz=1024, num_updates=2680, lr=4.95456e-05, gnorm=0.012, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=16872
2024-11-08 08:15:12 - progress_bar.py[line:274] - INFO: epoch 007:    344 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.855, ntokens=17215.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.24, wps=3228.3, ups=0.19, wpb=17215.6, bsz=1024, num_updates=2690, lr=4.9532e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=16925
2024-11-08 08:16:06 - progress_bar.py[line:274] - INFO: epoch 007:    354 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.924, ntokens=17631.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.59, wps=3280.2, ups=0.19, wpb=17631.8, bsz=1024, num_updates=2700, lr=4.95184e-05, gnorm=0.006, clip=0, loss_scale=4096, train_wall=30, gb_free=13.3, wall=16979
2024-11-08 08:17:00 - progress_bar.py[line:274] - INFO: epoch 007:    364 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.923, ntokens=17736.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.59, wps=3314.5, ups=0.19, wpb=17736.2, bsz=1024, num_updates=2710, lr=4.95048e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=17032
2024-11-08 08:17:52 - progress_bar.py[line:274] - INFO: epoch 007:    374 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.988, ntokens=17579.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.93, wps=3371.3, ups=0.19, wpb=17579.1, bsz=1024, num_updates=2720, lr=4.94912e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=30, gb_free=13.4, wall=17084
2024-11-08 08:18:44 - progress_bar.py[line:274] - INFO: epoch 007:    384 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.042, ntokens=17637.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=8.23, wps=3389.5, ups=0.19, wpb=17637.2, bsz=1024, num_updates=2730, lr=4.94776e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=30, gb_free=13.4, wall=17136
2024-11-08 08:19:17 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 2737 updates
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_7.ptcp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt

cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_7.ptcp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt

cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt
2024-11-08 08:19:17 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cp: cp: cp: cannot create regular file './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt'cannot create regular file './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt'cannot create regular file './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt'cannot create regular file './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt': File exists: File exists

: File exists: File exists

local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
2024-11-08 08:21:06 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000

slice_id 1 seek offset 50000
slice_id 3 seek offset 150000
slice_id 2 seek offset 100000
slice_id 5 seek offset 250000
2024-11-08 08:22:58 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 7 @ 2737 updates, score 0) (writing took 220.81195525400108 seconds)
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000
slice_id 4 seek offset 200000
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000
slice_id 6 seek offset 300000
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000
slice_id 7 seek offset 350000
2024-11-08 08:23:52 - train.py[line:336] - INFO: end of epoch 7 (average epoch stats below)
2024-11-08 08:23:52 - progress_bar.py[line:282] - INFO: epoch 007 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.907 | ntokens 17356.1 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 7.5 | wps 2700.2 | ups 0.16 | wpb 17356.1 | bsz 1023 | num_updates 2737 | lr 4.94681e-05 | gnorm 0.01 | clip 0 | loss_scale 4096 | train_wall 1269 | gb_free 13.2 | wall 17445
2024-11-08 08:23:52 - trainer.py[line:639] - INFO: loading train data for epoch 8
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 08:26:33 - trainer.py[line:703] - INFO: begin training epoch 8
2024-11-08 08:26:33 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 08:26:51 - progress_bar.py[line:274] - INFO: epoch 008:      3 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.954, ntokens=16701.5, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=7.75, wps=342.7, ups=0.02, wpb=16701.5, bsz=985.6, num_updates=2740, lr=4.9464e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=29, gb_free=13.5, wall=17624
2024-11-08 08:27:45 - progress_bar.py[line:274] - INFO: epoch 008:     13 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.879, ntokens=17282.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.36, wps=3213.1, ups=0.19, wpb=17282.2, bsz=1024, num_updates=2750, lr=4.94504e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=31, gb_free=13.6, wall=17678
2024-11-08 08:28:39 - progress_bar.py[line:274] - INFO: epoch 008:     23 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.92, ntokens=17443.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.57, wps=3262.9, ups=0.19, wpb=17443.5, bsz=1024, num_updates=2760, lr=4.94368e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=30, gb_free=13.4, wall=17731
2024-11-08 08:29:32 - progress_bar.py[line:274] - INFO: epoch 008:     33 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.857, ntokens=17217.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.24, wps=3241.9, ups=0.19, wpb=17217.5, bsz=1024, num_updates=2770, lr=4.94232e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=30, gb_free=13.4, wall=17784
2024-11-08 08:30:25 - progress_bar.py[line:274] - INFO: epoch 008:     43 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.864, ntokens=17338.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.28, wps=3260.1, ups=0.19, wpb=17338.6, bsz=1024, num_updates=2780, lr=4.94096e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=30, gb_free=13.3, wall=17837
2024-11-08 08:31:18 - progress_bar.py[line:274] - INFO: epoch 008:     53 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.887, ntokens=17443.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.4, wps=3309.3, ups=0.19, wpb=17443.7, bsz=1024, num_updates=2790, lr=4.9396e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=30, gb_free=13.3, wall=17890
2024-11-08 08:32:11 - progress_bar.py[line:274] - INFO: epoch 008:     63 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.789, ntokens=17049.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=6.91, wps=3194.6, ups=0.19, wpb=17049.6, bsz=1024, num_updates=2800, lr=4.93824e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=17943
2024-11-08 08:33:04 - progress_bar.py[line:274] - INFO: epoch 008:     73 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.89, ntokens=17328.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.41, wps=3255.7, ups=0.19, wpb=17328.1, bsz=1024, num_updates=2810, lr=4.93688e-05, gnorm=0.012, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=17997
2024-11-08 08:33:58 - progress_bar.py[line:274] - INFO: epoch 008:     83 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.872, ntokens=17280.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.32, wps=3237.2, ups=0.19, wpb=17280.7, bsz=1024, num_updates=2820, lr=4.93552e-05, gnorm=0.012, clip=0, loss_scale=4096, train_wall=30, gb_free=13.4, wall=18050
2024-11-08 08:34:51 - progress_bar.py[line:274] - INFO: epoch 008:     93 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.854, ntokens=17254.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.23, wps=3221.8, ups=0.19, wpb=17254.8, bsz=1024, num_updates=2830, lr=4.93416e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=18104
2024-11-08 08:35:45 - progress_bar.py[line:274] - INFO: epoch 008:    103 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.956, ntokens=17546.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.76, wps=3268.2, ups=0.19, wpb=17546.9, bsz=1024, num_updates=2840, lr=4.9328e-05, gnorm=0.012, clip=0, loss_scale=4096, train_wall=30, gb_free=13.4, wall=18157
2024-11-08 08:36:38 - progress_bar.py[line:274] - INFO: epoch 008:    113 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.922, ntokens=17328.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.58, wps=3260.8, ups=0.19, wpb=17328.4, bsz=1024, num_updates=2850, lr=4.93144e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=18210
2024-11-08 08:37:31 - progress_bar.py[line:274] - INFO: epoch 008:    123 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.897, ntokens=17307.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.45, wps=3244.4, ups=0.19, wpb=17307.3, bsz=1024, num_updates=2860, lr=4.93008e-05, gnorm=0.006, clip=0, loss_scale=4096, train_wall=30, gb_free=13, wall=18264
2024-11-08 08:38:24 - progress_bar.py[line:274] - INFO: epoch 008:    133 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.905, ntokens=17507.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.49, wps=3313.9, ups=0.19, wpb=17507.4, bsz=1024, num_updates=2870, lr=4.92872e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=31, gb_free=13.6, wall=18317
2024-11-08 08:39:18 - progress_bar.py[line:274] - INFO: epoch 008:    143 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.919, ntokens=17107.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.56, wps=3187.2, ups=0.19, wpb=17107.7, bsz=1024, num_updates=2880, lr=4.92735e-05, gnorm=0.012, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=18370
2024-11-08 08:40:10 - progress_bar.py[line:274] - INFO: epoch 008:    153 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.884, ntokens=17348.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.38, wps=3290.1, ups=0.19, wpb=17348.1, bsz=1024, num_updates=2890, lr=4.92599e-05, gnorm=0.014, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=18423
2024-11-08 08:41:04 - progress_bar.py[line:274] - INFO: epoch 008:    163 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.888, ntokens=17290.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.4, wps=3229.7, ups=0.19, wpb=17290.9, bsz=1024, num_updates=2900, lr=4.92463e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=18476
2024-11-08 08:41:58 - progress_bar.py[line:274] - INFO: epoch 008:    173 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.868, ntokens=17269.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.3, wps=3219.5, ups=0.19, wpb=17269.6, bsz=1024, num_updates=2910, lr=4.92327e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=18530
2024-11-08 08:42:51 - progress_bar.py[line:274] - INFO: epoch 008:    183 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.898, ntokens=17277, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.45, wps=3269.6, ups=0.19, wpb=17277, bsz=1024, num_updates=2920, lr=4.92191e-05, gnorm=0.006, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=18583
2024-11-08 08:43:43 - progress_bar.py[line:274] - INFO: epoch 008:    193 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.872, ntokens=17276.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.32, wps=3265.4, ups=0.19, wpb=17276.4, bsz=1024, num_updates=2930, lr=4.92055e-05, gnorm=0.005, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=18636
2024-11-08 08:44:37 - progress_bar.py[line:274] - INFO: epoch 008:    203 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.935, ntokens=17350.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.65, wps=3244.3, ups=0.19, wpb=17350.6, bsz=1024, num_updates=2940, lr=4.91919e-05, gnorm=0.006, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=18689
2024-11-08 08:45:30 - progress_bar.py[line:274] - INFO: epoch 008:    213 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.854, ntokens=17130.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.23, wps=3224.5, ups=0.19, wpb=17130.7, bsz=1024, num_updates=2950, lr=4.91783e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=18742
2024-11-08 08:46:23 - progress_bar.py[line:274] - INFO: epoch 008:    223 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.876, ntokens=17186.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.34, wps=3216.3, ups=0.19, wpb=17186.4, bsz=1024, num_updates=2960, lr=4.91647e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=18796
2024-11-08 08:47:17 - progress_bar.py[line:274] - INFO: epoch 008:    233 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.905, ntokens=17446.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.49, wps=3248.4, ups=0.19, wpb=17446.4, bsz=1024, num_updates=2970, lr=4.91511e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=18850
2024-11-08 08:48:10 - progress_bar.py[line:274] - INFO: epoch 008:    243 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.913, ntokens=17269.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.53, wps=3270, ups=0.19, wpb=17269.2, bsz=1024, num_updates=2980, lr=4.91375e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=30, gb_free=13.4, wall=18902
2024-11-08 08:49:04 - progress_bar.py[line:274] - INFO: epoch 008:    253 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.93, ntokens=17507.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.62, wps=3238.6, ups=0.18, wpb=17507.5, bsz=1024, num_updates=2990, lr=4.91239e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=18956
2024-11-08 08:49:59 - progress_bar.py[line:274] - INFO: epoch 008:    263 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.915, ntokens=17368, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.54, wps=3146.6, ups=0.18, wpb=17368, bsz=1024, num_updates=3000, lr=4.91103e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=40, gb_free=13.5, wall=19012
2024-11-08 08:50:54 - progress_bar.py[line:274] - INFO: epoch 008:    273 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.901, ntokens=17322.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.47, wps=3155.5, ups=0.18, wpb=17322.9, bsz=1024, num_updates=3010, lr=4.90967e-05, gnorm=0.005, clip=0, loss_scale=4096, train_wall=51, gb_free=13.3, wall=19067
2024-11-08 08:51:46 - progress_bar.py[line:274] - INFO: epoch 008:    283 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.877, ntokens=17312.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.35, wps=3321.5, ups=0.19, wpb=17312.1, bsz=1024, num_updates=3020, lr=4.90831e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=49, gb_free=13.4, wall=19119
2024-11-08 08:52:39 - progress_bar.py[line:274] - INFO: epoch 008:    293 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.89, ntokens=17304.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.41, wps=3300.5, ups=0.19, wpb=17304.7, bsz=1024, num_updates=3030, lr=4.90695e-05, gnorm=0.014, clip=0, loss_scale=4096, train_wall=32, gb_free=13.4, wall=19171
2024-11-08 08:53:32 - progress_bar.py[line:274] - INFO: epoch 008:    303 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.86, ntokens=17309.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.26, wps=3241, ups=0.19, wpb=17309.9, bsz=1024, num_updates=3040, lr=4.90559e-05, gnorm=0.013, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=19225
2024-11-08 08:54:25 - progress_bar.py[line:274] - INFO: epoch 008:    313 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.895, ntokens=17204.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.44, wps=3226.4, ups=0.19, wpb=17204.9, bsz=1024, num_updates=3050, lr=4.90423e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=19278
2024-11-08 08:55:19 - progress_bar.py[line:274] - INFO: epoch 008:    323 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.868, ntokens=17271.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.3, wps=3237.5, ups=0.19, wpb=17271.6, bsz=1024, num_updates=3060, lr=4.90287e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=30, gb_free=13.1, wall=19331
2024-11-08 08:56:13 - progress_bar.py[line:274] - INFO: epoch 008:    333 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.907, ntokens=17320.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.5, wps=3204.3, ups=0.18, wpb=17320.7, bsz=1024, num_updates=3070, lr=4.90151e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=19385
2024-11-08 08:57:06 - progress_bar.py[line:274] - INFO: epoch 008:    343 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.87, ntokens=17337.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.31, wps=3232.8, ups=0.19, wpb=17337.1, bsz=1024, num_updates=3080, lr=4.90015e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=19439
2024-11-08 08:58:00 - progress_bar.py[line:274] - INFO: epoch 008:    353 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.923, ntokens=17594.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.59, wps=3292.6, ups=0.19, wpb=17594.3, bsz=1024, num_updates=3090, lr=4.89879e-05, gnorm=0.005, clip=0, loss_scale=8192, train_wall=30, gb_free=13.4, wall=19492
2024-11-08 08:58:53 - progress_bar.py[line:274] - INFO: epoch 008:    363 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.905, ntokens=17590.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.49, wps=3296.6, ups=0.19, wpb=17590.3, bsz=1024, num_updates=3100, lr=4.89743e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=19546
2024-11-08 08:59:46 - progress_bar.py[line:274] - INFO: epoch 008:    373 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.978, ntokens=17664.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.88, wps=3375.1, ups=0.19, wpb=17664.5, bsz=1024, num_updates=3110, lr=4.89607e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=30, gb_free=12.8, wall=19598
2024-11-08 09:00:37 - progress_bar.py[line:274] - INFO: epoch 008:    383 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=3.011, ntokens=17433.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=8.06, wps=3365.6, ups=0.19, wpb=17433.6, bsz=1024, num_updates=3120, lr=4.89471e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=30, gb_free=13.2, wall=19650
2024-11-08 09:01:16 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 8 @ 3128 updates
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_8.ptcp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt

cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt
2024-11-08 09:01:16 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cp: cannot create regular file './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt'cannot create regular file './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt': File exists
: File exists
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
2024-11-08 09:03:06 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000

slice_id 5 seek offset 250000
slice_id 7 seek offset 350000
2024-11-08 09:04:58 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 8 @ 3128 updates, score 0) (writing took 221.9726812680019 seconds)
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000

slice_id 6 seek offset 300000
slice_id 1 seek offset 50000
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000

slice_id 3 seek offset 150000
slice_id 4 seek offset 200000
slice_id 2 seek offset 100000
2024-11-08 09:05:52 - train.py[line:336] - INFO: end of epoch 8 (average epoch stats below)
2024-11-08 09:05:52 - progress_bar.py[line:282] - INFO: epoch 008 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.898 | ntokens 17324.5 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 7.45 | wps 2688.2 | ups 0.16 | wpb 17324.5 | bsz 1023 | num_updates 3128 | lr 4.89362e-05 | gnorm 0.009 | clip 0 | loss_scale 8192 | train_wall 1235 | gb_free 13.2 | wall 19965
2024-11-08 09:05:52 - trainer.py[line:639] - INFO: loading train data for epoch 9
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 09:08:34 - trainer.py[line:703] - INFO: begin training epoch 9
2024-11-08 09:08:34 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 09:08:46 - progress_bar.py[line:274] - INFO: epoch 009:      2 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.973, ntokens=16820.7, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=7.85, wps=344, ups=0.02, wpb=16820.7, bsz=985.6, num_updates=3130, lr=4.89334e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=29, gb_free=13.5, wall=20139
2024-11-08 09:09:40 - progress_bar.py[line:274] - INFO: epoch 009:     12 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.878, ntokens=17388.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.35, wps=3227, ups=0.19, wpb=17388.3, bsz=1024, num_updates=3140, lr=4.89198e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=20193
2024-11-08 09:10:33 - progress_bar.py[line:274] - INFO: epoch 009:     22 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.902, ntokens=17392.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.48, wps=3281.9, ups=0.19, wpb=17392.7, bsz=1024, num_updates=3150, lr=4.89062e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=20246
2024-11-08 09:11:27 - progress_bar.py[line:274] - INFO: epoch 009:     32 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.851, ntokens=17174.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.22, wps=3176.8, ups=0.18, wpb=17174.6, bsz=1024, num_updates=3160, lr=4.88926e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=32, gb_free=13.6, wall=20300
2024-11-08 09:12:20 - progress_bar.py[line:274] - INFO: epoch 009:     42 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.868, ntokens=17454.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.3, wps=3302.5, ups=0.19, wpb=17454.8, bsz=1024, num_updates=3170, lr=4.8879e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=39, gb_free=13.2, wall=20353
2024-11-08 09:13:13 - progress_bar.py[line:274] - INFO: epoch 009:     52 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.862, ntokens=17346.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.27, wps=3296.4, ups=0.19, wpb=17346.3, bsz=1024, num_updates=3180, lr=4.88654e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=32, gb_free=13.5, wall=20405
2024-11-08 09:14:06 - progress_bar.py[line:274] - INFO: epoch 009:     62 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.827, ntokens=17143.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.1, wps=3199.9, ups=0.19, wpb=17143.2, bsz=1024, num_updates=3190, lr=4.88518e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=20459
2024-11-08 09:15:00 - progress_bar.py[line:274] - INFO: epoch 009:     72 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.848, ntokens=17153.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.2, wps=3196.4, ups=0.19, wpb=17153.5, bsz=1024, num_updates=3200, lr=4.88382e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=31, gb_free=13.2, wall=20512
2024-11-08 09:15:54 - progress_bar.py[line:274] - INFO: epoch 009:     82 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.932, ntokens=17614.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.63, wps=3281.2, ups=0.19, wpb=17614.2, bsz=1024, num_updates=3210, lr=4.88246e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=30, gb_free=13.3, wall=20566
2024-11-08 09:16:47 - progress_bar.py[line:274] - INFO: epoch 009:     92 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.848, ntokens=17204, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.2, wps=3216.7, ups=0.19, wpb=17204, bsz=1024, num_updates=3220, lr=4.8811e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=20620
2024-11-08 09:17:41 - progress_bar.py[line:274] - INFO: epoch 009:    102 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.925, ntokens=17617.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.6, wps=3258.5, ups=0.18, wpb=17617.7, bsz=1024, num_updates=3230, lr=4.87974e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=20674
2024-11-08 09:18:35 - progress_bar.py[line:274] - INFO: epoch 009:    112 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.894, ntokens=17149, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.43, wps=3209.5, ups=0.19, wpb=17149, bsz=1024, num_updates=3240, lr=4.87838e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=20727
2024-11-08 09:19:28 - progress_bar.py[line:274] - INFO: epoch 009:    122 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.841, ntokens=17441.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.16, wps=3295.3, ups=0.19, wpb=17441.8, bsz=1024, num_updates=3250, lr=4.87702e-05, gnorm=0.013, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=20780
2024-11-08 09:20:21 - progress_bar.py[line:274] - INFO: epoch 009:    132 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.912, ntokens=17554.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.53, wps=3280.7, ups=0.19, wpb=17554.6, bsz=1024, num_updates=3260, lr=4.87566e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=20834
2024-11-08 09:21:15 - progress_bar.py[line:274] - INFO: epoch 009:    142 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.85, ntokens=16985.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.21, wps=3158.1, ups=0.19, wpb=16985.9, bsz=1024, num_updates=3270, lr=4.8743e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=20887
2024-11-08 09:22:08 - progress_bar.py[line:274] - INFO: epoch 009:    152 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.856, ntokens=17253.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.24, wps=3234.2, ups=0.19, wpb=17253.5, bsz=1024, num_updates=3280, lr=4.87294e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=20941
2024-11-08 09:23:02 - progress_bar.py[line:274] - INFO: epoch 009:    162 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.868, ntokens=17271.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.3, wps=3232.5, ups=0.19, wpb=17271.9, bsz=1024, num_updates=3290, lr=4.87158e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=20994
2024-11-08 09:23:55 - progress_bar.py[line:274] - INFO: epoch 009:    172 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.87, ntokens=17344.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.31, wps=3268, ups=0.19, wpb=17344.3, bsz=1024, num_updates=3300, lr=4.87022e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=21047
2024-11-08 09:24:48 - progress_bar.py[line:274] - INFO: epoch 009:    182 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.899, ntokens=17533.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.46, wps=3264, ups=0.19, wpb=17533.2, bsz=1024, num_updates=3310, lr=4.86886e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=30, gb_free=13.4, wall=21101
2024-11-08 09:25:42 - progress_bar.py[line:274] - INFO: epoch 009:    192 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.827, ntokens=17045.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.09, wps=3190.9, ups=0.19, wpb=17045.2, bsz=1024, num_updates=3320, lr=4.8675e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=30, gb_free=13.3, wall=21154
2024-11-08 09:26:35 - progress_bar.py[line:274] - INFO: epoch 009:    202 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.882, ntokens=17216.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.37, wps=3242.5, ups=0.19, wpb=17216.2, bsz=1024, num_updates=3330, lr=4.86614e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=21207
2024-11-08 09:27:29 - progress_bar.py[line:274] - INFO: epoch 009:    212 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.827, ntokens=16984.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.09, wps=3149.3, ups=0.19, wpb=16984.7, bsz=1024, num_updates=3340, lr=4.86478e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=21261
2024-11-08 09:28:23 - progress_bar.py[line:274] - INFO: epoch 009:    222 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.815, ntokens=17054.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.03, wps=3158.5, ups=0.19, wpb=17054.7, bsz=1024, num_updates=3350, lr=4.86342e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=21315
2024-11-08 09:29:16 - progress_bar.py[line:274] - INFO: epoch 009:    232 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.89, ntokens=17538.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.41, wps=3318.3, ups=0.19, wpb=17538.4, bsz=1024, num_updates=3360, lr=4.86206e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=21368
2024-11-08 09:30:09 - progress_bar.py[line:274] - INFO: epoch 009:    242 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.834, ntokens=17091.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.13, wps=3213.4, ups=0.19, wpb=17091.4, bsz=1024, num_updates=3370, lr=4.8607e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=30, gb_free=13.4, wall=21421
2024-11-08 09:31:02 - progress_bar.py[line:274] - INFO: epoch 009:    252 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.893, ntokens=17728.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.43, wps=3329.4, ups=0.19, wpb=17728.3, bsz=1024, num_updates=3380, lr=4.85934e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=30, gb_free=13.4, wall=21475
2024-11-08 09:31:56 - progress_bar.py[line:274] - INFO: epoch 009:    262 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.883, ntokens=17493.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.38, wps=3268.7, ups=0.19, wpb=17493.2, bsz=1024, num_updates=3390, lr=4.85797e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=21528
2024-11-08 09:32:49 - progress_bar.py[line:274] - INFO: epoch 009:    272 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.86, ntokens=17326, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.26, wps=3242.9, ups=0.19, wpb=17326, bsz=1024, num_updates=3400, lr=4.85661e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=21582
2024-11-08 09:33:43 - progress_bar.py[line:274] - INFO: epoch 009:    282 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.855, ntokens=17167.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.24, wps=3161.8, ups=0.18, wpb=17167.6, bsz=1024, num_updates=3410, lr=4.85525e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=30, gb_free=13.4, wall=21636
2024-11-08 09:34:36 - progress_bar.py[line:274] - INFO: epoch 009:    292 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.815, ntokens=17148.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.04, wps=3232, ups=0.19, wpb=17148.2, bsz=1024, num_updates=3420, lr=4.85389e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=30, gb_free=13.3, wall=21689
2024-11-08 09:35:30 - progress_bar.py[line:274] - INFO: epoch 009:    302 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.819, ntokens=17146.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.05, wps=3209.7, ups=0.19, wpb=17146.4, bsz=1024, num_updates=3430, lr=4.85253e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=21742
2024-11-08 09:36:24 - progress_bar.py[line:274] - INFO: epoch 009:    312 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.89, ntokens=17286.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.41, wps=3205.3, ups=0.19, wpb=17286.2, bsz=1024, num_updates=3440, lr=4.85117e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=21796
2024-11-08 09:37:17 - progress_bar.py[line:274] - INFO: epoch 009:    322 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.836, ntokens=17275.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.14, wps=3233.1, ups=0.19, wpb=17275.4, bsz=1024, num_updates=3450, lr=4.84981e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=30, gb_free=13.4, wall=21850
2024-11-08 09:38:10 - progress_bar.py[line:274] - INFO: epoch 009:    332 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.864, ntokens=17253.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.28, wps=3278.1, ups=0.19, wpb=17253.2, bsz=1024, num_updates=3460, lr=4.84845e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=31, gb_free=13.4, wall=21902
2024-11-08 09:39:03 - progress_bar.py[line:274] - INFO: epoch 009:    342 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.851, ntokens=17484.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.22, wps=3271.9, ups=0.19, wpb=17484.5, bsz=1024, num_updates=3470, lr=4.84709e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=21956
2024-11-08 09:39:57 - progress_bar.py[line:274] - INFO: epoch 009:    352 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.856, ntokens=17329.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.24, wps=3250.1, ups=0.19, wpb=17329.3, bsz=1024, num_updates=3480, lr=4.84573e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=32, gb_free=13.5, wall=22009
2024-11-08 09:40:51 - progress_bar.py[line:274] - INFO: epoch 009:    362 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.891, ntokens=17638.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.42, wps=3261.2, ups=0.18, wpb=17638.4, bsz=1024, num_updates=3490, lr=4.84437e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=31, gb_free=13.4, wall=22063
2024-11-08 09:41:44 - progress_bar.py[line:274] - INFO: epoch 009:    372 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.99, ntokens=17953.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.95, wps=3346.2, ups=0.19, wpb=17953.3, bsz=1024, num_updates=3500, lr=4.84301e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=22117
2024-11-08 09:42:39 - progress_bar.py[line:274] - INFO: epoch 009:    382 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.99, ntokens=17403.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.94, wps=3213.3, ups=0.18, wpb=17403.6, bsz=1024, num_updates=3510, lr=4.84165e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=41, gb_free=13.4, wall=22171
2024-11-08 09:43:24 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 9 @ 3519 updates
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.ptcp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt

cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.ptcp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt

cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt
2024-11-08 09:43:24 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cp: cp: cannot create regular file './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt'cannot create regular file './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt'cannot create regular file './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt': File exists
: File exists: File exists

local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2024-11-08 09:45:12 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000

slice_id 7 seek offset 350000
slice_id 4 seek offset 200000
slice_id 2 seek offset 100000
2024-11-08 09:47:03 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 9 @ 3519 updates, score 0) (writing took 219.3430704769853 seconds)
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000

local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000
slice_id 6 seek offset 300000
slice_id 3 seek offset 150000
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000
slice_id 1 seek offset 50000
slice_id 5 seek offset 250000
2024-11-08 09:47:58 - train.py[line:336] - INFO: end of epoch 9 (average epoch stats below)
2024-11-08 09:47:58 - progress_bar.py[line:282] - INFO: epoch 009 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.874 | ntokens 17320.1 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 7.33 | wps 2681.4 | ups 0.15 | wpb 17320.1 | bsz 1023 | num_updates 3519 | lr 4.84043e-05 | gnorm 0.009 | clip 0 | loss_scale 8192 | train_wall 1227 | gb_free 13.2 | wall 22490
2024-11-08 09:47:58 - trainer.py[line:639] - INFO: loading train data for epoch 10
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 09:50:39 - trainer.py[line:703] - INFO: begin training epoch 10
2024-11-08 09:50:39 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 09:50:46 - progress_bar.py[line:274] - INFO: epoch 010:      1 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.981, ntokens=16894.9, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=7.9, wps=346.3, ups=0.02, wpb=16894.9, bsz=985.6, num_updates=3520, lr=4.84029e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=47, gb_free=13.4, wall=22659
2024-11-08 09:51:40 - progress_bar.py[line:274] - INFO: epoch 010:     11 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.89, ntokens=17520, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.41, wps=3256.5, ups=0.19, wpb=17520, bsz=1024, num_updates=3530, lr=4.83893e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=22713
2024-11-08 09:52:33 - progress_bar.py[line:274] - INFO: epoch 010:     21 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.883, ntokens=17302.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.38, wps=3267.6, ups=0.19, wpb=17302.3, bsz=1024, num_updates=3540, lr=4.83757e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=22766
2024-11-08 09:53:26 - progress_bar.py[line:274] - INFO: epoch 010:     31 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.822, ntokens=17263.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.07, wps=3265.7, ups=0.19, wpb=17263.1, bsz=1024, num_updates=3550, lr=4.83621e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=30, gb_free=13.1, wall=22818
2024-11-08 09:54:19 - progress_bar.py[line:274] - INFO: epoch 010:     41 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.884, ntokens=17433, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.38, wps=3267, ups=0.19, wpb=17433, bsz=1024, num_updates=3560, lr=4.83485e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=31, gb_free=13.4, wall=22872
2024-11-08 09:55:13 - progress_bar.py[line:274] - INFO: epoch 010:     51 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.875, ntokens=17524.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.34, wps=3279.5, ups=0.19, wpb=17524.4, bsz=1024, num_updates=3570, lr=4.83349e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=22925
2024-11-08 09:56:06 - progress_bar.py[line:274] - INFO: epoch 010:     61 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.779, ntokens=17038, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=6.86, wps=3185.2, ups=0.19, wpb=17038, bsz=1024, num_updates=3580, lr=4.83213e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=22979
2024-11-08 09:57:00 - progress_bar.py[line:274] - INFO: epoch 010:     71 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.846, ntokens=17128.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.19, wps=3209.1, ups=0.19, wpb=17128.8, bsz=1024, num_updates=3590, lr=4.83077e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=31, gb_free=13.5, wall=23032
2024-11-08 09:57:53 - progress_bar.py[line:274] - INFO: epoch 010:     81 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.908, ntokens=17500.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.5, wps=3310.7, ups=0.19, wpb=17500.4, bsz=1024, num_updates=3600, lr=4.82941e-05, gnorm=0.009, clip=0, loss_scale=16384, train_wall=31, gb_free=13.4, wall=23085
2024-11-08 09:58:46 - progress_bar.py[line:274] - INFO: epoch 010:     91 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.852, ntokens=17293.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.22, wps=3230.7, ups=0.19, wpb=17293.7, bsz=1024, num_updates=3610, lr=4.82805e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=30, gb_free=13.3, wall=23139
2024-11-08 09:59:40 - progress_bar.py[line:274] - INFO: epoch 010:    101 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.865, ntokens=17392.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.29, wps=3246.6, ups=0.19, wpb=17392.6, bsz=1024, num_updates=3620, lr=4.82669e-05, gnorm=0.011, clip=0, loss_scale=16384, train_wall=30, gb_free=13.3, wall=23192
2024-11-08 10:00:33 - progress_bar.py[line:274] - INFO: epoch 010:    111 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.871, ntokens=17176.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.32, wps=3209.3, ups=0.19, wpb=17176.8, bsz=1024, num_updates=3630, lr=4.82533e-05, gnorm=0.009, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=23246
2024-11-08 10:01:27 - progress_bar.py[line:274] - INFO: epoch 010:    121 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.856, ntokens=17437.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.24, wps=3239.4, ups=0.19, wpb=17437.3, bsz=1024, num_updates=3640, lr=4.82396e-05, gnorm=0.009, clip=0, loss_scale=16384, train_wall=30, gb_free=13.4, wall=23299
2024-11-08 10:02:21 - progress_bar.py[line:274] - INFO: epoch 010:    131 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.872, ntokens=17316.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.32, wps=3228, ups=0.19, wpb=17316.7, bsz=1024, num_updates=3650, lr=4.8226e-05, gnorm=0.009, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=23353
2024-11-08 10:02:37 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8192.0
2024-11-08 10:03:20 - progress_bar.py[line:274] - INFO: epoch 010:    142 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.873, ntokens=17182.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.33, wps=2896.4, ups=0.17, wpb=17182.8, bsz=1024, num_updates=3660, lr=4.82124e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=33, gb_free=13.5, wall=23412
2024-11-08 10:04:14 - progress_bar.py[line:274] - INFO: epoch 010:    152 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.863, ntokens=17327.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.27, wps=3207.8, ups=0.19, wpb=17327.9, bsz=1024, num_updates=3670, lr=4.81988e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=23466
2024-11-08 10:05:08 - progress_bar.py[line:274] - INFO: epoch 010:    162 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.856, ntokens=17306.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.24, wps=3221.5, ups=0.19, wpb=17306.2, bsz=1024, num_updates=3680, lr=4.81852e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=23520
2024-11-08 10:06:02 - progress_bar.py[line:274] - INFO: epoch 010:    172 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.853, ntokens=17440.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.22, wps=3215.2, ups=0.18, wpb=17440.2, bsz=1024, num_updates=3690, lr=4.81716e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=23574
2024-11-08 10:06:55 - progress_bar.py[line:274] - INFO: epoch 010:    182 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.879, ntokens=17538.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.36, wps=3293.9, ups=0.19, wpb=17538.5, bsz=1024, num_updates=3700, lr=4.8158e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=30, gb_free=13.4, wall=23628
2024-11-08 10:07:48 - progress_bar.py[line:274] - INFO: epoch 010:    192 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.837, ntokens=17190.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.15, wps=3242.5, ups=0.19, wpb=17190.8, bsz=1024, num_updates=3710, lr=4.81444e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=30, gb_free=13.3, wall=23681
2024-11-08 10:08:42 - progress_bar.py[line:274] - INFO: epoch 010:    202 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.835, ntokens=17140.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.14, wps=3203, ups=0.19, wpb=17140.4, bsz=1024, num_updates=3720, lr=4.81308e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=23734
2024-11-08 10:09:35 - progress_bar.py[line:274] - INFO: epoch 010:    212 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.866, ntokens=17188.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.29, wps=3224.8, ups=0.19, wpb=17188.4, bsz=1024, num_updates=3730, lr=4.81172e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=31, gb_free=13.6, wall=23787
2024-11-08 10:10:28 - progress_bar.py[line:274] - INFO: epoch 010:    222 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.818, ntokens=17198.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.05, wps=3239.3, ups=0.19, wpb=17198.7, bsz=1024, num_updates=3740, lr=4.81036e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=23841
2024-11-08 10:11:22 - progress_bar.py[line:274] - INFO: epoch 010:    232 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.886, ntokens=17646.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.39, wps=3288.3, ups=0.19, wpb=17646.5, bsz=1024, num_updates=3750, lr=4.809e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=23894
2024-11-08 10:12:15 - progress_bar.py[line:274] - INFO: epoch 010:    242 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.85, ntokens=17252.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.21, wps=3242.1, ups=0.19, wpb=17252.5, bsz=1024, num_updates=3760, lr=4.80764e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=23947
2024-11-08 10:13:09 - progress_bar.py[line:274] - INFO: epoch 010:    252 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.842, ntokens=17540.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.17, wps=3269.8, ups=0.19, wpb=17540.3, bsz=1024, num_updates=3770, lr=4.80628e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=24001
2024-11-08 10:14:02 - progress_bar.py[line:274] - INFO: epoch 010:    262 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.82, ntokens=17227.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.06, wps=3220.4, ups=0.19, wpb=17227.3, bsz=1024, num_updates=3780, lr=4.80492e-05, gnorm=0.012, clip=0, loss_scale=8192, train_wall=30, gb_free=13.3, wall=24055
2024-11-08 10:14:56 - progress_bar.py[line:274] - INFO: epoch 010:    272 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.839, ntokens=17236.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.15, wps=3225.5, ups=0.19, wpb=17236.4, bsz=1024, num_updates=3790, lr=4.80356e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=24108
2024-11-08 10:15:49 - progress_bar.py[line:274] - INFO: epoch 010:    282 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.853, ntokens=17252.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.23, wps=3219.4, ups=0.19, wpb=17252.2, bsz=1024, num_updates=3800, lr=4.8022e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=30, gb_free=13.4, wall=24162
2024-11-08 10:16:43 - progress_bar.py[line:274] - INFO: epoch 010:    292 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.846, ntokens=17320.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.19, wps=3225.2, ups=0.19, wpb=17320.7, bsz=1024, num_updates=3810, lr=4.80084e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=24215
2024-11-08 10:17:37 - progress_bar.py[line:274] - INFO: epoch 010:    302 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.841, ntokens=17428, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.16, wps=3218.1, ups=0.18, wpb=17428, bsz=1024, num_updates=3820, lr=4.79948e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=24269
2024-11-08 10:18:30 - progress_bar.py[line:274] - INFO: epoch 010:    312 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.897, ntokens=17247, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.45, wps=3263.2, ups=0.19, wpb=17247, bsz=1024, num_updates=3830, lr=4.79812e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=24322
2024-11-08 10:19:23 - progress_bar.py[line:274] - INFO: epoch 010:    322 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.827, ntokens=17327.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.1, wps=3256.7, ups=0.19, wpb=17327.3, bsz=1024, num_updates=3840, lr=4.79676e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=30, gb_free=13.3, wall=24376
2024-11-08 10:20:17 - progress_bar.py[line:274] - INFO: epoch 010:    332 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.82, ntokens=17145, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.06, wps=3178, ups=0.19, wpb=17145, bsz=1024, num_updates=3850, lr=4.7954e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=24429
2024-11-08 10:21:10 - progress_bar.py[line:274] - INFO: epoch 010:    342 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.854, ntokens=17426.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.23, wps=3282.4, ups=0.19, wpb=17426.6, bsz=1024, num_updates=3860, lr=4.79404e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=24483
2024-11-08 10:22:04 - progress_bar.py[line:274] - INFO: epoch 010:    352 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.891, ntokens=17558.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.42, wps=3289, ups=0.19, wpb=17558.9, bsz=1024, num_updates=3870, lr=4.79268e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=24536
2024-11-08 10:22:57 - progress_bar.py[line:274] - INFO: epoch 010:    362 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.869, ntokens=17507, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.3, wps=3250.9, ups=0.19, wpb=17507, bsz=1024, num_updates=3880, lr=4.79132e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=24590
2024-11-08 10:23:50 - progress_bar.py[line:274] - INFO: epoch 010:    372 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.917, ntokens=17597.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.55, wps=3328.7, ups=0.19, wpb=17597.5, bsz=1024, num_updates=3890, lr=4.78995e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=31, gb_free=13.5, wall=24643
2024-11-08 10:24:41 - progress_bar.py[line:274] - INFO: epoch 010:    382 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.993, ntokens=17622.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.96, wps=3464.5, ups=0.2, wpb=17622.2, bsz=1024, num_updates=3900, lr=4.78859e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=31, gb_free=13.4, wall=24694
2024-11-08 10:25:24 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 10 @ 3909 updates
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_10.ptcp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_10.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_10.pt

cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_10.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_10.pt
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_10.ptcp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_10.pt

2024-11-08 10:25:24 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cannot create regular file './polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_10.pt': File exists
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
2024-11-08 10:27:15 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000
slice_id 2 seek offset 100000
2024-11-08 10:29:07 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 10 @ 3909 updates, score 0) (writing took 222.5889514699811 seconds)
cp ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_bbox_fix_checkpoints/100_5e-5_512/checkpoint_epoch_10.pt
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000


local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000

slice_id 6 seek offset 300000
slice_id 1 seek offset 50000
slice_id 3 seek offset 150000
slice_id 7 seek offset 350000
slice_id 4 seek offset 200000
slice_id 5 seek offset 250000
2024-11-08 10:30:01 - train.py[line:336] - INFO: end of epoch 10 (average epoch stats below)
2024-11-08 10:30:01 - progress_bar.py[line:282] - INFO: epoch 010 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.864 | ntokens 17335.4 | nsentences 1023.01 | sample_size 1023.01 | sample_size_v1 0 | sample_size_v2 0 | ppl 7.28 | wps 2679.1 | ups 0.15 | wpb 17335.4 | bsz 1023 | num_updates 3909 | lr 4.78737e-05 | gnorm 0.009 | clip 0 | loss_scale 8192 | train_wall 1185 | gb_free 13.2 | wall 25014
2024-11-08 10:30:01 - trainer.py[line:639] - INFO: loading train data for epoch 11
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact_bbox_fix/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-08 10:32:42 - trainer.py[line:703] - INFO: begin training epoch 11
2024-11-08 10:32:42 - train.py[line:297] - INFO: Start iterating over samples
2024-11-08 10:32:50 - progress_bar.py[line:274] - INFO: epoch 011:      1 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.985, ntokens=16977.9, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=7.92, wps=347.2, ups=0.02, wpb=16977.9, bsz=985.6, num_updates=3910, lr=4.78723e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=29, gb_free=13.3, wall=25183
2024-11-08 10:33:43 - progress_bar.py[line:274] - INFO: epoch 011:     11 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.874, ntokens=17466.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.33, wps=3300.5, ups=0.19, wpb=17466.2, bsz=1024, num_updates=3920, lr=4.78587e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=25235
2024-11-08 10:34:36 - progress_bar.py[line:274] - INFO: epoch 011:     21 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.875, ntokens=17232.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.34, wps=3261.5, ups=0.19, wpb=17232.2, bsz=1024, num_updates=3930, lr=4.78451e-05, gnorm=0.011, clip=0, loss_scale=8192, train_wall=31, gb_free=13.6, wall=25288
2024-11-08 10:35:31 - progress_bar.py[line:274] - INFO: epoch 011:     31 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.849, ntokens=17421.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.2, wps=3152.5, ups=0.18, wpb=17421.6, bsz=1024, num_updates=3940, lr=4.78315e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=49, gb_free=13.1, wall=25344
2024-11-08 10:36:26 - progress_bar.py[line:274] - INFO: epoch 011:     41 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.854, ntokens=17403.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.23, wps=3160.4, ups=0.18, wpb=17403.5, bsz=1024, num_updates=3950, lr=4.78179e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=55, gb_free=13.3, wall=25399
2024-11-08 10:37:22 - progress_bar.py[line:274] - INFO: epoch 011:     51 / 391 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.836, ntokens=17456.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=7.14, wps=3151.8, ups=0.18, wpb=17456.1, bsz=1024, num_updates=3960, lr=4.78043e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=55, gb_free=13.5, wall=25454
Traceback (most recent call last):
  File "../../train.py", line 543, in <module>
    cli_main()
  File "../../train.py", line 536, in cli_main
Traceback (most recent call last):
  File "../../train.py", line 543, in <module>
    distributed_utils.call_main(cfg, main)
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 190, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/contextlib.py", line 74, in inner
    cli_main()    
return func(*args, **kwds)  File "../../train.py", line 536, in cli_main

  File "../../train.py", line 298, in train
    for i, samples in enumerate(progress):
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/logging/progress_bar.py", line 261, in __iter__
    distributed_utils.call_main(cfg, main)
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/distributed/utils.py", line 374, in call_main
    for i, obj in enumerate(self.iterable, start=self.n):
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 56, in __next__
    x = next(self._itr)
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 509, in _chunk_iterator
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/distributed/utils.py", line 348, in distributed_main
        for x in itr:main(cfg, **kwargs)

  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 56, in __next__
  File "../../train.py", line 190, in main
    x = next(self._itr)
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 637, in __next__
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "../../train.py", line 298, in train
    raise item
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 567, in run
    for i, samples in enumerate(progress):
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/logging/progress_bar.py", line 261, in __iter__
    for i, obj in enumerate(self.iterable, start=self.n):
      File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 56, in __next__
for item in self._source:
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    x = next(self._itr)
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 509, in _chunk_iterator
    for x in itr:    
data = self._next_data()  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 56, in __next__

  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    x = next(self._itr)
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 637, in __next__
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    raise item
  File "/home/ubuntu/src/fairseq/fairseq/fairseq/data/iterators.py", line 567, in run
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ubuntu/workspaces/AIHub-polygon-transformer/data/refcoco_dataset.py", line 82, in __getitem__
    for item in self._source:
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self.dataset[index]
  File "/home/ubuntu/workspaces/AIHub-polygon-transformer/data/file_dataset.py", line 111, in __getitem__
    column_l = [dtype(column_l[col_id]) for col_id, dtype in zip(self.selected_col_ids, self.dtypes)]
  File "/home/ubuntu/workspaces/AIHub-polygon-transformer/data/file_dataset.py", line 111, in <listcomp>
    column_l = [dtype(column_l[col_id]) for col_id, dtype in zip(self.selected_col_ids, self.dtypes)]
    data = self._next_data()
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
IndexError: list index out of range
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ubuntu/workspaces/AIHub-polygon-transformer/data/refcoco_dataset.py", line 82, in __getitem__
    data = self.dataset[index]
  File "/home/ubuntu/workspaces/AIHub-polygon-transformer/data/file_dataset.py", line 111, in __getitem__
    column_l = [dtype(column_l[col_id]) for col_id, dtype in zip(self.selected_col_ids, self.dtypes)]
  File "/home/ubuntu/workspaces/AIHub-polygon-transformer/data/file_dataset.py", line 111, in <listcomp>
    column_l = [dtype(column_l[col_id]) for col_id, dtype in zip(self.selected_col_ids, self.dtypes)]
IndexError: list index out of range
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1721037 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1721039 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1721040 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1721041 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1721043 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1721044 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 1 (pid: 1721038) of binary: /home/ubuntu/anaconda3/envs/polyformer/bin/python3
Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 248, in launch_agent
    failures=result.failures,
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
../../train.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-11-08_10:38:04
  host      : ip-172-31-11-84.us-west-2.compute.internal
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 1721042)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-11-08_10:38:04
  host      : ip-172-31-11-84.us-west-2.compute.internal
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 1721038)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
