/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launch.py:188: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  FutureWarning,
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2024-11-21 01:40:19 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu117 available.
2024-11-21 01:40:19 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu117 available.
2024-11-21 01:40:19 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu117 available.
2024-11-21 01:40:19 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu117 available.
2024-11-21 01:40:19 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu117 available.
2024-11-21 01:40:19 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu117 available.
2024-11-21 01:40:20 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu117 available.
2024-11-21 01:40:20 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu117 available.
2024-11-21 01:40:21 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2024-11-21 01:40:21 - utils.py[line:261] - INFO: Start init
2024-11-21 01:40:21 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2024-11-21 01:40:21 - utils.py[line:258] - INFO: distributed init (rank 2): env://
2024-11-21 01:40:21 - utils.py[line:261] - INFO: Start init
2024-11-21 01:40:21 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 2
2024-11-21 01:40:21 - utils.py[line:258] - INFO: distributed init (rank 5): env://
2024-11-21 01:40:21 - utils.py[line:261] - INFO: Start init
2024-11-21 01:40:21 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 5
2024-11-21 01:40:21 - utils.py[line:258] - INFO: distributed init (rank 3): env://
2024-11-21 01:40:21 - utils.py[line:261] - INFO: Start init
2024-11-21 01:40:21 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 3
2024-11-21 01:40:21 - utils.py[line:258] - INFO: distributed init (rank 7): env://
2024-11-21 01:40:21 - utils.py[line:261] - INFO: Start init
2024-11-21 01:40:21 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 7
2024-11-21 01:40:21 - utils.py[line:258] - INFO: distributed init (rank 6): env://
2024-11-21 01:40:21 - utils.py[line:261] - INFO: Start init
2024-11-21 01:40:21 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 6
2024-11-21 01:40:21 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2024-11-21 01:40:21 - utils.py[line:261] - INFO: Start init
2024-11-21 01:40:21 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2024-11-21 01:40:21 - utils.py[line:258] - INFO: distributed init (rank 4): env://
2024-11-21 01:40:21 - utils.py[line:261] - INFO: Start init
2024-11-21 01:40:21 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 4
2024-11-21 01:40:21 - distributed_c10d.py[line:354] - INFO: Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-21 01:40:21 - utils.py[line:274] - INFO: initialized host ailab-server-bengio as rank 4
single-machine distributed training is initialized.
2024-11-21 01:40:21 - distributed_c10d.py[line:354] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-21 01:40:21 - distributed_c10d.py[line:354] - INFO: Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-21 01:40:21 - distributed_c10d.py[line:354] - INFO: Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-21 01:40:21 - distributed_c10d.py[line:354] - INFO: Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-21 01:40:21 - utils.py[line:274] - INFO: initialized host ailab-server-bengio as rank 5
2024-11-21 01:40:21 - utils.py[line:274] - INFO: initialized host ailab-server-bengio as rank 1
2024-11-21 01:40:21 - utils.py[line:274] - INFO: initialized host ailab-server-bengio as rank 2
2024-11-21 01:40:21 - utils.py[line:274] - INFO: initialized host ailab-server-bengio as rank 3
single-machine distributed training is initialized.single-machine distributed training is initialized.
single-machine distributed training is initialized.
single-machine distributed training is initialized.

2024-11-21 01:40:21 - distributed_c10d.py[line:354] - INFO: Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-21 01:40:21 - utils.py[line:274] - INFO: initialized host ailab-server-bengio as rank 7
single-machine distributed training is initialized.
2024-11-21 01:40:21 - distributed_c10d.py[line:354] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-21 01:40:21 - utils.py[line:274] - INFO: initialized host ailab-server-bengio as rank 0
single-machine distributed training is initialized.
2024-11-21 01:40:21 - distributed_c10d.py[line:354] - INFO: Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-21 01:40:21 - utils.py[line:274] - INFO: initialized host ailab-server-bengio as rank 6
single-machine distributed training is initialized.
2024-11-21 01:40:24 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../polyformer_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 8, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 500, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 8, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512', 'restore_file': '../finetune/polyformer_b_aihub_indoor_80_unique_logs/checkpoint_epoch_1.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 500, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'score', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='polyformer_b', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='polyformer_b', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=8, batch_size_valid=8, best_checkpoint_metric='score', bf16=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, cls_weight=0.0005, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv,../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, det_weight=0.1, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_acc=True, eval_args='{"beam":5,"min_len":2,"max_len_a":0,"max_len_b":2}', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=100, max_image_size=512, max_source_positions=1024, max_src_length=80, max_target_positions=1024, max_tgt_length=420, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=8, num_bins=64, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', out_index=3, pad=1, patch_image_size=512, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, restore_file='../finetune/polyformer_b_aihub_indoor_80_unique_logs/checkpoint_epoch_1.pt', sample_patch_num=196, save_dir='./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512', save_interval=1, save_interval_updates=500, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', scst=False, scst_args='{}', seed=1, selected_cols='0,5,6,2,4,3,7', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='refcoco', tensorboard_logdir=None, threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[8], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../polyformer_module', uses_ema=False, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=500, vis_encoder_type='swin-base', wandb_project=None, warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'refcoco', 'data': '../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv,../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv', 'selected_cols': '0,5,6,2,4,3,7', 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 80, 'max_tgt_length': 420, 'code_dict_size': 8192, 'patch_image_size': 512, 'num_bins': 64, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': True, 'eval_args': '{"beam":5,"min_len":2,"max_len_a":0,"max_len_b":2}', 'uses_ema': False, 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'det_weight': 0.1, 'cls_weight': 0.0005, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2024-11-21 01:40:24 - base_task.py[line:187] - INFO: source dictionary: 4100 types
2024-11-21 01:40:24 - base_task.py[line:188] - INFO: target dictionary: 4100 types
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
local datafile ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
2024-11-21 01:40:35 - train.py[line:101] - INFO: PolyFormerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(4100, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): SwinTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (pos_drop): Dropout(p=0.0, inplace=False)
      (layers): ModuleList(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): Identity()
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.009)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=512, out_features=256, bias=False)
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=256, out_features=256, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.017)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=256, out_features=1024, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1024, out_features=256, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=256, out_features=256, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.026)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=256, out_features=1024, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1024, out_features=256, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=1024, out_features=512, bias=False)
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.035)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.043)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (2): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.052)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (3): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.061)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (4): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.070)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (5): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.078)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (6): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.087)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (7): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.096)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (8): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.104)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (9): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.113)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (10): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.122)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (11): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.130)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (12): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.139)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (13): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.148)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (14): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.157)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (15): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.165)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (16): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.174)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (17): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.183)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=2048, out_features=1024, bias=False)
            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.191)
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.200)
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
      )
      (norm3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
    (bert): XLMRobertaForMaskedLM(
      (roberta): XLMRobertaModel(
        (embeddings): XLMRobertaEmbeddings(
          (word_embeddings): Embedding(250002, 768, padding_idx=1)
          (position_embeddings): Embedding(514, 768, padding_idx=1)
          (token_type_embeddings): Embedding(1, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): XLMRobertaEncoder(
          (layer): ModuleList(
            (0): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
      )
      (lm_head): XLMRobertaLMHead(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (decoder): Linear(in_features=768, out_features=250002, bias=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(4100, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (reg_head): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): Linear(in_features=768, out_features=768, bias=True)
        (2): Linear(in_features=768, out_features=2, bias=True)
      )
    )
    (cls_head): Linear(in_features=768, out_features=3, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2024-11-21 01:40:35 - train.py[line:102] - INFO: task: RefcocoTask
2024-11-21 01:40:35 - train.py[line:103] - INFO: model: PolyFormerModel
2024-11-21 01:40:35 - train.py[line:104] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2024-11-21 01:40:35 - train.py[line:108] - INFO: num. shared model params: 478,547,732 (num. trained: 478,547,732)
2024-11-21 01:40:35 - train.py[line:115] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping




file ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 3 row count 6250 total row count 50000file ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 7 row count 6250 total row count 50000file ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 2 row count 6250 total row count 50000file ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 5 row count 6250 total row count 50000
file ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 1 row count 6250 total row count 50000



local datafile ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 6 row count 6250 total row count 50000file ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 0 row count 6250 total row count 50000
file ../../datasets/finetune/aihub_indoor_test_1120/aihub_indoor_test.tsv slice_id 4 row count 6250 total row count 50000

2024-11-21 01:40:57 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2024-11-21 01:40:57 - distributed_c10d.py[line:354] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-11-21 01:40:57 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2024-11-21 01:40:57 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.layers.0.downsample.reduction.bias <- encoder.embed_images.layers.1.downsample.reduction.bias
2024-11-21 01:40:57 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.layers.0.downsample.reduction.bias <- encoder.embed_images.layers.2.downsample.reduction.bias
2024-11-21 01:40:57 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.layers.0.downsample.reduction.bias <- decoder.cls_head.bias
2024-11-21 01:40:57 - trainer.py[line:124] - INFO: detected shared parameter: encoder.bert.roberta.embeddings.word_embeddings.weight <- encoder.bert.lm_head.decoder.weight
2024-11-21 01:40:57 - trainer.py[line:124] - INFO: detected shared parameter: encoder.bert.lm_head.bias <- encoder.bert.lm_head.decoder.bias
2024-11-21 01:40:57 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 8 workers***********************
2024-11-21 01:40:57 - utils.py[line:765] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.684 GB ; name = NVIDIA GeForce RTX 3090                 
2024-11-21 01:40:57 - utils.py[line:765] - INFO: rank   1: capabilities =  8.6  ; total memory = 23.684 GB ; name = NVIDIA GeForce RTX 3090                 
2024-11-21 01:40:57 - utils.py[line:765] - INFO: rank   2: capabilities =  8.6  ; total memory = 23.684 GB ; name = NVIDIA GeForce RTX 3090                 
2024-11-21 01:40:57 - utils.py[line:765] - INFO: rank   3: capabilities =  8.6  ; total memory = 23.684 GB ; name = NVIDIA GeForce RTX 3090                 
2024-11-21 01:40:57 - utils.py[line:765] - INFO: rank   4: capabilities =  8.6  ; total memory = 23.684 GB ; name = NVIDIA GeForce RTX 3090                 
2024-11-21 01:40:57 - utils.py[line:765] - INFO: rank   5: capabilities =  8.6  ; total memory = 23.684 GB ; name = NVIDIA GeForce RTX 3090                 
2024-11-21 01:40:57 - utils.py[line:765] - INFO: rank   6: capabilities =  8.6  ; total memory = 23.684 GB ; name = NVIDIA GeForce RTX 3090                 
2024-11-21 01:40:57 - utils.py[line:765] - INFO: rank   7: capabilities =  8.6  ; total memory = 23.684 GB ; name = NVIDIA GeForce RTX 3090                 
2024-11-21 01:40:57 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 8 workers***********************
2024-11-21 01:40:57 - train.py[line:145] - INFO: training on 8 devices (GPUs/TPUs)
2024-11-21 01:40:57 - train.py[line:151] - INFO: max tokens per device = None and max sentences per device = 8
2024-11-21 01:40:57 - trainer.py[line:458] - INFO: Preparing to load checkpoint ../finetune/polyformer_b_aihub_indoor_80_unique_logs/checkpoint_epoch_1.pt
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
2024-11-21 01:41:11 - trainer.py[line:619] - INFO: Loaded checkpoint ../finetune/polyformer_b_aihub_indoor_80_unique_logs/checkpoint_epoch_1.pt (epoch 2 @ 0 updates)
2024-11-21 01:41:11 - trainer.py[line:639] - INFO: loading train data for epoch 1
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping


local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 3 row count 3052 total row count 24413file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 7 row count 3051 total row count 24413file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 5 row count 3051 total row count 24413


file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 6 row count 3051 total row count 24413
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 1 row count 3052 total row count 24413
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 0 row count 3052 total row count 24413
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 2 row count 3052 total row count 24413
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 4 row count 3052 total row count 24413
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
slice_id 7 seek offset 21362
slice_id 0 seek offset 0
Total steps 4800, warmup steps 288, warmup_factor 0.003472222222222222
Total steps 4800, warmup steps 288, warmup_factor 0.003472222222222222
slice_id 5 seek offset 15260
2024-11-21 01:41:23 - trainer.py[line:703] - INFO: begin training epoch 1
2024-11-21 01:41:23 - train.py[line:297] - INFO: Start iterating over samples
slice_id 6 seek offset 18311
slice_id 4 seek offset 12208
slice_id 3 seek offset 9156
Total steps 4800, warmup steps 288, warmup_factor 0.003472222222222222
Total steps 4800, warmup steps 288, warmup_factor 0.003472222222222222
Total steps 4800, warmup steps 288, warmup_factor 0.003472222222222222
slice_id 2 seek offset 6104
Total steps 4800, warmup steps 288, warmup_factor 0.003472222222222222
slice_id 1 seek offset 3052
Total steps 4800, warmup steps 288, warmup_factor 0.003472222222222222
Total steps 4800, warmup steps 288, warmup_factor 0.003472222222222222
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
loss_reg: 0.006128109553502291 loss_cls: 0.0029600218404084444
loss_reg: 0.006554095433321456 loss_cls: 0.004178334027528763
loss_reg: 0.004888883512125417 loss_cls: 0.004526202566921711
loss_reg: 0.006359111385792293 loss_cls: 0.003629266982898116
loss_reg: 0.006151648092522174 loss_cls: 0.0034115202724933624
loss_reg: 0.004529713712762628 loss_cls: 0.003907142207026482
loss_reg: 0.006012974984688473 loss_cls: 0.004003563895821571
loss_reg: 0.005258882037642277 loss_cls: 0.0028979757335036993
loss_reg: 0.009169041529910264 loss_cls: 0.004100690595805645
loss_reg: 0.005214069390433771 loss_cls: 0.0038777668960392475
loss_reg: 0.007766290335903196 loss_cls: 0.0030013166833668947
loss_reg: 0.010695192131607039 loss_cls: 0.0034323311410844326
loss_reg: 0.005580091910199764 loss_cls: 0.003283566562458873loss_reg: 0.005649127942332451 loss_cls: 0.0034443677868694067

loss_reg: 0.00625019498329944 loss_cls: 0.004083800595253706
loss_reg: 0.005426318415119181 loss_cls: 0.0035906522534787655
loss_reg: 0.006102934321933722 loss_cls: 0.0038689542561769485
loss_reg: 0.005937733038047337 loss_cls: 0.005332066677510738
loss_reg: 0.0049879105792720296 loss_cls: 0.003056461689993739
loss_reg: 0.005330210827414028 loss_cls: 0.003635804634541273
loss_reg: 0.006787053907950724 loss_cls: 0.0043234266340732574
loss_reg: 0.00505541393693888 loss_cls: 0.0057448106817901134
loss_reg: 0.004030194758917246 loss_cls: 0.0037006738130003214
loss_reg: 0.00568590369148943 loss_cls: 0.005240954924374819
loss_reg: 0.00554634872145224 loss_cls: 0.004779804963618517
loss_reg: 0.005590859675933496 loss_cls: 0.0036476056557148695
loss_reg: 0.0050343786926768126 loss_cls: 0.003047897480428219
loss_reg: 0.005878115586509148 loss_cls: 0.0038924263790249825
loss_reg: 0.004508923495244945 loss_cls: 0.004285659175366163
loss_reg: 0.00512176439905597 loss_cls: 0.0035002250224351883
loss_reg: 0.006093569587382556 loss_cls: 0.003962715156376362
loss_reg: 0.005986550702756848 loss_cls: 0.004115294199436903
loss_reg: 0.007055070174592121 loss_cls: 0.0045930431224405766
loss_reg: 0.0045197253393385334 loss_cls: 0.004283261951059103
loss_reg: 0.005500177268086281 loss_cls: 0.004397428594529629
loss_reg: 0.006254475746360227 loss_cls: 0.0029491297900676727
loss_reg: 0.006580106729409735 loss_cls: 0.004130259621888399
loss_reg: 0.004500935710541787 loss_cls: 0.004043159540742636
loss_reg: 0.004755141554222037 loss_cls: 0.003905628575012088
loss_reg: 0.005744931653957552 loss_cls: 0.0047713532112538815
loss_reg: 0.0036060721983069335 loss_cls: 0.005123988259583712
loss_reg: 0.004691136848805759 loss_cls: 0.005283718463033438
loss_reg: 0.005056559224063667 loss_cls: 0.0036238855682313442
loss_reg: 0.005177094976475957 loss_cls: 0.00333813251927495
loss_reg: 0.008438942571559395 loss_cls: 0.003321688622236252
loss_reg: 0.004406300924419743 loss_cls: 0.004234375432133675
loss_reg: 0.0047631018389210165 loss_cls: 0.0042482116259634495
loss_reg: 0.00369896770897849 loss_cls: 0.004128124564886093
loss_reg: 0.004329238050811447 loss_cls: 0.0047180321998894215
loss_reg: 0.003985198857006056 loss_cls: 0.005344608332961798
loss_reg: 0.004609678276243746 loss_cls: 0.004390138667076826
loss_reg: 0.005993878563955658 loss_cls: 0.004394920077174902
loss_reg: 0.0050793248001255115 loss_cls: 0.003770552109926939
loss_reg: 0.00383540045615662 loss_cls: 0.006197781767696142
loss_reg: 0.004247533984088687 loss_cls: 0.004369164817035198
loss_reg: 0.004287420494468744 loss_cls: 0.003966058138757944
loss_reg: 0.005402854466379916 loss_cls: 0.004301207140088081
loss_reg: 0.006155923224511422 loss_cls: 0.003119411412626505
loss_reg: 0.008046600459475759 loss_cls: 0.005211078096181154
loss_reg: 0.007766047716868974 loss_cls: 0.004186918493360281
loss_reg: 0.004964945950104441 loss_cls: 0.0036427245941013098
loss_reg: 0.006831250741451697 loss_cls: 0.004334909841418266
loss_reg: 0.004651096415749367 loss_cls: 0.004542305134236813
loss_reg: 0.004747770092915022 loss_cls: 0.004560078028589487
2024-11-21 01:41:59 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.756, ntokens=8977, nsentences=512, sample_size=512, sample_size_v1=0, sample_size_v2=0, ppl=6.75, wps=2986.9, ups=0.33, wpb=8977, bsz=512, num_updates=10, lr=1.73611e-06, gnorm=0.006, clip=0, loss_scale=128, train_wall=33, gb_free=5.8, wall=62
2024-11-21 01:42:29 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.756, ntokens=9002.6, nsentences=512, sample_size=512, sample_size_v1=0, sample_size_v2=0, ppl=6.76, wps=3012.9, ups=0.33, wpb=9002.6, bsz=512, num_updates=20, lr=3.47222e-06, gnorm=0.007, clip=0, loss_scale=128, train_wall=30, gb_free=5.8, wall=92
2024-11-21 01:42:58 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.746, ntokens=8834.6, nsentences=512, sample_size=512, sample_size_v1=0, sample_size_v2=0, ppl=6.71, wps=3002.5, ups=0.34, wpb=8834.6, bsz=512, num_updates=30, lr=5.20833e-06, gnorm=0.006, clip=0, loss_scale=128, train_wall=29, gb_free=5.8, wall=121
2024-11-21 01:43:27 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.779, ntokens=9047.5, nsentences=508.5, sample_size=508.5, sample_size_v1=0, sample_size_v2=0, ppl=6.86, wps=3104.2, ups=0.34, wpb=9047.5, bsz=508.5, num_updates=40, lr=6.94444e-06, gnorm=0.006, clip=0, loss_scale=128, train_wall=29, gb_free=5.8, wall=150
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.ptcp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt

cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
2024-11-21 01:43:51 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 48 updates
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
2024-11-21 01:43:51 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 3 row count 3052 total row count 24413
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 2 row count 3052 total row count 24413
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 1 row count 3052 total row count 24413
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 5 row count 3051 total row count 24413
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 7 row count 3051 total row count 24413
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 4 row count 3052 total row count 24413
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 6 row count 3051 total row count 24413
slice_id 3 seek offset 9156
slice_id 2 seek offset 6104
slice_id 1 seek offset 3052
slice_id 5 seek offset 15260
slice_id 6 seek offset 18311
slice_id 4 seek offset 12208
slice_id 7 seek offset 21362
2024-11-21 01:45:22 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_best.pt
2024-11-21 01:47:03 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 1 @ 48 updates, score 0) (writing took 192.0054576320108 seconds)
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
2024-11-21 01:47:52 - train.py[line:336] - INFO: end of epoch 1 (average epoch stats below)
2024-11-21 01:47:52 - progress_bar.py[line:282] - INFO: epoch 001 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.764 | ntokens 8938.17 | nsentences 508.604 | sample_size 508.604 | sample_size_v1 0 | sample_size_v2 0 | ppl 6.79 | wps 1103.8 | ups 0.12 | wpb 8938.2 | bsz 508.6 | num_updates 48 | lr 8.33333e-06 | gnorm 0.006 | clip 0 | loss_scale 128 | train_wall 143 | gb_free 5.7 | wall 415
2024-11-21 01:47:52 - trainer.py[line:639] - INFO: loading train data for epoch 2
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 0 row count 3052 total row count 24413
slice_id 0 seek offset 0
2024-11-21 01:48:03 - trainer.py[line:703] - INFO: begin training epoch 2
2024-11-21 01:48:03 - train.py[line:297] - INFO: Start iterating over samples
2024-11-21 01:48:12 - progress_bar.py[line:274] - INFO: epoch 002:      2 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.779, ntokens=8817.4, nsentences=499.2, sample_size=499.2, sample_size_v1=0, sample_size_v2=0, ppl=6.87, wps=310.1, ups=0.04, wpb=8817.4, bsz=499.2, num_updates=50, lr=8.68056e-06, gnorm=0.006, clip=0, loss_scale=128, train_wall=28, gb_free=5.8, wall=435
2024-11-21 01:48:41 - progress_bar.py[line:274] - INFO: epoch 002:     12 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.739, ntokens=8801.6, nsentences=512, sample_size=512, sample_size_v1=0, sample_size_v2=0, ppl=6.68, wps=2976.7, ups=0.34, wpb=8801.6, bsz=512, num_updates=60, lr=1.04167e-05, gnorm=0.006, clip=0, loss_scale=128, train_wall=29, gb_free=5.8, wall=464
2024-11-21 01:49:12 - progress_bar.py[line:274] - INFO: epoch 002:     22 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.743, ntokens=8839.5, nsentences=508.5, sample_size=508.5, sample_size_v1=0, sample_size_v2=0, ppl=6.7, wps=2885.2, ups=0.33, wpb=8839.5, bsz=508.5, num_updates=70, lr=1.21528e-05, gnorm=0.006, clip=0, loss_scale=128, train_wall=29, gb_free=5.7, wall=495
2024-11-21 01:49:43 - progress_bar.py[line:274] - INFO: epoch 002:     32 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.77, ntokens=8980.5, nsentences=512, sample_size=512, sample_size_v1=0, sample_size_v2=0, ppl=6.82, wps=2859.3, ups=0.32, wpb=8980.5, bsz=512, num_updates=80, lr=1.38889e-05, gnorm=0.009, clip=0, loss_scale=128, train_wall=29, gb_free=5.8, wall=526
2024-11-21 01:50:14 - progress_bar.py[line:274] - INFO: epoch 002:     42 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.795, ntokens=9113, nsentences=512, sample_size=512, sample_size_v1=0, sample_size_v2=0, ppl=6.94, wps=2946.5, ups=0.32, wpb=9113, bsz=512, num_updates=90, lr=1.5625e-05, gnorm=0.009, clip=0, loss_scale=128, train_wall=30, gb_free=5.7, wall=557
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_2.ptcp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt

2024-11-21 01:50:33 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 96 updates
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
2024-11-21 01:50:33 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 1 row count 3052 total row count 24413file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 3 row count 3052 total row count 24413
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 5 row count 3051 total row count 24413

file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 2 row count 3052 total row count 24413
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping

local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 4 row count 3052 total row count 24413
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 6 row count 3051 total row count 24413
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 7 row count 3051 total row count 24413
slice_id 5 seek offset 15260
slice_id 3 seek offset 9156
slice_id 2 seek offset 6104
slice_id 1 seek offset 3052
slice_id 4 seek offset 12208
slice_id 6 seek offset 18311
slice_id 7 seek offset 21362
2024-11-21 01:52:11 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_best.pt
2024-11-21 01:53:59 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 2 @ 96 updates, score 0) (writing took 205.94182154512964 seconds)
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
2024-11-21 01:54:51 - train.py[line:336] - INFO: end of epoch 2 (average epoch stats below)
2024-11-21 01:54:51 - progress_bar.py[line:282] - INFO: epoch 002 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.763 | ntokens 8898.44 | nsentences 508.604 | sample_size 508.604 | sample_size_v1 0 | sample_size_v2 0 | ppl 6.79 | wps 1020 | ups 0.11 | wpb 8898.4 | bsz 508.6 | num_updates 96 | lr 1.66667e-05 | gnorm 0.008 | clip 0 | loss_scale 128 | train_wall 140 | gb_free 5.7 | wall 834
2024-11-21 01:54:51 - trainer.py[line:639] - INFO: loading train data for epoch 3
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 0 row count 3052 total row count 24413
slice_id 0 seek offset 0
2024-11-21 01:55:02 - trainer.py[line:703] - INFO: begin training epoch 3
2024-11-21 01:55:02 - train.py[line:297] - INFO: Start iterating over samples
2024-11-21 01:55:16 - progress_bar.py[line:274] - INFO: epoch 003:      4 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.77, ntokens=8785.1, nsentences=499.2, sample_size=499.2, sample_size_v1=0, sample_size_v2=0, ppl=6.82, wps=291.3, ups=0.03, wpb=8785.1, bsz=499.2, num_updates=100, lr=1.73611e-05, gnorm=0.01, clip=0, loss_scale=128, train_wall=28, gb_free=5.8, wall=859
2024-11-21 01:55:46 - progress_bar.py[line:274] - INFO: epoch 003:     14 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.753, ntokens=8843.2, nsentences=508.5, sample_size=508.5, sample_size_v1=0, sample_size_v2=0, ppl=6.74, wps=2977.2, ups=0.34, wpb=8843.2, bsz=508.5, num_updates=110, lr=1.90972e-05, gnorm=0.01, clip=0, loss_scale=128, train_wall=29, gb_free=5.8, wall=888
2024-11-21 01:56:16 - progress_bar.py[line:274] - INFO: epoch 003:     24 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.765, ntokens=8906.6, nsentences=512, sample_size=512, sample_size_v1=0, sample_size_v2=0, ppl=6.8, wps=2962.9, ups=0.33, wpb=8906.6, bsz=512, num_updates=120, lr=2.08333e-05, gnorm=0.01, clip=0, loss_scale=128, train_wall=29, gb_free=5.8, wall=919
2024-11-21 01:56:45 - progress_bar.py[line:274] - INFO: epoch 003:     34 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.773, ntokens=8969.9, nsentences=512, sample_size=512, sample_size_v1=0, sample_size_v2=0, ppl=6.83, wps=3023.6, ups=0.34, wpb=8969.9, bsz=512, num_updates=130, lr=2.25694e-05, gnorm=0.01, clip=0, loss_scale=128, train_wall=29, gb_free=5.8, wall=948
2024-11-21 01:57:15 - progress_bar.py[line:274] - INFO: epoch 003:     44 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.772, ntokens=9007.1, nsentences=512, sample_size=512, sample_size_v1=0, sample_size_v2=0, ppl=6.83, wps=3049.3, ups=0.34, wpb=9007.1, bsz=512, num_updates=140, lr=2.43056e-05, gnorm=0.007, clip=0, loss_scale=128, train_wall=29, gb_free=5.8, wall=978
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_3.ptcp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_3.ptcp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt


2024-11-21 01:57:26 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 144 updates
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
2024-11-21 01:57:26 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 2 row count 3052 total row count 24413
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 5 row count 3051 total row count 24413
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 3 row count 3052 total row count 24413
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 7 row count 3051 total row count 24413
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 4 row count 3052 total row count 24413
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 1 row count 3052 total row count 24413
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 6 row count 3051 total row count 24413
slice_id 5 seek offset 15260
slice_id 2 seek offset 6104
slice_id 3 seek offset 9156
slice_id 7 seek offset 21362
slice_id 1 seek offset 3052
slice_id 4 seek offset 12208
slice_id 6 seek offset 18311
2024-11-21 01:59:00 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_best.pt
2024-11-21 02:00:48 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 3 @ 144 updates, score 0) (writing took 202.24672822281718 seconds)
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
2024-11-21 02:01:39 - train.py[line:336] - INFO: end of epoch 3 (average epoch stats below)
2024-11-21 02:01:39 - progress_bar.py[line:282] - INFO: epoch 003 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.76 | ntokens 8861.71 | nsentences 508.604 | sample_size 508.604 | sample_size_v1 0 | sample_size_v2 0 | ppl 6.78 | wps 1042.3 | ups 0.12 | wpb 8861.7 | bsz 508.6 | num_updates 144 | lr 2.5e-05 | gnorm 0.009 | clip 0 | loss_scale 128 | train_wall 139 | gb_free 5.7 | wall 1242
2024-11-21 02:01:39 - trainer.py[line:639] - INFO: loading train data for epoch 4
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 0 row count 3052 total row count 24413
slice_id 0 seek offset 0
2024-11-21 02:01:50 - trainer.py[line:703] - INFO: begin training epoch 4
2024-11-21 02:01:50 - train.py[line:297] - INFO: Start iterating over samples
2024-11-21 02:02:10 - progress_bar.py[line:274] - INFO: epoch 004:      6 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.74, ntokens=8445.6, nsentences=495.7, sample_size=495.7, sample_size_v1=0, sample_size_v2=0, ppl=6.68, wps=286.1, ups=0.03, wpb=8445.6, bsz=495.7, num_updates=150, lr=2.60417e-05, gnorm=0.012, clip=0, loss_scale=128, train_wall=28, gb_free=5.8, wall=1273
2024-11-21 02:02:41 - progress_bar.py[line:274] - INFO: epoch 004:     16 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.784, ntokens=9053.1, nsentences=512, sample_size=512, sample_size_v1=0, sample_size_v2=0, ppl=6.89, wps=2943.2, ups=0.33, wpb=9053.1, bsz=512, num_updates=160, lr=2.77778e-05, gnorm=0.012, clip=0, loss_scale=128, train_wall=29, gb_free=5.7, wall=1304
2024-11-21 02:03:12 - progress_bar.py[line:274] - INFO: epoch 004:     26 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.813, ntokens=9094.3, nsentences=512, sample_size=512, sample_size_v1=0, sample_size_v2=0, ppl=7.03, wps=2927.9, ups=0.32, wpb=9094.3, bsz=512, num_updates=170, lr=2.95139e-05, gnorm=0.016, clip=0, loss_scale=128, train_wall=30, gb_free=5.8, wall=1335
2024-11-21 02:03:42 - progress_bar.py[line:274] - INFO: epoch 004:     36 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.826, ntokens=9150.5, nsentences=512, sample_size=512, sample_size_v1=0, sample_size_v2=0, ppl=7.09, wps=3081.9, ups=0.34, wpb=9150.5, bsz=512, num_updates=180, lr=3.125e-05, gnorm=0.013, clip=0, loss_scale=128, train_wall=30, gb_free=5.7, wall=1364
2024-11-21 02:04:11 - progress_bar.py[line:274] - INFO: epoch 004:     46 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.72, ntokens=8802.6, nsentences=512, sample_size=512, sample_size_v1=0, sample_size_v2=0, ppl=6.59, wps=2996, ups=0.34, wpb=8802.6, bsz=512, num_updates=190, lr=3.29861e-05, gnorm=0.014, clip=0, loss_scale=128, train_wall=29, gb_free=5.7, wall=1394
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_4.ptcp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt

cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt
2024-11-21 02:04:16 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 192 updates
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt
2024-11-21 02:04:16 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 5 row count 3051 total row count 24413file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 3 row count 3052 total row count 24413file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 2 row count 3052 total row count 24413


local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 1 row count 3052 total row count 24413
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 7 row count 3051 total row count 24413
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 4 row count 3052 total row count 24413
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 6 row count 3051 total row count 24413
slice_id 5 seek offset 15260
slice_id 2 seek offset 6104
slice_id 3 seek offset 9156
slice_id 7 seek offset 21362
slice_id 1 seek offset 3052
slice_id 4 seek offset 12208
slice_id 6 seek offset 18311
2024-11-21 02:06:00 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_best.pt
2024-11-21 02:07:50 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 4 @ 192 updates, score 0) (writing took 213.63798567419872 seconds)
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt
2024-11-21 02:08:43 - train.py[line:336] - INFO: end of epoch 4 (average epoch stats below)
2024-11-21 02:08:43 - progress_bar.py[line:282] - INFO: epoch 004 | loss 0.001 | loss_v1 0 | loss_v2 0 | nll_loss 2.783 | ntokens 8926.98 | nsentences 508.604 | sample_size 508.604 | sample_size_v1 0 | sample_size_v2 0 | ppl 6.88 | wps 1011.1 | ups 0.11 | wpb 8927 | bsz 508.6 | num_updates 192 | lr 3.33333e-05 | gnorm 0.014 | clip 0 | loss_scale 128 | train_wall 140 | gb_free 5.8 | wall 1666
2024-11-21 02:08:43 - trainer.py[line:639] - INFO: loading train data for epoch 5
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 0 row count 3052 total row count 24413
slice_id 0 seek offset 0
2024-11-21 02:08:55 - trainer.py[line:703] - INFO: begin training epoch 5
2024-11-21 02:08:55 - train.py[line:297] - INFO: Start iterating over samples
2024-11-21 02:09:22 - progress_bar.py[line:274] - INFO: epoch 005:      8 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.802, ntokens=8731, nsentences=499.2, sample_size=499.2, sample_size_v1=0, sample_size_v2=0, ppl=6.97, wps=281.1, ups=0.03, wpb=8731, bsz=499.2, num_updates=200, lr=3.47222e-05, gnorm=0.016, clip=0, loss_scale=128, train_wall=28, gb_free=5.7, wall=1704
2024-11-21 02:09:53 - progress_bar.py[line:274] - INFO: epoch 005:     18 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.824, ntokens=9095.4, nsentences=512, sample_size=512, sample_size_v1=0, sample_size_v2=0, ppl=7.08, wps=2857.8, ups=0.31, wpb=9095.4, bsz=512, num_updates=210, lr=3.64583e-05, gnorm=0.016, clip=0, loss_scale=128, train_wall=29, gb_free=5.7, wall=1736
2024-11-21 02:10:23 - progress_bar.py[line:274] - INFO: epoch 005:     28 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.814, ntokens=9007.7, nsentences=512, sample_size=512, sample_size_v1=0, sample_size_v2=0, ppl=7.03, wps=3046.7, ups=0.34, wpb=9007.7, bsz=512, num_updates=220, lr=3.81944e-05, gnorm=0.016, clip=0, loss_scale=128, train_wall=29, gb_free=5.7, wall=1766
2024-11-21 02:10:53 - progress_bar.py[line:274] - INFO: epoch 005:     38 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.823, ntokens=8990.4, nsentences=508.5, sample_size=508.5, sample_size_v1=0, sample_size_v2=0, ppl=7.07, wps=3036.2, ups=0.34, wpb=8990.4, bsz=508.5, num_updates=230, lr=3.99306e-05, gnorm=0.016, clip=0, loss_scale=128, train_wall=28, gb_free=5.7, wall=1795
2024-11-21 02:11:22 - progress_bar.py[line:274] - INFO: epoch 005:     48 / 48 loss=0.001, loss_v1=0, loss_v2=0, nll_loss=2.743, ntokens=8563.4, nsentences=499.2, sample_size=499.2, sample_size_v1=0, sample_size_v2=0, ppl=6.69, wps=2952.2, ups=0.34, wpb=8563.4, bsz=499.2, num_updates=240, lr=4.16667e-05, gnorm=0.011, clip=0, loss_scale=128, train_wall=29, gb_free=5.7, wall=1824
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_5.ptcp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt

cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt
2024-11-21 02:11:22 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 240 updates
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt
2024-11-21 02:11:22 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_best.pt
cp ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt
cp: cannot create regular file './polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt': File exists
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 1 row count 3052 total row count 24413
slice_id 1 seek offset 3052
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping

local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 3 row count 3052 total row count 24413
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 2 row count 3052 total row count 24413
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 5 row count 3051 total row count 24413
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 4 row count 3052 total row count 24413
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 7 row count 3051 total row count 24413
local datafile ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_indoor_train_1120/aihub_indoor_train.tsv slice_id 6 row count 3051 total row count 24413
slice_id 3 seek offset 9156
slice_id 2 seek offset 6104
slice_id 5 seek offset 15260
slice_id 7 seek offset 21362
slice_id 4 seek offset 12208
slice_id 6 seek offset 18311
2024-11-21 02:13:01 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_indoor_80_unique_resume_checkpoints/100_5e-5_512/checkpoint_best.pt
WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3952516 closing signal SIGINT
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3952517 closing signal SIGINT
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3952518 closing signal SIGINT
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3952519 closing signal SIGINT
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3952520 closing signal SIGINT
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3952521 closing signal SIGINT
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3952522 closing signal SIGINT
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3952523 closing signal SIGINT
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3952516 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3952517 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3952518 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3952519 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3952520 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3952521 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3952522 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3952523 closing signal SIGTERM
Traceback (most recent call last):
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 850, in _invoke_run
    time.sleep(monitor_interval)
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 3952415 got signal: 2

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 716, in run
    self._shutdown(e.sigval)
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py", line 289, in _shutdown
    self._pcontext.close(death_sig)
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 332, in close
    self._close(death_sig=death_sig, timeout=timeout)
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 709, in _close
    handler.proc.wait(time_to_wait)
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/subprocess.py", line 1019, in wait
    return self._wait(timeout=timeout)
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/subprocess.py", line 1647, in _wait
    time.sleep(delay)
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 3952415 got signal: 2

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    result = agent.run()
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 721, in run
    self._shutdown()
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py", line 289, in _shutdown
    self._pcontext.close(death_sig)
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 332, in close
    self._close(death_sig=death_sig, timeout=timeout)
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 709, in _close
    handler.proc.wait(time_to_wait)
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/subprocess.py", line 1019, in wait
    return self._wait(timeout=timeout)
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/subprocess.py", line 1647, in _wait
    time.sleep(delay)
  File "/home/sangbeom_lee/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 3952415 got signal: 2
