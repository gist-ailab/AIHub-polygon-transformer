/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/distributed/launch.py:188: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  FutureWarning,
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2024-11-07 03:49:02 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-07 03:49:02 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-07 03:49:02 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-07 03:49:02 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-07 03:49:02 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-07 03:49:02 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-07 03:49:02 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-07 03:49:02 - file_utils.py[line:39] - INFO: PyTorch version 1.13.1+cu116 available.
2024-11-07 03:49:04 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2024-11-07 03:49:04 - utils.py[line:261] - INFO: Start init
2024-11-07 03:49:04 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2024-11-07 03:49:04 - utils.py[line:258] - INFO: distributed init (rank 5): env://
2024-11-07 03:49:04 - utils.py[line:261] - INFO: Start init
2024-11-07 03:49:04 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 5
2024-11-07 03:49:04 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2024-11-07 03:49:04 - utils.py[line:261] - INFO: Start init
2024-11-07 03:49:04 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2024-11-07 03:49:04 - utils.py[line:258] - INFO: distributed init (rank 3): env://
2024-11-07 03:49:04 - utils.py[line:261] - INFO: Start init
2024-11-07 03:49:04 - utils.py[line:258] - INFO: distributed init (rank 2): env://
2024-11-07 03:49:04 - utils.py[line:261] - INFO: Start init
2024-11-07 03:49:04 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 3
2024-11-07 03:49:04 - utils.py[line:258] - INFO: distributed init (rank 4): env://
2024-11-07 03:49:04 - utils.py[line:261] - INFO: Start init
2024-11-07 03:49:04 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 2
2024-11-07 03:49:04 - utils.py[line:258] - INFO: distributed init (rank 7): env://
2024-11-07 03:49:04 - utils.py[line:261] - INFO: Start init
2024-11-07 03:49:04 - utils.py[line:258] - INFO: distributed init (rank 6): env://
2024-11-07 03:49:04 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 4
2024-11-07 03:49:04 - utils.py[line:261] - INFO: Start init
2024-11-07 03:49:04 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 7
2024-11-07 03:49:04 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:1 to store for rank: 6
2024-11-07 03:49:04 - distributed_c10d.py[line:354] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-07 03:49:04 - distributed_c10d.py[line:354] - INFO: Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-07 03:49:04 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 1
single-machine distributed training is initialized.
2024-11-07 03:49:04 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 6
single-machine distributed training is initialized.
2024-11-07 03:49:04 - distributed_c10d.py[line:354] - INFO: Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-07 03:49:04 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 5
single-machine distributed training is initialized.
2024-11-07 03:49:04 - distributed_c10d.py[line:354] - INFO: Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-07 03:49:04 - distributed_c10d.py[line:354] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-07 03:49:04 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 3
single-machine distributed training is initialized.
2024-11-07 03:49:04 - distributed_c10d.py[line:354] - INFO: Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-07 03:49:04 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 0
single-machine distributed training is initialized.
2024-11-07 03:49:04 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 2
single-machine distributed training is initialized.
2024-11-07 03:49:04 - distributed_c10d.py[line:354] - INFO: Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-07 03:49:04 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 4
single-machine distributed training is initialized.
2024-11-07 03:49:04 - distributed_c10d.py[line:354] - INFO: Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2024-11-07 03:49:04 - utils.py[line:274] - INFO: initialized host ip-172-31-11-84 as rank 7
single-machine distributed training is initialized.
2024-11-07 03:49:08 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../polyformer_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 500, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512', 'restore_file': '../pretrain/polyformer_b_pretrain_aihub_manufact_80_checkpoints/20_5e-5_512/checkpoint.best_score_0.4980.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 500, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'score', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='polyformer_b', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='polyformer_b', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=16, batch_size_valid=16, best_checkpoint_metric='score', bf16=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, cls_weight=0.0005, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv,../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, det_weight=0.1, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_acc=True, eval_args='{"beam":5,"min_len":2,"max_len_a":0,"max_len_b":2}', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=100, max_image_size=512, max_source_positions=1024, max_src_length=80, max_target_positions=1024, max_tgt_length=420, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=8, num_bins=64, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', out_index=3, pad=1, patch_image_size=512, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, restore_file='../pretrain/polyformer_b_pretrain_aihub_manufact_80_checkpoints/20_5e-5_512/checkpoint.best_score_0.4980.pt', sample_patch_num=196, save_dir='./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512', save_interval=1, save_interval_updates=500, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', scst=False, scst_args='{}', seed=1, selected_cols='0,5,6,2,4,3,7', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='refcoco', tensorboard_logdir=None, threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[8], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../polyformer_module', uses_ema=False, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=500, vis_encoder_type='swin-base', wandb_project=None, warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'refcoco', 'data': '../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv,../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv', 'selected_cols': '0,5,6,2,4,3,7', 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 80, 'max_tgt_length': 420, 'code_dict_size': 8192, 'patch_image_size': 512, 'num_bins': 64, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': True, 'eval_args': '{"beam":5,"min_len":2,"max_len_a":0,"max_len_b":2}', 'uses_ema': False, 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'det_weight': 0.1, 'cls_weight': 0.0005, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2024-11-07 03:49:08 - base_task.py[line:187] - INFO: source dictionary: 4100 types
2024-11-07 03:49:08 - base_task.py[line:188] - INFO: target dictionary: 4100 types
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
The model and loaded state dict do not match exactly

unexpected key in source state_dict: norm.weight, norm.bias, head.weight, head.bias, layers.0.blocks.1.attn_mask, layers.1.blocks.1.attn_mask, layers.2.blocks.1.attn_mask, layers.2.blocks.3.attn_mask, layers.2.blocks.5.attn_mask, layers.2.blocks.7.attn_mask, layers.2.blocks.9.attn_mask, layers.2.blocks.11.attn_mask, layers.2.blocks.13.attn_mask, layers.2.blocks.15.attn_mask, layers.2.blocks.17.attn_mask

missing keys in source state_dict: norm3.weight, norm3.bias

Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
Loaded Swin Pretrained Weights ../../pretrained_weights/swin_base_patch4_window12_384_22k.pth
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
The model and loaded state dict do not match exactly

unexpected key in source state_dict: norm.weight, norm.bias, head.weight, head.bias, layers.0.blocks.1.attn_mask, layers.1.blocks.1.attn_mask, layers.2.blocks.1.attn_mask, layers.2.blocks.3.attn_mask, layers.2.blocks.5.attn_mask, layers.2.blocks.7.attn_mask, layers.2.blocks.9.attn_mask, layers.2.blocks.11.attn_mask, layers.2.blocks.13.attn_mask, layers.2.blocks.15.attn_mask, layers.2.blocks.17.attn_mask

missing keys in source state_dict: norm3.weight, norm3.bias

2024-11-07 03:49:22 - train.py[line:101] - INFO: PolyFormerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(4100, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): SwinTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (pos_drop): Dropout(p=0.0, inplace=False)
      (layers): ModuleList(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): Identity()
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.009)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=512, out_features=256, bias=False)
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=256, out_features=256, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.017)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=256, out_features=1024, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1024, out_features=256, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=256, out_features=256, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.026)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=256, out_features=1024, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1024, out_features=256, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=1024, out_features=512, bias=False)
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.035)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.043)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (2): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.052)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (3): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.061)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (4): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.070)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (5): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.078)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (6): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.087)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (7): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.096)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (8): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.104)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (9): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.113)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (10): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.122)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (11): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.130)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (12): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.139)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (13): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.148)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (14): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.157)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (15): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.165)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (16): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.174)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (17): SwinTransformerBlock(
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.183)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=2048, out_features=1024, bias=False)
            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.191)
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.200)
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
      )
      (norm3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
    (bert): XLMRobertaForMaskedLM(
      (roberta): XLMRobertaModel(
        (embeddings): XLMRobertaEmbeddings(
          (word_embeddings): Embedding(250002, 768, padding_idx=1)
          (position_embeddings): Embedding(514, 768, padding_idx=1)
          (token_type_embeddings): Embedding(1, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): XLMRobertaEncoder(
          (layer): ModuleList(
            (0): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): XLMRobertaLayer(
              (attention): XLMRobertaAttention(
                (self): XLMRobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): XLMRobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): XLMRobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): XLMRobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
      )
      (lm_head): XLMRobertaLMHead(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (decoder): Linear(in_features=768, out_features=250002, bias=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(4100, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (reg_head): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): Linear(in_features=768, out_features=768, bias=True)
        (2): Linear(in_features=768, out_features=2, bias=True)
      )
    )
    (cls_head): Linear(in_features=768, out_features=3, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2024-11-07 03:49:22 - train.py[line:102] - INFO: task: RefcocoTask
2024-11-07 03:49:22 - train.py[line:103] - INFO: model: PolyFormerModel
2024-11-07 03:49:22 - train.py[line:104] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2024-11-07 03:49:22 - train.py[line:108] - INFO: num. shared model params: 478,547,732 (num. trained: 478,547,732)
2024-11-07 03:49:22 - train.py[line:115] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 3 row count 6955 total row count 55640
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 1 row count 6955 total row count 55640file ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 7 row count 6955 total row count 55640file ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 0 row count 6955 total row count 55640


local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 4 row count 6955 total row count 55640
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 2 row count 6955 total row count 55640
file ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 5 row count 6955 total row count 55640
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_val.tsv slice_id 6 row count 6955 total row count 55640
2024-11-07 03:49:44 - distributed_c10d.py[line:319] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2024-11-07 03:49:45 - distributed_c10d.py[line:354] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-11-07 03:49:45 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2024-11-07 03:49:45 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.layers.0.downsample.reduction.bias <- encoder.embed_images.layers.1.downsample.reduction.bias
2024-11-07 03:49:45 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.layers.0.downsample.reduction.bias <- encoder.embed_images.layers.2.downsample.reduction.bias
2024-11-07 03:49:45 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.layers.0.downsample.reduction.bias <- decoder.cls_head.bias
2024-11-07 03:49:45 - trainer.py[line:124] - INFO: detected shared parameter: encoder.bert.roberta.embeddings.word_embeddings.weight <- encoder.bert.lm_head.decoder.weight
2024-11-07 03:49:45 - trainer.py[line:124] - INFO: detected shared parameter: encoder.bert.lm_head.bias <- encoder.bert.lm_head.decoder.bias
2024-11-07 03:49:47 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 8 workers***********************
2024-11-07 03:49:47 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-07 03:49:47 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-07 03:49:47 - utils.py[line:765] - INFO: rank   2: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-07 03:49:47 - utils.py[line:765] - INFO: rank   3: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-07 03:49:47 - utils.py[line:765] - INFO: rank   4: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-07 03:49:47 - utils.py[line:765] - INFO: rank   5: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-07 03:49:47 - utils.py[line:765] - INFO: rank   6: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-07 03:49:47 - utils.py[line:765] - INFO: rank   7: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
2024-11-07 03:49:47 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 8 workers***********************
2024-11-07 03:49:47 - train.py[line:145] - INFO: training on 8 devices (GPUs/TPUs)
2024-11-07 03:49:47 - train.py[line:151] - INFO: max tokens per device = None and max sentences per device = 16
2024-11-07 03:49:47 - trainer.py[line:458] - INFO: Preparing to load checkpoint ../pretrain/polyformer_b_pretrain_aihub_manufact_80_checkpoints/20_5e-5_512/checkpoint.best_score_0.4980.pt
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
2024-11-07 03:49:58 - trainer.py[line:619] - INFO: Loaded checkpoint ../pretrain/polyformer_b_pretrain_aihub_manufact_80_checkpoints/20_5e-5_512/checkpoint.best_score_0.4980.pt (epoch 20 @ 0 updates)
2024-11-07 03:49:58 - trainer.py[line:639] - INFO: loading train data for epoch 1
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
slice_id 5 seek offset 250000
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000

local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000

/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
slice_id 6 seek offset 300000
slice_id 4 seek offset 200000
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000

file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000
slice_id 7 seek offset 350000
slice_id 3 seek offset 150000
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torchvision/transforms/functional.py:443: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  "Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. "
slice_id 2 seek offset 100000
slice_id 1 seek offset 50000
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
slice_id 0 seek offset 0
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
Total steps 39100, warmup steps 2346, warmup_factor 0.00042625745950554135
2024-11-07 03:52:41 - trainer.py[line:703] - INFO: begin training epoch 1
2024-11-07 03:52:41 - train.py[line:297] - INFO: Start iterating over samples
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/ubuntu/anaconda3/envs/polyformer/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
loss_reg: 0.3977091073167286 loss_cls: 0.011207920499145985
loss_reg: 0.36102111555514227 loss_cls: 0.008432662114501
loss_reg: 0.3659482435985721 loss_cls: 0.011590862646698952
loss_reg: 0.40414460153298293 loss_cls: 0.010221962817013264
loss_reg: 0.3992227223160886 loss_cls: 0.011034611612558365
loss_reg: 0.12776814955705784 loss_cls: 0.009030530229210854
loss_reg: 0.397620823524556 loss_cls: 0.010044220834970474
loss_reg: 0.3436609833096163 loss_cls: 0.014174502342939377
loss_reg: 0.34072814757152153 loss_cls: 0.013733647763729095
loss_reg: 0.3751142060351273 loss_cls: 0.01454905141144991
loss_reg: 0.1033040109244737 loss_cls: 0.008840864524245262
loss_reg: 0.3059362593536628 loss_cls: 0.012865675613284111
loss_reg: 0.3873861934686729 loss_cls: 0.014050877653062344
loss_reg: 0.330013615158273 loss_cls: 0.008872412145137787
loss_reg: 0.28083771322726864 loss_cls: 0.008129016496241093
loss_reg: 0.36615990072163 loss_cls: 0.013098638504743576
loss_reg: 0.42926307327699054 loss_cls: 0.012041449546813965
loss_reg: 0.3974993785701384 loss_cls: 0.010014061816036701
loss_reg: 0.10808560299420962 loss_cls: 0.008410517126321793
loss_reg: 0.3483265163529442 loss_cls: 0.01362575776875019
loss_reg: 0.3410682527623609 loss_cls: 0.010380369611084461
loss_reg: 0.31725091620140383 loss_cls: 0.009255710989236832
loss_reg: 0.3375077907095839 loss_cls: 0.009613128378987312
loss_reg: 0.3194472806975795 loss_cls: 0.01042796578258276
loss_reg: 0.28734452167930136 loss_cls: 0.009594316594302654
loss_reg: 0.32506921004403466 loss_cls: 0.011178459972143173
loss_reg: 0.3466766482980053 loss_cls: 0.005753102712333202
loss_reg: 0.1110948166951431 loss_cls: 0.008790903724730015
loss_reg: 0.34166236751649565 loss_cls: 0.00943810399621725
loss_reg: 0.3252306742838178 loss_cls: 0.007585520856082439
loss_reg: 0.33559849392962043 loss_cls: 0.014350993558764458
loss_reg: 0.30780160064696105 loss_cls: 0.010498312301933765
loss_reg: 0.25552591388664164 loss_cls: 0.010789147578179836
loss_reg: 0.3323987143947288 loss_cls: 0.014300311915576458
loss_reg: 0.35805291699707076 loss_cls: 0.014479395933449268
loss_reg: 0.12645976553117527 loss_cls: 0.011551731266081333
loss_reg: 0.3515741016843843 loss_cls: 0.010200627148151398
loss_reg: 0.37713995475018497 loss_cls: 0.012143791653215885
loss_reg: 0.36451311779706674 loss_cls: 0.00949885230511427
loss_reg: 0.3652265786048845 loss_cls: 0.011390489526093006
loss_reg: 0.40701820874289685 loss_cls: 0.009534839540719986
loss_reg: 0.2867527895314106 loss_cls: 0.009989197365939617
loss_reg: 0.10005091385957973 loss_cls: 0.010042562149465084
loss_reg: 0.3687750068970539 loss_cls: 0.014218823984265327
loss_reg: 0.34608525678801894 loss_cls: 0.016426049172878265
loss_reg: 0.387080502091767 loss_cls: 0.00909595936536789
loss_reg: 0.39374707652537494 loss_cls: 0.008176208473742008
loss_reg: 0.35929305420831004 loss_cls: 0.01025272998958826
loss_reg: 0.3225347412891489 loss_cls: 0.010904733091592789
loss_reg: 0.411494124332507 loss_cls: 0.017676519230008125
loss_reg: 0.13646483675045715 loss_cls: 0.01094895601272583
loss_reg: 0.3124420250399511 loss_cls: 0.012744979932904243
loss_reg: 0.3426326453805473 loss_cls: 0.011134658008813858
loss_reg: 0.350518995264716 loss_cls: 0.006630134768784046
loss_reg: 0.3161635480520825 loss_cls: 0.008819271810352802
loss_reg: 0.3697117669004861 loss_cls: 0.009494295343756676
loss_reg: 0.3289472645558596 loss_cls: 0.007596579845994711
loss_reg: 0.357074597122021 loss_cls: 0.012098364531993866
loss_reg: 0.06936681786385841 loss_cls: 0.009038225747644901
loss_reg: 0.2759805479901225 loss_cls: 0.010288569144904613
loss_reg: 0.37552321793842913 loss_cls: 0.017154542729258537
loss_reg: 0.34872697707570877 loss_cls: 0.010856518521904945
loss_reg: 0.35927887358941996 loss_cls: 0.01577123999595642
loss_reg: 0.3829147089775387 loss_cls: 0.01200323086231947
2024-11-07 03:53:40 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 391 loss=0.021, loss_v1=0, loss_v2=0, nll_loss=22.66, ntokens=17540.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=6.62685e+06, wps=3314.2, ups=0.19, wpb=17540.3, bsz=1024, num_updates=10, lr=2.13129e-07, gnorm=0.078, clip=0, loss_scale=128, train_wall=36, gb_free=13.4, wall=233
2024-11-07 03:54:34 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 391 loss=0.02, loss_v1=0, loss_v2=0, nll_loss=21.937, ntokens=17260.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.01446e+06, wps=3206.8, ups=0.19, wpb=17260.7, bsz=1024, num_updates=20, lr=4.26257e-07, gnorm=0.08, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=287
2024-11-07 03:55:28 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 391 loss=0.019, loss_v1=0, loss_v2=0, nll_loss=21.397, ntokens=17251.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=2.76114e+06, wps=3200.9, ups=0.19, wpb=17251.5, bsz=1024, num_updates=30, lr=6.39386e-07, gnorm=0.115, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=341
2024-11-07 03:56:22 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 391 loss=0.014, loss_v1=0, loss_v2=0, nll_loss=20.492, ntokens=17478.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=1.47514e+06, wps=3219.3, ups=0.18, wpb=17478.8, bsz=1024, num_updates=40, lr=8.52515e-07, gnorm=0.19, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=395
2024-11-07 03:57:16 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 391 loss=0.009, loss_v1=0, loss_v2=0, nll_loss=18.376, ntokens=17533.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=340123, wps=3248.7, ups=0.19, wpb=17533.4, bsz=1024, num_updates=50, lr=1.06564e-06, gnorm=0.092, clip=0, loss_scale=128, train_wall=30, gb_free=13.4, wall=449
2024-11-07 03:58:10 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 391 loss=0.007, loss_v1=0, loss_v2=0, nll_loss=16.603, ntokens=17189.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=99516.8, wps=3174, ups=0.18, wpb=17189.2, bsz=1024, num_updates=60, lr=1.27877e-06, gnorm=0.03, clip=0, loss_scale=128, train_wall=30, gb_free=13.2, wall=503
2024-11-07 03:59:04 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 391 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=15.083, ntokens=17125.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=34715.8, wps=3190.2, ups=0.19, wpb=17125.8, bsz=1024, num_updates=70, lr=1.4919e-06, gnorm=0.019, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=557
2024-11-07 03:59:58 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 391 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=13.575, ntokens=17101.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12202.2, wps=3158.4, ups=0.18, wpb=17101.4, bsz=1024, num_updates=80, lr=1.70503e-06, gnorm=0.015, clip=0, loss_scale=128, train_wall=30, gb_free=13.2, wall=611
2024-11-07 04:00:52 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 391 loss=0.006, loss_v1=0, loss_v2=0, nll_loss=12.356, ntokens=17305.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=5242.19, wps=3210.2, ups=0.19, wpb=17305.5, bsz=1024, num_updates=90, lr=1.91816e-06, gnorm=0.012, clip=0, loss_scale=128, train_wall=31, gb_free=13.5, wall=665
2024-11-07 04:01:46 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 391 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=11.11, ntokens=17447.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=2210.68, wps=3234.2, ups=0.19, wpb=17447.2, bsz=1024, num_updates=100, lr=2.13129e-06, gnorm=0.01, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=719
2024-11-07 04:02:39 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 391 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=9.878, ntokens=17243, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=941.15, wps=3223.6, ups=0.19, wpb=17243, bsz=1024, num_updates=110, lr=2.34442e-06, gnorm=0.01, clip=0, loss_scale=128, train_wall=30, gb_free=13.4, wall=773
2024-11-07 04:03:33 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 391 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=8.791, ntokens=17360.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=443.06, wps=3229.3, ups=0.19, wpb=17360.4, bsz=1024, num_updates=120, lr=2.55754e-06, gnorm=0.008, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=826
2024-11-07 04:04:27 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 391 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=7.996, ntokens=17477.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=255.38, wps=3248.9, ups=0.19, wpb=17477.1, bsz=1024, num_updates=130, lr=2.77067e-06, gnorm=0.007, clip=0, loss_scale=128, train_wall=30, gb_free=13.2, wall=880
2024-11-07 04:05:20 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 391 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=7.339, ntokens=17116.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=161.93, wps=3201.3, ups=0.19, wpb=17116.8, bsz=1024, num_updates=140, lr=2.9838e-06, gnorm=0.006, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=934
2024-11-07 04:06:14 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 391 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=6.659, ntokens=16833.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=101.08, wps=3121.3, ups=0.19, wpb=16833.8, bsz=1024, num_updates=150, lr=3.19693e-06, gnorm=0.006, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=988
2024-11-07 04:07:07 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 391 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=6.544, ntokens=17365.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=93.33, wps=3263.5, ups=0.19, wpb=17365.6, bsz=1024, num_updates=160, lr=3.41006e-06, gnorm=0.005, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=1041
2024-11-07 04:08:01 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 391 loss=0.005, loss_v1=0, loss_v2=0, nll_loss=6.203, ntokens=17362, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=73.69, wps=3228.4, ups=0.19, wpb=17362, bsz=1024, num_updates=170, lr=3.62319e-06, gnorm=0.005, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=1095
2024-11-07 04:08:55 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 391 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=5.99, ntokens=17273, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=63.57, wps=3215.7, ups=0.19, wpb=17273, bsz=1024, num_updates=180, lr=3.83632e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=1148
2024-11-07 04:09:48 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 391 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=5.751, ntokens=17160.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=53.84, wps=3227.5, ups=0.19, wpb=17160.1, bsz=1024, num_updates=190, lr=4.04945e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.4, wall=1201
2024-11-07 04:10:41 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 391 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=5.64, ntokens=17197.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=49.86, wps=3211.6, ups=0.19, wpb=17197.6, bsz=1024, num_updates=200, lr=4.26257e-06, gnorm=0.005, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=1255
2024-11-07 04:11:35 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 391 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=5.527, ntokens=17104.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=46.09, wps=3203.5, ups=0.19, wpb=17104.6, bsz=1024, num_updates=210, lr=4.4757e-06, gnorm=0.006, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=1308
2024-11-07 04:12:28 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 391 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=5.528, ntokens=17212.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=46.16, wps=3244.6, ups=0.19, wpb=17212.7, bsz=1024, num_updates=220, lr=4.68883e-06, gnorm=0.007, clip=0, loss_scale=128, train_wall=30, gb_free=13.1, wall=1361
2024-11-07 04:13:21 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 391 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=5.617, ntokens=17548.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=49.08, wps=3281.7, ups=0.19, wpb=17548.1, bsz=1024, num_updates=230, lr=4.90196e-06, gnorm=0.011, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=1415
2024-11-07 04:14:15 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 391 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=5.79, ntokens=17237.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=55.34, wps=3231.6, ups=0.19, wpb=17237.3, bsz=1024, num_updates=240, lr=5.11509e-06, gnorm=0.017, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=1468
2024-11-07 04:15:09 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 391 loss=0.004, loss_v1=0, loss_v2=0, nll_loss=5.993, ntokens=17724.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=63.67, wps=3293.6, ups=0.19, wpb=17724.1, bsz=1024, num_updates=250, lr=5.32822e-06, gnorm=0.006, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=1522
2024-11-07 04:16:02 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=5.768, ntokens=17418.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=54.48, wps=3244.9, ups=0.19, wpb=17418.1, bsz=1024, num_updates=260, lr=5.54135e-06, gnorm=0.005, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=1576
2024-11-07 04:16:57 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=5.628, ntokens=17186.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=49.46, wps=3157.4, ups=0.18, wpb=17186.2, bsz=1024, num_updates=270, lr=5.75448e-06, gnorm=0.005, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=1630
2024-11-07 04:17:50 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=5.575, ntokens=17241.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=47.67, wps=3234.7, ups=0.19, wpb=17241.2, bsz=1024, num_updates=280, lr=5.9676e-06, gnorm=0.005, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=1683
2024-11-07 04:18:44 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=5.496, ntokens=17176.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=45.13, wps=3200.2, ups=0.19, wpb=17176.9, bsz=1024, num_updates=290, lr=6.18073e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=12.8, wall=1737
2024-11-07 04:19:37 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=5.434, ntokens=17101.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=43.22, wps=3219.4, ups=0.19, wpb=17101.7, bsz=1024, num_updates=300, lr=6.39386e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=1790
2024-11-07 04:20:31 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=5.471, ntokens=17503, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=44.37, wps=3251.9, ups=0.19, wpb=17503, bsz=1024, num_updates=310, lr=6.60699e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=1844
2024-11-07 04:21:24 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=5.471, ntokens=17704.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=44.34, wps=3297.8, ups=0.19, wpb=17704.2, bsz=1024, num_updates=320, lr=6.82012e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=1898
2024-11-07 04:22:17 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=5.298, ntokens=17217.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=39.35, wps=3255.8, ups=0.19, wpb=17217.9, bsz=1024, num_updates=330, lr=7.03325e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=1951
2024-11-07 04:23:11 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=5.329, ntokens=17513.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=40.2, wps=3269.4, ups=0.19, wpb=17513.1, bsz=1024, num_updates=340, lr=7.24638e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=2004
2024-11-07 04:24:04 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=5.248, ntokens=17225, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=37.99, wps=3223.5, ups=0.19, wpb=17225, bsz=1024, num_updates=350, lr=7.45951e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=2058
2024-11-07 04:24:58 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=5.306, ntokens=17669.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=39.56, wps=3310.3, ups=0.19, wpb=17669.3, bsz=1024, num_updates=360, lr=7.67263e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=2111
2024-11-07 04:25:51 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=5.316, ntokens=17888.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=39.83, wps=3326.8, ups=0.19, wpb=17888.1, bsz=1024, num_updates=370, lr=7.88576e-06, gnorm=0.005, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=2165
2024-11-07 04:26:45 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=5.241, ntokens=17546.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=37.82, wps=3289.2, ups=0.19, wpb=17546.2, bsz=1024, num_updates=380, lr=8.09889e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=2218
2024-11-07 04:27:36 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=5.189, ntokens=17471.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=36.47, wps=3380.7, ups=0.19, wpb=17471.4, bsz=1024, num_updates=390, lr=8.31202e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=2270
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_1.ptcp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt

cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_1.ptcp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt

cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
2024-11-07 04:27:38 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 391 updates
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
2024-11-07 04:27:38 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cannot stat './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt'cp: cp: cp: cannot stat './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt': No such file or directorycannot stat './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt'cannot stat './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt'
: No such file or directory
: No such file or directory
: No such file or directory
cp: cp: cp: cannot stat './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt'cannot stat './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt'cannot stat './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt': No such file or directory
: No such file or directory: No such file or directory

local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
2024-11-07 04:27:49 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt
2024-11-07 04:28:00 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 1 @ 391 updates, score 0) (writing took 21.804202956001973 seconds)
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_1.pt
2024-11-07 04:28:05 - train.py[line:336] - INFO: end of epoch 1 (average epoch stats below)
2024-11-07 04:28:05 - progress_bar.py[line:282] - INFO: epoch 001 | loss 0.006 | loss_v1 0 | loss_v2 0 | nll_loss 8.931 | ntokens 17325.8 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 487.95 | wps 3198.6 | ups 0.18 | wpb 17325.8 | bsz 1023 | num_updates 391 | lr 8.33333e-06 | gnorm 0.021 | clip 0 | loss_scale 128 | train_wall 1191 | gb_free 13.2 | wall 2298
2024-11-07 04:28:05 - trainer.py[line:639] - INFO: loading train data for epoch 2
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000
slice_id 6 seek offset 300000
slice_id 4 seek offset 200000
slice_id 2 seek offset 100000
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping



file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000



slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
slice_id 3 seek offset 150000
slice_id 5 seek offset 250000
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-07 04:30:44 - trainer.py[line:703] - INFO: begin training epoch 2
2024-11-07 04:30:44 - train.py[line:297] - INFO: Start iterating over samples
2024-11-07 04:31:34 - progress_bar.py[line:274] - INFO: epoch 002:      9 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=5.15, ntokens=16820.5, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=35.5, wps=707.6, ups=0.04, wpb=16820.5, bsz=985.6, num_updates=400, lr=8.52515e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=29, gb_free=13.6, wall=2508
2024-11-07 04:32:27 - progress_bar.py[line:274] - INFO: epoch 002:     19 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=5.107, ntokens=17396.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=34.47, wps=3293.3, ups=0.19, wpb=17396.1, bsz=1024, num_updates=410, lr=8.73828e-06, gnorm=0.005, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=2560
2024-11-07 04:33:20 - progress_bar.py[line:274] - INFO: epoch 002:     29 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=5.069, ntokens=17345.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=33.58, wps=3268.9, ups=0.19, wpb=17345.7, bsz=1024, num_updates=420, lr=8.95141e-06, gnorm=0.005, clip=0, loss_scale=128, train_wall=30, gb_free=13.4, wall=2613
2024-11-07 04:34:13 - progress_bar.py[line:274] - INFO: epoch 002:     39 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=5.046, ntokens=17270.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=33.03, wps=3251.3, ups=0.19, wpb=17270.9, bsz=1024, num_updates=430, lr=9.16454e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=2667
2024-11-07 04:35:06 - progress_bar.py[line:274] - INFO: epoch 002:     49 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=5.118, ntokens=17754.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=34.73, wps=3358.7, ups=0.19, wpb=17754.5, bsz=1024, num_updates=440, lr=9.37766e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.6, wall=2719
2024-11-07 04:35:59 - progress_bar.py[line:274] - INFO: epoch 002:     59 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.986, ntokens=17258.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=31.68, wps=3262.8, ups=0.19, wpb=17258.4, bsz=1024, num_updates=450, lr=9.59079e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=2772
2024-11-07 04:36:52 - progress_bar.py[line:274] - INFO: epoch 002:     69 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.966, ntokens=17259.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=31.25, wps=3256.2, ups=0.19, wpb=17259.7, bsz=1024, num_updates=460, lr=9.80392e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=31, gb_free=13.3, wall=2825
2024-11-07 04:37:46 - progress_bar.py[line:274] - INFO: epoch 002:     79 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.998, ntokens=17348.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=31.96, wps=3232.4, ups=0.19, wpb=17348.2, bsz=1024, num_updates=470, lr=1.00171e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=31, gb_free=13.4, wall=2879
2024-11-07 04:38:38 - progress_bar.py[line:274] - INFO: epoch 002:     89 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.989, ntokens=17455.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=31.75, wps=3296.6, ups=0.19, wpb=17455.2, bsz=1024, num_updates=480, lr=1.02302e-05, gnorm=0.003, clip=0, loss_scale=128, train_wall=30, gb_free=12.8, wall=2932
2024-11-07 04:39:31 - progress_bar.py[line:274] - INFO: epoch 002:     99 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.979, ntokens=17548, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=31.54, wps=3315, ups=0.19, wpb=17548, bsz=1024, num_updates=490, lr=1.04433e-05, gnorm=0.004, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=2985
2024-11-07 04:40:25 - progress_bar.py[line:274] - INFO: epoch 002:    109 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.916, ntokens=17220.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=30.19, wps=3234.7, ups=0.19, wpb=17220.2, bsz=1024, num_updates=500, lr=1.06564e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=30, gb_free=13.3, wall=3038
2024-11-07 04:41:18 - progress_bar.py[line:274] - INFO: epoch 002:    119 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.965, ntokens=17522.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=31.23, wps=3285.5, ups=0.19, wpb=17522.6, bsz=1024, num_updates=510, lr=1.08696e-05, gnorm=0.005, clip=0, loss_scale=128, train_wall=30, gb_free=13.5, wall=3091
2024-11-07 04:42:11 - progress_bar.py[line:274] - INFO: epoch 002:    129 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.924, ntokens=17362.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=30.35, wps=3273.2, ups=0.19, wpb=17362.3, bsz=1024, num_updates=520, lr=1.10827e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=31, gb_free=13.6, wall=3145
2024-11-07 04:43:04 - progress_bar.py[line:274] - INFO: epoch 002:    139 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.869, ntokens=17226, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=29.22, wps=3220.4, ups=0.19, wpb=17226, bsz=1024, num_updates=530, lr=1.12958e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=3198
2024-11-07 04:43:57 - progress_bar.py[line:274] - INFO: epoch 002:    149 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.851, ntokens=17187.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=28.86, wps=3256.1, ups=0.19, wpb=17187.8, bsz=1024, num_updates=540, lr=1.1509e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=3251
2024-11-07 04:44:50 - progress_bar.py[line:274] - INFO: epoch 002:    159 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.907, ntokens=17475.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=30, wps=3305.1, ups=0.19, wpb=17475.4, bsz=1024, num_updates=550, lr=1.17221e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=3304
2024-11-07 04:45:43 - progress_bar.py[line:274] - INFO: epoch 002:    169 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.815, ntokens=17175.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=28.15, wps=3237.1, ups=0.19, wpb=17175.8, bsz=1024, num_updates=560, lr=1.19352e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.2, wall=3357
2024-11-07 04:46:36 - progress_bar.py[line:274] - INFO: epoch 002:    179 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.856, ntokens=17451.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=28.95, wps=3299.5, ups=0.19, wpb=17451.7, bsz=1024, num_updates=570, lr=1.21483e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=31, gb_free=13.5, wall=3410
2024-11-07 04:47:29 - progress_bar.py[line:274] - INFO: epoch 002:    189 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.793, ntokens=17070.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=27.72, wps=3224.7, ups=0.19, wpb=17070.6, bsz=1024, num_updates=580, lr=1.23615e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=3463
2024-11-07 04:48:22 - progress_bar.py[line:274] - INFO: epoch 002:    199 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.843, ntokens=17445, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=28.71, wps=3300.3, ups=0.19, wpb=17445, bsz=1024, num_updates=590, lr=1.25746e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=3515
2024-11-07 04:49:15 - progress_bar.py[line:274] - INFO: epoch 002:    209 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.734, ntokens=17023.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=26.61, wps=3231.6, ups=0.19, wpb=17023.5, bsz=1024, num_updates=600, lr=1.27877e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=3568
2024-11-07 04:50:07 - progress_bar.py[line:274] - INFO: epoch 002:    219 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.789, ntokens=17181.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=27.65, wps=3274.3, ups=0.19, wpb=17181.5, bsz=1024, num_updates=610, lr=1.30009e-05, gnorm=0.003, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=3621
2024-11-07 04:51:00 - progress_bar.py[line:274] - INFO: epoch 002:    229 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.791, ntokens=17304.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=27.68, wps=3253.2, ups=0.19, wpb=17304.7, bsz=1024, num_updates=620, lr=1.3214e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.2, wall=3674
2024-11-07 04:51:53 - progress_bar.py[line:274] - INFO: epoch 002:    239 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.72, ntokens=16997.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=26.35, wps=3193.6, ups=0.19, wpb=16997.3, bsz=1024, num_updates=630, lr=1.34271e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=3727
2024-11-07 04:52:46 - progress_bar.py[line:274] - INFO: epoch 002:    249 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.84, ntokens=17665.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=28.64, wps=3355.2, ups=0.19, wpb=17665.8, bsz=1024, num_updates=640, lr=1.36402e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=3780
2024-11-07 04:53:39 - progress_bar.py[line:274] - INFO: epoch 002:    259 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.727, ntokens=17233.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=26.49, wps=3272, ups=0.19, wpb=17233.4, bsz=1024, num_updates=650, lr=1.38534e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=3832
2024-11-07 04:54:32 - progress_bar.py[line:274] - INFO: epoch 002:    269 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.77, ntokens=17403.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=27.29, wps=3291.1, ups=0.19, wpb=17403.1, bsz=1024, num_updates=660, lr=1.40665e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=3885
2024-11-07 04:55:25 - progress_bar.py[line:274] - INFO: epoch 002:    279 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.729, ntokens=17183.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=26.52, wps=3234.6, ups=0.19, wpb=17183.8, bsz=1024, num_updates=670, lr=1.42796e-05, gnorm=0.003, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=3938
2024-11-07 04:56:18 - progress_bar.py[line:274] - INFO: epoch 002:    289 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.699, ntokens=17030.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=25.97, wps=3200.9, ups=0.19, wpb=17030.9, bsz=1024, num_updates=680, lr=1.44928e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=3992
2024-11-07 04:57:11 - progress_bar.py[line:274] - INFO: epoch 002:    299 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.755, ntokens=17398.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=27, wps=3299.7, ups=0.19, wpb=17398.1, bsz=1024, num_updates=690, lr=1.47059e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=4044
2024-11-07 04:58:03 - progress_bar.py[line:274] - INFO: epoch 002:    309 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.706, ntokens=17366.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=26.09, wps=3293.9, ups=0.19, wpb=17366.5, bsz=1024, num_updates=700, lr=1.4919e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=4097
2024-11-07 04:58:56 - progress_bar.py[line:274] - INFO: epoch 002:    319 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.73, ntokens=17491.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=26.55, wps=3310.3, ups=0.19, wpb=17491.4, bsz=1024, num_updates=710, lr=1.51321e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.1, wall=4150
2024-11-07 04:59:49 - progress_bar.py[line:274] - INFO: epoch 002:    329 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.708, ntokens=17297.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=26.14, wps=3278.4, ups=0.19, wpb=17297.5, bsz=1024, num_updates=720, lr=1.53453e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=4203
2024-11-07 05:00:42 - progress_bar.py[line:274] - INFO: epoch 002:    339 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.723, ntokens=17357.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=26.41, wps=3250.9, ups=0.19, wpb=17357.7, bsz=1024, num_updates=730, lr=1.55584e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=4256
2024-11-07 05:01:36 - progress_bar.py[line:274] - INFO: epoch 002:    349 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.707, ntokens=17502.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=26.13, wps=3273.6, ups=0.19, wpb=17502.6, bsz=1024, num_updates=740, lr=1.57715e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.3, wall=4309
2024-11-07 05:02:29 - progress_bar.py[line:274] - INFO: epoch 002:    359 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.675, ntokens=17466.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=25.55, wps=3288.8, ups=0.19, wpb=17466.8, bsz=1024, num_updates=750, lr=1.59847e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=4363
2024-11-07 05:03:22 - progress_bar.py[line:274] - INFO: epoch 002:    369 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.734, ntokens=17610.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=26.62, wps=3316.4, ups=0.19, wpb=17610.1, bsz=1024, num_updates=760, lr=1.61978e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=4416
2024-11-07 05:04:14 - progress_bar.py[line:274] - INFO: epoch 002:    379 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.748, ntokens=17647.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=26.88, wps=3431.1, ups=0.19, wpb=17647.7, bsz=1024, num_updates=770, lr=1.64109e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.3, wall=4467
2024-11-07 05:05:05 - progress_bar.py[line:274] - INFO: epoch 002:    389 / 391 loss=0.003, loss_v1=0, loss_v2=0, nll_loss=4.663, ntokens=17343.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=25.33, wps=3371.9, ups=0.19, wpb=17343.4, bsz=1024, num_updates=780, lr=1.6624e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=4519
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt2024-11-07 05:05:12 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 782 updates
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt

cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
2024-11-07 05:05:12 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cp: cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt'cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt': File exists
: File exists
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2024-11-07 05:07:03 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000

slice_id 5 seek offset 250000
slice_id 3 seek offset 150000
2024-11-07 05:08:54 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 2 @ 782 updates, score 0) (writing took 221.90327846098808 seconds)
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_2.pt
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000


slice_id 6 seek offset 300000
slice_id 4 seek offset 200000
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000

slice_id 2 seek offset 100000
slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
2024-11-07 05:09:48 - train.py[line:336] - INFO: end of epoch 2 (average epoch stats below)
2024-11-07 05:09:48 - progress_bar.py[line:282] - INFO: epoch 002 | loss 0.003 | loss_v1 0 | loss_v2 0 | nll_loss 4.847 | ntokens 17333.8 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 28.78 | wps 2707.1 | ups 0.16 | wpb 17333.8 | bsz 1023 | num_updates 782 | lr 1.66667e-05 | gnorm 0.004 | clip 0 | loss_scale 256 | train_wall 1186 | gb_free 13.2 | wall 4802
2024-11-07 05:09:48 - trainer.py[line:639] - INFO: loading train data for epoch 3
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-07 05:12:28 - trainer.py[line:703] - INFO: begin training epoch 3
2024-11-07 05:12:28 - train.py[line:297] - INFO: Start iterating over samples
2024-11-07 05:13:13 - progress_bar.py[line:274] - INFO: epoch 003:      8 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.651, ntokens=16499.1, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=25.13, wps=338.2, ups=0.02, wpb=16499.1, bsz=985.6, num_updates=790, lr=1.68372e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=29, gb_free=13.4, wall=5006
2024-11-07 05:14:05 - progress_bar.py[line:274] - INFO: epoch 003:     18 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.703, ntokens=17576.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=26.04, wps=3343.2, ups=0.19, wpb=17576.9, bsz=1024, num_updates=800, lr=1.70503e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=5059
2024-11-07 05:14:59 - progress_bar.py[line:274] - INFO: epoch 003:     28 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.634, ntokens=17397.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=24.82, wps=3267.8, ups=0.19, wpb=17397.9, bsz=1024, num_updates=810, lr=1.72634e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.3, wall=5112
2024-11-07 05:15:52 - progress_bar.py[line:274] - INFO: epoch 003:     38 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.628, ntokens=17349.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=24.73, wps=3262.6, ups=0.19, wpb=17349.3, bsz=1024, num_updates=820, lr=1.74766e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.3, wall=5165
2024-11-07 05:16:45 - progress_bar.py[line:274] - INFO: epoch 003:     48 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.653, ntokens=17613.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=25.15, wps=3301.6, ups=0.19, wpb=17613.7, bsz=1024, num_updates=830, lr=1.76897e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=5219
2024-11-07 05:17:38 - progress_bar.py[line:274] - INFO: epoch 003:     58 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.611, ntokens=17375.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=24.44, wps=3290, ups=0.19, wpb=17375.5, bsz=1024, num_updates=840, lr=1.79028e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=5272
2024-11-07 05:18:31 - progress_bar.py[line:274] - INFO: epoch 003:     68 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.537, ntokens=16894.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=23.22, wps=3188.4, ups=0.19, wpb=16894.2, bsz=1024, num_updates=850, lr=1.81159e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=31, gb_free=13.6, wall=5325
2024-11-07 05:19:24 - progress_bar.py[line:274] - INFO: epoch 003:     78 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.617, ntokens=17353.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=24.55, wps=3247.7, ups=0.19, wpb=17353.2, bsz=1024, num_updates=860, lr=1.83291e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=5378
2024-11-07 05:20:18 - progress_bar.py[line:274] - INFO: epoch 003:     88 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.541, ntokens=17157, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=23.27, wps=3203.7, ups=0.19, wpb=17157, bsz=1024, num_updates=870, lr=1.85422e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=5431
2024-11-07 05:21:12 - progress_bar.py[line:274] - INFO: epoch 003:     98 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.627, ntokens=17454.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=24.7, wps=3256.9, ups=0.19, wpb=17454.4, bsz=1024, num_updates=880, lr=1.87553e-05, gnorm=0.004, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=5485
2024-11-07 05:22:05 - progress_bar.py[line:274] - INFO: epoch 003:    108 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.579, ntokens=17366.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=23.9, wps=3269.1, ups=0.19, wpb=17366.1, bsz=1024, num_updates=890, lr=1.89685e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13, wall=5538
2024-11-07 05:23:00 - progress_bar.py[line:274] - INFO: epoch 003:    118 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.607, ntokens=17555.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=24.38, wps=3193.3, ups=0.18, wpb=17555.4, bsz=1024, num_updates=900, lr=1.91816e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=31, gb_free=13.4, wall=5593
2024-11-07 05:23:55 - progress_bar.py[line:274] - INFO: epoch 003:    128 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.56, ntokens=17361.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=23.59, wps=3165, ups=0.18, wpb=17361.6, bsz=1024, num_updates=910, lr=1.93947e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=5648
2024-11-07 05:24:49 - progress_bar.py[line:274] - INFO: epoch 003:    138 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.502, ntokens=17126.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=22.66, wps=3151.7, ups=0.18, wpb=17126.4, bsz=1024, num_updates=920, lr=1.96078e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=5702
2024-11-07 05:25:43 - progress_bar.py[line:274] - INFO: epoch 003:    148 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.527, ntokens=17210, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=23.05, wps=3191.1, ups=0.19, wpb=17210, bsz=1024, num_updates=930, lr=1.9821e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=5756
2024-11-07 05:26:36 - progress_bar.py[line:274] - INFO: epoch 003:    158 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.531, ntokens=17360, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=23.11, wps=3240.7, ups=0.19, wpb=17360, bsz=1024, num_updates=940, lr=2.00341e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=5810
2024-11-07 05:27:30 - progress_bar.py[line:274] - INFO: epoch 003:    168 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.481, ntokens=17161.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=22.33, wps=3223.3, ups=0.19, wpb=17161.7, bsz=1024, num_updates=950, lr=2.02472e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=5863
2024-11-07 05:28:23 - progress_bar.py[line:274] - INFO: epoch 003:    178 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.519, ntokens=17341.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=22.93, wps=3240.3, ups=0.19, wpb=17341.8, bsz=1024, num_updates=960, lr=2.04604e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.3, wall=5917
2024-11-07 05:29:17 - progress_bar.py[line:274] - INFO: epoch 003:    188 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.482, ntokens=17261.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=22.35, wps=3232.3, ups=0.19, wpb=17261.1, bsz=1024, num_updates=970, lr=2.06735e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=5970
2024-11-07 05:30:09 - progress_bar.py[line:274] - INFO: epoch 003:    198 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.462, ntokens=17135.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=22.03, wps=3249.4, ups=0.19, wpb=17135.6, bsz=1024, num_updates=980, lr=2.08866e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=6023
2024-11-07 05:31:03 - progress_bar.py[line:274] - INFO: epoch 003:    208 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.451, ntokens=17048, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=21.87, wps=3203.3, ups=0.19, wpb=17048, bsz=1024, num_updates=990, lr=2.10997e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=6076
2024-11-07 05:31:56 - progress_bar.py[line:274] - INFO: epoch 003:    218 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.424, ntokens=16912.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=21.47, wps=3191.4, ups=0.19, wpb=16912.1, bsz=1024, num_updates=1000, lr=2.13129e-05, gnorm=0.005, clip=0, loss_scale=256, train_wall=30, gb_free=13.4, wall=6129
2024-11-07 05:32:48 - progress_bar.py[line:274] - INFO: epoch 003:    228 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.523, ntokens=17606.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=22.99, wps=3350.7, ups=0.19, wpb=17606.3, bsz=1024, num_updates=1010, lr=2.1526e-05, gnorm=0.006, clip=0, loss_scale=256, train_wall=30, gb_free=13.5, wall=6182
2024-11-07 05:33:41 - progress_bar.py[line:274] - INFO: epoch 003:    238 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.413, ntokens=17114.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=21.3, wps=3229.9, ups=0.19, wpb=17114.8, bsz=1024, num_updates=1020, lr=2.17391e-05, gnorm=0.007, clip=0, loss_scale=256, train_wall=30, gb_free=13.6, wall=6235
2024-11-07 05:34:34 - progress_bar.py[line:274] - INFO: epoch 003:    248 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.547, ntokens=17758.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=23.38, wps=3323.3, ups=0.19, wpb=17758.9, bsz=1024, num_updates=1030, lr=2.19523e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=6288
2024-11-07 05:35:27 - progress_bar.py[line:274] - INFO: epoch 003:    258 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.422, ntokens=17330.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=21.44, wps=3301, ups=0.19, wpb=17330.8, bsz=1024, num_updates=1040, lr=2.21654e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=6340
2024-11-07 05:36:20 - progress_bar.py[line:274] - INFO: epoch 003:    268 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.498, ntokens=17492.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=22.59, wps=3307, ups=0.19, wpb=17492.9, bsz=1024, num_updates=1050, lr=2.23785e-05, gnorm=0.008, clip=0, loss_scale=512, train_wall=30, gb_free=13.6, wall=6393
2024-11-07 05:37:12 - progress_bar.py[line:274] - INFO: epoch 003:    278 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.432, ntokens=17268.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=21.58, wps=3288.8, ups=0.19, wpb=17268.7, bsz=1024, num_updates=1060, lr=2.25916e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=30, gb_free=13.2, wall=6446
2024-11-07 05:38:05 - progress_bar.py[line:274] - INFO: epoch 003:    288 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.34, ntokens=16817.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=20.25, wps=3179.6, ups=0.19, wpb=16817.1, bsz=1024, num_updates=1070, lr=2.28048e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=30, gb_free=13.4, wall=6499
2024-11-07 05:38:58 - progress_bar.py[line:274] - INFO: epoch 003:    298 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.447, ntokens=17399.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=21.81, wps=3307, ups=0.19, wpb=17399.6, bsz=1024, num_updates=1080, lr=2.30179e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=30, gb_free=13.1, wall=6551
2024-11-07 05:39:50 - progress_bar.py[line:274] - INFO: epoch 003:    308 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.424, ntokens=17382.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=21.47, wps=3325.4, ups=0.19, wpb=17382.4, bsz=1024, num_updates=1090, lr=2.3231e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=30, gb_free=13.4, wall=6604
2024-11-07 05:40:44 - progress_bar.py[line:274] - INFO: epoch 003:    318 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.405, ntokens=17352.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=21.18, wps=3248.1, ups=0.19, wpb=17352.5, bsz=1024, num_updates=1100, lr=2.34442e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=31, gb_free=13.5, wall=6657
2024-11-07 05:41:36 - progress_bar.py[line:274] - INFO: epoch 003:    328 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.389, ntokens=17319.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=20.96, wps=3275.9, ups=0.19, wpb=17319.8, bsz=1024, num_updates=1110, lr=2.36573e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=30, gb_free=13.5, wall=6710
2024-11-07 05:42:29 - progress_bar.py[line:274] - INFO: epoch 003:    338 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.419, ntokens=17548, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=21.39, wps=3356.1, ups=0.19, wpb=17548, bsz=1024, num_updates=1120, lr=2.38704e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=6762
2024-11-07 05:43:22 - progress_bar.py[line:274] - INFO: epoch 003:    348 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.393, ntokens=17372.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=21.01, wps=3288.7, ups=0.19, wpb=17372.9, bsz=1024, num_updates=1130, lr=2.40835e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=30, gb_free=13.5, wall=6815
2024-11-07 05:44:15 - progress_bar.py[line:274] - INFO: epoch 003:    358 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.378, ntokens=17523.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=20.8, wps=3280.8, ups=0.19, wpb=17523.6, bsz=1024, num_updates=1140, lr=2.42967e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=6868
2024-11-07 05:45:08 - progress_bar.py[line:274] - INFO: epoch 003:    368 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.429, ntokens=17615.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=21.54, wps=3317.5, ups=0.19, wpb=17615.3, bsz=1024, num_updates=1150, lr=2.45098e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=6922
2024-11-07 05:46:00 - progress_bar.py[line:274] - INFO: epoch 003:    378 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.423, ntokens=17438.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=21.45, wps=3385.5, ups=0.19, wpb=17438.5, bsz=1024, num_updates=1160, lr=2.47229e-05, gnorm=0.004, clip=0, loss_scale=512, train_wall=30, gb_free=13.4, wall=6973
2024-11-07 05:46:51 - progress_bar.py[line:274] - INFO: epoch 003:    388 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.46, ntokens=17522, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=22.01, wps=3416.9, ups=0.2, wpb=17522, bsz=1024, num_updates=1170, lr=2.49361e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=30, gb_free=13.4, wall=7024
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
2024-11-07 05:47:03 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 1173 updates
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
2024-11-07 05:47:03 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
2024-11-07 05:48:54 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt
2024-11-07 05:50:45 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 3 @ 1173 updates, score 0) (writing took 222.20742660100223 seconds)
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_3.pt
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000
slice_id 4 seek offset 200000
slice_id 6 seek offset 300000
slice_id 2 seek offset 100000
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000
slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
slice_id 5 seek offset 250000
slice_id 3 seek offset 150000
2024-11-07 05:51:40 - train.py[line:336] - INFO: end of epoch 3 (average epoch stats below)
2024-11-07 05:51:40 - progress_bar.py[line:282] - INFO: epoch 003 | loss 0.002 | loss_v1 0 | loss_v2 0 | nll_loss 4.504 | ntokens 17319.9 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 22.69 | wps 2696.3 | ups 0.16 | wpb 17319.9 | bsz 1023 | num_updates 1173 | lr 2.5e-05 | gnorm 0.006 | clip 0 | loss_scale 512 | train_wall 1186 | gb_free 13.3 | wall 7313
2024-11-07 05:51:40 - trainer.py[line:639] - INFO: loading train data for epoch 4
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-07 05:54:21 - trainer.py[line:703] - INFO: begin training epoch 4
2024-11-07 05:54:21 - train.py[line:297] - INFO: Start iterating over samples
2024-11-07 05:55:00 - progress_bar.py[line:274] - INFO: epoch 004:      7 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.395, ntokens=16893.2, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=21.04, wps=345.1, ups=0.02, wpb=16893.2, bsz=985.6, num_updates=1180, lr=2.51492e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=29, gb_free=13.5, wall=7514
2024-11-07 05:55:53 - progress_bar.py[line:274] - INFO: epoch 004:     17 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.381, ntokens=17563.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=20.84, wps=3339.5, ups=0.19, wpb=17563.2, bsz=1024, num_updates=1190, lr=2.53623e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=30, gb_free=13.5, wall=7566
2024-11-07 05:56:46 - progress_bar.py[line:274] - INFO: epoch 004:     27 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.353, ntokens=17519, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=20.43, wps=3303.4, ups=0.19, wpb=17519, bsz=1024, num_updates=1200, lr=2.55754e-05, gnorm=0.01, clip=0, loss_scale=512, train_wall=30, gb_free=13.5, wall=7620
2024-11-07 05:57:39 - progress_bar.py[line:274] - INFO: epoch 004:     37 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.311, ntokens=17448.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=19.85, wps=3316, ups=0.19, wpb=17448.6, bsz=1024, num_updates=1210, lr=2.57886e-05, gnorm=0.008, clip=0, loss_scale=512, train_wall=30, gb_free=13.4, wall=7672
2024-11-07 05:58:31 - progress_bar.py[line:274] - INFO: epoch 004:     47 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.342, ntokens=17472.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=20.27, wps=3334.9, ups=0.19, wpb=17472.3, bsz=1024, num_updates=1220, lr=2.60017e-05, gnorm=0.008, clip=0, loss_scale=512, train_wall=30, gb_free=13.6, wall=7725
2024-11-07 05:59:24 - progress_bar.py[line:274] - INFO: epoch 004:     57 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.278, ntokens=17335.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=19.39, wps=3264, ups=0.19, wpb=17335.9, bsz=1024, num_updates=1230, lr=2.62148e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=30, gb_free=13.6, wall=7778
2024-11-07 06:00:17 - progress_bar.py[line:274] - INFO: epoch 004:     67 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.256, ntokens=17100.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=19.11, wps=3262.3, ups=0.19, wpb=17100.3, bsz=1024, num_updates=1240, lr=2.6428e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=7830
2024-11-07 06:01:13 - progress_bar.py[line:274] - INFO: epoch 004:     77 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.241, ntokens=17068.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=18.91, wps=3020.2, ups=0.18, wpb=17068.5, bsz=1024, num_updates=1250, lr=2.66411e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=44, gb_free=13.3, wall=7887
2024-11-07 06:02:05 - progress_bar.py[line:274] - INFO: epoch 004:     87 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.308, ntokens=17510.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=19.81, wps=3374.7, ups=0.19, wpb=17510.1, bsz=1024, num_updates=1260, lr=2.68542e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=52, gb_free=13.5, wall=7938
2024-11-07 06:02:57 - progress_bar.py[line:274] - INFO: epoch 004:     97 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.255, ntokens=17323.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=19.09, wps=3347, ups=0.19, wpb=17323.8, bsz=1024, num_updates=1270, lr=2.70673e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=48, gb_free=13.5, wall=7990
2024-11-07 06:03:49 - progress_bar.py[line:274] - INFO: epoch 004:    107 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.269, ntokens=17291.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=19.28, wps=3288.5, ups=0.19, wpb=17291.4, bsz=1024, num_updates=1280, lr=2.72805e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=46, gb_free=13.4, wall=8043
2024-11-07 06:04:41 - progress_bar.py[line:274] - INFO: epoch 004:    117 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.259, ntokens=17383.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=19.15, wps=3345.7, ups=0.19, wpb=17383.6, bsz=1024, num_updates=1290, lr=2.74936e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=39, gb_free=13.6, wall=8095
2024-11-07 06:05:34 - progress_bar.py[line:274] - INFO: epoch 004:    127 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.237, ntokens=17377.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=18.85, wps=3297.9, ups=0.19, wpb=17377.6, bsz=1024, num_updates=1300, lr=2.77067e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=30, gb_free=13.5, wall=8147
2024-11-07 06:06:28 - progress_bar.py[line:274] - INFO: epoch 004:    137 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.212, ntokens=17259.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=18.54, wps=3215.5, ups=0.19, wpb=17259.7, bsz=1024, num_updates=1310, lr=2.79199e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=30, gb_free=13.4, wall=8201
2024-11-07 06:07:21 - progress_bar.py[line:274] - INFO: epoch 004:    147 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.238, ntokens=17374, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=18.87, wps=3278.8, ups=0.19, wpb=17374, bsz=1024, num_updates=1320, lr=2.8133e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=30, gb_free=13.6, wall=8254
2024-11-07 06:08:14 - progress_bar.py[line:274] - INFO: epoch 004:    157 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.213, ntokens=17327.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=18.55, wps=3223.6, ups=0.19, wpb=17327.2, bsz=1024, num_updates=1330, lr=2.83461e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=30, gb_free=13.6, wall=8308
2024-11-07 06:09:07 - progress_bar.py[line:274] - INFO: epoch 004:    167 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.188, ntokens=17212.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=18.23, wps=3243.7, ups=0.19, wpb=17212.6, bsz=1024, num_updates=1340, lr=2.85592e-05, gnorm=0.005, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=8361
2024-11-07 06:10:01 - progress_bar.py[line:274] - INFO: epoch 004:    177 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.226, ntokens=17400.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=18.71, wps=3271.4, ups=0.19, wpb=17400.1, bsz=1024, num_updates=1350, lr=2.87724e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=30, gb_free=13.5, wall=8414
2024-11-07 06:10:53 - progress_bar.py[line:274] - INFO: epoch 004:    187 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.158, ntokens=17256.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=17.86, wps=3270, ups=0.19, wpb=17256.7, bsz=1024, num_updates=1360, lr=2.89855e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=30, gb_free=13.3, wall=8467
2024-11-07 06:11:47 - progress_bar.py[line:274] - INFO: epoch 004:    197 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.175, ntokens=17263.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=18.07, wps=3251.2, ups=0.19, wpb=17263.8, bsz=1024, num_updates=1370, lr=2.91986e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=30, gb_free=13.4, wall=8520
2024-11-07 06:12:40 - progress_bar.py[line:274] - INFO: epoch 004:    207 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.154, ntokens=17146.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=17.8, wps=3216.3, ups=0.19, wpb=17146.1, bsz=1024, num_updates=1380, lr=2.94118e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=30, gb_free=13.6, wall=8573
2024-11-07 06:13:32 - progress_bar.py[line:274] - INFO: epoch 004:    217 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.158, ntokens=17203.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=17.85, wps=3286.1, ups=0.19, wpb=17203.2, bsz=1024, num_updates=1390, lr=2.96249e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=30, gb_free=13.6, wall=8626
2024-11-07 06:14:27 - progress_bar.py[line:274] - INFO: epoch 004:    227 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.119, ntokens=17291.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=17.37, wps=3154.5, ups=0.18, wpb=17291.5, bsz=1024, num_updates=1400, lr=2.9838e-05, gnorm=0.008, clip=0, loss_scale=512, train_wall=38, gb_free=13.5, wall=8680
2024-11-07 06:15:23 - progress_bar.py[line:274] - INFO: epoch 004:    237 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.139, ntokens=17126.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=17.62, wps=3059.2, ups=0.18, wpb=17126.1, bsz=1024, num_updates=1410, lr=3.00512e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=56, gb_free=13.3, wall=8736
2024-11-07 06:16:18 - progress_bar.py[line:274] - INFO: epoch 004:    247 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.126, ntokens=17483.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=17.46, wps=3190, ups=0.18, wpb=17483.5, bsz=1024, num_updates=1420, lr=3.02643e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=55, gb_free=13.6, wall=8791
2024-11-07 06:17:10 - progress_bar.py[line:274] - INFO: epoch 004:    257 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.115, ntokens=17358.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=17.33, wps=3331.7, ups=0.19, wpb=17358.3, bsz=1024, num_updates=1430, lr=3.04774e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=52, gb_free=13.3, wall=8843
2024-11-07 06:18:06 - progress_bar.py[line:274] - INFO: epoch 004:    267 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.086, ntokens=17119.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=16.99, wps=3034.5, ups=0.18, wpb=17119.7, bsz=1024, num_updates=1440, lr=3.06905e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=56, gb_free=13.5, wall=8900
2024-11-07 06:19:00 - progress_bar.py[line:274] - INFO: epoch 004:    277 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.099, ntokens=17177.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=17.14, wps=3199.9, ups=0.19, wpb=17177.4, bsz=1024, num_updates=1450, lr=3.09037e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=54, gb_free=13.3, wall=8953
2024-11-07 06:19:53 - progress_bar.py[line:274] - INFO: epoch 004:    287 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.1, ntokens=17219, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=17.15, wps=3272.7, ups=0.19, wpb=17219, bsz=1024, num_updates=1460, lr=3.11168e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=53, gb_free=13.3, wall=9006
2024-11-07 06:20:47 - progress_bar.py[line:274] - INFO: epoch 004:    297 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.089, ntokens=17232.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=17.02, wps=3156.5, ups=0.18, wpb=17232.4, bsz=1024, num_updates=1470, lr=3.13299e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=55, gb_free=13.6, wall=9061
2024-11-07 06:21:41 - progress_bar.py[line:274] - INFO: epoch 004:    307 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.085, ntokens=17260.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=16.97, wps=3204.2, ups=0.19, wpb=17260.7, bsz=1024, num_updates=1480, lr=3.15431e-05, gnorm=0.008, clip=0, loss_scale=512, train_wall=54, gb_free=13.5, wall=9115
2024-11-07 06:22:33 - progress_bar.py[line:274] - INFO: epoch 004:    317 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.101, ntokens=17428.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=17.17, wps=3384.5, ups=0.19, wpb=17428.5, bsz=1024, num_updates=1490, lr=3.17562e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=51, gb_free=13.4, wall=9166
2024-11-07 06:23:26 - progress_bar.py[line:274] - INFO: epoch 004:    327 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.028, ntokens=17114.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=16.31, wps=3173.6, ups=0.19, wpb=17114.3, bsz=1024, num_updates=1500, lr=3.19693e-05, gnorm=0.006, clip=0, loss_scale=512, train_wall=53, gb_free=13.5, wall=9220
2024-11-07 06:24:19 - progress_bar.py[line:274] - INFO: epoch 004:    337 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.107, ntokens=17536.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=17.23, wps=3370, ups=0.19, wpb=17536.7, bsz=1024, num_updates=1510, lr=3.21824e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=46, gb_free=13.5, wall=9272
2024-11-07 06:25:11 - progress_bar.py[line:274] - INFO: epoch 004:    347 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.056, ntokens=17380.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=16.63, wps=3303.7, ups=0.19, wpb=17380.8, bsz=1024, num_updates=1520, lr=3.23956e-05, gnorm=0.009, clip=0, loss_scale=512, train_wall=31, gb_free=13.3, wall=9325
2024-11-07 06:26:05 - progress_bar.py[line:274] - INFO: epoch 004:    357 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.111, ntokens=17588.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=17.28, wps=3282.4, ups=0.19, wpb=17588.3, bsz=1024, num_updates=1530, lr=3.26087e-05, gnorm=0.007, clip=0, loss_scale=512, train_wall=31, gb_free=13.4, wall=9378
2024-11-07 06:26:58 - progress_bar.py[line:274] - INFO: epoch 004:    367 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.092, ntokens=17641.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=17.06, wps=3284.7, ups=0.19, wpb=17641.5, bsz=1024, num_updates=1540, lr=3.28218e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=9432
2024-11-07 06:27:51 - progress_bar.py[line:274] - INFO: epoch 004:    377 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.245, ntokens=17916.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=18.97, wps=3425.3, ups=0.19, wpb=17916.3, bsz=1024, num_updates=1550, lr=3.3035e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=33, gb_free=13.5, wall=9484
2024-11-07 06:28:45 - progress_bar.py[line:274] - INFO: epoch 004:    387 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.241, ntokens=17563.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=18.91, wps=3232.3, ups=0.18, wpb=17563.5, bsz=1024, num_updates=1560, lr=3.32481e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=52, gb_free=13.4, wall=9539
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt
2024-11-07 06:29:03 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 1564 updates
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_4.ptcp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt

cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt
2024-11-07 06:29:03 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cp: cp: cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt'cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt'cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt': File exists
: File exists: File exists

local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
2024-11-07 06:30:52 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000


slice_id 7 seek offset 350000
slice_id 5 seek offset 250000
slice_id 3 seek offset 150000
2024-11-07 06:32:43 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 4 @ 1564 updates, score 0) (writing took 219.82252859897562 seconds)
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_4.pt
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000
slice_id 1 seek offset 50000
slice_id 6 seek offset 300000
slice_id 2 seek offset 100000
slice_id 4 seek offset 200000
2024-11-07 06:33:37 - train.py[line:336] - INFO: end of epoch 4 (average epoch stats below)
2024-11-07 06:33:37 - progress_bar.py[line:282] - INFO: epoch 004 | loss 0.002 | loss_v1 0 | loss_v2 0 | nll_loss 4.192 | ntokens 17337.7 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 18.27 | wps 2693 | ups 0.16 | wpb 17337.7 | bsz 1023 | num_updates 1564 | lr 3.33333e-05 | gnorm 0.007 | clip 0 | loss_scale 1024 | train_wall 1552 | gb_free 13.2 | wall 9831
2024-11-07 06:33:37 - trainer.py[line:639] - INFO: loading train data for epoch 5
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-07 06:36:17 - trainer.py[line:703] - INFO: begin training epoch 5
2024-11-07 06:36:17 - train.py[line:297] - INFO: Start iterating over samples
2024-11-07 06:36:51 - progress_bar.py[line:274] - INFO: epoch 005:      6 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.113, ntokens=16895.2, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=17.31, wps=347.6, ups=0.02, wpb=16895.2, bsz=985.6, num_updates=1570, lr=3.34612e-05, gnorm=0.011, clip=0, loss_scale=1024, train_wall=36, gb_free=13.5, wall=10025
2024-11-07 06:37:45 - progress_bar.py[line:274] - INFO: epoch 005:     16 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.075, ntokens=17492.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=16.86, wps=3257.2, ups=0.19, wpb=17492.1, bsz=1024, num_updates=1580, lr=3.36743e-05, gnorm=0.012, clip=0, loss_scale=1024, train_wall=31, gb_free=13.4, wall=10078
2024-11-07 06:38:37 - progress_bar.py[line:274] - INFO: epoch 005:     26 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.056, ntokens=17361.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=16.64, wps=3312.6, ups=0.19, wpb=17361.8, bsz=1024, num_updates=1590, lr=3.38875e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=10131
2024-11-07 06:39:32 - progress_bar.py[line:274] - INFO: epoch 005:     36 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.01, ntokens=17373.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=16.11, wps=3187.8, ups=0.18, wpb=17373.8, bsz=1024, num_updates=1600, lr=3.41006e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=10185
2024-11-07 06:40:27 - progress_bar.py[line:274] - INFO: epoch 005:     46 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.046, ntokens=17521.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=16.52, wps=3198.9, ups=0.18, wpb=17521.6, bsz=1024, num_updates=1610, lr=3.43137e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=10240
2024-11-07 06:41:20 - progress_bar.py[line:274] - INFO: epoch 005:     56 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.976, ntokens=17239.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=15.73, wps=3239.1, ups=0.19, wpb=17239.9, bsz=1024, num_updates=1620, lr=3.45269e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=31, gb_free=13.6, wall=10293
2024-11-07 06:42:13 - progress_bar.py[line:274] - INFO: epoch 005:     66 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.944, ntokens=16966.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=15.39, wps=3181.1, ups=0.19, wpb=16966.2, bsz=1024, num_updates=1630, lr=3.474e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=10347
2024-11-07 06:43:07 - progress_bar.py[line:274] - INFO: epoch 005:     76 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.973, ntokens=17168.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=15.71, wps=3207, ups=0.19, wpb=17168.1, bsz=1024, num_updates=1640, lr=3.49531e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=10400
2024-11-07 06:44:00 - progress_bar.py[line:274] - INFO: epoch 005:     86 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.991, ntokens=17344.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=15.9, wps=3262.3, ups=0.19, wpb=17344.3, bsz=1024, num_updates=1650, lr=3.51662e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=10453
2024-11-07 06:44:53 - progress_bar.py[line:274] - INFO: epoch 005:     96 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.948, ntokens=17161.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=15.43, wps=3245.5, ups=0.19, wpb=17161.5, bsz=1024, num_updates=1660, lr=3.53794e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=10506
2024-11-07 06:45:47 - progress_bar.py[line:274] - INFO: epoch 005:    106 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.016, ntokens=17374.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=16.17, wps=3221.8, ups=0.19, wpb=17374.3, bsz=1024, num_updates=1670, lr=3.55925e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=30, gb_free=13.2, wall=10560
2024-11-07 06:46:41 - progress_bar.py[line:274] - INFO: epoch 005:    116 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.97, ntokens=17274.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=15.67, wps=3171.9, ups=0.18, wpb=17274.4, bsz=1024, num_updates=1680, lr=3.58056e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=10615
2024-11-07 06:47:34 - progress_bar.py[line:274] - INFO: epoch 005:    126 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.986, ntokens=17428.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=15.84, wps=3263.5, ups=0.19, wpb=17428.1, bsz=1024, num_updates=1690, lr=3.60188e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=31, gb_free=13.4, wall=10668
2024-11-07 06:48:28 - progress_bar.py[line:274] - INFO: epoch 005:    136 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.956, ntokens=17418.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=15.52, wps=3269.8, ups=0.19, wpb=17418.7, bsz=1024, num_updates=1700, lr=3.62319e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=10721
2024-11-07 06:49:21 - progress_bar.py[line:274] - INFO: epoch 005:    146 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.943, ntokens=17071.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=15.38, wps=3184.9, ups=0.19, wpb=17071.4, bsz=1024, num_updates=1710, lr=3.6445e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=10775
2024-11-07 06:50:14 - progress_bar.py[line:274] - INFO: epoch 005:    156 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.931, ntokens=17300.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=15.25, wps=3260.9, ups=0.19, wpb=17300.1, bsz=1024, num_updates=1720, lr=3.66581e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=10828
2024-11-07 06:51:07 - progress_bar.py[line:274] - INFO: epoch 005:    166 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.935, ntokens=17182.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=15.3, wps=3247.7, ups=0.19, wpb=17182.6, bsz=1024, num_updates=1730, lr=3.68713e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=10881
2024-11-07 06:52:00 - progress_bar.py[line:274] - INFO: epoch 005:    176 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.96, ntokens=17513.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=15.56, wps=3291.2, ups=0.19, wpb=17513.5, bsz=1024, num_updates=1740, lr=3.70844e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=10934
2024-11-07 06:52:54 - progress_bar.py[line:274] - INFO: epoch 005:    186 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.941, ntokens=17157.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=15.35, wps=3210.1, ups=0.19, wpb=17157.8, bsz=1024, num_updates=1750, lr=3.72975e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=10987
2024-11-07 06:53:47 - progress_bar.py[line:274] - INFO: epoch 005:    196 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.941, ntokens=17384.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=15.35, wps=3246.4, ups=0.19, wpb=17384.9, bsz=1024, num_updates=1760, lr=3.75107e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=11041
2024-11-07 06:54:41 - progress_bar.py[line:274] - INFO: epoch 005:    206 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.909, ntokens=17162.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=15.02, wps=3214.3, ups=0.19, wpb=17162.1, bsz=1024, num_updates=1770, lr=3.77238e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=30, gb_free=13.3, wall=11094
2024-11-07 06:55:34 - progress_bar.py[line:274] - INFO: epoch 005:    216 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.913, ntokens=17060.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=15.06, wps=3208.2, ups=0.19, wpb=17060.3, bsz=1024, num_updates=1780, lr=3.79369e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=30, gb_free=13.3, wall=11148
2024-11-07 06:56:27 - progress_bar.py[line:274] - INFO: epoch 005:    226 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.884, ntokens=17412.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.77, wps=3281.7, ups=0.19, wpb=17412.6, bsz=1024, num_updates=1790, lr=3.815e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=11201
2024-11-07 06:57:20 - progress_bar.py[line:274] - INFO: epoch 005:    236 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.916, ntokens=17136.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=15.09, wps=3227, ups=0.19, wpb=17136.5, bsz=1024, num_updates=1800, lr=3.83632e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=11254
2024-11-07 06:58:13 - progress_bar.py[line:274] - INFO: epoch 005:    246 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.946, ntokens=17650.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=15.41, wps=3349.4, ups=0.19, wpb=17650.3, bsz=1024, num_updates=1810, lr=3.85763e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=11306
2024-11-07 06:59:07 - progress_bar.py[line:274] - INFO: epoch 005:    256 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.905, ntokens=17449, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.98, wps=3253.8, ups=0.19, wpb=17449, bsz=1024, num_updates=1820, lr=3.87894e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=31, gb_free=13.4, wall=11360
2024-11-07 07:00:00 - progress_bar.py[line:274] - INFO: epoch 005:    266 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.928, ntokens=17380.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=15.22, wps=3230.6, ups=0.19, wpb=17380.8, bsz=1024, num_updates=1830, lr=3.90026e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=35, gb_free=13.2, wall=11414
2024-11-07 07:00:54 - progress_bar.py[line:274] - INFO: epoch 005:    276 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.881, ntokens=17134.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.74, wps=3211.7, ups=0.19, wpb=17134.2, bsz=1024, num_updates=1840, lr=3.92157e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=31, gb_free=13.4, wall=11467
2024-11-07 07:01:47 - progress_bar.py[line:274] - INFO: epoch 005:    286 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.89, ntokens=17307.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.83, wps=3257.3, ups=0.19, wpb=17307.8, bsz=1024, num_updates=1850, lr=3.94288e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=11520
2024-11-07 07:02:40 - progress_bar.py[line:274] - INFO: epoch 005:    296 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.901, ntokens=17178.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.94, wps=3232.7, ups=0.19, wpb=17178.1, bsz=1024, num_updates=1860, lr=3.96419e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=11573
2024-11-07 07:03:33 - progress_bar.py[line:274] - INFO: epoch 005:    306 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.892, ntokens=17440.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.85, wps=3261.5, ups=0.19, wpb=17440.3, bsz=1024, num_updates=1870, lr=3.98551e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=11627
2024-11-07 07:04:26 - progress_bar.py[line:274] - INFO: epoch 005:    316 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.885, ntokens=17220.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.78, wps=3247.2, ups=0.19, wpb=17220.6, bsz=1024, num_updates=1880, lr=4.00682e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=11680
2024-11-07 07:05:19 - progress_bar.py[line:274] - INFO: epoch 005:    326 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.858, ntokens=17263.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.5, wps=3276.9, ups=0.19, wpb=17263.2, bsz=1024, num_updates=1890, lr=4.02813e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=30, gb_free=13.1, wall=11733
2024-11-07 07:06:13 - progress_bar.py[line:274] - INFO: epoch 005:    336 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.887, ntokens=17341.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.8, wps=3243.6, ups=0.19, wpb=17341.4, bsz=1024, num_updates=1900, lr=4.04945e-05, gnorm=0.01, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=11786
2024-11-07 07:07:06 - progress_bar.py[line:274] - INFO: epoch 005:    346 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.819, ntokens=17213.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.12, wps=3200.7, ups=0.19, wpb=17213.5, bsz=1024, num_updates=1910, lr=4.07076e-05, gnorm=0.01, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=11840
2024-11-07 07:08:00 - progress_bar.py[line:274] - INFO: epoch 005:    356 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.937, ntokens=17560.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=15.31, wps=3249.4, ups=0.19, wpb=17560.1, bsz=1024, num_updates=1920, lr=4.09207e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=11894
2024-11-07 07:08:58 - progress_bar.py[line:274] - INFO: epoch 005:    366 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.883, ntokens=17475.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.75, wps=3036.5, ups=0.17, wpb=17475.1, bsz=1024, num_updates=1930, lr=4.11338e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=31, gb_free=13.5, wall=11952
2024-11-07 07:09:53 - progress_bar.py[line:274] - INFO: epoch 005:    376 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.058, ntokens=17690.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=16.66, wps=3189.4, ups=0.18, wpb=17690.7, bsz=1024, num_updates=1940, lr=4.1347e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=30, gb_free=13.4, wall=12007
2024-11-07 07:10:49 - progress_bar.py[line:274] - INFO: epoch 005:    386 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=4.015, ntokens=17241, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=16.17, wps=3130.3, ups=0.18, wpb=17241, bsz=1024, num_updates=1950, lr=4.15601e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=30, gb_free=13.2, wall=12062
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt2024-11-07 07:11:12 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 1955 updates

cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_5.ptcp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt

cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt
2024-11-07 07:11:12 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cp: cp: cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt'cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt'cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt': File exists: File exists

: File exists
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
2024-11-07 07:13:01 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000

file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000
slice_id 1 seek offset 50000
slice_id 5 seek offset 250000
slice_id 7 seek offset 350000
2024-11-07 07:14:52 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 5 @ 1955 updates, score 0) (writing took 220.0086488040106 seconds)
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_5.pt
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000
slice_id 2 seek offset 100000
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000
slice_id 6 seek offset 300000
slice_id 4 seek offset 200000
slice_id 3 seek offset 150000
2024-11-07 07:15:46 - train.py[line:336] - INFO: end of epoch 5 (average epoch stats below)
2024-11-07 07:15:46 - progress_bar.py[line:282] - INFO: epoch 005 | loss 0.002 | loss_v1 0 | loss_v2 0 | nll_loss 3.948 | ntokens 17303.9 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 15.43 | wps 2675 | ups 0.15 | wpb 17303.9 | bsz 1023 | num_updates 1955 | lr 4.16667e-05 | gnorm 0.008 | clip 0 | loss_scale 1024 | train_wall 1193 | gb_free 13.3 | wall 12360
2024-11-07 07:15:46 - trainer.py[line:639] - INFO: loading train data for epoch 6
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-07 07:18:26 - trainer.py[line:703] - INFO: begin training epoch 6
2024-11-07 07:18:26 - train.py[line:297] - INFO: Start iterating over samples
2024-11-07 07:18:55 - progress_bar.py[line:274] - INFO: epoch 006:      5 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.921, ntokens=16515.2, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=15.15, wps=339.4, ups=0.02, wpb=16515.2, bsz=985.6, num_updates=1960, lr=4.17732e-05, gnorm=0.012, clip=0, loss_scale=1024, train_wall=29, gb_free=13, wall=12549
2024-11-07 07:19:49 - progress_bar.py[line:274] - INFO: epoch 006:     15 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.895, ntokens=17449.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.88, wps=3266.4, ups=0.19, wpb=17449.9, bsz=1024, num_updates=1970, lr=4.19864e-05, gnorm=0.013, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=12602
2024-11-07 07:20:41 - progress_bar.py[line:274] - INFO: epoch 006:     25 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.898, ntokens=17543.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.91, wps=3340.5, ups=0.19, wpb=17543.9, bsz=1024, num_updates=1980, lr=4.21995e-05, gnorm=0.007, clip=0, loss_scale=1024, train_wall=31, gb_free=13.3, wall=12655
2024-11-07 07:21:36 - progress_bar.py[line:274] - INFO: epoch 006:     35 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.865, ntokens=17221.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.57, wps=3162.1, ups=0.18, wpb=17221.5, bsz=1024, num_updates=1990, lr=4.24126e-05, gnorm=0.008, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=12709
2024-11-07 07:22:28 - progress_bar.py[line:274] - INFO: epoch 006:     45 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.822, ntokens=17422, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.14, wps=3307.8, ups=0.19, wpb=17422, bsz=1024, num_updates=2000, lr=4.26257e-05, gnorm=0.01, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=12762
2024-11-07 07:23:21 - progress_bar.py[line:274] - INFO: epoch 006:     55 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.847, ntokens=17520.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.39, wps=3298.3, ups=0.19, wpb=17520.4, bsz=1024, num_updates=2010, lr=4.28389e-05, gnorm=0.009, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=12815
2024-11-07 07:24:14 - progress_bar.py[line:274] - INFO: epoch 006:     65 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.762, ntokens=16837.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.57, wps=3208.9, ups=0.19, wpb=16837.9, bsz=1024, num_updates=2020, lr=4.3052e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.1, wall=12867
2024-11-07 07:25:07 - progress_bar.py[line:274] - INFO: epoch 006:     75 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.855, ntokens=17495.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.47, wps=3314.1, ups=0.19, wpb=17495.6, bsz=1024, num_updates=2030, lr=4.32651e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.5, wall=12920
2024-11-07 07:26:00 - progress_bar.py[line:274] - INFO: epoch 006:     85 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.835, ntokens=17339.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.27, wps=3265.3, ups=0.19, wpb=17339.5, bsz=1024, num_updates=2040, lr=4.34783e-05, gnorm=0.006, clip=0, loss_scale=1024, train_wall=30, gb_free=13.6, wall=12973
2024-11-07 07:26:53 - progress_bar.py[line:274] - INFO: epoch 006:     95 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.825, ntokens=17277.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.17, wps=3254.7, ups=0.19, wpb=17277.5, bsz=1024, num_updates=2050, lr=4.36914e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=13026
2024-11-07 07:27:46 - progress_bar.py[line:274] - INFO: epoch 006:    105 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.837, ntokens=17319.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.29, wps=3259.6, ups=0.19, wpb=17319.2, bsz=1024, num_updates=2060, lr=4.39045e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=13079
2024-11-07 07:28:39 - progress_bar.py[line:274] - INFO: epoch 006:    115 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.819, ntokens=17095.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.11, wps=3213.7, ups=0.19, wpb=17095.5, bsz=1024, num_updates=2070, lr=4.41176e-05, gnorm=0.006, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=13133
2024-11-07 07:29:32 - progress_bar.py[line:274] - INFO: epoch 006:    125 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.794, ntokens=17417.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.87, wps=3291.5, ups=0.19, wpb=17417.3, bsz=1024, num_updates=2080, lr=4.43308e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=30, gb_free=13.4, wall=13186
2024-11-07 07:30:25 - progress_bar.py[line:274] - INFO: epoch 006:    135 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.84, ntokens=17330.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.32, wps=3253.1, ups=0.19, wpb=17330.5, bsz=1024, num_updates=2090, lr=4.45439e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=13239
2024-11-07 07:31:18 - progress_bar.py[line:274] - INFO: epoch 006:    145 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.791, ntokens=17032.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.84, wps=3213.4, ups=0.19, wpb=17032.2, bsz=1024, num_updates=2100, lr=4.4757e-05, gnorm=0.013, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=13292
2024-11-07 07:32:11 - progress_bar.py[line:274] - INFO: epoch 006:    155 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.805, ntokens=17341.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.98, wps=3282.2, ups=0.19, wpb=17341.1, bsz=1024, num_updates=2110, lr=4.49702e-05, gnorm=0.015, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=13345
2024-11-07 07:33:04 - progress_bar.py[line:274] - INFO: epoch 006:    165 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.797, ntokens=17147.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.9, wps=3234.7, ups=0.19, wpb=17147.3, bsz=1024, num_updates=2120, lr=4.51833e-05, gnorm=0.012, clip=0, loss_scale=2048, train_wall=30, gb_free=13.3, wall=13398
2024-11-07 07:33:58 - progress_bar.py[line:274] - INFO: epoch 006:    175 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.805, ntokens=17402, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.97, wps=3252.2, ups=0.19, wpb=17402, bsz=1024, num_updates=2130, lr=4.53964e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=13451
2024-11-07 07:34:51 - progress_bar.py[line:274] - INFO: epoch 006:    185 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.805, ntokens=17337, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.98, wps=3285.6, ups=0.19, wpb=17337, bsz=1024, num_updates=2140, lr=4.56095e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=13504
2024-11-07 07:35:44 - progress_bar.py[line:274] - INFO: epoch 006:    195 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.78, ntokens=17261.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.74, wps=3250.2, ups=0.19, wpb=17261.1, bsz=1024, num_updates=2150, lr=4.58227e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=13557
2024-11-07 07:36:36 - progress_bar.py[line:274] - INFO: epoch 006:    205 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.793, ntokens=17031.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.86, wps=3231.9, ups=0.19, wpb=17031.2, bsz=1024, num_updates=2160, lr=4.60358e-05, gnorm=0.006, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=13610
2024-11-07 07:37:29 - progress_bar.py[line:274] - INFO: epoch 006:    215 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.719, ntokens=17026.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.17, wps=3240.4, ups=0.19, wpb=17026.9, bsz=1024, num_updates=2170, lr=4.62489e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=31, gb_free=13.5, wall=13662
2024-11-07 07:38:22 - progress_bar.py[line:274] - INFO: epoch 006:    225 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.788, ntokens=17359.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.81, wps=3272.3, ups=0.19, wpb=17359.2, bsz=1024, num_updates=2180, lr=4.64621e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=13715
2024-11-07 07:39:15 - progress_bar.py[line:274] - INFO: epoch 006:    235 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.756, ntokens=17134.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.51, wps=3255.7, ups=0.19, wpb=17134.2, bsz=1024, num_updates=2190, lr=4.66752e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=30, gb_free=13.1, wall=13768
2024-11-07 07:40:08 - progress_bar.py[line:274] - INFO: epoch 006:    245 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.748, ntokens=17255, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.44, wps=3243.8, ups=0.19, wpb=17255, bsz=1024, num_updates=2200, lr=4.68883e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=30, gb_free=13.3, wall=13821
2024-11-07 07:41:01 - progress_bar.py[line:274] - INFO: epoch 006:    255 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.779, ntokens=17535.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.73, wps=3281.6, ups=0.19, wpb=17535.8, bsz=1024, num_updates=2210, lr=4.71014e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=30, gb_free=13.4, wall=13875
2024-11-07 07:41:55 - progress_bar.py[line:274] - INFO: epoch 006:    265 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.808, ntokens=17365.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.01, wps=3221.2, ups=0.19, wpb=17365.1, bsz=1024, num_updates=2220, lr=4.73146e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=30, gb_free=13.3, wall=13929
2024-11-07 07:42:49 - progress_bar.py[line:274] - INFO: epoch 006:    275 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.749, ntokens=17119.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.44, wps=3193.5, ups=0.19, wpb=17119.5, bsz=1024, num_updates=2230, lr=4.75277e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=13982
2024-11-07 07:43:42 - progress_bar.py[line:274] - INFO: epoch 006:    285 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.739, ntokens=17182.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.35, wps=3195.1, ups=0.19, wpb=17182.4, bsz=1024, num_updates=2240, lr=4.77408e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=14036
2024-11-07 07:44:36 - progress_bar.py[line:274] - INFO: epoch 006:    295 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.758, ntokens=17370.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.53, wps=3234.6, ups=0.19, wpb=17370.6, bsz=1024, num_updates=2250, lr=4.7954e-05, gnorm=0.006, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=14090
2024-11-07 07:45:30 - progress_bar.py[line:274] - INFO: epoch 006:    305 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.74, ntokens=17177.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.36, wps=3184.2, ups=0.19, wpb=17177.8, bsz=1024, num_updates=2260, lr=4.81671e-05, gnorm=0.005, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=14144
2024-11-07 07:46:23 - progress_bar.py[line:274] - INFO: epoch 006:    315 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.771, ntokens=17383.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.65, wps=3292.5, ups=0.19, wpb=17383.8, bsz=1024, num_updates=2270, lr=4.83802e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=30, gb_free=13.1, wall=14196
2024-11-07 07:47:16 - progress_bar.py[line:274] - INFO: epoch 006:    325 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.783, ntokens=17343.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.76, wps=3257.5, ups=0.19, wpb=17343.9, bsz=1024, num_updates=2280, lr=4.85934e-05, gnorm=0.011, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=14250
2024-11-07 07:48:09 - progress_bar.py[line:274] - INFO: epoch 006:    335 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.727, ntokens=17256.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.24, wps=3265.9, ups=0.19, wpb=17256.9, bsz=1024, num_updates=2290, lr=4.88065e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=31, gb_free=13.6, wall=14302
2024-11-07 07:49:04 - progress_bar.py[line:274] - INFO: epoch 006:    345 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.731, ntokens=17219.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.28, wps=3133.8, ups=0.18, wpb=17219.7, bsz=1024, num_updates=2300, lr=4.90196e-05, gnorm=0.006, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=14357
2024-11-07 07:49:57 - progress_bar.py[line:274] - INFO: epoch 006:    355 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.791, ntokens=17660.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.84, wps=3320.4, ups=0.19, wpb=17660.4, bsz=1024, num_updates=2310, lr=4.92327e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=14411
2024-11-07 07:50:50 - progress_bar.py[line:274] - INFO: epoch 006:    365 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.765, ntokens=17557.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.6, wps=3291.3, ups=0.19, wpb=17557.2, bsz=1024, num_updates=2320, lr=4.94459e-05, gnorm=0.006, clip=0, loss_scale=2048, train_wall=30, gb_free=13, wall=14464
2024-11-07 07:51:43 - progress_bar.py[line:274] - INFO: epoch 006:    375 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.918, ntokens=17623.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=15.11, wps=3350, ups=0.19, wpb=17623.7, bsz=1024, num_updates=2330, lr=4.9659e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=30, gb_free=13.2, wall=14517
2024-11-07 07:52:34 - progress_bar.py[line:274] - INFO: epoch 006:    385 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.887, ntokens=17234.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.8, wps=3356.7, ups=0.19, wpb=17234.6, bsz=1024, num_updates=2340, lr=4.98721e-05, gnorm=0.006, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=14568
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt
2024-11-07 07:53:02 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 2346 updates
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_6.ptcp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt

cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_6.ptcp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt

cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt
2024-11-07 07:53:02 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cp: cp: cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt'cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt'cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt': File exists: File exists
: File exists

local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2024-11-07 07:54:52 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000

slice_id 7 seek offset 350000
slice_id 3 seek offset 150000
slice_id 5 seek offset 250000
2024-11-07 07:56:43 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 6 @ 2346 updates, score 0) (writing took 221.32699325602152 seconds)
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_6.pt
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000


local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000
slice_id 6 seek offset 300000
slice_id 2 seek offset 100000
slice_id 4 seek offset 200000
slice_id 1 seek offset 50000
2024-11-07 07:57:37 - train.py[line:336] - INFO: end of epoch 6 (average epoch stats below)
2024-11-07 07:57:37 - progress_bar.py[line:282] - INFO: epoch 006 | loss 0.002 | loss_v1 0 | loss_v2 0 | nll_loss 3.803 | ntokens 17288.1 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 13.95 | wps 2691.9 | ups 0.16 | wpb 17288.1 | bsz 1023 | num_updates 2346 | lr 5e-05 | gnorm 0.008 | clip 0 | loss_scale 2048 | train_wall 1185 | gb_free 13.3 | wall 14871
2024-11-07 07:57:37 - trainer.py[line:639] - INFO: loading train data for epoch 7
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-07 08:00:17 - trainer.py[line:703] - INFO: begin training epoch 7
2024-11-07 08:00:17 - train.py[line:297] - INFO: Start iterating over samples
2024-11-07 08:00:41 - progress_bar.py[line:274] - INFO: epoch 007:      4 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.832, ntokens=16697.9, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=14.24, wps=343.3, ups=0.02, wpb=16697.9, bsz=985.6, num_updates=2350, lr=4.99946e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=29, gb_free=13.5, wall=15054
2024-11-07 08:01:34 - progress_bar.py[line:274] - INFO: epoch 007:     14 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.788, ntokens=17597.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.81, wps=3305.6, ups=0.19, wpb=17597.9, bsz=1024, num_updates=2360, lr=4.9981e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=31, gb_free=12.7, wall=15108
2024-11-07 08:02:27 - progress_bar.py[line:274] - INFO: epoch 007:     24 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.767, ntokens=17490.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.61, wps=3292.3, ups=0.19, wpb=17490.6, bsz=1024, num_updates=2370, lr=4.99674e-05, gnorm=0.011, clip=0, loss_scale=2048, train_wall=31, gb_free=13.5, wall=15161
2024-11-07 08:03:20 - progress_bar.py[line:274] - INFO: epoch 007:     34 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.772, ntokens=17387.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.66, wps=3287.2, ups=0.19, wpb=17387.8, bsz=1024, num_updates=2380, lr=4.99537e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=31, gb_free=13.6, wall=15214
2024-11-07 08:04:13 - progress_bar.py[line:274] - INFO: epoch 007:     44 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.733, ntokens=17497.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.3, wps=3318, ups=0.19, wpb=17497.9, bsz=1024, num_updates=2390, lr=4.99401e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=15266
2024-11-07 08:05:06 - progress_bar.py[line:274] - INFO: epoch 007:     54 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.743, ntokens=17732.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.38, wps=3329.5, ups=0.19, wpb=17732.9, bsz=1024, num_updates=2400, lr=4.99265e-05, gnorm=0.006, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=15320
2024-11-07 08:05:59 - progress_bar.py[line:274] - INFO: epoch 007:     64 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.666, ntokens=17132.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.7, wps=3224.6, ups=0.19, wpb=17132.8, bsz=1024, num_updates=2410, lr=4.99129e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=30, gb_free=13.1, wall=15373
2024-11-07 08:06:53 - progress_bar.py[line:274] - INFO: epoch 007:     74 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.714, ntokens=17323.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.12, wps=3252.5, ups=0.19, wpb=17323.2, bsz=1024, num_updates=2420, lr=4.98993e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=31, gb_free=13.5, wall=15426
2024-11-07 08:07:46 - progress_bar.py[line:274] - INFO: epoch 007:     84 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.729, ntokens=17286.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.26, wps=3245.2, ups=0.19, wpb=17286.5, bsz=1024, num_updates=2430, lr=4.98857e-05, gnorm=0.006, clip=0, loss_scale=2048, train_wall=30, gb_free=13.4, wall=15479
2024-11-07 08:08:39 - progress_bar.py[line:274] - INFO: epoch 007:     94 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.693, ntokens=17300.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.93, wps=3273.4, ups=0.19, wpb=17300.5, bsz=1024, num_updates=2440, lr=4.98721e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=15532
2024-11-07 08:09:32 - progress_bar.py[line:274] - INFO: epoch 007:    104 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.777, ntokens=17739.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.71, wps=3328.4, ups=0.19, wpb=17739.7, bsz=1024, num_updates=2450, lr=4.98585e-05, gnorm=0.01, clip=0, loss_scale=2048, train_wall=30, gb_free=13.4, wall=15585
2024-11-07 08:10:25 - progress_bar.py[line:274] - INFO: epoch 007:    114 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.725, ntokens=17258.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.22, wps=3243.5, ups=0.19, wpb=17258.6, bsz=1024, num_updates=2460, lr=4.98449e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=15639
2024-11-07 08:11:19 - progress_bar.py[line:274] - INFO: epoch 007:    124 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.713, ntokens=17327.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.11, wps=3241.9, ups=0.19, wpb=17327.9, bsz=1024, num_updates=2470, lr=4.98313e-05, gnorm=0.006, clip=0, loss_scale=2048, train_wall=31, gb_free=13.6, wall=15692
2024-11-07 08:12:14 - progress_bar.py[line:274] - INFO: epoch 007:    134 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.686, ntokens=17358.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.87, wps=3118.9, ups=0.18, wpb=17358.6, bsz=1024, num_updates=2480, lr=4.98177e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=31, gb_free=13.6, wall=15748
2024-11-07 08:13:08 - progress_bar.py[line:274] - INFO: epoch 007:    144 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.712, ntokens=17150, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.1, wps=3211.6, ups=0.19, wpb=17150, bsz=1024, num_updates=2490, lr=4.98041e-05, gnorm=0.009, clip=0, loss_scale=2048, train_wall=30, gb_free=13.1, wall=15801
2024-11-07 08:14:01 - progress_bar.py[line:274] - INFO: epoch 007:    154 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.688, ntokens=17488.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.89, wps=3292.4, ups=0.19, wpb=17488.6, bsz=1024, num_updates=2500, lr=4.97905e-05, gnorm=0.008, clip=0, loss_scale=2048, train_wall=30, gb_free=12.8, wall=15854
2024-11-07 08:14:54 - progress_bar.py[line:274] - INFO: epoch 007:    164 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.655, ntokens=17129.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.6, wps=3247.7, ups=0.19, wpb=17129.6, bsz=1024, num_updates=2510, lr=4.97769e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=15907
2024-11-07 08:15:47 - progress_bar.py[line:274] - INFO: epoch 007:    174 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.719, ntokens=17370.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.17, wps=3269.5, ups=0.19, wpb=17370.5, bsz=1024, num_updates=2520, lr=4.97633e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=30, gb_free=13.5, wall=15960
2024-11-07 08:16:39 - progress_bar.py[line:274] - INFO: epoch 007:    184 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.652, ntokens=17259.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.57, wps=3279.1, ups=0.19, wpb=17259.4, bsz=1024, num_updates=2530, lr=4.97497e-05, gnorm=0.011, clip=0, loss_scale=2048, train_wall=30, gb_free=13.3, wall=16013
2024-11-07 08:17:33 - progress_bar.py[line:274] - INFO: epoch 007:    194 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.69, ntokens=17163, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.9, wps=3215.5, ups=0.19, wpb=17163, bsz=1024, num_updates=2540, lr=4.97361e-05, gnorm=0.011, clip=0, loss_scale=2048, train_wall=30, gb_free=13.3, wall=16066
2024-11-07 08:18:26 - progress_bar.py[line:274] - INFO: epoch 007:    204 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.692, ntokens=17168.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.92, wps=3191, ups=0.19, wpb=17168.6, bsz=1024, num_updates=2550, lr=4.97225e-05, gnorm=0.007, clip=0, loss_scale=2048, train_wall=30, gb_free=13.6, wall=16120
2024-11-07 08:19:20 - progress_bar.py[line:274] - INFO: epoch 007:    214 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.627, ntokens=17163.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.35, wps=3209.2, ups=0.19, wpb=17163.3, bsz=1024, num_updates=2560, lr=4.97089e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=30, gb_free=13.4, wall=16173
2024-11-07 08:20:13 - progress_bar.py[line:274] - INFO: epoch 007:    224 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.684, ntokens=17360.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.85, wps=3271.9, ups=0.19, wpb=17360.6, bsz=1024, num_updates=2570, lr=4.96953e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=16227
2024-11-07 08:21:07 - progress_bar.py[line:274] - INFO: epoch 007:    234 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.64, ntokens=17136.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.46, wps=3178.2, ups=0.19, wpb=17136.7, bsz=1024, num_updates=2580, lr=4.96817e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=16280
2024-11-07 08:22:00 - progress_bar.py[line:274] - INFO: epoch 007:    244 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.659, ntokens=17349.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.64, wps=3272.1, ups=0.19, wpb=17349.8, bsz=1024, num_updates=2590, lr=4.96681e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=30, gb_free=13.3, wall=16333
2024-11-07 08:22:53 - progress_bar.py[line:274] - INFO: epoch 007:    254 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.699, ntokens=17722.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.99, wps=3353.2, ups=0.19, wpb=17722.3, bsz=1024, num_updates=2600, lr=4.96545e-05, gnorm=0.013, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=16386
2024-11-07 08:23:46 - progress_bar.py[line:274] - INFO: epoch 007:    264 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.686, ntokens=17398.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.87, wps=3260.1, ups=0.19, wpb=17398.3, bsz=1024, num_updates=2610, lr=4.96409e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=30, gb_free=13.2, wall=16440
2024-11-07 08:24:39 - progress_bar.py[line:274] - INFO: epoch 007:    274 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.639, ntokens=17221.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.46, wps=3240.1, ups=0.19, wpb=17221.4, bsz=1024, num_updates=2620, lr=4.96273e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=16493
2024-11-07 08:25:33 - progress_bar.py[line:274] - INFO: epoch 007:    284 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.592, ntokens=17171.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.06, wps=3222.4, ups=0.19, wpb=17171.3, bsz=1024, num_updates=2630, lr=4.96136e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=16546
2024-11-07 08:26:26 - progress_bar.py[line:274] - INFO: epoch 007:    294 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.665, ntokens=17258.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.69, wps=3234.8, ups=0.19, wpb=17258.2, bsz=1024, num_updates=2640, lr=4.96e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=16599
2024-11-07 08:27:19 - progress_bar.py[line:274] - INFO: epoch 007:    304 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.654, ntokens=17431.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.59, wps=3291.3, ups=0.19, wpb=17431.3, bsz=1024, num_updates=2650, lr=4.95864e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=30, gb_free=13.4, wall=16652
2024-11-07 08:28:12 - progress_bar.py[line:274] - INFO: epoch 007:    314 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.689, ntokens=17414.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.9, wps=3298.3, ups=0.19, wpb=17414.6, bsz=1024, num_updates=2660, lr=4.95728e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=16705
2024-11-07 08:29:05 - progress_bar.py[line:274] - INFO: epoch 007:    324 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.642, ntokens=17356, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.48, wps=3248.1, ups=0.19, wpb=17356, bsz=1024, num_updates=2670, lr=4.95592e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=30, gb_free=13, wall=16759
2024-11-07 08:29:58 - progress_bar.py[line:274] - INFO: epoch 007:    334 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.635, ntokens=17306.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.42, wps=3246.3, ups=0.19, wpb=17306.2, bsz=1024, num_updates=2680, lr=4.95456e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=16812
2024-11-07 08:30:51 - progress_bar.py[line:274] - INFO: epoch 007:    344 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.62, ntokens=17215.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.29, wps=3273.6, ups=0.19, wpb=17215.6, bsz=1024, num_updates=2690, lr=4.9532e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=16865
2024-11-07 08:31:44 - progress_bar.py[line:274] - INFO: epoch 007:    354 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.664, ntokens=17631.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.67, wps=3314.9, ups=0.19, wpb=17631.8, bsz=1024, num_updates=2700, lr=4.95184e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=31, gb_free=13.3, wall=16918
2024-11-07 08:32:38 - progress_bar.py[line:274] - INFO: epoch 007:    364 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.672, ntokens=17736.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.75, wps=3329.2, ups=0.19, wpb=17736.2, bsz=1024, num_updates=2710, lr=4.95048e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=16971
2024-11-07 08:33:30 - progress_bar.py[line:274] - INFO: epoch 007:    374 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.763, ntokens=17579.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.58, wps=3379.2, ups=0.19, wpb=17579.1, bsz=1024, num_updates=2720, lr=4.94912e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=30, gb_free=13.4, wall=17023
2024-11-07 08:34:21 - progress_bar.py[line:274] - INFO: epoch 007:    384 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.836, ntokens=17637.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=14.28, wps=3448.6, ups=0.2, wpb=17637.2, bsz=1024, num_updates=2730, lr=4.94776e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=30, gb_free=13.4, wall=17074
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt2024-11-07 08:34:53 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 2737 updates

cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_7.ptcp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_7.ptcp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt


cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt
2024-11-07 08:34:53 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cp: cp: cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt'cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt'cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt': File exists
: File exists: File exists

local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
2024-11-07 08:36:43 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000

slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
slice_id 3 seek offset 150000
2024-11-07 08:38:35 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 7 @ 2737 updates, score 0) (writing took 221.51980265500606 seconds)
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_7.pt
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000
slice_id 6 seek offset 300000
slice_id 4 seek offset 200000
slice_id 2 seek offset 100000
slice_id 5 seek offset 250000
2024-11-07 08:39:29 - train.py[line:336] - INFO: end of epoch 7 (average epoch stats below)
2024-11-07 08:39:29 - progress_bar.py[line:282] - INFO: epoch 007 | loss 0.002 | loss_v1 0 | loss_v2 0 | nll_loss 3.697 | ntokens 17356.1 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.97 | wps 2701.9 | ups 0.16 | wpb 17356.1 | bsz 1023 | num_updates 2737 | lr 4.94681e-05 | gnorm 0.008 | clip 0 | loss_scale 4096 | train_wall 1187 | gb_free 13.2 | wall 17383
2024-11-07 08:39:29 - trainer.py[line:639] - INFO: loading train data for epoch 8
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-07 08:42:09 - trainer.py[line:703] - INFO: begin training epoch 8
2024-11-07 08:42:09 - train.py[line:297] - INFO: Start iterating over samples
2024-11-07 08:42:27 - progress_bar.py[line:274] - INFO: epoch 008:      3 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.745, ntokens=16701.5, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=13.4, wps=343.1, ups=0.02, wpb=16701.5, bsz=985.6, num_updates=2740, lr=4.9464e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=29, gb_free=13.6, wall=17561
2024-11-07 08:43:21 - progress_bar.py[line:274] - INFO: epoch 008:     13 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.613, ntokens=17282.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.24, wps=3254.8, ups=0.19, wpb=17282.2, bsz=1024, num_updates=2750, lr=4.94504e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=17614
2024-11-07 08:44:14 - progress_bar.py[line:274] - INFO: epoch 008:     23 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.678, ntokens=17443.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.8, wps=3275.4, ups=0.19, wpb=17443.5, bsz=1024, num_updates=2760, lr=4.94368e-05, gnorm=0.012, clip=0, loss_scale=4096, train_wall=30, gb_free=13.4, wall=17667
2024-11-07 08:45:07 - progress_bar.py[line:274] - INFO: epoch 008:     33 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.618, ntokens=17217.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.28, wps=3221.6, ups=0.19, wpb=17217.5, bsz=1024, num_updates=2770, lr=4.94232e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=31, gb_free=13.4, wall=17721
2024-11-07 08:46:01 - progress_bar.py[line:274] - INFO: epoch 008:     43 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.617, ntokens=17338.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.27, wps=3257, ups=0.19, wpb=17338.6, bsz=1024, num_updates=2780, lr=4.94096e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=30, gb_free=13.3, wall=17774
2024-11-07 08:46:53 - progress_bar.py[line:274] - INFO: epoch 008:     53 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.6, ntokens=17443.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.12, wps=3314.5, ups=0.19, wpb=17443.7, bsz=1024, num_updates=2790, lr=4.9396e-05, gnorm=0.013, clip=0, loss_scale=4096, train_wall=30, gb_free=13.4, wall=17827
2024-11-07 08:47:47 - progress_bar.py[line:274] - INFO: epoch 008:     63 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.546, ntokens=17049.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.68, wps=3174.5, ups=0.19, wpb=17049.6, bsz=1024, num_updates=2800, lr=4.93824e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=17880
2024-11-07 08:48:40 - progress_bar.py[line:274] - INFO: epoch 008:     73 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.621, ntokens=17328.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.3, wps=3267.6, ups=0.19, wpb=17328.1, bsz=1024, num_updates=2810, lr=4.93688e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=17933
2024-11-07 08:49:36 - progress_bar.py[line:274] - INFO: epoch 008:     83 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.619, ntokens=17280.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.28, wps=3092.5, ups=0.18, wpb=17280.7, bsz=1024, num_updates=2820, lr=4.93552e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=45, gb_free=13.4, wall=17989
2024-11-07 08:50:31 - progress_bar.py[line:274] - INFO: epoch 008:     93 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.577, ntokens=17254.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.94, wps=3106.9, ups=0.18, wpb=17254.8, bsz=1024, num_updates=2830, lr=4.93416e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=55, gb_free=13.5, wall=18045
2024-11-07 08:51:27 - progress_bar.py[line:274] - INFO: epoch 008:    103 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.637, ntokens=17546.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.44, wps=3171.7, ups=0.18, wpb=17546.9, bsz=1024, num_updates=2840, lr=4.9328e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=55, gb_free=13.4, wall=18100
2024-11-07 08:52:19 - progress_bar.py[line:274] - INFO: epoch 008:    113 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.602, ntokens=17328.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.14, wps=3301.1, ups=0.19, wpb=17328.4, bsz=1024, num_updates=2850, lr=4.93144e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=52, gb_free=13.6, wall=18153
2024-11-07 08:53:11 - progress_bar.py[line:274] - INFO: epoch 008:    123 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.607, ntokens=17307.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.19, wps=3353.1, ups=0.19, wpb=17307.3, bsz=1024, num_updates=2860, lr=4.93008e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=47, gb_free=13, wall=18204
2024-11-07 08:54:03 - progress_bar.py[line:274] - INFO: epoch 008:    133 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.626, ntokens=17507.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.34, wps=3367.8, ups=0.19, wpb=17507.4, bsz=1024, num_updates=2870, lr=4.92872e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=33, gb_free=13.6, wall=18256
2024-11-07 08:54:56 - progress_bar.py[line:274] - INFO: epoch 008:    143 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.562, ntokens=17107.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.81, wps=3216, ups=0.19, wpb=17107.7, bsz=1024, num_updates=2880, lr=4.92735e-05, gnorm=0.011, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=18309
2024-11-07 08:55:49 - progress_bar.py[line:274] - INFO: epoch 008:    153 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.595, ntokens=17348.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.08, wps=3239.9, ups=0.19, wpb=17348.1, bsz=1024, num_updates=2890, lr=4.92599e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=18363
2024-11-07 08:56:43 - progress_bar.py[line:274] - INFO: epoch 008:    163 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.576, ntokens=17290.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.93, wps=3239.9, ups=0.19, wpb=17290.9, bsz=1024, num_updates=2900, lr=4.92463e-05, gnorm=0.006, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=18416
2024-11-07 08:57:36 - progress_bar.py[line:274] - INFO: epoch 008:    173 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.584, ntokens=17269.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.99, wps=3274.4, ups=0.19, wpb=17269.6, bsz=1024, num_updates=2910, lr=4.92327e-05, gnorm=0.006, clip=0, loss_scale=4096, train_wall=31, gb_free=13.5, wall=18469
2024-11-07 08:58:29 - progress_bar.py[line:274] - INFO: epoch 008:    183 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.568, ntokens=17277, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.86, wps=3260.4, ups=0.19, wpb=17277, bsz=1024, num_updates=2920, lr=4.92191e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=18522
2024-11-07 08:59:21 - progress_bar.py[line:274] - INFO: epoch 008:    193 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.574, ntokens=17276.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.91, wps=3267.4, ups=0.19, wpb=17276.4, bsz=1024, num_updates=2930, lr=4.92055e-05, gnorm=0.006, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=18575
2024-11-07 09:00:15 - progress_bar.py[line:274] - INFO: epoch 008:    203 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.631, ntokens=17350.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.38, wps=3265.6, ups=0.19, wpb=17350.6, bsz=1024, num_updates=2940, lr=4.91919e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=18628
2024-11-07 09:01:08 - progress_bar.py[line:274] - INFO: epoch 008:    213 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.52, ntokens=17130.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.47, wps=3188.3, ups=0.19, wpb=17130.7, bsz=1024, num_updates=2950, lr=4.91783e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=18682
2024-11-07 09:02:02 - progress_bar.py[line:274] - INFO: epoch 008:    223 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.577, ntokens=17186.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.93, wps=3196.3, ups=0.19, wpb=17186.4, bsz=1024, num_updates=2960, lr=4.91647e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=18736
2024-11-07 09:02:55 - progress_bar.py[line:274] - INFO: epoch 008:    233 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.579, ntokens=17446.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.95, wps=3269.5, ups=0.19, wpb=17446.4, bsz=1024, num_updates=2970, lr=4.91511e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=18789
2024-11-07 09:03:49 - progress_bar.py[line:274] - INFO: epoch 008:    243 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.557, ntokens=17269.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.77, wps=3231.9, ups=0.19, wpb=17269.2, bsz=1024, num_updates=2980, lr=4.91375e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=30, gb_free=13.4, wall=18842
2024-11-07 09:04:42 - progress_bar.py[line:274] - INFO: epoch 008:    253 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.594, ntokens=17507.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.08, wps=3327.6, ups=0.19, wpb=17507.5, bsz=1024, num_updates=2990, lr=4.91239e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=18895
2024-11-07 09:05:34 - progress_bar.py[line:274] - INFO: epoch 008:    263 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.58, ntokens=17368, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.96, wps=3277.5, ups=0.19, wpb=17368, bsz=1024, num_updates=3000, lr=4.91103e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=31, gb_free=13.5, wall=18948
2024-11-07 09:06:28 - progress_bar.py[line:274] - INFO: epoch 008:    273 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.581, ntokens=17322.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.97, wps=3246.4, ups=0.19, wpb=17322.9, bsz=1024, num_updates=3010, lr=4.90967e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=30, gb_free=13.3, wall=19001
2024-11-07 09:07:21 - progress_bar.py[line:274] - INFO: epoch 008:    283 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.525, ntokens=17312.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.51, wps=3263.2, ups=0.19, wpb=17312.1, bsz=1024, num_updates=3020, lr=4.90831e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=30, gb_free=13.4, wall=19054
2024-11-07 09:08:15 - progress_bar.py[line:274] - INFO: epoch 008:    293 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.592, ntokens=17304.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.06, wps=3225.4, ups=0.19, wpb=17304.7, bsz=1024, num_updates=3030, lr=4.90695e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=30, gb_free=13.4, wall=19108
2024-11-07 09:09:08 - progress_bar.py[line:274] - INFO: epoch 008:    303 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.548, ntokens=17309.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.7, wps=3260.9, ups=0.19, wpb=17309.9, bsz=1024, num_updates=3040, lr=4.90559e-05, gnorm=0.009, clip=0, loss_scale=4096, train_wall=30, gb_free=13.5, wall=19161
2024-11-07 09:10:01 - progress_bar.py[line:274] - INFO: epoch 008:    313 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.561, ntokens=17204.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.8, wps=3226.9, ups=0.19, wpb=17204.9, bsz=1024, num_updates=3050, lr=4.90423e-05, gnorm=0.007, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=19214
2024-11-07 09:10:54 - progress_bar.py[line:274] - INFO: epoch 008:    323 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.547, ntokens=17271.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.69, wps=3252.8, ups=0.19, wpb=17271.6, bsz=1024, num_updates=3060, lr=4.90287e-05, gnorm=0.008, clip=0, loss_scale=4096, train_wall=30, gb_free=13.1, wall=19268
2024-11-07 09:11:47 - progress_bar.py[line:274] - INFO: epoch 008:    333 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.562, ntokens=17320.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.81, wps=3262.6, ups=0.19, wpb=17320.7, bsz=1024, num_updates=3070, lr=4.90151e-05, gnorm=0.01, clip=0, loss_scale=4096, train_wall=30, gb_free=13.6, wall=19321
2024-11-07 09:12:40 - progress_bar.py[line:274] - INFO: epoch 008:    343 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.55, ntokens=17337.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.71, wps=3256.3, ups=0.19, wpb=17337.1, bsz=1024, num_updates=3080, lr=4.90015e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=19374
2024-11-07 09:13:34 - progress_bar.py[line:274] - INFO: epoch 008:    353 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.583, ntokens=17594.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.99, wps=3274.3, ups=0.19, wpb=17594.3, bsz=1024, num_updates=3090, lr=4.89879e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=30, gb_free=13.4, wall=19428
2024-11-07 09:14:27 - progress_bar.py[line:274] - INFO: epoch 008:    363 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.56, ntokens=17590.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.79, wps=3335.5, ups=0.19, wpb=17590.3, bsz=1024, num_updates=3100, lr=4.89743e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=19480
2024-11-07 09:15:20 - progress_bar.py[line:274] - INFO: epoch 008:    373 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.683, ntokens=17664.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.85, wps=3302.7, ups=0.19, wpb=17664.5, bsz=1024, num_updates=3110, lr=4.89607e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=30, gb_free=12.8, wall=19534
2024-11-07 09:16:12 - progress_bar.py[line:274] - INFO: epoch 008:    383 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.74, ntokens=17433.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=13.36, wps=3397.5, ups=0.19, wpb=17433.6, bsz=1024, num_updates=3120, lr=4.89471e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=30, gb_free=13.2, wall=19585
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt2024-11-07 09:16:50 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 8 @ 3128 updates

cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt
2024-11-07 09:16:50 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cp: cp: cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt'cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt'cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt': File exists
: File exists: File exists

local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
2024-11-07 09:18:40 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000


slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
slice_id 5 seek offset 250000
2024-11-07 09:20:31 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 8 @ 3128 updates, score 0) (writing took 221.2953284799878 seconds)
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_8.pt
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000
slice_id 3 seek offset 150000
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000
slice_id 6 seek offset 300000
slice_id 2 seek offset 100000
slice_id 4 seek offset 200000
2024-11-07 09:21:26 - train.py[line:336] - INFO: end of epoch 8 (average epoch stats below)
2024-11-07 09:21:26 - progress_bar.py[line:282] - INFO: epoch 008 | loss 0.002 | loss_v1 0 | loss_v2 0 | nll_loss 3.595 | ntokens 17324.5 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.09 | wps 2691.8 | ups 0.16 | wpb 17324.5 | bsz 1023 | num_updates 3128 | lr 4.89362e-05 | gnorm 0.008 | clip 0 | loss_scale 8192 | train_wall 1293 | gb_free 13.2 | wall 19899
2024-11-07 09:21:26 - trainer.py[line:639] - INFO: loading train data for epoch 9
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-07 09:24:06 - trainer.py[line:703] - INFO: begin training epoch 9
2024-11-07 09:24:06 - train.py[line:297] - INFO: Start iterating over samples
2024-11-07 09:24:19 - progress_bar.py[line:274] - INFO: epoch 009:      2 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.695, ntokens=16820.7, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=12.96, wps=345.3, ups=0.02, wpb=16820.7, bsz=985.6, num_updates=3130, lr=4.89334e-05, gnorm=0.005, clip=0, loss_scale=8192, train_wall=29, gb_free=13.5, wall=20072
2024-11-07 09:25:12 - progress_bar.py[line:274] - INFO: epoch 009:     12 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.576, ntokens=17388.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.93, wps=3276, ups=0.19, wpb=17388.3, bsz=1024, num_updates=3140, lr=4.89198e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=31, gb_free=13.6, wall=20125
2024-11-07 09:26:05 - progress_bar.py[line:274] - INFO: epoch 009:     22 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.579, ntokens=17392.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.95, wps=3254.8, ups=0.19, wpb=17392.7, bsz=1024, num_updates=3150, lr=4.89062e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=31, gb_free=13.6, wall=20179
2024-11-07 09:26:58 - progress_bar.py[line:274] - INFO: epoch 009:     32 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.533, ntokens=17174.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.58, wps=3252.3, ups=0.19, wpb=17174.6, bsz=1024, num_updates=3160, lr=4.88926e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=20232
2024-11-07 09:27:51 - progress_bar.py[line:274] - INFO: epoch 009:     42 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.557, ntokens=17454.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.77, wps=3283.1, ups=0.19, wpb=17454.8, bsz=1024, num_updates=3170, lr=4.8879e-05, gnorm=0.005, clip=0, loss_scale=8192, train_wall=30, gb_free=13.2, wall=20285
2024-11-07 09:28:44 - progress_bar.py[line:274] - INFO: epoch 009:     52 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.52, ntokens=17346.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.47, wps=3299.6, ups=0.19, wpb=17346.3, bsz=1024, num_updates=3180, lr=4.88654e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=20337
2024-11-07 09:29:37 - progress_bar.py[line:274] - INFO: epoch 009:     62 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.469, ntokens=17143.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.07, wps=3233.5, ups=0.19, wpb=17143.2, bsz=1024, num_updates=3190, lr=4.88518e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=20390
2024-11-07 09:30:30 - progress_bar.py[line:274] - INFO: epoch 009:     72 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.497, ntokens=17153.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.29, wps=3243.8, ups=0.19, wpb=17153.5, bsz=1024, num_updates=3200, lr=4.88382e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=30, gb_free=13.2, wall=20443
2024-11-07 09:31:23 - progress_bar.py[line:274] - INFO: epoch 009:     82 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.592, ntokens=17614.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.06, wps=3321.8, ups=0.19, wpb=17614.2, bsz=1024, num_updates=3210, lr=4.88246e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=30, gb_free=13.3, wall=20496
2024-11-07 09:32:16 - progress_bar.py[line:274] - INFO: epoch 009:     92 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.521, ntokens=17204, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.48, wps=3231, ups=0.19, wpb=17204, bsz=1024, num_updates=3220, lr=4.8811e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=20550
2024-11-07 09:33:09 - progress_bar.py[line:274] - INFO: epoch 009:    102 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.571, ntokens=17617.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.89, wps=3324.8, ups=0.19, wpb=17617.7, bsz=1024, num_updates=3230, lr=4.87974e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=20603
2024-11-07 09:34:02 - progress_bar.py[line:274] - INFO: epoch 009:    112 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.524, ntokens=17149, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.5, wps=3215.7, ups=0.19, wpb=17149, bsz=1024, num_updates=3240, lr=4.87838e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=20656
2024-11-07 09:34:56 - progress_bar.py[line:274] - INFO: epoch 009:    122 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.549, ntokens=17441.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.7, wps=3269.3, ups=0.19, wpb=17441.8, bsz=1024, num_updates=3250, lr=4.87702e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=20709
2024-11-07 09:35:49 - progress_bar.py[line:274] - INFO: epoch 009:    132 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.565, ntokens=17554.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.84, wps=3317.6, ups=0.19, wpb=17554.6, bsz=1024, num_updates=3260, lr=4.87566e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=20762
2024-11-07 09:36:42 - progress_bar.py[line:274] - INFO: epoch 009:    142 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.494, ntokens=16985.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.27, wps=3163.1, ups=0.19, wpb=16985.9, bsz=1024, num_updates=3270, lr=4.8743e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=20816
2024-11-07 09:37:35 - progress_bar.py[line:274] - INFO: epoch 009:    152 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.507, ntokens=17253.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.37, wps=3245.9, ups=0.19, wpb=17253.5, bsz=1024, num_updates=3280, lr=4.87294e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=20869
2024-11-07 09:38:29 - progress_bar.py[line:274] - INFO: epoch 009:    162 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.521, ntokens=17271.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.48, wps=3252.1, ups=0.19, wpb=17271.9, bsz=1024, num_updates=3290, lr=4.87158e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=20922
2024-11-07 09:39:22 - progress_bar.py[line:274] - INFO: epoch 009:    172 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.525, ntokens=17344.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.51, wps=3226.3, ups=0.19, wpb=17344.3, bsz=1024, num_updates=3300, lr=4.87022e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=20976
2024-11-07 09:40:15 - progress_bar.py[line:274] - INFO: epoch 009:    182 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.528, ntokens=17533.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.53, wps=3328.2, ups=0.19, wpb=17533.2, bsz=1024, num_updates=3310, lr=4.86886e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=30, gb_free=13.4, wall=21029
2024-11-07 09:41:08 - progress_bar.py[line:274] - INFO: epoch 009:    192 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.505, ntokens=17045.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.35, wps=3191.2, ups=0.19, wpb=17045.2, bsz=1024, num_updates=3320, lr=4.8675e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=30, gb_free=13.4, wall=21082
2024-11-07 09:42:01 - progress_bar.py[line:274] - INFO: epoch 009:    202 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.488, ntokens=17216.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.22, wps=3269.2, ups=0.19, wpb=17216.2, bsz=1024, num_updates=3330, lr=4.86614e-05, gnorm=0.005, clip=0, loss_scale=8192, train_wall=31, gb_free=13.6, wall=21135
2024-11-07 09:42:54 - progress_bar.py[line:274] - INFO: epoch 009:    212 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.491, ntokens=16984.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.24, wps=3218.8, ups=0.19, wpb=16984.7, bsz=1024, num_updates=3340, lr=4.86478e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=21187
2024-11-07 09:43:46 - progress_bar.py[line:274] - INFO: epoch 009:    222 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.47, ntokens=17054.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.08, wps=3253.4, ups=0.19, wpb=17054.7, bsz=1024, num_updates=3350, lr=4.86342e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=21240
2024-11-07 09:44:39 - progress_bar.py[line:274] - INFO: epoch 009:    232 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.508, ntokens=17538.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.38, wps=3302.6, ups=0.19, wpb=17538.4, bsz=1024, num_updates=3360, lr=4.86206e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=21293
2024-11-07 09:45:32 - progress_bar.py[line:274] - INFO: epoch 009:    242 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.46, ntokens=17091.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11, wps=3232.3, ups=0.19, wpb=17091.4, bsz=1024, num_updates=3370, lr=4.8607e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=30, gb_free=13.4, wall=21346
2024-11-07 09:46:25 - progress_bar.py[line:274] - INFO: epoch 009:    252 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.54, ntokens=17728.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.63, wps=3334, ups=0.19, wpb=17728.3, bsz=1024, num_updates=3380, lr=4.85934e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=30, gb_free=13.4, wall=21399
2024-11-07 09:47:19 - progress_bar.py[line:274] - INFO: epoch 009:    262 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.523, ntokens=17493.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.5, wps=3295.6, ups=0.19, wpb=17493.2, bsz=1024, num_updates=3390, lr=4.85797e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=31, gb_free=13.5, wall=21452
2024-11-07 09:48:11 - progress_bar.py[line:274] - INFO: epoch 009:    272 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.527, ntokens=17326, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.53, wps=3278.5, ups=0.19, wpb=17326, bsz=1024, num_updates=3400, lr=4.85661e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=21505
2024-11-07 09:49:04 - progress_bar.py[line:274] - INFO: epoch 009:    282 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.457, ntokens=17167.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.98, wps=3272.4, ups=0.19, wpb=17167.6, bsz=1024, num_updates=3410, lr=4.85525e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=30, gb_free=13.4, wall=21557
2024-11-07 09:49:57 - progress_bar.py[line:274] - INFO: epoch 009:    292 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.503, ntokens=17148.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.33, wps=3237.1, ups=0.19, wpb=17148.2, bsz=1024, num_updates=3420, lr=4.85389e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=30, gb_free=13.3, wall=21610
2024-11-07 09:50:50 - progress_bar.py[line:274] - INFO: epoch 009:    302 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.453, ntokens=17146.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.95, wps=3237.2, ups=0.19, wpb=17146.4, bsz=1024, num_updates=3430, lr=4.85253e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=31, gb_free=13.5, wall=21663
2024-11-07 09:51:43 - progress_bar.py[line:274] - INFO: epoch 009:    312 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.525, ntokens=17286.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.51, wps=3277.8, ups=0.19, wpb=17286.2, bsz=1024, num_updates=3440, lr=4.85117e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=21716
2024-11-07 09:52:36 - progress_bar.py[line:274] - INFO: epoch 009:    322 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.499, ntokens=17275.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.31, wps=3231.2, ups=0.19, wpb=17275.4, bsz=1024, num_updates=3450, lr=4.84981e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=30, gb_free=13.4, wall=21769
2024-11-07 09:53:29 - progress_bar.py[line:274] - INFO: epoch 009:    332 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.48, ntokens=17253.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.16, wps=3265.9, ups=0.19, wpb=17253.2, bsz=1024, num_updates=3460, lr=4.84845e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=30, gb_free=13.4, wall=21822
2024-11-07 09:54:22 - progress_bar.py[line:274] - INFO: epoch 009:    342 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.49, ntokens=17484.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.24, wps=3291, ups=0.19, wpb=17484.5, bsz=1024, num_updates=3470, lr=4.84709e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=21875
2024-11-07 09:55:15 - progress_bar.py[line:274] - INFO: epoch 009:    352 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.501, ntokens=17329.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.33, wps=3278.6, ups=0.19, wpb=17329.3, bsz=1024, num_updates=3480, lr=4.84573e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=21928
2024-11-07 09:56:08 - progress_bar.py[line:274] - INFO: epoch 009:    362 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.506, ntokens=17638.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.36, wps=3308.8, ups=0.19, wpb=17638.4, bsz=1024, num_updates=3490, lr=4.84437e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=30, gb_free=13.4, wall=21982
2024-11-07 09:57:00 - progress_bar.py[line:274] - INFO: epoch 009:    372 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.651, ntokens=17953.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.56, wps=3430.6, ups=0.19, wpb=17953.3, bsz=1024, num_updates=3500, lr=4.84301e-05, gnorm=0.007, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=22034
2024-11-07 09:57:53 - progress_bar.py[line:274] - INFO: epoch 009:    382 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.67, ntokens=17403.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.73, wps=3305.1, ups=0.19, wpb=17403.6, bsz=1024, num_updates=3510, lr=4.84165e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=30, gb_free=13.4, wall=22087
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt2024-11-07 09:58:35 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 9 @ 3519 updates

cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_9.ptcp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt

cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_9.ptcp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt

cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt
2024-11-07 09:58:35 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cp: cp: cp: cp: cp: cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt'cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt'cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt'cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt'cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt'cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt': File exists: File exists

: File exists: File exists: File exists

: File exists

local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
2024-11-07 09:59:45 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000

slice_id 6 seek offset 300000
slice_id 4 seek offset 200000
slice_id 2 seek offset 100000
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping



file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000



slice_id 3 seek offset 150000
slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
slice_id 5 seek offset 250000
2024-11-07 10:02:07 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 9 @ 3519 updates, score 0) (writing took 211.15634601100464 seconds)
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_9.pt
2024-11-07 10:03:01 - train.py[line:336] - INFO: end of epoch 9 (average epoch stats below)
2024-11-07 10:03:01 - progress_bar.py[line:282] - INFO: epoch 009 | loss 0.002 | loss_v1 0 | loss_v2 0 | nll_loss 3.527 | ntokens 17320.1 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.53 | wps 2713.9 | ups 0.16 | wpb 17320.1 | bsz 1023 | num_updates 3519 | lr 4.84043e-05 | gnorm 0.007 | clip 0 | loss_scale 8192 | train_wall 1186 | gb_free 13.2 | wall 22395
2024-11-07 10:03:01 - trainer.py[line:639] - INFO: loading train data for epoch 10
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-07 10:05:41 - trainer.py[line:703] - INFO: begin training epoch 10
2024-11-07 10:05:41 - train.py[line:297] - INFO: Start iterating over samples
2024-11-07 10:05:49 - progress_bar.py[line:274] - INFO: epoch 010:      1 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.66, ntokens=16894.9, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=12.64, wps=355, ups=0.02, wpb=16894.9, bsz=985.6, num_updates=3520, lr=4.84029e-05, gnorm=0.006, clip=0, loss_scale=8192, train_wall=29, gb_free=13.4, wall=22562
2024-11-07 10:06:42 - progress_bar.py[line:274] - INFO: epoch 010:     11 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.532, ntokens=17520, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.57, wps=3328, ups=0.19, wpb=17520, bsz=1024, num_updates=3530, lr=4.83893e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=22615
2024-11-07 10:07:35 - progress_bar.py[line:274] - INFO: epoch 010:     21 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.505, ntokens=17302.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.35, wps=3267.2, ups=0.19, wpb=17302.3, bsz=1024, num_updates=3540, lr=4.83757e-05, gnorm=0.01, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=22668
2024-11-07 10:08:28 - progress_bar.py[line:274] - INFO: epoch 010:     31 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.507, ntokens=17263.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.37, wps=3254, ups=0.19, wpb=17263.1, bsz=1024, num_updates=3550, lr=4.83621e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=30, gb_free=13.1, wall=22721
2024-11-07 10:09:21 - progress_bar.py[line:274] - INFO: epoch 010:     41 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.498, ntokens=17433, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.3, wps=3286.8, ups=0.19, wpb=17433, bsz=1024, num_updates=3560, lr=4.83485e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=31, gb_free=13.4, wall=22774
2024-11-07 10:10:14 - progress_bar.py[line:274] - INFO: epoch 010:     51 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.495, ntokens=17524.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.28, wps=3288.7, ups=0.19, wpb=17524.4, bsz=1024, num_updates=3570, lr=4.83349e-05, gnorm=0.009, clip=0, loss_scale=8192, train_wall=30, gb_free=13.5, wall=22827
2024-11-07 10:11:07 - progress_bar.py[line:274] - INFO: epoch 010:     61 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.394, ntokens=17038, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.51, wps=3203.3, ups=0.19, wpb=17038, bsz=1024, num_updates=3580, lr=4.83213e-05, gnorm=0.008, clip=0, loss_scale=8192, train_wall=30, gb_free=13.6, wall=22881
2024-11-07 10:12:01 - progress_bar.py[line:274] - INFO: epoch 010:     71 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.44, ntokens=17128.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.86, wps=3195, ups=0.19, wpb=17128.8, bsz=1024, num_updates=3590, lr=4.83077e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=22934
2024-11-07 10:12:54 - progress_bar.py[line:274] - INFO: epoch 010:     81 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.53, ntokens=17500.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.55, wps=3268.7, ups=0.19, wpb=17500.4, bsz=1024, num_updates=3600, lr=4.82941e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=30, gb_free=13.4, wall=22988
2024-11-07 10:13:47 - progress_bar.py[line:274] - INFO: epoch 010:     91 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.457, ntokens=17293.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.98, wps=3252.3, ups=0.19, wpb=17293.7, bsz=1024, num_updates=3610, lr=4.82805e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=30, gb_free=13.3, wall=23041
2024-11-07 10:14:41 - progress_bar.py[line:274] - INFO: epoch 010:    101 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.496, ntokens=17392.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.28, wps=3254.5, ups=0.19, wpb=17392.6, bsz=1024, num_updates=3620, lr=4.82669e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=30, gb_free=13.4, wall=23094
2024-11-07 10:15:34 - progress_bar.py[line:274] - INFO: epoch 010:    111 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.482, ntokens=17176.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.17, wps=3214.4, ups=0.19, wpb=17176.8, bsz=1024, num_updates=3630, lr=4.82533e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=23148
2024-11-07 10:16:27 - progress_bar.py[line:274] - INFO: epoch 010:    121 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.469, ntokens=17437.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.07, wps=3283.2, ups=0.19, wpb=17437.3, bsz=1024, num_updates=3640, lr=4.82396e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=30, gb_free=13.4, wall=23201
2024-11-07 10:17:20 - progress_bar.py[line:274] - INFO: epoch 010:    131 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.501, ntokens=17316.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.32, wps=3266.7, ups=0.19, wpb=17316.7, bsz=1024, num_updates=3650, lr=4.8226e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=23254
2024-11-07 10:18:14 - progress_bar.py[line:274] - INFO: epoch 010:    141 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.482, ntokens=17200.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.18, wps=3224.3, ups=0.19, wpb=17200.2, bsz=1024, num_updates=3660, lr=4.82124e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=23307
2024-11-07 10:19:07 - progress_bar.py[line:274] - INFO: epoch 010:    151 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.449, ntokens=17287.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.92, wps=3254.9, ups=0.19, wpb=17287.5, bsz=1024, num_updates=3670, lr=4.81988e-05, gnorm=0.009, clip=0, loss_scale=16384, train_wall=30, gb_free=13, wall=23360
2024-11-07 10:20:00 - progress_bar.py[line:274] - INFO: epoch 010:    161 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.495, ntokens=17327.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.28, wps=3235.5, ups=0.19, wpb=17327.3, bsz=1024, num_updates=3680, lr=4.81852e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=23414
2024-11-07 10:20:53 - progress_bar.py[line:274] - INFO: epoch 010:    171 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.459, ntokens=17392.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.99, wps=3282.1, ups=0.19, wpb=17392.8, bsz=1024, num_updates=3690, lr=4.81716e-05, gnorm=0.006, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=23467
2024-11-07 10:21:47 - progress_bar.py[line:274] - INFO: epoch 010:    181 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.49, ntokens=17476.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.24, wps=3288.2, ups=0.19, wpb=17476.1, bsz=1024, num_updates=3700, lr=4.8158e-05, gnorm=0.005, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=23520
2024-11-07 10:22:40 - progress_bar.py[line:274] - INFO: epoch 010:    191 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.458, ntokens=17206.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.99, wps=3250.4, ups=0.19, wpb=17206.2, bsz=1024, num_updates=3710, lr=4.81444e-05, gnorm=0.006, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=23573
2024-11-07 10:23:33 - progress_bar.py[line:274] - INFO: epoch 010:    201 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.468, ntokens=17228.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.07, wps=3207.8, ups=0.19, wpb=17228.9, bsz=1024, num_updates=3720, lr=4.81308e-05, gnorm=0.006, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=23627
2024-11-07 10:24:27 - progress_bar.py[line:274] - INFO: epoch 010:    211 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.42, ntokens=17183.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.71, wps=3194.1, ups=0.19, wpb=17183.3, bsz=1024, num_updates=3730, lr=4.81172e-05, gnorm=0.006, clip=0, loss_scale=16384, train_wall=30, gb_free=13.3, wall=23681
2024-11-07 10:25:20 - progress_bar.py[line:274] - INFO: epoch 010:    221 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.465, ntokens=17160.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.04, wps=3223.6, ups=0.19, wpb=17160.6, bsz=1024, num_updates=3740, lr=4.81036e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=23734
2024-11-07 10:26:14 - progress_bar.py[line:274] - INFO: epoch 010:    231 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.48, ntokens=17725.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.16, wps=3319.3, ups=0.19, wpb=17725.4, bsz=1024, num_updates=3750, lr=4.809e-05, gnorm=0.009, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=23787
2024-11-07 10:27:07 - progress_bar.py[line:274] - INFO: epoch 010:    241 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.423, ntokens=17142.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.72, wps=3217.9, ups=0.19, wpb=17142.3, bsz=1024, num_updates=3760, lr=4.80764e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=31, gb_free=13.6, wall=23840
2024-11-07 10:28:00 - progress_bar.py[line:274] - INFO: epoch 010:    251 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.477, ntokens=17597.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.14, wps=3302.7, ups=0.19, wpb=17597.8, bsz=1024, num_updates=3770, lr=4.80628e-05, gnorm=0.009, clip=0, loss_scale=16384, train_wall=30, gb_free=13.4, wall=23894
2024-11-07 10:28:53 - progress_bar.py[line:274] - INFO: epoch 010:    261 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.433, ntokens=17172.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.8, wps=3275.5, ups=0.19, wpb=17172.1, bsz=1024, num_updates=3780, lr=4.80492e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=30, gb_free=13.3, wall=23946
2024-11-07 10:29:46 - progress_bar.py[line:274] - INFO: epoch 010:    271 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.445, ntokens=17205.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.89, wps=3238.2, ups=0.19, wpb=17205.5, bsz=1024, num_updates=3790, lr=4.80356e-05, gnorm=0.006, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=23999
2024-11-07 10:30:39 - progress_bar.py[line:274] - INFO: epoch 010:    281 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.456, ntokens=17353.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.98, wps=3255.8, ups=0.19, wpb=17353.4, bsz=1024, num_updates=3800, lr=4.8022e-05, gnorm=0.006, clip=0, loss_scale=16384, train_wall=30, gb_free=13.4, wall=24053
2024-11-07 10:31:32 - progress_bar.py[line:274] - INFO: epoch 010:    291 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.446, ntokens=17234.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.9, wps=3260.3, ups=0.19, wpb=17234.8, bsz=1024, num_updates=3810, lr=4.80084e-05, gnorm=0.009, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=24105
2024-11-07 10:32:26 - progress_bar.py[line:274] - INFO: epoch 010:    301 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.464, ntokens=17438.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.04, wps=3258.3, ups=0.19, wpb=17438.7, bsz=1024, num_updates=3820, lr=4.79948e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=24159
2024-11-07 10:33:19 - progress_bar.py[line:274] - INFO: epoch 010:    311 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.53, ntokens=17349.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.55, wps=3270.3, ups=0.19, wpb=17349.3, bsz=1024, num_updates=3830, lr=4.79812e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=24212
2024-11-07 10:34:12 - progress_bar.py[line:274] - INFO: epoch 010:    321 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.452, ntokens=17301.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.94, wps=3220.9, ups=0.19, wpb=17301.7, bsz=1024, num_updates=3840, lr=4.79676e-05, gnorm=0.009, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=24266
2024-11-07 10:35:06 - progress_bar.py[line:274] - INFO: epoch 010:    331 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.427, ntokens=17147.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.76, wps=3196.5, ups=0.19, wpb=17147.7, bsz=1024, num_updates=3850, lr=4.7954e-05, gnorm=0.01, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=24319
2024-11-07 10:36:00 - progress_bar.py[line:274] - INFO: epoch 010:    341 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.431, ntokens=17435.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.79, wps=3250.3, ups=0.19, wpb=17435.8, bsz=1024, num_updates=3860, lr=4.79404e-05, gnorm=0.011, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=24373
2024-11-07 10:36:53 - progress_bar.py[line:274] - INFO: epoch 010:    351 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.513, ntokens=17591.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.42, wps=3265.7, ups=0.19, wpb=17591.9, bsz=1024, num_updates=3870, lr=4.79268e-05, gnorm=0.01, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=24427
2024-11-07 10:37:47 - progress_bar.py[line:274] - INFO: epoch 010:    361 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.434, ntokens=17443.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.81, wps=3254.9, ups=0.19, wpb=17443.9, bsz=1024, num_updates=3880, lr=4.79132e-05, gnorm=0.013, clip=0, loss_scale=16384, train_wall=30, gb_free=13.4, wall=24481
2024-11-07 10:38:40 - progress_bar.py[line:274] - INFO: epoch 010:    371 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.556, ntokens=17616, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.76, wps=3318.2, ups=0.19, wpb=17616, bsz=1024, num_updates=3890, lr=4.78995e-05, gnorm=0.011, clip=0, loss_scale=16384, train_wall=30, gb_free=13.4, wall=24534
2024-11-07 10:39:31 - progress_bar.py[line:274] - INFO: epoch 010:    381 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.629, ntokens=17640.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.37, wps=3451.5, ups=0.2, wpb=17640.6, bsz=1024, num_updates=3900, lr=4.78859e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=24585
2024-11-07 10:40:20 - progress_bar.py[line:274] - INFO: epoch 010:    391 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.664, ntokens=16836.9, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=12.68, wps=3482.3, ups=0.21, wpb=16836.9, bsz=985.6, num_updates=3910, lr=4.78723e-05, gnorm=0.006, clip=0, loss_scale=16384, train_wall=29, gb_free=13.2, wall=24633
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_10.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_10.ptcp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_10.pt

2024-11-07 10:40:20 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 10 @ 3910 updates
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_10.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_10.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_10.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_10.pt
2024-11-07 10:40:20 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cp: cp: cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_10.pt'cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_10.pt'cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_10.pt': File exists
: File exists: File exists

local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
2024-11-07 10:42:08 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping


file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000

slice_id 1 seek offset 50000
slice_id 7 seek offset 350000
slice_id 3 seek offset 150000
2024-11-07 10:43:59 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 10 @ 3910 updates, score 0) (writing took 219.8397065269819 seconds)
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_10.pt
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000
slice_id 6 seek offset 300000
slice_id 2 seek offset 100000
slice_id 4 seek offset 200000
slice_id 5 seek offset 250000
2024-11-07 10:44:54 - train.py[line:336] - INFO: end of epoch 10 (average epoch stats below)
2024-11-07 10:44:54 - progress_bar.py[line:282] - INFO: epoch 010 | loss 0.002 | loss_v1 0 | loss_v2 0 | nll_loss 3.481 | ntokens 17334.5 | nsentences 1023.02 | sample_size 1023.02 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.17 | wps 2697.3 | ups 0.16 | wpb 17334.5 | bsz 1023 | num_updates 3910 | lr 4.78723e-05 | gnorm 0.008 | clip 0 | loss_scale 16384 | train_wall 1186 | gb_free 13.2 | wall 24907
2024-11-07 10:44:54 - trainer.py[line:639] - INFO: loading train data for epoch 11
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-07 10:47:34 - trainer.py[line:703] - INFO: begin training epoch 11
2024-11-07 10:47:34 - train.py[line:297] - INFO: Start iterating over samples
2024-11-07 10:48:29 - progress_bar.py[line:274] - INFO: epoch 011:     10 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.486, ntokens=17580.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.2, wps=358.9, ups=0.02, wpb=17580.5, bsz=1024, num_updates=3920, lr=4.78587e-05, gnorm=0.006, clip=0, loss_scale=16384, train_wall=30, gb_free=13.4, wall=25123
2024-11-07 10:49:22 - progress_bar.py[line:274] - INFO: epoch 011:     20 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.463, ntokens=17219.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.02, wps=3256.3, ups=0.19, wpb=17219.8, bsz=1024, num_updates=3930, lr=4.78451e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=31, gb_free=13.5, wall=25176
2024-11-07 10:50:16 - progress_bar.py[line:274] - INFO: epoch 011:     30 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.44, ntokens=17390, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.85, wps=3252.5, ups=0.19, wpb=17390, bsz=1024, num_updates=3940, lr=4.78315e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=31, gb_free=13.5, wall=25229
2024-11-07 10:51:09 - progress_bar.py[line:274] - INFO: epoch 011:     40 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.467, ntokens=17383.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.06, wps=3257.3, ups=0.19, wpb=17383.6, bsz=1024, num_updates=3950, lr=4.78179e-05, gnorm=0.009, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=25283
2024-11-07 10:52:02 - progress_bar.py[line:274] - INFO: epoch 011:     50 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.428, ntokens=17462.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.76, wps=3300.6, ups=0.19, wpb=17462.8, bsz=1024, num_updates=3960, lr=4.78043e-05, gnorm=0.011, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=25335
2024-11-07 10:52:55 - progress_bar.py[line:274] - INFO: epoch 011:     60 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.411, ntokens=17184.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.63, wps=3236.4, ups=0.19, wpb=17184.1, bsz=1024, num_updates=3970, lr=4.77907e-05, gnorm=0.009, clip=0, loss_scale=16384, train_wall=30, gb_free=13.3, wall=25389
2024-11-07 10:53:48 - progress_bar.py[line:274] - INFO: epoch 011:     70 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.377, ntokens=17043.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.39, wps=3223.1, ups=0.19, wpb=17043.7, bsz=1024, num_updates=3980, lr=4.77771e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=25441
2024-11-07 10:54:41 - progress_bar.py[line:274] - INFO: epoch 011:     80 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.46, ntokens=17333.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.01, wps=3257.9, ups=0.19, wpb=17333.6, bsz=1024, num_updates=3990, lr=4.77635e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=25495
2024-11-07 10:55:35 - progress_bar.py[line:274] - INFO: epoch 011:     90 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.411, ntokens=17197.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.63, wps=3212.6, ups=0.19, wpb=17197.6, bsz=1024, num_updates=4000, lr=4.77499e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=25548
2024-11-07 10:56:28 - progress_bar.py[line:274] - INFO: epoch 011:    100 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.457, ntokens=17442.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.98, wps=3285, ups=0.19, wpb=17442.6, bsz=1024, num_updates=4010, lr=4.77363e-05, gnorm=0.01, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=25601
2024-11-07 10:57:22 - progress_bar.py[line:274] - INFO: epoch 011:    110 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.469, ntokens=17281.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.07, wps=3218.1, ups=0.19, wpb=17281.7, bsz=1024, num_updates=4020, lr=4.77227e-05, gnorm=0.01, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=25655
2024-11-07 10:58:15 - progress_bar.py[line:274] - INFO: epoch 011:    120 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.443, ntokens=17415, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.87, wps=3260.3, ups=0.19, wpb=17415, bsz=1024, num_updates=4030, lr=4.77091e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=25708
2024-11-07 10:59:08 - progress_bar.py[line:274] - INFO: epoch 011:    130 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.426, ntokens=17285, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.75, wps=3267.4, ups=0.19, wpb=17285, bsz=1024, num_updates=4040, lr=4.76955e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=30, gb_free=13.3, wall=25761
2024-11-07 11:00:01 - progress_bar.py[line:274] - INFO: epoch 011:    140 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.424, ntokens=17111.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.73, wps=3206.2, ups=0.19, wpb=17111.3, bsz=1024, num_updates=4050, lr=4.76819e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=25815
2024-11-07 11:00:54 - progress_bar.py[line:274] - INFO: epoch 011:    150 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.375, ntokens=17052.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.37, wps=3207.3, ups=0.19, wpb=17052.3, bsz=1024, num_updates=4060, lr=4.76683e-05, gnorm=0.01, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=25868
2024-11-07 11:01:47 - progress_bar.py[line:274] - INFO: epoch 011:    160 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.442, ntokens=17276.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.87, wps=3274.6, ups=0.19, wpb=17276.7, bsz=1024, num_updates=4070, lr=4.76547e-05, gnorm=0.01, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=25921
2024-11-07 11:02:40 - progress_bar.py[line:274] - INFO: epoch 011:    170 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.439, ntokens=17365.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.85, wps=3266.5, ups=0.19, wpb=17365.7, bsz=1024, num_updates=4080, lr=4.76411e-05, gnorm=0.009, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=25974
2024-11-07 11:03:33 - progress_bar.py[line:274] - INFO: epoch 011:    180 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.46, ntokens=17682.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11, wps=3345.1, ups=0.19, wpb=17682.2, bsz=1024, num_updates=4090, lr=4.76275e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=31, gb_free=13.4, wall=26027
2024-11-07 11:04:26 - progress_bar.py[line:274] - INFO: epoch 011:    190 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.462, ntokens=17291.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.02, wps=3241.3, ups=0.19, wpb=17291.2, bsz=1024, num_updates=4100, lr=4.76139e-05, gnorm=0.008, clip=0, loss_scale=32768, train_wall=30, gb_free=13.3, wall=26080
2024-11-07 11:05:19 - progress_bar.py[line:274] - INFO: epoch 011:    200 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.381, ntokens=17044, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.42, wps=3218.8, ups=0.19, wpb=17044, bsz=1024, num_updates=4110, lr=4.76003e-05, gnorm=0.009, clip=0, loss_scale=32768, train_wall=30, gb_free=13.4, wall=26133
2024-11-07 11:05:30 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16384.0
2024-11-07 11:06:19 - progress_bar.py[line:274] - INFO: epoch 011:    211 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.365, ntokens=16993.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.3, wps=2866.4, ups=0.17, wpb=16993.2, bsz=1024, num_updates=4120, lr=4.75867e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=33, gb_free=13.4, wall=26192
2024-11-07 11:07:11 - progress_bar.py[line:274] - INFO: epoch 011:    221 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.43, ntokens=17167.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.78, wps=3260.5, ups=0.19, wpb=17167.4, bsz=1024, num_updates=4130, lr=4.75731e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=26245
2024-11-07 11:08:05 - progress_bar.py[line:274] - INFO: epoch 011:    231 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.429, ntokens=17512.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.77, wps=3269.9, ups=0.19, wpb=17512.8, bsz=1024, num_updates=4140, lr=4.75594e-05, gnorm=0.005, clip=0, loss_scale=16384, train_wall=30, gb_free=13.4, wall=26298
2024-11-07 11:08:58 - progress_bar.py[line:274] - INFO: epoch 011:    241 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.365, ntokens=17020.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.3, wps=3213.5, ups=0.19, wpb=17020.7, bsz=1024, num_updates=4150, lr=4.75458e-05, gnorm=0.005, clip=0, loss_scale=16384, train_wall=31, gb_free=13.6, wall=26351
2024-11-07 11:09:51 - progress_bar.py[line:274] - INFO: epoch 011:    251 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.434, ntokens=17674, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.81, wps=3303.9, ups=0.19, wpb=17674, bsz=1024, num_updates=4160, lr=4.75322e-05, gnorm=0.006, clip=0, loss_scale=16384, train_wall=30, gb_free=13.4, wall=26405
2024-11-07 11:10:44 - progress_bar.py[line:274] - INFO: epoch 011:    261 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.417, ntokens=17313.9, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.68, wps=3277, ups=0.19, wpb=17313.9, bsz=1024, num_updates=4170, lr=4.75186e-05, gnorm=0.004, clip=0, loss_scale=16384, train_wall=30, gb_free=13.2, wall=26458
2024-11-07 11:11:37 - progress_bar.py[line:274] - INFO: epoch 011:    271 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.447, ntokens=17471.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.9, wps=3312.8, ups=0.19, wpb=17471.3, bsz=1024, num_updates=4180, lr=4.7505e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=26510
2024-11-07 11:12:30 - progress_bar.py[line:274] - INFO: epoch 011:    281 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.371, ntokens=17121.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.34, wps=3223.3, ups=0.19, wpb=17121.6, bsz=1024, num_updates=4190, lr=4.74914e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=30, gb_free=13.4, wall=26564
2024-11-07 11:13:24 - progress_bar.py[line:274] - INFO: epoch 011:    291 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.37, ntokens=16918.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.34, wps=3164.3, ups=0.19, wpb=16918.2, bsz=1024, num_updates=4200, lr=4.74778e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=26617
2024-11-07 11:14:17 - progress_bar.py[line:274] - INFO: epoch 011:    301 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.422, ntokens=17515.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.71, wps=3290.6, ups=0.19, wpb=17515.4, bsz=1024, num_updates=4210, lr=4.74642e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=26670
2024-11-07 11:15:10 - progress_bar.py[line:274] - INFO: epoch 011:    311 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.484, ntokens=17243.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.19, wps=3249.9, ups=0.19, wpb=17243.8, bsz=1024, num_updates=4220, lr=4.74506e-05, gnorm=0.006, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=26723
2024-11-07 11:16:04 - progress_bar.py[line:274] - INFO: epoch 011:    321 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.388, ntokens=17260.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.47, wps=3211.1, ups=0.19, wpb=17260.5, bsz=1024, num_updates=4230, lr=4.7437e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=26777
2024-11-07 11:17:00 - progress_bar.py[line:274] - INFO: epoch 011:    331 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.409, ntokens=17288, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.62, wps=3079.6, ups=0.18, wpb=17288, bsz=1024, num_updates=4240, lr=4.74234e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=26833
2024-11-07 11:17:54 - progress_bar.py[line:274] - INFO: epoch 011:    341 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.436, ntokens=17596.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.82, wps=3247.9, ups=0.18, wpb=17596.8, bsz=1024, num_updates=4250, lr=4.74098e-05, gnorm=0.012, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=26887
2024-11-07 11:18:49 - progress_bar.py[line:274] - INFO: epoch 011:    351 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.444, ntokens=17365.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.89, wps=3180, ups=0.18, wpb=17365.3, bsz=1024, num_updates=4260, lr=4.73962e-05, gnorm=0.014, clip=0, loss_scale=16384, train_wall=31, gb_free=13.5, wall=26942
2024-11-07 11:19:44 - progress_bar.py[line:274] - INFO: epoch 011:    361 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.422, ntokens=17544.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.72, wps=3185.3, ups=0.18, wpb=17544.2, bsz=1024, num_updates=4270, lr=4.73826e-05, gnorm=0.013, clip=0, loss_scale=16384, train_wall=30, gb_free=13.4, wall=26997
2024-11-07 11:20:41 - progress_bar.py[line:274] - INFO: epoch 011:    371 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.547, ntokens=17807, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=11.69, wps=3098.6, ups=0.17, wpb=17807, bsz=1024, num_updates=4280, lr=4.7369e-05, gnorm=0.013, clip=0, loss_scale=16384, train_wall=31, gb_free=13.4, wall=27055
2024-11-07 11:21:37 - progress_bar.py[line:274] - INFO: epoch 011:    381 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.605, ntokens=17582.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=12.16, wps=3146.2, ups=0.18, wpb=17582.7, bsz=1024, num_updates=4290, lr=4.73554e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=31, gb_free=13.5, wall=27110
2024-11-07 11:22:29 - progress_bar.py[line:274] - INFO: epoch 011:    391 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.55, ntokens=16566.1, nsentences=985.6, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=11.71, wps=3165.7, ups=0.19, wpb=16566.1, bsz=985.6, num_updates=4300, lr=4.73418e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=29, gb_free=13.4, wall=27163
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_11.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_11.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_11.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_11.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_11.pt
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_11.pt
2024-11-07 11:22:29 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 11 @ 4300 updates
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_11.pt
2024-11-07 11:22:29 - trainer.py[line:431] - INFO: Saving checkpoint to ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt
cp: cp: cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_11.pt'cannot create regular file './polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_11.pt': File exists: File exists

local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 begin to initialize row_count and line_idx-to-offset mapping
2024-11-07 11:24:20 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 3 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 7 row count 50000 total row count 400000

slice_id 3 seek offset 150000
slice_id 7 seek offset 350000
2024-11-07 11:26:11 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_best.pt (epoch 11 @ 4300 updates, score 0) (writing took 222.0328797190159 seconds)
cp ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_last.pt ./polyformer_b_aihub_manufact_80_checkpoints/100_5e-5_512/checkpoint_epoch_11.pt
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 2 row count 50000 total row count 400000
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 6 row count 50000 total row count 400000
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 4 row count 50000 total row count 400000
slice_id 2 seek offset 100000
slice_id 6 seek offset 300000
slice_id 4 seek offset 200000
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping

file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 5 row count 50000 total row count 400000file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 1 row count 50000 total row count 400000

slice_id 1 seek offset 50000
slice_id 5 seek offset 250000
2024-11-07 11:27:06 - train.py[line:336] - INFO: end of epoch 11 (average epoch stats below)
2024-11-07 11:27:06 - progress_bar.py[line:282] - INFO: epoch 011 | loss 0.002 | loss_v1 0 | loss_v2 0 | nll_loss 3.438 | ntokens 17307.9 | nsentences 1023.01 | sample_size 1023.01 | sample_size_v1 0 | sample_size_v2 0 | ppl 10.83 | wps 2666 | ups 0.15 | wpb 17307.9 | bsz 1023 | num_updates 4300 | lr 4.73418e-05 | gnorm 0.008 | clip 0 | loss_scale 16384 | train_wall 1187 | gb_free 13.4 | wall 27439
2024-11-07 11:27:06 - trainer.py[line:639] - INFO: loading train data for epoch 12
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../datasets/finetune/aihub_manufact/aihub_manufact_train.tsv slice_id 0 row count 50000 total row count 400000
slice_id 0 seek offset 0
2024-11-07 11:29:46 - trainer.py[line:703] - INFO: begin training epoch 12
2024-11-07 11:29:46 - train.py[line:297] - INFO: Start iterating over samples
2024-11-07 11:30:42 - progress_bar.py[line:274] - INFO: epoch 012:     10 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.428, ntokens=17445.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.76, wps=354.2, ups=0.02, wpb=17445.1, bsz=1024, num_updates=4310, lr=4.73282e-05, gnorm=0.01, clip=0, loss_scale=16384, train_wall=30, gb_free=13.4, wall=27655
2024-11-07 11:31:35 - progress_bar.py[line:274] - INFO: epoch 012:     20 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.415, ntokens=17351.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.67, wps=3253.6, ups=0.19, wpb=17351.6, bsz=1024, num_updates=4320, lr=4.73146e-05, gnorm=0.013, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=27709
2024-11-07 11:32:28 - progress_bar.py[line:274] - INFO: epoch 012:     30 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.437, ntokens=17231.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.83, wps=3249.3, ups=0.19, wpb=17231.3, bsz=1024, num_updates=4330, lr=4.7301e-05, gnorm=0.012, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=27762
2024-11-07 11:33:22 - progress_bar.py[line:274] - INFO: epoch 012:     40 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.397, ntokens=17212, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.53, wps=3214.9, ups=0.19, wpb=17212, bsz=1024, num_updates=4340, lr=4.72874e-05, gnorm=0.011, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=27815
2024-11-07 11:34:15 - progress_bar.py[line:274] - INFO: epoch 012:     50 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.412, ntokens=17505.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.64, wps=3305.4, ups=0.19, wpb=17505.5, bsz=1024, num_updates=4350, lr=4.72738e-05, gnorm=0.006, clip=0, loss_scale=16384, train_wall=30, gb_free=13.4, wall=27868
2024-11-07 11:35:08 - progress_bar.py[line:274] - INFO: epoch 012:     60 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.396, ntokens=17258, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.53, wps=3246.9, ups=0.19, wpb=17258, bsz=1024, num_updates=4360, lr=4.72602e-05, gnorm=0.006, clip=0, loss_scale=16384, train_wall=30, gb_free=13.2, wall=27921
2024-11-07 11:36:01 - progress_bar.py[line:274] - INFO: epoch 012:     70 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.328, ntokens=17035.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.04, wps=3204.2, ups=0.19, wpb=17035.3, bsz=1024, num_updates=4370, lr=4.72466e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=27975
2024-11-07 11:36:54 - progress_bar.py[line:274] - INFO: epoch 012:     80 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.432, ntokens=17385.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.79, wps=3261.1, ups=0.19, wpb=17385.5, bsz=1024, num_updates=4380, lr=4.7233e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=30, gb_free=13.3, wall=28028
2024-11-07 11:37:48 - progress_bar.py[line:274] - INFO: epoch 012:     90 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.397, ntokens=17291.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.54, wps=3249.6, ups=0.19, wpb=17291.2, bsz=1024, num_updates=4390, lr=4.72194e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=28081
2024-11-07 11:38:41 - progress_bar.py[line:274] - INFO: epoch 012:    100 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.388, ntokens=17388.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.47, wps=3266.7, ups=0.19, wpb=17388.2, bsz=1024, num_updates=4400, lr=4.72057e-05, gnorm=0.01, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=28134
2024-11-07 11:39:34 - progress_bar.py[line:274] - INFO: epoch 012:    110 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.407, ntokens=17081.1, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.61, wps=3183.2, ups=0.19, wpb=17081.1, bsz=1024, num_updates=4410, lr=4.71921e-05, gnorm=0.006, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=28188
2024-11-07 11:40:28 - progress_bar.py[line:274] - INFO: epoch 012:    120 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.376, ntokens=17301.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.38, wps=3250.2, ups=0.19, wpb=17301.3, bsz=1024, num_updates=4420, lr=4.71785e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=28241
2024-11-07 11:41:21 - progress_bar.py[line:274] - INFO: epoch 012:    130 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.429, ntokens=17453.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.77, wps=3289.3, ups=0.19, wpb=17453.7, bsz=1024, num_updates=4430, lr=4.71649e-05, gnorm=0.009, clip=0, loss_scale=16384, train_wall=30, gb_free=13.2, wall=28294
2024-11-07 11:42:14 - progress_bar.py[line:274] - INFO: epoch 012:    140 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.397, ntokens=17184.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.53, wps=3229.1, ups=0.19, wpb=17184.4, bsz=1024, num_updates=4440, lr=4.71513e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=31, gb_free=13.5, wall=28347
2024-11-07 11:43:07 - progress_bar.py[line:274] - INFO: epoch 012:    150 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.339, ntokens=17027.3, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.12, wps=3230.6, ups=0.19, wpb=17027.3, bsz=1024, num_updates=4450, lr=4.71377e-05, gnorm=0.01, clip=0, loss_scale=16384, train_wall=31, gb_free=13.6, wall=28400
2024-11-07 11:44:00 - progress_bar.py[line:274] - INFO: epoch 012:    160 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.443, ntokens=17479.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.88, wps=3281.7, ups=0.19, wpb=17479.4, bsz=1024, num_updates=4460, lr=4.71241e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=30, gb_free=13.6, wall=28453
2024-11-07 11:44:53 - progress_bar.py[line:274] - INFO: epoch 012:    170 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.369, ntokens=17185.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.33, wps=3223.8, ups=0.19, wpb=17185.4, bsz=1024, num_updates=4470, lr=4.71105e-05, gnorm=0.009, clip=0, loss_scale=16384, train_wall=30, gb_free=13.5, wall=28507
2024-11-07 11:45:47 - progress_bar.py[line:274] - INFO: epoch 012:    180 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.386, ntokens=17388.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.46, wps=3247.5, ups=0.19, wpb=17388.5, bsz=1024, num_updates=4480, lr=4.70969e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=31, gb_free=13.4, wall=28560
2024-11-07 11:46:43 - progress_bar.py[line:274] - INFO: epoch 012:    190 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.394, ntokens=17207.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.51, wps=3053.4, ups=0.18, wpb=17207.8, bsz=1024, num_updates=4490, lr=4.70833e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=46, gb_free=13.3, wall=28617
2024-11-07 11:47:39 - progress_bar.py[line:274] - INFO: epoch 012:    200 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.335, ntokens=16968.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.09, wps=3015.2, ups=0.18, wpb=16968.5, bsz=1024, num_updates=4500, lr=4.70697e-05, gnorm=0.009, clip=0, loss_scale=16384, train_wall=56, gb_free=13.4, wall=28673
2024-11-07 11:48:36 - progress_bar.py[line:274] - INFO: epoch 012:    210 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.333, ntokens=16941.4, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.08, wps=3021.6, ups=0.18, wpb=16941.4, bsz=1024, num_updates=4510, lr=4.70561e-05, gnorm=0.01, clip=0, loss_scale=16384, train_wall=56, gb_free=13.6, wall=28729
2024-11-07 11:49:32 - progress_bar.py[line:274] - INFO: epoch 012:    220 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.381, ntokens=17093.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.42, wps=3047.9, ups=0.18, wpb=17093.8, bsz=1024, num_updates=4520, lr=4.70425e-05, gnorm=0.009, clip=0, loss_scale=16384, train_wall=56, gb_free=13.1, wall=28785
2024-11-07 11:50:28 - progress_bar.py[line:274] - INFO: epoch 012:    230 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.409, ntokens=17645.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.62, wps=3149.2, ups=0.18, wpb=17645.8, bsz=1024, num_updates=4530, lr=4.70289e-05, gnorm=0.009, clip=0, loss_scale=16384, train_wall=56, gb_free=13.5, wall=28841
2024-11-07 11:51:23 - progress_bar.py[line:274] - INFO: epoch 012:    240 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.354, ntokens=17130.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.22, wps=3068.9, ups=0.18, wpb=17130.5, bsz=1024, num_updates=4540, lr=4.70153e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=56, gb_free=13.3, wall=28897
2024-11-07 11:52:17 - progress_bar.py[line:274] - INFO: epoch 012:    250 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.391, ntokens=17678.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.49, wps=3276.8, ups=0.19, wpb=17678.8, bsz=1024, num_updates=4550, lr=4.70017e-05, gnorm=0.007, clip=0, loss_scale=16384, train_wall=54, gb_free=13.6, wall=28951
2024-11-07 11:53:12 - progress_bar.py[line:274] - INFO: epoch 012:    260 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.361, ntokens=17235.2, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.27, wps=3173.1, ups=0.18, wpb=17235.2, bsz=1024, num_updates=4560, lr=4.69881e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=54, gb_free=13.4, wall=29005
2024-11-07 11:54:05 - progress_bar.py[line:274] - INFO: epoch 012:    270 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.409, ntokens=17383.6, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.62, wps=3283.8, ups=0.19, wpb=17383.6, bsz=1024, num_updates=4570, lr=4.69745e-05, gnorm=0.004, clip=0, loss_scale=16384, train_wall=53, gb_free=13.4, wall=29058
2024-11-07 11:55:01 - progress_bar.py[line:274] - INFO: epoch 012:    280 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.316, ntokens=17053.5, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=9.96, wps=3034.9, ups=0.18, wpb=17053.5, bsz=1024, num_updates=4580, lr=4.69609e-05, gnorm=0.006, clip=0, loss_scale=16384, train_wall=56, gb_free=13.4, wall=29114
2024-11-07 11:55:56 - progress_bar.py[line:274] - INFO: epoch 012:    290 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.355, ntokens=17091.8, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.23, wps=3123.3, ups=0.18, wpb=17091.8, bsz=1024, num_updates=4590, lr=4.69473e-05, gnorm=0.005, clip=0, loss_scale=16384, train_wall=55, gb_free=12.6, wall=29169
2024-11-07 11:56:49 - progress_bar.py[line:274] - INFO: epoch 012:    300 / 391 loss=0.002, loss_v1=0, loss_v2=0, nll_loss=3.352, ntokens=17329.7, nsentences=1024, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=10.21, wps=3233.3, ups=0.19, wpb=17329.7, bsz=1024, num_updates=4600, lr=4.69337e-05, gnorm=0.008, clip=0, loss_scale=16384, train_wall=54, gb_free=13.5, wall=29223
